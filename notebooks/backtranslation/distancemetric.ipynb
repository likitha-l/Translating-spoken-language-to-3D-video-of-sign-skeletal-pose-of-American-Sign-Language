{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"distancemetric.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPVG8LVOfI2bbmJ+WaD7XBf"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sr4i_r88lwOd"},"source":["### Metric Evaluation\n","Looking through different metric evaluation for translation. Looks like BLEU is not great because its lack of understanding synonyms. \n","\n","Instead we should be looking at it in the embedding space so that translation of synonyms should be rewarded not penalized.\n","\n","\n","Looking at two metrics to calculate Vector Similarity between two word embeddings (https://medium.com/@Intellica.AI/comparison-of-different-word-embeddings-on-text-similarity-a-use-case-in-nlp-e83e08469c1c)\n"," - cosine similarity\n"," - word mover's distance\n","\n","Also might look at SLA - https://moj-analytical-services.github.io/NLP-guidance/LSA.html\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KJdpoDmtmial","executionInfo":{"status":"ok","timestamp":1606533015777,"user_tz":480,"elapsed":1679,"user":{"displayName":"Juyoung Lee","photoUrl":"","userId":"16438012406002097348"}},"outputId":"11c5db2c-8ffa-4f8e-ae30-2f1536c3d8a7"},"source":["import os \n","from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)\n","\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","import pickle\n","\n","MAIN_DIR = '/content/drive/My Drive/Colab Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/backtranslation'\n","DATA_DIR = os.path.join(MAIN_DIR, 'data')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hZS52Wf41Okg"},"source":["# Load embedding dictionary\n","import gensim.downloader as api\n","model = api.load('glove-wiki-gigaword-200')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VvziQo6Pnpck"},"source":["## Cosine Similarity\n","ranges from -1 to 1 where -1 means opposite direction and 1 means same direction"]},{"cell_type":"code","metadata":{"id":"N0CrUxiTnS6H"},"source":["# can use this method if we want to use our custom embedding\n","from sklearn.metrics.pairwise import cosine_similarity\n","def get_cosine_similarity(feature_vec_1, feature_vec_2):    \n","    return cosine_similarity(feature_vec_1.reshape(1, -1), feature_vec_2.reshape(1, -1))[0][0]\n","  \n","# or use he gensim model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bKBcBK3op4Gl"},"source":["Quick test and while some makes sense. the food and fear I thought should've been further"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bGndoYKfn0d9","executionInfo":{"status":"ok","timestamp":1606530096108,"user_tz":480,"elapsed":687,"user":{"displayName":"Juyoung Lee","photoUrl":"","userId":"16438012406002097348"}},"outputId":"d271c7f7-7c09-48a7-bfd1-21bae811ec97"},"source":["# quick test\n","sim_one = get_cosine_similarity(embedding_dict[\"food\"], embedding_dict[\"lunch\"])\n","sim_two = get_cosine_similarity(embedding_dict[\"food\"], embedding_dict[\"vegetable\"])\n","\n","print(f\"cosine similarity is {sim_one} for food and lunch\")\n","print(f\"cosine similarity is {sim_two} for food and vegetable\")\n","\n","\n","sim_three = get_cosine_similarity(embedding_dict[\"food\"], embedding_dict[\"vlog\"])\n","print(f\"cosine similarity is {sim_three} for food and vlog\")\n","\n","# Would've expected this to be further\n","sim = get_cosine_similarity(embedding_dict[\"food\"], embedding_dict[\"fear\"])\n","print(f\"cosine similarity is {sim} for food and fear\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cosine similarity is 0.45461034774780273 for food and lunch\n","cosine similarity is 0.489216685295105 for food and vegetable\n","cosine similarity is -0.13879083096981049 for food and vlog\n","cosine similarity is 0.341911256313324 for food and fear\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ED2b9HO4qAF0"},"source":["### Word Mover's Distance\n","This uses the word embeddings of the words in two texts to measure the minimum distance that the words in one text need to “travel” in semantic space to reach the words in the other text."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M6REXeNvrxfF","executionInfo":{"status":"ok","timestamp":1606532663537,"user_tz":480,"elapsed":718,"user":{"displayName":"Juyoung Lee","photoUrl":"","userId":"16438012406002097348"}},"outputId":"e673a439-3b74-4d5d-e930-59720afa9271"},"source":["em_distance = model.wmdistance(['lunch'],['food'])\n","print(f\"wmd is {em_distance} between food and lunch\" )\n","\n","em_distance = model.wmdistance(['vegetable'],['food'])\n","print(f\"wmd is {em_distance} between food and vegetable\" )\n","\n","em_distance = model.wmdistance(['food'],['vlog'])\n","print(f\"wmd is {em_distance} between food and vlog\" )\n","\n","em_distance = model.wmdistance(['food'],['fear'])\n","print(f\"wmd is {em_distance} between food and fear\" )\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["wmd is 7.103362083435058 between food and lunch\n","wmd is 6.914583206176758 between food and vegetable\n","wmd is 8.87607192993164 between food and vlog\n","wmd is 7.493886470794679 between food and fear\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QkWKb9uCz82b"},"source":["The distance calculation is simliar bewteen the two metrics. I think the cosine similarity is better for our case"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EGYP3WxT0cKw","executionInfo":{"status":"ok","timestamp":1606533018543,"user_tz":480,"elapsed":1099,"user":{"displayName":"Juyoung Lee","photoUrl":"","userId":"16438012406002097348"}},"outputId":"543f4990-a8f5-4c81-9c2e-2560748eb4be"},"source":["print(f\"wmd distance {model.wmdistance('happy', 'excited')}\")\n","print(f\"cosine similarity {model.similarity('happy', 'excited')}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["wmd distance 7.417353117194251\n","cosine similarity 0.6576606035232544\n"],"name":"stdout"}]}]}