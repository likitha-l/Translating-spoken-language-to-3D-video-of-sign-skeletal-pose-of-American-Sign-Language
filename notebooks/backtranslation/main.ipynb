{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":["amNuMKGEdBzN","T0H7SgIYc-A3","FWL_NPQIfX9k","1xCa96JZhhlC","CpkimGTWtgId","1f4CVdCjH0FK"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"N5JJ0_IyZ48p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606592799206,"user_tz":480,"elapsed":1813,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"}},"outputId":"faf9143c-a7c0-475a-b1b2-9950f1dc85ee"},"source":["import os \n","from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nqUKFqOtaaBs","executionInfo":{"status":"ok","timestamp":1606592810991,"user_tz":480,"elapsed":4979,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"}},"outputId":"03062bc4-ea76-46b0-97f1-0a46bc51badf"},"source":["MAIN_DIR = '/content/drive/My Drive/Colab Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/backtranslation'\n","DATA_DIR = os.path.join(MAIN_DIR, 'data')\n","MODEL_DIR = os.path.join(MAIN_DIR, 'model')\n","CONF_DIR = os.path.join(MAIN_DIR, 'conf')\n","\n","import os\n","import yaml\n","import random\n","import sys\n","from typing import Union, List, Dict\n","from logging import Logger\n","import logging\n","from sys import platform\n","import queue\n","import time\n","\n","from itertools import groupby\n","import numpy as np\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import tensorflow as tf\n","tf.config.set_visible_devices([], \"GPU\")\n","from torchtext import data\n","from torchtext.data import Dataset, Iterator\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","from torch import Tensor\n","\n","# some non path dependent python modules to import\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/backtranslation/dataset.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/backtranslation/vocabulary.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/backtranslation/initialization.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/backtranslation/embeddings.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/backtranslation/transformer_layers.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/backtranslation/attention.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/backtranslation/batch.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/backtranslation/loss.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/backtranslation/builders.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/backtranslation/mscoco_rouge.py .\n","\n","!pip install sacrebleu==\"1.4.2\"\n","\n","from dataset import SignTranslationDataset\n","from vocabulary import (\n","    build_vocab,\n","    Vocabulary,\n","    TextVocabulary,\n","    GlossVocabulary,\n","    UNK_TOKEN,\n","    EOS_TOKEN,\n","    BOS_TOKEN,\n","    PAD_TOKEN,\n","    SIL_TOKEN\n",")\n","from initialization import initialize_model\n","from embeddings import Embeddings, SpatialEmbeddings\n","from transformer_layers import TransformerEncoderLayer, PositionalEncoding, TransformerDecoderLayer\n","from attention import BahdanauAttention, LuongAttention\n","from batch import Batch\n","from loss import XentLoss\n","from builders import build_optimizer, build_scheduler, build_gradient_clipper\n","\n","import mscoco_rouge\n","import sacrebleu"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: sacrebleu==1.4.2 in /usr/local/lib/python3.6/dist-packages (1.4.2)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu==1.4.2) (2.0.0)\n","Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu==1.4.2) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"amNuMKGEdBzN"},"source":["### Random helper methods"]},{"cell_type":"code","metadata":{"id":"RXx7sdoFbCbP"},"source":["def load_config(path='sign.yaml') -> dict:\n","    \"\"\"\n","    Loads and parses a YAML configuration file.\n","\n","    :param path: path to YAML configuration file\n","    :return: configuration dictionary\n","    \"\"\"\n","    with open(path, \"r\", encoding=\"utf-8\") as ymlfile:\n","        cfg = yaml.safe_load(ymlfile)\n","    return cfg\n","def set_seed(seed: int):\n","    \"\"\"\n","    Set the random seed for modules torch, numpy and random.\n","\n","    :param seed: random seed\n","    \"\"\"\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","def subsequent_mask(size: int) -> Tensor:\n","    \"\"\"\n","    Mask out subsequent positions (to prevent attending to future positions)\n","    Transformer helper function.\n","\n","    :param size: size of mask (2nd and 3rd dim)\n","    :return: Tensor with 0s and 1s of shape (1, size, size)\n","    \"\"\"\n","    mask = np.triu(np.ones((1, size, size)), k=1).astype(\"uint8\")\n","    return torch.from_numpy(mask) == 0\n","def freeze_params(module: nn.Module):\n","    \"\"\"\n","    Freeze the parameters of this module,\n","    i.e. do not update them during training\n","\n","    :param module: freeze parameters of this module\n","    \"\"\"\n","    for _, p in module.named_parameters():\n","        p.requires_grad = False\n","# from onmt\n","def tile(x: Tensor, count: int, dim=0) -> Tensor:\n","    \"\"\"\n","    Tiles x on dimension dim count times. From OpenNMT. Used for beam search.\n","\n","    :param x: tensor to tile\n","    :param count: number of tiles\n","    :param dim: dimension along which the tensor is tiled\n","    :return: tiled tensor\n","    \"\"\"\n","    if isinstance(x, tuple):\n","        h, c = x\n","        return tile(h, count, dim=dim), tile(c, count, dim=dim)\n","\n","    perm = list(range(len(x.size())))\n","    if dim != 0:\n","        perm[0], perm[dim] = perm[dim], perm[0]\n","        x = x.permute(perm).contiguous()\n","    out_size = list(x.size())\n","    out_size[0] *= count\n","    batch = x.size(0)\n","    x = (\n","        x.view(batch, -1)\n","        .transpose(0, 1)\n","        .repeat(count, 1)\n","        .transpose(0, 1)\n","        .contiguous()\n","        .view(*out_size)\n","    )\n","    if dim != 0:\n","        x = x.permute(perm).contiguous()\n","    return x\n","def log_cfg(cfg: dict, logger: Logger, prefix: str = \"cfg\"):\n","    \"\"\"\n","    Write configuration to log.\n","\n","    :param cfg: configuration to log\n","    :param logger: logger that defines where log is written to\n","    :param prefix: prefix for logging\n","    \"\"\"\n","    for k, v in cfg.items():\n","        if isinstance(v, dict):\n","            p = \".\".join([prefix, k])\n","            log_cfg(v, logger, prefix=p)\n","        else:\n","            p = \".\".join([prefix, k])\n","            logger.info(\"{:34s} : {}\".format(p, v))\n","def make_logger(model_dir: str, log_file: str = \"train.log\") -> Logger:\n","    \"\"\"\n","    Create a logger for logging the training process.\n","\n","    :param model_dir: path to logging directory\n","    :param log_file: path to logging file\n","    :return: logger object\n","    \"\"\"\n","    #if not logger.handlers:\n","    logger = logging.getLogger(__name__)\n","    while len(logger.handlers) > 0:\n","        h = logger.handlers[0]\n","        print('removing {}'.format(h))\n","        logger.removeHandler(h)\n","    logger.propagate = False\n","    logger.setLevel(logging.INFO)\n","    # Create handlers\n","    c_handler = logging.StreamHandler()\n","    f_handler = logging.FileHandler(os.path.join(MODEL_DIR, log_file), mode='w')\n","\n","    # Create formatters and add it to handlers\n","    c_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n","    f_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n","    c_handler.setFormatter(c_format)\n","    f_handler.setFormatter(f_format)\n","\n","    # Add handlers to the logger\n","    logger.addHandler(c_handler)\n","    logger.addHandler(f_handler)\n","\n","    return logger\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T0H7SgIYc-A3"},"source":["### Dataset creation"]},{"cell_type":"code","metadata":{"id":"Mnpj78TedAF0"},"source":["# coding: utf-8\n","\"\"\"\n","Data module\n","\"\"\"\n","from torchtext import data\n","from torchtext.data import Field\n","from typing import Tuple\n","import pickle\n","\n","class SignTranslationDataset(data.Dataset):\n","    \"\"\"Defines a dataset for machine translation.\"\"\"\n","\n","    @staticmethod\n","    def sort_key(ex):\n","        return data.interleave_keys(len(ex.sgn), len(ex.txt))\n","\n","    def __init__(\n","        self,\n","        path: str,\n","        fields: Tuple[Field, Field],\n","        **kwargs\n","    ):\n","        \"\"\"Create a SignTranslationDataset given paths and fields.\n","\n","        Arguments:\n","            path: Common prefix of paths to the data files for both languages.\n","            exts: A tuple containing the extension to path for each language.\n","            fields: A tuple containing the fields that will be used for data\n","                in each language.\n","            Remaining keyword arguments: Passed to the constructor of\n","                data.Dataset.\n","        \"\"\"\n","        if not isinstance(fields[0], (tuple, list)):\n","            fields = [\n","                (\"sgn\", fields[0]),\n","                (\"txt\", fields[1]),\n","            ]\n","\n","\n","        # read in the data\n","        with open(path, 'rb') as f:\n","            dataset = pickle.load(f)\n","        examples = []\n","        for i, skeleton in enumerate(dataset[\"skeleton\"]):\n","            examples.append(\n","                data.Example.fromlist(\n","                    [\n","                        # This is for numerical stability\n","                        skeleton[0:skeleton.shape[0]:2] + 1e-8,\n","                        dataset[\"gloss\"][i].strip(),\n","                    ],\n","                    fields,\n","                )\n","            )\n","            \n","        super().__init__(examples, fields, **kwargs)\n","def load_data(data_cfg: dict) -> (Dataset, Dataset, Dataset, Vocabulary, Vocabulary):\n","    \"\"\"\n","    Load train, dev and optionally test data as specified in configuration.\n","    Vocabularies are created from the training set with a limit of `voc_limit`\n","    tokens and a minimum token frequency of `voc_min_freq`\n","    (specified in the configuration dictionary).\n","\n","    The training data is filtered to include sentences up to `max_sent_length`\n","    on source and target side.\n","\n","    If you set ``random_train_subset``, a random selection of this size is used\n","    from the training set instead of the full training set.\n","\n","    If you set ``random_dev_subset``, a random selection of this size is used\n","    from the dev development instead of the full development set.\n","\n","    :param data_cfg: configuration dictionary for data\n","        (\"data\" part of configuration file)\n","    :return:\n","        - train_data: training dataset\n","        - dev_data: development dataset\n","        - txt_vocab: spoken text vocabulary extracted from training data\n","    \"\"\"\n","\n","    train_path = os.path.join(DATA_DIR, 'train.pkl')\n","    dev_path = os.path.join(DATA_DIR, 'val.pkl')\n","    \n","    # this is the length of the skeleton output (240)\n","    pad_feature_size = data_cfg[\"feature_size\"]\n","    \n","    level = data_cfg[\"level\"] # word\n","    txt_lowercase = data_cfg[\"txt_lowercase\"]\n","    max_sent_length = data_cfg[\"max_sent_length\"] # this should be the max length of frame (176)\n","\n","    def tokenize_text(text):\n","        if level == \"char\":\n","            return list(text)\n","        else:\n","            return text.split()\n","\n","    def tokenize_features(features):\n","        ft_list = torch.split(features, 1, dim=0)\n","        return [ft.squeeze() for ft in ft_list]\n","\n","    # NOTE (Cihan): The something was necessary to match the function signature.\n","    def stack_features(features, something):\n","        return torch.stack([torch.stack(ft, dim=0) for ft in features], dim=0)\n","\n","    sgn_field = data.Field(\n","        use_vocab=False,\n","        init_token=None,\n","        dtype=torch.float32,\n","        # preprocessing=tokenize_features,\n","        tokenize=lambda features: features,  # TODO (Cihan): is this necessary?\n","        batch_first=True,\n","        include_lengths=True,\n","        # postprocessing=stack_features,\n","        pad_token=torch.zeros((pad_feature_size,)),\n","    )\n","\n","    txt_field = data.Field(\n","        init_token=BOS_TOKEN,\n","        eos_token=EOS_TOKEN,\n","        pad_token=PAD_TOKEN,\n","        tokenize=tokenize_text,\n","        unk_token=UNK_TOKEN,\n","        batch_first=True,\n","        lower=txt_lowercase,\n","        include_lengths=True,\n","    )\n","\n","    train_data = SignTranslationDataset(\n","        path=train_path,\n","        fields=(sgn_field, txt_field),\n","        filter_pred=lambda x: len(vars(x)[\"sgn\"]) <= max_sent_length\n","        and len(vars(x)[\"txt\"]) <= 1,\n","    )\n","\n","    txt_max_size = data_cfg.get(\"txt_voc_limit\", sys.maxsize)\n","    txt_min_freq = data_cfg.get(\"txt_voc_min_freq\", 1)\n","    txt_vocab_file = data_cfg.get(\"txt_vocab\", None)\n","    \n","    txt_vocab = build_vocab(\n","        field=\"txt\",\n","        min_freq=txt_min_freq,\n","        max_size=txt_max_size,\n","        dataset=train_data,\n","        vocab_file=txt_vocab_file,\n","    )\n","    \n","    random_train_subset = data_cfg.get(\"random_train_subset\", -1)\n","    if random_train_subset > -1:\n","        # select this many training examples randomly and discard the rest\n","        keep_ratio = random_train_subset / len(train_data)\n","        keep, _ = train_data.split(\n","            split_ratio=[keep_ratio, 1 - keep_ratio], random_state=random.getstate()\n","        )\n","        train_data = keep\n","\n","  \n","    dev_data = SignTranslationDataset(\n","        path=dev_path,\n","        fields=(sgn_field, txt_field),\n","    )\n","    random_dev_subset = data_cfg.get(\"random_dev_subset\", -1)\n","    if random_dev_subset > -1:\n","        # select this many development examples randomly and discard the rest\n","        keep_ratio = random_dev_subset / len(dev_data)\n","        keep, _ = dev_data.split(\n","            split_ratio=[keep_ratio, 1 - keep_ratio], random_state=random.getstate()\n","        )\n","        dev_data = keep\n","\n","    txt_field.vocab = txt_vocab\n","    return train_data, dev_data, txt_vocab\n","\n","\n","def make_data_iter(\n","    dataset: Dataset,\n","    batch_size: int,\n","    batch_type: str = \"sentence\",\n","    train: bool = False,\n","    shuffle: bool = False,\n",") -> Iterator:\n","    \"\"\"\n","    Returns a torchtext iterator for a torchtext dataset.\n","\n","    :param dataset: torchtext dataset containing sgn and optionally txt\n","    :param batch_size: size of the batches the iterator prepares\n","    :param batch_type: measure batch size by sentence count or by token count\n","    :param train: whether it's training time, when turned off,\n","        bucketing, sorting within batches and shuffling is disabled\n","    :param shuffle: whether to shuffle the data before each epoch\n","        (no effect if set to True for testing)\n","    :return: torchtext iterator\n","    \"\"\"\n","\n","    #batch_size_fn = token_batch_size_fn if batch_type == \"token\" else None\n","    batch_size_fn = None\n","\n","    if train:\n","        # optionally shuffle and sort during training\n","        data_iter = data.BucketIterator(\n","            repeat=False,\n","            sort=False,\n","            dataset=dataset,\n","            batch_size=batch_size,\n","            batch_size_fn=batch_size_fn,\n","            train=True,\n","            sort_within_batch=True,\n","            sort_key=lambda x: len(x.sgn),\n","            shuffle=shuffle,\n","        )\n","    else:\n","        # don't sort/shuffle for validation/inference\n","        data_iter = data.BucketIterator(\n","            repeat=False,\n","            dataset=dataset,\n","            batch_size=batch_size,\n","            batch_size_fn=batch_size_fn,\n","            train=False,\n","            sort=False,\n","        )\n","    return data_iter"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FWL_NPQIfX9k"},"source":["### Building the Model\n","#### First is building blocks for making the Transformer"]},{"cell_type":"code","metadata":{"id":"CnArhKi6g7b5"},"source":["# pylint: disable=abstract-method\n","class Encoder(nn.Module):\n","    \"\"\"\n","    Base encoder class\n","    \"\"\"\n","\n","    @property\n","    def output_size(self):\n","        \"\"\"\n","        Return the output size\n","\n","        :return:\n","        \"\"\"\n","        return self._output_size\n","        \n","class TransformerEncoder(Encoder):\n","    \"\"\"\n","    Transformer Encoder\n","    \"\"\"\n","\n","    # pylint: disable=unused-argument\n","    def __init__(\n","        self,\n","        hidden_size: int = 512,\n","        ff_size: int = 2048,\n","        num_layers: int = 8,\n","        num_heads: int = 4,\n","        dropout: float = 0.1,\n","        emb_dropout: float = 0.1,\n","        freeze: bool = False,\n","        **kwargs\n","    ):\n","        \"\"\"\n","        Initializes the Transformer.\n","        :param hidden_size: hidden size and size of embeddings\n","        :param ff_size: position-wise feed-forward layer size.\n","          (Typically this is 2*hidden_size.)\n","        :param num_layers: number of layers\n","        :param num_heads: number of heads for multi-headed attention\n","        :param dropout: dropout probability for Transformer layers\n","        :param emb_dropout: Is applied to the input (word embeddings).\n","        :param freeze: freeze the parameters of the encoder during training\n","        :param kwargs:\n","        \"\"\"\n","        super(TransformerEncoder, self).__init__()\n","\n","        # build all (num_layers) layers\n","        self.layers = nn.ModuleList(\n","            [\n","                TransformerEncoderLayer(\n","                    size=hidden_size,\n","                    ff_size=ff_size,\n","                    num_heads=num_heads,\n","                    dropout=dropout,\n","                )\n","                for _ in range(num_layers)\n","            ]\n","        )\n","\n","        self.layer_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n","        self.pe = PositionalEncoding(hidden_size)\n","        self.emb_dropout = nn.Dropout(p=emb_dropout)\n","\n","        self._output_size = hidden_size\n","\n","        if freeze:\n","            freeze_params(self)\n","\n","    # pylint: disable=arguments-differ\n","    def forward(\n","        self, embed_src: Tensor, src_length: Tensor, mask: Tensor\n","    ) -> (Tensor, Tensor):\n","        \"\"\"\n","        Pass the input (and mask) through each layer in turn.\n","        Applies a Transformer encoder to sequence of embeddings x.\n","        The input mini-batch x needs to be sorted by src length.\n","        x and mask should have the same dimensions [batch, time, dim].\n","\n","        :param embed_src: embedded src inputs,\n","            shape (batch_size, src_len, embed_size)\n","        :param src_length: length of src inputs\n","            (counting tokens before padding), shape (batch_size)\n","        :param mask: indicates padding areas (zeros where padding), shape\n","            (batch_size, src_len, embed_size)\n","        :return:\n","            - output: hidden states with\n","                shape (batch_size, max_length, directions*hidden),\n","            - hidden_concat: last hidden state with\n","                shape (batch_size, directions*hidden)\n","        \"\"\"\n","        x = self.pe(embed_src)  # add position encoding to word embeddings\n","        x = self.emb_dropout(x)\n","\n","        for layer in self.layers:\n","            x = layer(x, mask)\n","        return self.layer_norm(x), None\n","\n","    def __repr__(self):\n","        return \"%s(num_layers=%r, num_heads=%r)\" % (\n","            self.__class__.__name__,\n","            len(self.layers),\n","            self.layers[0].src_src_att.num_heads,\n","        )\n","\n","# pylint: disable=abstract-method\n","class Decoder(nn.Module):\n","    \"\"\"\n","    Base decoder class\n","    \"\"\"\n","\n","    @property\n","    def output_size(self):\n","        \"\"\"\n","        Return the output size (size of the target vocabulary)\n","\n","        :return:\n","        \"\"\"\n","        return self._output_size\n","\n","class TransformerDecoder(Decoder):\n","    \"\"\"\n","    A transformer decoder with N masked layers.\n","    Decoder layers are masked so that an attention head cannot see the future.\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        num_layers: int = 4,\n","        num_heads: int = 8,\n","        hidden_size: int = 512,\n","        ff_size: int = 2048,\n","        dropout: float = 0.1,\n","        emb_dropout: float = 0.1,\n","        vocab_size: int = 1,\n","        freeze: bool = False,\n","        **kwargs\n","    ):\n","        \"\"\"\n","        Initialize a Transformer decoder.\n","\n","        :param num_layers: number of Transformer layers\n","        :param num_heads: number of heads for each layer\n","        :param hidden_size: hidden size\n","        :param ff_size: position-wise feed-forward size\n","        :param dropout: dropout probability (1-keep)\n","        :param emb_dropout: dropout probability for embeddings\n","        :param vocab_size: size of the output vocabulary\n","        :param freeze: set to True keep all decoder parameters fixed\n","        :param kwargs:\n","        \"\"\"\n","        super(TransformerDecoder, self).__init__()\n","\n","        self._hidden_size = hidden_size\n","        self._output_size = vocab_size\n","\n","        # create num_layers decoder layers and put them in a list\n","        self.layers = nn.ModuleList(\n","            [\n","                TransformerDecoderLayer(\n","                    size=hidden_size,\n","                    ff_size=ff_size,\n","                    num_heads=num_heads,\n","                    dropout=dropout,\n","                )\n","                for _ in range(num_layers)\n","            ]\n","        )\n","\n","        self.pe = PositionalEncoding(hidden_size)\n","        self.layer_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n","\n","        self.emb_dropout = nn.Dropout(p=emb_dropout)\n","        self.output_layer = nn.Linear(hidden_size, vocab_size, bias=False)\n","\n","        if freeze:\n","            freeze_params(self)\n","\n","    def forward(\n","        self,\n","        trg_embed: Tensor = None,\n","        encoder_output: Tensor = None,\n","        encoder_hidden: Tensor = None,\n","        src_mask: Tensor = None,\n","        unroll_steps: int = None,\n","        hidden: Tensor = None,\n","        trg_mask: Tensor = None,\n","        **kwargs\n","    ):\n","        \"\"\"\n","        Transformer decoder forward pass.\n","\n","        :param trg_embed: embedded targets\n","        :param encoder_output: source representations\n","        :param encoder_hidden: unused\n","        :param src_mask:\n","        :param unroll_steps: unused\n","        :param hidden: unused\n","        :param trg_mask: to mask out target paddings\n","                         Note that a subsequent mask is applied here.\n","        :param kwargs:\n","        :return:\n","        \"\"\"\n","        assert trg_mask is not None, \"trg_mask required for Transformer\"\n","\n","        x = self.pe(trg_embed)  # add position encoding to word embedding\n","        x = self.emb_dropout(x)\n","\n","        trg_mask = trg_mask & subsequent_mask(trg_embed.size(1)).type_as(trg_mask)\n","\n","        for layer in self.layers:\n","            x = layer(x=x, memory=encoder_output, src_mask=src_mask, trg_mask=trg_mask)\n","\n","        x = self.layer_norm(x)\n","        output = self.output_layer(x)\n","\n","        return output, x, None, None\n","\n","    def __repr__(self):\n","        return \"%s(num_layers=%r, num_heads=%r)\" % (\n","            self.__class__.__name__,\n","            len(self.layers),\n","            self.layers[0].trg_trg_att.num_heads,\n","        )\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1xCa96JZhhlC"},"source":["### Main Sign Translation Model and the training methods"]},{"cell_type":"code","metadata":{"id":"HW8-kKELfXsm"},"source":["def greedy(\n","    src_mask: Tensor,\n","    embed: Embeddings,\n","    bos_index: int,\n","    eos_index: int,\n","    max_output_length: int,\n","    decoder: Decoder,\n","    encoder_output: Tensor,\n","    encoder_hidden: Tensor,\n",") -> (np.array, np.array):\n","    \"\"\"\n","    Greedy decoding. Select the token word highest probability at each time\n","    step. This function is a wrapper that calls recurrent_greedy for\n","    recurrent decoders and transformer_greedy for transformer decoders.\n","\n","    :param src_mask: mask for source inputs, 0 for positions after </s>\n","    :param embed: target embedding\n","    :param bos_index: index of <s> in the vocabulary\n","    :param eos_index: index of </s> in the vocabulary\n","    :param max_output_length: maximum length for the hypotheses\n","    :param decoder: decoder to use for greedy decoding\n","    :param encoder_output: encoder hidden states for attention\n","    :param encoder_hidden: encoder last state for decoder initialization\n","    :return:\n","    \"\"\"\n","\n","    if isinstance(decoder, TransformerDecoder):\n","        # Transformer greedy decoding\n","        greedy_fun = transformer_greedy\n","    else:\n","        # Recurrent greedy decoding\n","        greedy_fun = recurrent_greedy\n","\n","    return greedy_fun(\n","        src_mask=src_mask,\n","        embed=embed,\n","        bos_index=bos_index,\n","        eos_index=eos_index,\n","        max_output_length=max_output_length,\n","        decoder=decoder,\n","        encoder_output=encoder_output,\n","        encoder_hidden=encoder_hidden,\n","    )\n","\n","def transformer_greedy(\n","    src_mask: Tensor,\n","    embed: Embeddings,\n","    bos_index: int,\n","    eos_index: int,\n","    max_output_length: int,\n","    decoder: Decoder,\n","    encoder_output: Tensor,\n","    encoder_hidden: Tensor,\n",") -> (np.array, None):\n","    \"\"\"\n","    Special greedy function for transformer, since it works differently.\n","    The transformer remembers all previous states and attends to them.\n","\n","    :param src_mask: mask for source inputs, 0 for positions after </s>\n","    :param embed: target embedding layer\n","    :param bos_index: index of <s> in the vocabulary\n","    :param eos_index: index of </s> in the vocabulary\n","    :param max_output_length: maximum length for the hypotheses\n","    :param decoder: decoder to use for greedy decoding\n","    :param encoder_output: encoder hidden states for attention\n","    :param encoder_hidden: encoder final state (unused in Transformer)\n","    :return:\n","        - stacked_output: output hypotheses (2d array of indices),\n","        - stacked_attention_scores: attention scores (3d array)\n","    \"\"\"\n","\n","    batch_size = src_mask.size(0)\n","\n","    # start with BOS-symbol for each sentence in the batch\n","    ys = encoder_output.new_full([batch_size, 1], bos_index, dtype=torch.long)\n","\n","    # a subsequent mask is intersected with this in decoder forward pass\n","    trg_mask = src_mask.new_ones([1, 1, 1])\n","    finished = src_mask.new_zeros((batch_size)).byte()\n","\n","    for _ in range(max_output_length):\n","\n","        trg_embed = embed(ys)  # embed the previous tokens\n","\n","        # pylint: disable=unused-variable\n","        with torch.no_grad():\n","            logits, out, _, _ = decoder(\n","                trg_embed=trg_embed,\n","                encoder_output=encoder_output,\n","                encoder_hidden=None,\n","                src_mask=src_mask,\n","                unroll_steps=None,\n","                hidden=None,\n","                trg_mask=trg_mask,\n","            )\n","\n","            logits = logits[:, -1]\n","            _, next_word = torch.max(logits, dim=1)\n","            next_word = next_word.data\n","            ys = torch.cat([ys, next_word.unsqueeze(-1)], dim=1)\n","\n","        # check if previous symbol was <eos>\n","        is_eos = torch.eq(next_word, eos_index)\n","        finished += is_eos\n","        # stop predicting if <eos> reached for all elements in batch\n","        if (finished >= 1).sum() == batch_size:\n","            break\n","\n","    ys = ys[:, 1:]  # remove BOS-symbol\n","    return ys.detach().cpu().numpy(), None\n","    \n","class SignModel(nn.Module):\n","    \"\"\"\n","    Base Model class\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        encoder: Encoder,\n","        gloss_output_layer: nn.Module,\n","        decoder: Decoder,\n","        sgn_embed: SpatialEmbeddings,\n","        txt_embed: Embeddings,\n","        gls_vocab: GlossVocabulary,\n","        txt_vocab: TextVocabulary,\n","        do_recognition: bool = True,\n","        do_translation: bool = True,\n","    ):\n","        \"\"\"\n","        Create a new encoder-decoder model\n","\n","        :param encoder: encoder\n","        :param decoder: decoder\n","        :param sgn_embed: spatial feature frame embeddings\n","        :param txt_embed: spoken language word embedding\n","        :param gls_vocab: gls vocabulary\n","        :param txt_vocab: spoken language vocabulary\n","        :param do_recognition: flag to build the model with recognition output.\n","        :param do_translation: flag to build the model with translation decoder.\n","        \"\"\"\n","        super().__init__()\n","\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","        self.sgn_embed = sgn_embed\n","        self.txt_embed = txt_embed\n","\n","        self.gls_vocab = gls_vocab\n","        self.txt_vocab = txt_vocab\n","\n","        self.txt_bos_index = self.txt_vocab.stoi[BOS_TOKEN]\n","        self.txt_pad_index = self.txt_vocab.stoi[PAD_TOKEN]\n","        self.txt_eos_index = self.txt_vocab.stoi[EOS_TOKEN]\n","\n","        self.gloss_output_layer = gloss_output_layer\n","        self.do_recognition = do_recognition\n","        self.do_translation = do_translation\n","\n","    # pylint: disable=arguments-differ\n","    def forward(\n","        self,\n","        sgn: Tensor,\n","        sgn_mask: Tensor,\n","        sgn_lengths: Tensor,\n","        txt_input: Tensor,\n","        txt_mask: Tensor = None,\n","    ) -> (Tensor, Tensor, Tensor, Tensor):\n","        \"\"\"\n","        First encodes the source sentence.\n","        Then produces the target one word at a time.\n","\n","        :param sgn: source input\n","        :param sgn_mask: source mask\n","        :param sgn_lengths: length of source inputs\n","        :param txt_input: target input\n","        :param txt_mask: target mask\n","        :return: decoder outputs\n","        \"\"\"\n","        encoder_output, encoder_hidden = self.encode(\n","            sgn=sgn, sgn_mask=sgn_mask, sgn_length=sgn_lengths\n","        )\n","\n","        if self.do_recognition:\n","            # Gloss Recognition Part\n","            # N x T x C\n","            gloss_scores = self.gloss_output_layer(encoder_output)\n","            # N x T x C\n","            gloss_probabilities = gloss_scores.log_softmax(2)\n","            # Turn it into T x N x C\n","            gloss_probabilities = gloss_probabilities.permute(1, 0, 2)\n","        else:\n","            gloss_probabilities = None\n","\n","        if self.do_translation:\n","            unroll_steps = txt_input.size(1)\n","            decoder_outputs = self.decode(\n","                encoder_output=encoder_output,\n","                encoder_hidden=encoder_hidden,\n","                sgn_mask=sgn_mask,\n","                txt_input=txt_input,\n","                unroll_steps=unroll_steps,\n","                txt_mask=txt_mask,\n","            )\n","        else:\n","            decoder_outputs = None\n","\n","        return decoder_outputs, gloss_probabilities\n","\n","    def encode(\n","        self, sgn: Tensor, sgn_mask: Tensor, sgn_length: Tensor\n","    ) -> (Tensor, Tensor):\n","        \"\"\"\n","        Encodes the source sentence.\n","\n","        :param sgn:\n","        :param sgn_mask:\n","        :param sgn_length:\n","        :return: encoder outputs (output, hidden_concat)\n","        \"\"\"\n","        return self.encoder(\n","            embed_src=self.sgn_embed(x=sgn, mask=sgn_mask),\n","            src_length=sgn_length,\n","            mask=sgn_mask,\n","        )\n","\n","    def decode(\n","        self,\n","        encoder_output: Tensor,\n","        encoder_hidden: Tensor,\n","        sgn_mask: Tensor,\n","        txt_input: Tensor,\n","        unroll_steps: int,\n","        decoder_hidden: Tensor = None,\n","        txt_mask: Tensor = None,\n","    ) -> (Tensor, Tensor, Tensor, Tensor):\n","        \"\"\"\n","        Decode, given an encoded source sentence.\n","\n","        :param encoder_output: encoder states for attention computation\n","        :param encoder_hidden: last encoder state for decoder initialization\n","        :param sgn_mask: sign sequence mask, 1 at valid tokens\n","        :param txt_input: spoken language sentence inputs\n","        :param unroll_steps: number of steps to unroll the decoder for\n","        :param decoder_hidden: decoder hidden state (optional)\n","        :param txt_mask: mask for spoken language words\n","        :return: decoder outputs (outputs, hidden, att_probs, att_vectors)\n","        \"\"\"\n","        return self.decoder(\n","            encoder_output=encoder_output,\n","            encoder_hidden=encoder_hidden,\n","            src_mask=sgn_mask,\n","            trg_embed=self.txt_embed(x=txt_input, mask=txt_mask),\n","            trg_mask=txt_mask,\n","            unroll_steps=unroll_steps,\n","            hidden=decoder_hidden,\n","        )\n","\n","    def get_loss_for_batch(\n","        self,\n","        batch: Batch,\n","        recognition_loss_function: nn.Module,\n","        translation_loss_function: nn.Module,\n","        recognition_loss_weight: float,\n","        translation_loss_weight: float,\n","    ) -> (Tensor, Tensor):\n","        \"\"\"\n","        Compute non-normalized loss and number of tokens for a batch\n","\n","        :param batch: batch to compute loss for\n","        :param recognition_loss_function: Sign Language Recognition Loss Function (CTC)\n","        :param translation_loss_function: Sign Language Translation Loss Function (XEntropy)\n","        :param recognition_loss_weight: Weight for recognition loss\n","        :param translation_loss_weight: Weight for translation loss\n","        :return: recognition_loss: sum of losses over sequences in the batch\n","        :return: translation_loss: sum of losses over non-pad elements in the batch\n","        \"\"\"\n","        # pylint: disable=unused-variable\n","\n","        # Do a forward pass\n","        decoder_outputs, gloss_probabilities = self.forward(\n","            sgn=batch.sgn,\n","            sgn_mask=batch.sgn_mask,\n","            sgn_lengths=batch.sgn_lengths,\n","            txt_input=batch.txt_input,\n","            txt_mask=batch.txt_mask,\n","        )\n","\n","        if self.do_recognition:\n","            assert gloss_probabilities is not None\n","            # Calculate Recognition Loss\n","            recognition_loss = (\n","                recognition_loss_function(\n","                    gloss_probabilities,\n","                    batch.gls,\n","                    batch.sgn_lengths.long(),\n","                    batch.gls_lengths.long(),\n","                )\n","                * recognition_loss_weight\n","            )\n","        else:\n","            recognition_loss = None\n","\n","        if self.do_translation:\n","            assert decoder_outputs is not None\n","            word_outputs, _, _, _ = decoder_outputs\n","            # Calculate Translation Loss\n","            txt_log_probs = F.log_softmax(word_outputs, dim=-1)\n","            translation_loss = (\n","                translation_loss_function(txt_log_probs, batch.txt)\n","                * translation_loss_weight\n","            )\n","        else:\n","            translation_loss = None\n","\n","        return recognition_loss, translation_loss\n","\n","    def run_batch(\n","        self,\n","        batch: Batch,\n","        recognition_beam_size: int = 1,\n","        translation_beam_size: int = 1,\n","        translation_beam_alpha: float = -1,\n","        translation_max_output_length: int = 100,\n","    ) -> (np.array, np.array, np.array):\n","        \"\"\"\n","        Get outputs and attentions scores for a given batch\n","\n","        :param batch: batch to generate hypotheses for\n","        :param recognition_beam_size: size of the beam for CTC beam search\n","            if 1 use greedy\n","        :param translation_beam_size: size of the beam for translation beam search\n","            if 1 use greedy\n","        :param translation_beam_alpha: alpha value for beam search\n","        :param translation_max_output_length: maximum length of translation hypotheses\n","        :return: stacked_output: hypotheses for batch,\n","            stacked_attention_scores: attention scores for batch\n","        \"\"\"\n","\n","        encoder_output, encoder_hidden = self.encode(\n","            sgn=batch.sgn, sgn_mask=batch.sgn_mask, sgn_length=batch.sgn_lengths\n","        )\n","\n","        if self.do_recognition:\n","            # Gloss Recognition Part\n","            # N x T x C\n","            gloss_scores = self.gloss_output_layer(encoder_output)\n","            # N x T x C\n","            gloss_probabilities = gloss_scores.log_softmax(2)\n","            # Turn it into T x N x C\n","            gloss_probabilities = gloss_probabilities.permute(1, 0, 2)\n","            gloss_probabilities = gloss_probabilities.cpu().detach().numpy()\n","            tf_gloss_probabilities = np.concatenate(\n","                (gloss_probabilities[:, :, 1:], gloss_probabilities[:, :, 0, None]),\n","                axis=-1,\n","            )\n","\n","            assert recognition_beam_size > 0\n","            ctc_decode, _ = tf.nn.ctc_beam_search_decoder(\n","                inputs=tf_gloss_probabilities,\n","                sequence_length=batch.sgn_lengths.cpu().detach().numpy(),\n","                beam_width=recognition_beam_size,\n","                top_paths=1,\n","            )\n","            ctc_decode = ctc_decode[0]\n","            # Create a decoded gloss list for each sample\n","            tmp_gloss_sequences = [[] for i in range(gloss_scores.shape[0])]\n","            for (value_idx, dense_idx) in enumerate(ctc_decode.indices):\n","                tmp_gloss_sequences[dense_idx[0]].append(\n","                    ctc_decode.values[value_idx].numpy() + 1\n","                )\n","            decoded_gloss_sequences = []\n","            for seq_idx in range(0, len(tmp_gloss_sequences)):\n","                decoded_gloss_sequences.append(\n","                    [x[0] for x in groupby(tmp_gloss_sequences[seq_idx])]\n","                )\n","        else:\n","            decoded_gloss_sequences = None\n","\n","        if self.do_translation:\n","            # greedy decoding\n","            if translation_beam_size < 2:\n","                stacked_txt_output, stacked_attention_scores = greedy(\n","                    encoder_hidden=encoder_hidden,\n","                    encoder_output=encoder_output,\n","                    src_mask=batch.sgn_mask,\n","                    embed=self.txt_embed,\n","                    bos_index=self.txt_bos_index,\n","                    eos_index=self.txt_eos_index,\n","                    decoder=self.decoder,\n","                    max_output_length=translation_max_output_length,\n","                )\n","                # batch, time, max_sgn_length\n","            else:  # beam size\n","                stacked_txt_output, stacked_attention_scores = beam_search(\n","                    size=translation_beam_size,\n","                    encoder_hidden=encoder_hidden,\n","                    encoder_output=encoder_output,\n","                    src_mask=batch.sgn_mask,\n","                    embed=self.txt_embed,\n","                    max_output_length=translation_max_output_length,\n","                    alpha=translation_beam_alpha,\n","                    eos_index=self.txt_eos_index,\n","                    pad_index=self.txt_pad_index,\n","                    bos_index=self.txt_bos_index,\n","                    decoder=self.decoder,\n","                )\n","        else:\n","            stacked_txt_output = stacked_attention_scores = None\n","\n","        return decoded_gloss_sequences, stacked_txt_output, stacked_attention_scores\n","\n","    def __repr__(self) -> str:\n","        \"\"\"\n","        String representation: a description of encoder, decoder and embeddings\n","\n","        :return: string representation\n","        \"\"\"\n","        return (\n","            \"%s(\\n\"\n","            \"\\tencoder=%s,\\n\"\n","            \"\\tdecoder=%s,\\n\"\n","            \"\\tsgn_embed=%s,\\n\"\n","            \"\\ttxt_embed=%s)\"\n","            % (\n","                self.__class__.__name__,\n","                self.encoder,\n","                self.decoder,\n","                self.sgn_embed,\n","                self.txt_embed,\n","            )\n","        )\n","\n","def build_model(\n","    cfg: dict,\n","    sgn_dim: int,\n","    gls_vocab: GlossVocabulary,\n","    txt_vocab: TextVocabulary,\n","    do_recognition: bool = True,\n","    do_translation: bool = True,\n",") -> SignModel:\n","    \"\"\"\n","    Build and initialize the model according to the configuration.\n","\n","    :param cfg: dictionary configuration containing model specifications\n","    :param sgn_dim: feature dimension of the sign frame representation, i.e. 2560 for EfficientNet-7.\n","    :param gls_vocab: sign gloss vocabulary\n","    :param txt_vocab: spoken language word vocabulary\n","    :return: built and initialized model\n","    :param do_recognition: flag to build the model with recognition output.\n","    :param do_translation: flag to build the model with translation decoder.\n","    \"\"\"\n","\n","    txt_padding_idx = txt_vocab.stoi[PAD_TOKEN]\n","\n","    sgn_embed: SpatialEmbeddings = SpatialEmbeddings(\n","        **cfg[\"encoder\"][\"embeddings\"],\n","        num_heads=cfg[\"encoder\"][\"num_heads\"],\n","        input_size=sgn_dim,\n","    )\n","\n","    # build encoder\n","    enc_dropout = cfg[\"encoder\"].get(\"dropout\", 0.0)\n","    enc_emb_dropout = cfg[\"encoder\"][\"embeddings\"].get(\"dropout\", enc_dropout)\n","    if cfg[\"encoder\"].get(\"type\", \"recurrent\") == \"transformer\":\n","        assert (\n","            cfg[\"encoder\"][\"embeddings\"][\"embedding_dim\"]\n","            == cfg[\"encoder\"][\"hidden_size\"]\n","        ), \"for transformer, emb_size must be hidden_size\"\n","\n","        encoder = TransformerEncoder(\n","            **cfg[\"encoder\"],\n","            emb_size=sgn_embed.embedding_dim,\n","            emb_dropout=enc_emb_dropout,\n","        )\n","    else:\n","        encoder = RecurrentEncoder(\n","            **cfg[\"encoder\"],\n","            emb_size=sgn_embed.embedding_dim,\n","            emb_dropout=enc_emb_dropout,\n","        )\n","\n","    if do_recognition:\n","        gloss_output_layer = nn.Linear(encoder.output_size, len(gls_vocab))\n","        if cfg[\"encoder\"].get(\"freeze\", False):\n","            freeze_params(gloss_output_layer)\n","    else:\n","        gloss_output_layer = None\n","\n","    # build decoder and word embeddings\n","    if do_translation:\n","        txt_embed: Union[Embeddings, None] = Embeddings(\n","            **cfg[\"decoder\"][\"embeddings\"],\n","            num_heads=cfg[\"decoder\"][\"num_heads\"],\n","            vocab_size=len(txt_vocab),\n","            padding_idx=txt_padding_idx,\n","        )\n","        dec_dropout = cfg[\"decoder\"].get(\"dropout\", 0.0)\n","        dec_emb_dropout = cfg[\"decoder\"][\"embeddings\"].get(\"dropout\", dec_dropout)\n","        if cfg[\"decoder\"].get(\"type\", \"recurrent\") == \"transformer\":\n","            decoder = TransformerDecoder(\n","                **cfg[\"decoder\"],\n","                encoder=encoder,\n","                vocab_size=len(txt_vocab),\n","                emb_size=txt_embed.embedding_dim,\n","                emb_dropout=dec_emb_dropout,\n","            )\n","        else:\n","            decoder = RecurrentDecoder(\n","                **cfg[\"decoder\"],\n","                encoder=encoder,\n","                vocab_size=len(txt_vocab),\n","                emb_size=txt_embed.embedding_dim,\n","                emb_dropout=dec_emb_dropout,\n","            )\n","    else:\n","        txt_embed = None\n","        decoder = None\n","\n","    model: SignModel = SignModel(\n","        encoder=encoder,\n","        gloss_output_layer=gloss_output_layer,\n","        decoder=decoder,\n","        sgn_embed=sgn_embed,\n","        txt_embed=txt_embed,\n","        gls_vocab=gls_vocab,\n","        txt_vocab=txt_vocab,\n","        do_recognition=do_recognition,\n","        do_translation=do_translation,\n","    )\n","\n","    if do_translation:\n","        # tie softmax layer with txt embeddings\n","        if cfg.get(\"tied_softmax\", False):\n","            # noinspection PyUnresolvedReferences\n","            if txt_embed.lut.weight.shape == model.decoder.output_layer.weight.shape:\n","                # (also) share txt embeddings and softmax layer:\n","                # noinspection PyUnresolvedReferences\n","                model.decoder.output_layer.weight = txt_embed.lut.weight\n","            else:\n","                raise ValueError(\n","                    \"For tied_softmax, the decoder embedding_dim and decoder \"\n","                    \"hidden_size must be the same.\"\n","                    \"The decoder must be a Transformer.\"\n","                )\n","\n","    # custom initialization of model parameters\n","    initialize_model(model, cfg, txt_padding_idx)\n","\n","    return model\n","\n","class TrainManager:\n","    \"\"\" Manages training loop, validations, learning rate scheduling\n","    and early stopping.\"\"\"\n","\n","    def __init__(self, model: SignModel, config: dict, logger) -> None:\n","        \"\"\"\n","        Creates a new TrainManager for a model, specified as in configuration.\n","\n","        :param model: torch module defining the model\n","        :param config: dictionary containing the training configurations\n","        \"\"\"\n","        train_config = config[\"training\"]\n","\n","        # files for logging and storing\n","        self.model_dir = MODEL_DIR\n","        self.logger = logger\n","\n","        self.logging_freq = train_config.get(\"logging_freq\", 100)\n","        self.valid_report_file = \"{}/validations.txt\".format(self.model_dir)\n","\n","        # input\n","        self.feature_size = (\n","            sum(config[\"data\"][\"feature_size\"])\n","            if isinstance(config[\"data\"][\"feature_size\"], list)\n","            else config[\"data\"][\"feature_size\"]\n","        )\n","        self.dataset_version = config[\"data\"].get(\"version\", \"phoenix_2014_trans\")\n","\n","        # model\n","        self.model = model\n","        self.txt_pad_index = self.model.txt_pad_index\n","        self.txt_bos_index = self.model.txt_bos_index\n","        self._log_parameters_list()\n","        # Check if we are doing only recognition or only translation or both\n","        self.do_recognition = (\n","            config[\"training\"].get(\"recognition_loss_weight\", 1.0) > 0.0\n","        )\n","        self.do_translation = (\n","            config[\"training\"].get(\"translation_loss_weight\", 1.0) > 0.0\n","        )\n","\n","        # Get Recognition and Translation specific parameters\n","        if self.do_recognition:\n","            self._get_recognition_params(train_config=train_config)\n","        if self.do_translation:\n","            self._get_translation_params(train_config=train_config)\n","\n","        # optimization\n","        self.last_best_lr = train_config.get(\"learning_rate\", -1)\n","        self.learning_rate_min = train_config.get(\"learning_rate_min\", 1.0e-8)\n","        self.clip_grad_fun = build_gradient_clipper(config=train_config)\n","        self.optimizer = build_optimizer(\n","            config=train_config, parameters=model.parameters()\n","        )\n","        self.batch_multiplier = train_config.get(\"batch_multiplier\", 1)\n","\n","        # validation & early stopping\n","        self.validation_freq = train_config.get(\"validation_freq\", 100)\n","        self.num_valid_log = train_config.get(\"num_valid_log\", 5)\n","        self.ckpt_queue = queue.Queue(maxsize=train_config.get(\"keep_last_ckpts\", 5))\n","        self.eval_metric = train_config.get(\"eval_metric\", \"bleu\")\n","        if self.eval_metric not in [\"bleu\", \"chrf\", \"wer\", \"rouge\"]:\n","            raise ValueError(\n","                \"Invalid setting for 'eval_metric': {}\".format(self.eval_metric)\n","            )\n","        self.early_stopping_metric = train_config.get(\n","            \"early_stopping_metric\", \"eval_metric\"\n","        )\n","\n","        # if we schedule after BLEU/chrf, we want to maximize it, else minimize\n","        # early_stopping_metric decides on how to find the early stopping point:\n","        # ckpts are written when there's a new high/low score for this metric\n","        if self.early_stopping_metric in [\n","            \"ppl\",\n","            \"translation_loss\",\n","            \"recognition_loss\",\n","        ]:\n","            self.minimize_metric = True\n","        elif self.early_stopping_metric == \"eval_metric\":\n","            if self.eval_metric in [\"bleu\", \"chrf\", \"rouge\"]:\n","                assert self.do_translation\n","                self.minimize_metric = False\n","            else:  # eval metric that has to get minimized (not yet implemented)\n","                self.minimize_metric = True\n","        else:\n","            raise ValueError(\n","                \"Invalid setting for 'early_stopping_metric': {}\".format(\n","                    self.early_stopping_metric\n","                )\n","            )\n","\n","        # data_augmentation parameters\n","        self.frame_subsampling_ratio = config[\"data\"].get(\n","            \"frame_subsampling_ratio\", None\n","        )\n","        self.random_frame_subsampling = config[\"data\"].get(\n","            \"random_frame_subsampling\", None\n","        )\n","        self.random_frame_masking_ratio = config[\"data\"].get(\n","            \"random_frame_masking_ratio\", None\n","        )\n","\n","        # learning rate scheduling\n","        self.scheduler, self.scheduler_step_at = build_scheduler(\n","            config=train_config,\n","            scheduler_mode=\"min\" if self.minimize_metric else \"max\",\n","            optimizer=self.optimizer,\n","            hidden_size=config[\"model\"][\"encoder\"][\"hidden_size\"],\n","        )\n","\n","        # data & batch handling\n","        self.level = config[\"data\"][\"level\"]\n","        if self.level not in [\"word\", \"bpe\", \"char\"]:\n","            raise ValueError(\"Invalid segmentation level': {}\".format(self.level))\n","\n","        self.shuffle = train_config.get(\"shuffle\", True)\n","        self.epochs = train_config[\"epochs\"]\n","        self.batch_size = train_config[\"batch_size\"]\n","        self.batch_type = train_config.get(\"batch_type\", \"sentence\")\n","        self.eval_batch_size = train_config.get(\"eval_batch_size\", self.batch_size)\n","        self.eval_batch_type = train_config.get(\"eval_batch_type\", self.batch_type)\n","\n","        self.use_cuda = train_config[\"use_cuda\"]\n","        if self.use_cuda:\n","            self.model.cuda()\n","            if self.do_translation:\n","                self.translation_loss_function.cuda()\n","            if self.do_recognition:\n","                self.recognition_loss_function.cuda()\n","\n","        # initialize training statistics\n","        self.steps = 0\n","        # stop training if this flag is True by reaching learning rate minimum\n","        self.stop = False\n","        self.total_txt_tokens = 0\n","        self.total_gls_tokens = 0\n","        self.best_ckpt_iteration = 0\n","        # initial values for best scores\n","        self.best_ckpt_score = np.inf if self.minimize_metric else -np.inf\n","        self.best_all_ckpt_scores = {}\n","        # comparison function for scores\n","        self.is_best = (\n","            lambda score: score < self.best_ckpt_score\n","            if self.minimize_metric\n","            else score > self.best_ckpt_score\n","        )\n","\n","        # model parameters\n","        if \"load_model\" in train_config.keys():\n","            model_load_path = train_config[\"load_model\"]\n","            self.logger.info(\"Loading model from %s\", model_load_path)\n","            reset_best_ckpt = train_config.get(\"reset_best_ckpt\", False)\n","            reset_scheduler = train_config.get(\"reset_scheduler\", False)\n","            reset_optimizer = train_config.get(\"reset_optimizer\", False)\n","            self.init_from_checkpoint(\n","                model_load_path,\n","                reset_best_ckpt=reset_best_ckpt,\n","                reset_scheduler=reset_scheduler,\n","                reset_optimizer=reset_optimizer,\n","            )\n","\n","    def _get_recognition_params(self, train_config) -> None:\n","        # NOTE (Cihan): The blank label is the silence index in the gloss vocabulary.\n","        #   There is an assertion in the GlossVocabulary class's __init__.\n","        #   This is necessary to do TensorFlow decoding, as it is hardcoded\n","        #   Currently it is hardcoded as 0.\n","        self.gls_silence_token = self.model.gls_vocab.stoi[SIL_TOKEN]\n","        assert self.gls_silence_token == 0\n","\n","        self.recognition_loss_function = torch.nn.CTCLoss(\n","            blank=self.gls_silence_token, zero_infinity=True\n","        )\n","        self.recognition_loss_weight = train_config.get(\"recognition_loss_weight\", 1.0)\n","        self.eval_recognition_beam_size = train_config.get(\n","            \"eval_recognition_beam_size\", 1\n","        )\n","\n","    def _get_translation_params(self, train_config) -> None:\n","        self.label_smoothing = train_config.get(\"label_smoothing\", 0.0)\n","        self.translation_loss_function = XentLoss(\n","            pad_index=self.txt_pad_index, smoothing=self.label_smoothing\n","        )\n","        self.translation_normalization_mode = train_config.get(\n","            \"translation_normalization\", \"batch\"\n","        )\n","        if self.translation_normalization_mode not in [\"batch\", \"tokens\"]:\n","            raise ValueError(\n","                \"Invalid normalization {}.\".format(self.translation_normalization_mode)\n","            )\n","        self.translation_loss_weight = train_config.get(\"translation_loss_weight\", 1.0)\n","        self.eval_translation_beam_size = train_config.get(\n","            \"eval_translation_beam_size\", 1\n","        )\n","        self.eval_translation_beam_alpha = train_config.get(\n","            \"eval_translation_beam_alpha\", -1\n","        )\n","        self.translation_max_output_length = train_config.get(\n","            \"translation_max_output_length\", None\n","        )\n","\n","    def _save_checkpoint(self) -> None:\n","        \"\"\"\n","        Save the model's current parameters and the training state to a\n","        checkpoint.\n","\n","        The training state contains the total number of training steps,\n","        the total number of training tokens,\n","        the best checkpoint score and iteration so far,\n","        and optimizer and scheduler states.\n","\n","        \"\"\"\n","        model_path = \"{}/{}.ckpt\".format(self.model_dir, self.steps)\n","        state = {\n","            \"steps\": self.steps,\n","            \"total_txt_tokens\": self.total_txt_tokens if self.do_translation else 0,\n","            \"total_gls_tokens\": self.total_gls_tokens if self.do_recognition else 0,\n","            \"best_ckpt_score\": self.best_ckpt_score,\n","            \"best_all_ckpt_scores\": self.best_all_ckpt_scores,\n","            \"best_ckpt_iteration\": self.best_ckpt_iteration,\n","            \"model_state\": self.model.state_dict(),\n","            \"optimizer_state\": self.optimizer.state_dict(),\n","            \"scheduler_state\": self.scheduler.state_dict()\n","            if self.scheduler is not None\n","            else None,\n","        }\n","        torch.save(state, model_path)\n","        if self.ckpt_queue.full():\n","            to_delete = self.ckpt_queue.get()  # delete oldest ckpt\n","            try:\n","                os.remove(to_delete)\n","            except FileNotFoundError:\n","                self.logger.warning(\n","                    \"Wanted to delete old checkpoint %s but \" \"file does not exist.\",\n","                    to_delete,\n","                )\n","\n","        self.ckpt_queue.put(model_path)\n","\n","        # create/modify symbolic link for best checkpoint\n","        #symlink_update(\n","        #    \"{}.ckpt\".format(self.steps), \"{}/best.ckpt\".format(self.model_dir)\n","        #)\n","\n","    def init_from_checkpoint(\n","        self,\n","        path: str,\n","        reset_best_ckpt: bool = False,\n","        reset_scheduler: bool = False,\n","        reset_optimizer: bool = False,\n","    ) -> None:\n","        \"\"\"\n","        Initialize the trainer from a given checkpoint file.\n","\n","        This checkpoint file contains not only model parameters, but also\n","        scheduler and optimizer states, see `self._save_checkpoint`.\n","\n","        :param path: path to checkpoint\n","        :param reset_best_ckpt: reset tracking of the best checkpoint,\n","                                use for domain adaptation with a new dev\n","                                set or when using a new metric for fine-tuning.\n","        :param reset_scheduler: reset the learning rate scheduler, and do not\n","                                use the one stored in the checkpoint.\n","        :param reset_optimizer: reset the optimizer, and do not use the one\n","                                stored in the checkpoint.\n","        \"\"\"\n","        model_checkpoint = load_checkpoint(path=path, use_cuda=self.use_cuda)\n","\n","        # restore model and optimizer parameters\n","        self.model.load_state_dict(model_checkpoint[\"model_state\"])\n","\n","        if not reset_optimizer:\n","            self.optimizer.load_state_dict(model_checkpoint[\"optimizer_state\"])\n","        else:\n","            self.logger.info(\"Reset optimizer.\")\n","\n","        if not reset_scheduler:\n","            if (\n","                model_checkpoint[\"scheduler_state\"] is not None\n","                and self.scheduler is not None\n","            ):\n","                self.scheduler.load_state_dict(model_checkpoint[\"scheduler_state\"])\n","        else:\n","            self.logger.info(\"Reset scheduler.\")\n","\n","        # restore counts\n","        self.steps = model_checkpoint[\"steps\"]\n","        self.total_txt_tokens = model_checkpoint[\"total_txt_tokens\"]\n","        self.total_gls_tokens = model_checkpoint[\"total_gls_tokens\"]\n","\n","        if not reset_best_ckpt:\n","            self.best_ckpt_score = model_checkpoint[\"best_ckpt_score\"]\n","            self.best_all_ckpt_scores = model_checkpoint[\"best_all_ckpt_scores\"]\n","            self.best_ckpt_iteration = model_checkpoint[\"best_ckpt_iteration\"]\n","        else:\n","            self.logger.info(\"Reset tracking of the best checkpoint.\")\n","\n","        # move parameters to cuda\n","        if self.use_cuda:\n","            self.model.cuda()\n","\n","    def train_and_validate(self, train_data: Dataset, valid_data: Dataset) -> None:\n","        \"\"\"\n","        Train the model and validate it from time to time on the validation set.\n","\n","        :param train_data: training data\n","        :param valid_data: validation data\n","        \"\"\"\n","        train_iter = make_data_iter(\n","            train_data,\n","            batch_size=self.batch_size,\n","            batch_type=self.batch_type,\n","            train=True,\n","            shuffle=self.shuffle,\n","        )\n","        epoch_no = None\n","        for epoch_no in range(self.epochs):\n","            self.logger.info(\"EPOCH %d\", epoch_no + 1)\n","\n","            if self.scheduler is not None and self.scheduler_step_at == \"epoch\":\n","                self.scheduler.step(epoch=epoch_no)\n","\n","            self.model.train()\n","            start = time.time()\n","            total_valid_duration = 0\n","            count = self.batch_multiplier - 1\n","\n","            if self.do_recognition:\n","                processed_gls_tokens = self.total_gls_tokens\n","                epoch_recognition_loss = 0\n","            if self.do_translation:\n","                processed_txt_tokens = self.total_txt_tokens\n","                epoch_translation_loss = 0\n","\n","            for batch in iter(train_iter):\n","                # reactivate training\n","                # create a Batch object from torchtext batch\n","                batch = Batch(\n","                    is_train=True,\n","                    torch_batch=batch,\n","                    txt_pad_index=self.txt_pad_index,\n","                    sgn_dim=self.feature_size,\n","                    use_cuda=self.use_cuda,\n","                    frame_subsampling_ratio=self.frame_subsampling_ratio,\n","                    random_frame_subsampling=self.random_frame_subsampling,\n","                    random_frame_masking_ratio=self.random_frame_masking_ratio,\n","                )\n","\n","                # only update every batch_multiplier batches\n","                # see https://medium.com/@davidlmorton/\n","                # increasing-mini-batch-size-without-increasing-\n","                # memory-6794e10db672\n","                update = count == 0\n","\n","                recognition_loss, translation_loss = self._train_batch(\n","                    batch, update=update\n","                )\n","\n","                if self.do_recognition:\n","                    epoch_recognition_loss += recognition_loss.detach().cpu().numpy()\n","\n","                if self.do_translation:\n","                    epoch_translation_loss += translation_loss.detach().cpu().numpy()\n","\n","                count = self.batch_multiplier if update else count\n","                count -= 1\n","\n","                if (\n","                    self.scheduler is not None\n","                    and self.scheduler_step_at == \"step\"\n","                    and update\n","                ):\n","                    self.scheduler.step()\n","\n","                # log learning progress\n","                if self.steps % self.logging_freq == 0 and update:\n","                    elapsed = time.time() - start - total_valid_duration\n","\n","                    log_out = \"[Epoch: {:03d} Step: {:08d}] \".format(\n","                        epoch_no + 1, self.steps,\n","                    )\n","\n","                    if self.do_recognition:\n","                        elapsed_gls_tokens = (\n","                            self.total_gls_tokens - processed_gls_tokens\n","                        )\n","                        processed_gls_tokens = self.total_gls_tokens\n","                        log_out += \"Batch Recognition Loss: {:10.6f} => \".format(\n","                            recognition_loss\n","                        )\n","                        log_out += \"Gls Tokens per Sec: {:8.0f} || \".format(\n","                            elapsed_gls_tokens / elapsed\n","                        )\n","                    if self.do_translation:\n","                        elapsed_txt_tokens = (\n","                            self.total_txt_tokens - processed_txt_tokens\n","                        )\n","                        processed_txt_tokens = self.total_txt_tokens\n","                        log_out += \"Batch Translation Loss: {:10.6f} => \".format(\n","                            translation_loss\n","                        )\n","                        log_out += \"Txt Tokens per Sec: {:8.0f} || \".format(\n","                            elapsed_txt_tokens / elapsed\n","                        )\n","                    log_out += \"Lr: {:.6f}\".format(self.optimizer.param_groups[0][\"lr\"])\n","                    self.logger.info(log_out)\n","                    start = time.time()\n","                    total_valid_duration = 0\n","\n","                # validate on the entire dev set\n","                if self.steps % self.validation_freq == 0 and update:\n","                    valid_start_time = time.time()\n","                    # TODO (Cihan): There must be a better way of passing\n","                    #   these recognition only and translation only parameters!\n","                    #   Maybe have a NamedTuple with optional fields?\n","                    #   Hmm... Future Cihan's problem.\n","                    val_res = validate_on_data(\n","                        model=self.model,\n","                        data=valid_data,\n","                        batch_size=self.eval_batch_size,\n","                        use_cuda=self.use_cuda,\n","                        batch_type=self.eval_batch_type,\n","                        dataset_version=self.dataset_version,\n","                        sgn_dim=self.feature_size,\n","                        txt_pad_index=self.txt_pad_index,\n","                        # Recognition Parameters\n","                        do_recognition=self.do_recognition,\n","                        recognition_loss_function=self.recognition_loss_function\n","                        if self.do_recognition\n","                        else None,\n","                        recognition_loss_weight=self.recognition_loss_weight\n","                        if self.do_recognition\n","                        else None,\n","                        recognition_beam_size=self.eval_recognition_beam_size\n","                        if self.do_recognition\n","                        else None,\n","                        # Translation Parameters\n","                        do_translation=self.do_translation,\n","                        translation_loss_function=self.translation_loss_function\n","                        if self.do_translation\n","                        else None,\n","                        translation_max_output_length=self.translation_max_output_length\n","                        if self.do_translation\n","                        else None,\n","                        level=self.level if self.do_translation else None,\n","                        translation_loss_weight=self.translation_loss_weight\n","                        if self.do_translation\n","                        else None,\n","                        translation_beam_size=self.eval_translation_beam_size\n","                        if self.do_translation\n","                        else None,\n","                        translation_beam_alpha=self.eval_translation_beam_alpha\n","                        if self.do_translation\n","                        else None,\n","                        frame_subsampling_ratio=self.frame_subsampling_ratio,\n","                    )\n","                    self.model.train()\n","\n","                    if self.early_stopping_metric == \"recognition_loss\":\n","                        assert self.do_recognition\n","                        ckpt_score = val_res[\"valid_recognition_loss\"]\n","                    elif self.early_stopping_metric == \"translation_loss\":\n","                        assert self.do_translation\n","                        ckpt_score = val_res[\"valid_translation_loss\"]\n","                    elif self.early_stopping_metric in [\"ppl\", \"perplexity\"]:\n","                        assert self.do_translation\n","                        ckpt_score = val_res[\"valid_ppl\"]\n","                    else:\n","                        ckpt_score = val_res[\"valid_scores\"][self.eval_metric]\n","\n","                    new_best = False\n","                    if self.is_best(ckpt_score):\n","                        self.best_ckpt_score = ckpt_score\n","                        self.best_all_ckpt_scores = val_res[\"valid_scores\"]\n","                        self.best_ckpt_iteration = self.steps\n","                        self.logger.info(\n","                            \"Hooray! New best validation result [%s]!\",\n","                            self.early_stopping_metric,\n","                        )\n","                        if self.ckpt_queue.maxsize > 0:\n","                            self.logger.info(\"Saving new checkpoint.\")\n","                            new_best = True\n","                            self._save_checkpoint()\n","\n","                    if (\n","                        self.scheduler is not None\n","                        and self.scheduler_step_at == \"validation\"\n","                    ):\n","                        prev_lr = self.scheduler.optimizer.param_groups[0][\"lr\"]\n","                        self.scheduler.step(ckpt_score)\n","                        now_lr = self.scheduler.optimizer.param_groups[0][\"lr\"]\n","\n","                        if prev_lr != now_lr:\n","                            if self.last_best_lr != prev_lr:\n","                                self.stop = True\n","\n","                    # append to validation report\n","                    self._add_report(\n","                        valid_scores=val_res[\"valid_scores\"],\n","                        valid_recognition_loss=val_res[\"valid_recognition_loss\"]\n","                        if self.do_recognition\n","                        else None,\n","                        valid_translation_loss=val_res[\"valid_translation_loss\"]\n","                        if self.do_translation\n","                        else None,\n","                        valid_ppl=val_res[\"valid_ppl\"] if self.do_translation else None,\n","                        eval_metric=self.eval_metric,\n","                        new_best=new_best,\n","                    )\n","                    valid_duration = time.time() - valid_start_time\n","                    total_valid_duration += valid_duration\n","                    self.logger.info(\n","                        \"Validation result at epoch %3d, step %8d: duration: %.4fs\\n\\t\"\n","                        \"Recognition Beam Size: %d\\t\"\n","                        \"Translation Beam Size: %d\\t\"\n","                        \"Translation Beam Alpha: %d\\n\\t\"\n","                        \"Recognition Loss: %4.5f\\t\"\n","                        \"Translation Loss: %4.5f\\t\"\n","                        \"PPL: %4.5f\\n\\t\"\n","                        \"Eval Metric: %s\\n\\t\"\n","                        \"WER %3.2f\\t(DEL: %3.2f,\\tINS: %3.2f,\\tSUB: %3.2f)\\n\\t\"\n","                        \"BLEU-1 %.2f\\n\\t\"\n","                        \"CHRF %.2f\\t\"\n","                        \"ROUGE %.2f\",\n","                        epoch_no + 1,\n","                        self.steps,\n","                        valid_duration,\n","                        self.eval_recognition_beam_size if self.do_recognition else -1,\n","                        self.eval_translation_beam_size if self.do_translation else -1,\n","                        self.eval_translation_beam_alpha if self.do_translation else -1,\n","                        val_res[\"valid_recognition_loss\"]\n","                        if self.do_recognition\n","                        else -1,\n","                        val_res[\"valid_translation_loss\"]\n","                        if self.do_translation\n","                        else -1,\n","                        val_res[\"valid_ppl\"] if self.do_translation else -1,\n","                        self.eval_metric.upper(),\n","                        # WER\n","                        val_res[\"valid_scores\"][\"wer\"] if self.do_recognition else -1,\n","                        val_res[\"valid_scores\"][\"wer_scores\"][\"del_rate\"]\n","                        if self.do_recognition\n","                        else -1,\n","                        val_res[\"valid_scores\"][\"wer_scores\"][\"ins_rate\"]\n","                        if self.do_recognition\n","                        else -1,\n","                        val_res[\"valid_scores\"][\"wer_scores\"][\"sub_rate\"]\n","                        if self.do_recognition\n","                        else -1,\n","                        # BLEU\n","                        val_res[\"valid_scores\"][\"bleu\"] if self.do_translation else -1,\n","                        # Other\n","                        val_res[\"valid_scores\"][\"chrf\"] if self.do_translation else -1,\n","                        val_res[\"valid_scores\"][\"rouge\"] if self.do_translation else -1,\n","                    )\n","\n","                if self.stop:\n","                    break\n","            if self.stop:\n","                if (\n","                    self.scheduler is not None\n","                    and self.scheduler_step_at == \"validation\"\n","                    and self.last_best_lr != prev_lr\n","                ):\n","                    self.logger.info(\n","                        \"Training ended since there were no improvements in\"\n","                        \"the last learning rate step: %f\",\n","                        prev_lr,\n","                    )\n","                else:\n","                    self.logger.info(\n","                        \"Training ended since minimum lr %f was reached.\",\n","                        self.learning_rate_min,\n","                    )\n","                break\n","\n","            self.logger.info(\n","                \"Epoch %3d: Total Training Recognition Loss %.2f \"\n","                \" Total Training Translation Loss %.2f \",\n","                epoch_no + 1,\n","                epoch_recognition_loss if self.do_recognition else -1,\n","                epoch_translation_loss if self.do_translation else -1,\n","            )\n","        else:\n","            self.logger.info(\"Training ended after %3d epochs.\", epoch_no + 1)\n","        self.logger.info(\n","            \"Best validation result at step %8d: %6.2f %s.\",\n","            self.best_ckpt_iteration,\n","            self.best_ckpt_score,\n","            self.early_stopping_metric,\n","        )\n","\n","    def _train_batch(self, batch: Batch, update: bool = True) -> (Tensor, Tensor):\n","        \"\"\"\n","        Train the model on one batch: Compute the loss, make a gradient step.\n","\n","        :param batch: training batch\n","        :param update: if False, only store gradient. if True also make update\n","        :return normalized_recognition_loss: Normalized recognition loss\n","        :return normalized_translation_loss: Normalized translation loss\n","        \"\"\"\n","\n","        recognition_loss, translation_loss = self.model.get_loss_for_batch(\n","            batch=batch,\n","            recognition_loss_function=self.recognition_loss_function\n","            if self.do_recognition\n","            else None,\n","            translation_loss_function=self.translation_loss_function\n","            if self.do_translation\n","            else None,\n","            recognition_loss_weight=self.recognition_loss_weight\n","            if self.do_recognition\n","            else None,\n","            translation_loss_weight=self.translation_loss_weight\n","            if self.do_translation\n","            else None,\n","        )\n","\n","        # normalize translation loss\n","        if self.do_translation:\n","            if self.translation_normalization_mode == \"batch\":\n","                txt_normalization_factor = batch.num_seqs\n","            elif self.translation_normalization_mode == \"tokens\":\n","                txt_normalization_factor = batch.num_txt_tokens\n","            else:\n","                raise NotImplementedError(\"Only normalize by 'batch' or 'tokens'\")\n","\n","            # division needed since loss.backward sums the gradients until updated\n","            normalized_translation_loss = translation_loss / (\n","                txt_normalization_factor * self.batch_multiplier\n","            )\n","        else:\n","            normalized_translation_loss = 0\n","\n","        # TODO (Cihan): Add Gloss Token normalization (?)\n","        #   I think they are already being normalized by batch\n","        #   I need to think about if I want to normalize them by token.\n","        if self.do_recognition:\n","            normalized_recognition_loss = recognition_loss / self.batch_multiplier\n","        else:\n","            normalized_recognition_loss = 0\n","\n","        total_loss = normalized_recognition_loss + normalized_translation_loss\n","        # compute gradients\n","        total_loss.backward()\n","\n","        if self.clip_grad_fun is not None:\n","            # clip gradients (in-place)\n","            self.clip_grad_fun(params=self.model.parameters())\n","\n","        if update:\n","            # make gradient step\n","            self.optimizer.step()\n","            self.optimizer.zero_grad()\n","\n","            # increment step counter\n","            self.steps += 1\n","\n","        # increment token counter\n","        if self.do_recognition:\n","            self.total_gls_tokens += batch.num_gls_tokens\n","        if self.do_translation:\n","            self.total_txt_tokens += batch.num_txt_tokens\n","\n","        return normalized_recognition_loss, normalized_translation_loss\n","\n","    def _add_report(\n","        self,\n","        valid_scores: Dict,\n","        valid_recognition_loss: float,\n","        valid_translation_loss: float,\n","        valid_ppl: float,\n","        eval_metric: str,\n","        new_best: bool = False,\n","    ) -> None:\n","        \"\"\"\n","        Append a one-line report to validation logging file.\n","\n","        :param valid_scores: Dictionary of validation scores\n","        :param valid_recognition_loss: validation loss (sum over whole validation set)\n","        :param valid_translation_loss: validation loss (sum over whole validation set)\n","        :param valid_ppl: validation perplexity\n","        :param eval_metric: evaluation metric, e.g. \"bleu\"\n","        :param new_best: whether this is a new best model\n","        \"\"\"\n","        current_lr = -1\n","        # ignores other param groups for now\n","        for param_group in self.optimizer.param_groups:\n","            current_lr = param_group[\"lr\"]\n","\n","        if new_best:\n","            self.last_best_lr = current_lr\n","\n","        if current_lr < self.learning_rate_min:\n","            self.stop = True\n","\n","        with open(self.valid_report_file, \"a\", encoding=\"utf-8\") as opened_file:\n","            opened_file.write(\n","                \"Steps: {}\\t\"\n","                \"Recognition Loss: {:.5f}\\t\"\n","                \"Translation Loss: {:.5f}\\t\"\n","                \"PPL: {:.5f}\\t\"\n","                \"Eval Metric: {}\\t\"\n","                \"WER {:.2f}\\t(DEL: {:.2f},\\tINS: {:.2f},\\tSUB: {:.2f})\\t\"\n","                \"BLEU {:.2f}\\t\"\n","                \"CHRF {:.2f}\\t\"\n","                \"ROUGE {:.2f}\\t\"\n","                \"LR: {:.8f}\\t{}\\n\".format(\n","                    self.steps,\n","                    valid_recognition_loss if self.do_recognition else -1,\n","                    valid_translation_loss if self.do_translation else -1,\n","                    valid_ppl if self.do_translation else -1,\n","                    eval_metric,\n","                    # WER\n","                    valid_scores[\"wer\"] if self.do_recognition else -1,\n","                    valid_scores[\"wer_scores\"][\"del_rate\"]\n","                    if self.do_recognition\n","                    else -1,\n","                    valid_scores[\"wer_scores\"][\"ins_rate\"]\n","                    if self.do_recognition\n","                    else -1,\n","                    valid_scores[\"wer_scores\"][\"sub_rate\"]\n","                    if self.do_recognition\n","                    else -1,\n","                    # BLEU\n","                    valid_scores[\"bleu\"] if self.do_translation else -1,\n","                    # Other\n","                    valid_scores[\"chrf\"] if self.do_translation else -1,\n","                    valid_scores[\"rouge\"] if self.do_translation else -1,\n","                    current_lr,\n","                    \"*\" if new_best else \"\",\n","                )\n","            )\n","\n","    def _log_parameters_list(self) -> None:\n","        \"\"\"\n","        Write all model parameters (name, shape) to the log.\n","        \"\"\"\n","        model_parameters = filter(lambda p: p.requires_grad, self.model.parameters())\n","        n_params = sum([np.prod(p.size()) for p in model_parameters])\n","        self.logger.info(\"Total params: %d\", n_params)\n","        trainable_params = [\n","            n for (n, p) in self.model.named_parameters() if p.requires_grad\n","        ]\n","        self.logger.info(\"Trainable parameters: %s\", sorted(trainable_params))\n","        assert trainable_params\n","\n","    def _log_examples(\n","        self,\n","        sequences: List[str],\n","        gls_references: List[str],\n","        gls_hypotheses: List[str],\n","        txt_references: List[str],\n","        txt_hypotheses: List[str],\n","    ) -> None:\n","        \"\"\"\n","        Log `self.num_valid_log` number of samples from valid.\n","\n","        :param sequences: sign video sequence names (list of strings)\n","        :param txt_hypotheses: decoded txt hypotheses (list of strings)\n","        :param txt_references: decoded txt references (list of strings)\n","        :param gls_hypotheses: decoded gls hypotheses (list of strings)\n","        :param gls_references: decoded gls references (list of strings)\n","        \"\"\"\n","\n","        if self.do_recognition:\n","            assert len(gls_references) == len(gls_hypotheses)\n","            num_sequences = len(gls_hypotheses)\n","        if self.do_translation:\n","            assert len(txt_references) == len(txt_hypotheses)\n","            num_sequences = len(txt_hypotheses)\n","\n","        rand_idx = np.sort(np.random.permutation(num_sequences)[: self.num_valid_log])\n","        self.logger.info(\"Logging Recognition and Translation Outputs\")\n","        self.logger.info(\"=\" * 120)\n","        for ri in rand_idx:\n","            self.logger.info(\"Logging Sequence: %s\", sequences[ri])\n","            if self.do_recognition:\n","                gls_res = wer_single(r=gls_references[ri], h=gls_hypotheses[ri])\n","                self.logger.info(\n","                    \"\\tGloss Reference :\\t%s\", gls_res[\"alignment_out\"][\"align_ref\"]\n","                )\n","                self.logger.info(\n","                    \"\\tGloss Hypothesis:\\t%s\", gls_res[\"alignment_out\"][\"align_hyp\"]\n","                )\n","                self.logger.info(\n","                    \"\\tGloss Alignment :\\t%s\", gls_res[\"alignment_out\"][\"alignment\"]\n","                )\n","            if self.do_recognition and self.do_translation:\n","                self.logger.info(\"\\t\" + \"-\" * 116)\n","            if self.do_translation:\n","                txt_res = wer_single(r=txt_references[ri], h=txt_hypotheses[ri])\n","                self.logger.info(\n","                    \"\\tText Reference  :\\t%s\", txt_res[\"alignment_out\"][\"align_ref\"]\n","                )\n","                self.logger.info(\n","                    \"\\tText Hypothesis :\\t%s\", txt_res[\"alignment_out\"][\"align_hyp\"]\n","                )\n","                self.logger.info(\n","                    \"\\tText Alignment  :\\t%s\", txt_res[\"alignment_out\"][\"alignment\"]\n","                )\n","            self.logger.info(\"=\" * 120)\n","\n","    def _store_outputs(\n","        self, tag: str, sequence_ids: List[str], hypotheses: List[str], sub_folder=None\n","    ) -> None:\n","        \"\"\"\n","        Write current validation outputs to file in `self.model_dir.`\n","\n","        :param hypotheses: list of strings\n","        \"\"\"\n","        if sub_folder:\n","            out_folder = os.path.join(self.model_dir, sub_folder)\n","            if not os.path.exists(out_folder):\n","                os.makedirs(out_folder)\n","            current_valid_output_file = \"{}/{}.{}\".format(out_folder, self.steps, tag)\n","        else:\n","            out_folder = self.model_dir\n","            current_valid_output_file = \"{}/{}\".format(out_folder, tag)\n","\n","        with open(current_valid_output_file, \"w\", encoding=\"utf-8\") as opened_file:\n","            for seq, hyp in zip(sequence_ids, hypotheses):\n","                opened_file.write(\"{}|{}\\n\".format(seq, hyp))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CpkimGTWtgId"},"source":["### Validation Code"]},{"cell_type":"code","metadata":{"id":"kNh3WX3steyH"},"source":["def validate_on_data(\n","    model: SignModel,\n","    data: Dataset,\n","    batch_size: int,\n","    use_cuda: bool,\n","    sgn_dim: int,\n","    do_recognition: bool,\n","    recognition_loss_function: torch.nn.Module,\n","    recognition_loss_weight: int,\n","    do_translation: bool,\n","    translation_loss_function: torch.nn.Module,\n","    translation_loss_weight: int,\n","    translation_max_output_length: int,\n","    level: str,\n","    txt_pad_index: int,\n","    recognition_beam_size: int = 1,\n","    translation_beam_size: int = 1,\n","    translation_beam_alpha: int = -1,\n","    batch_type: str = \"sentence\",\n","    dataset_version: str = \"phoenix_2014_trans\",\n","    frame_subsampling_ratio: int = None,\n",") -> (\n","    float,\n","    float,\n","    float,\n","    List[str],\n","    List[List[str]],\n","    List[str],\n","    List[str],\n","    List[List[str]],\n","    List[np.array],\n","):\n","    \"\"\"\n","    Generate translations for the given data.\n","    If `loss_function` is not None and references are given,\n","    also compute the loss.\n","\n","    :return:\n","        - current_valid_score: current validation score [eval_metric],\n","        - valid_loss: validation loss,\n","        - valid_ppl:, validation perplexity,\n","        - valid_sources: validation sources,\n","        - valid_sources_raw: raw validation sources (before post-processing),\n","        - valid_references: validation references,\n","        - valid_hypotheses: validation_hypotheses,\n","        - decoded_valid: raw validation hypotheses (before post-processing),\n","        - valid_attention_scores: attention scores for validation hypotheses\n","    \"\"\"\n","    valid_iter = make_data_iter(\n","        dataset=data,\n","        batch_size=batch_size,\n","        batch_type=batch_type,\n","        shuffle=False,\n","        train=False,\n","    )\n","\n","    # disable dropout\n","    model.eval()\n","    # don't track gradients during validation\n","    with torch.no_grad():\n","        all_gls_outputs = []\n","        all_txt_outputs = []\n","        all_attention_scores = []\n","        total_recognition_loss = 0\n","        total_translation_loss = 0\n","        total_num_txt_tokens = 0\n","        total_num_gls_tokens = 0\n","        total_num_seqs = 0\n","        for valid_batch in iter(valid_iter):\n","            batch = Batch(\n","                is_train=False,\n","                torch_batch=valid_batch,\n","                txt_pad_index=txt_pad_index,\n","                sgn_dim=sgn_dim,\n","                use_cuda=use_cuda,\n","                frame_subsampling_ratio=frame_subsampling_ratio,\n","            )\n","            sort_reverse_index = batch.sort_by_sgn_lengths()\n","\n","            batch_recognition_loss, batch_translation_loss = model.get_loss_for_batch(\n","                batch=batch,\n","                recognition_loss_function=recognition_loss_function\n","                if do_recognition\n","                else None,\n","                translation_loss_function=translation_loss_function\n","                if do_translation\n","                else None,\n","                recognition_loss_weight=recognition_loss_weight\n","                if do_recognition\n","                else None,\n","                translation_loss_weight=translation_loss_weight\n","                if do_translation\n","                else None,\n","            )\n","\n","            if do_translation:\n","                total_translation_loss += batch_translation_loss\n","                total_num_txt_tokens += batch.num_txt_tokens\n","            total_num_seqs += batch.num_seqs\n","            \n","            (\n","                batch_gls_predictions,\n","                batch_txt_predictions,\n","                batch_attention_scores,\n","            ) = model.run_batch(\n","                batch=batch,\n","                recognition_beam_size=recognition_beam_size if do_recognition else None,\n","                translation_beam_size=translation_beam_size if do_translation else None,\n","                translation_beam_alpha=translation_beam_alpha\n","                if do_translation\n","                else None,\n","                translation_max_output_length=translation_max_output_length\n","                if do_translation\n","                else None,\n","            )\n","\n","            # sort outputs back to original order\n","            if do_recognition:\n","                all_gls_outputs.extend(\n","                    [batch_gls_predictions[sri] for sri in sort_reverse_index]\n","                )\n","            if do_translation:\n","                all_txt_outputs.extend(batch_txt_predictions[sort_reverse_index])\n","            all_attention_scores.extend(\n","                batch_attention_scores[sort_reverse_index]\n","                if batch_attention_scores is not None\n","                else []\n","            )\n","\n","        if do_translation:\n","            assert len(all_txt_outputs) == len(data)\n","            if (\n","                translation_loss_function is not None\n","                and translation_loss_weight != 0\n","                and total_num_txt_tokens > 0\n","            ):\n","                # total validation translation loss\n","                valid_translation_loss = total_translation_loss\n","                # exponent of token-level negative log prob\n","                valid_ppl = torch.exp(total_translation_loss / total_num_txt_tokens)\n","            else:\n","                valid_translation_loss = -1\n","                valid_ppl = -1\n","            # decode back to symbols\n","            decoded_txt = model.txt_vocab.arrays_to_sentences(arrays=all_txt_outputs)\n","            # evaluate with metric on full dataset\n","            join_char = \" \" if level in [\"word\", \"bpe\"] else \"\"\n","            # Construct text sequences for metrics\n","            txt_ref = [join_char.join(t) for t in data.txt]\n","            txt_hyp = [join_char.join(t) for t in decoded_txt]\n","\n","            # post-process\n","            if level == \"bpe\":\n","                txt_ref = [bpe_postprocess(v) for v in txt_ref]\n","                txt_hyp = [bpe_postprocess(v) for v in txt_hyp]\n","            assert len(txt_ref) == len(txt_hyp)\n","\n","            # TXT Metrics\n","            txt_bleu = bleu(references=txt_ref, hypotheses=txt_hyp)\n","            txt_chrf = chrf(references=txt_ref, hypotheses=txt_hyp)\n","            txt_rouge = rouge(references=txt_ref, hypotheses=txt_hyp)\n","\n","        valid_scores = {}\n","        if do_translation:\n","            valid_scores[\"bleu\"] = txt_bleu[\"bleu1\"]\n","            valid_scores[\"bleu_scores\"] = txt_bleu\n","            valid_scores[\"chrf\"] = txt_chrf\n","            valid_scores[\"rouge\"] = txt_rouge\n","\n","    results = {\n","        \"valid_scores\": valid_scores,\n","        \"all_attention_scores\": all_attention_scores,\n","    }\n","\n","    if do_translation:\n","        results[\"valid_translation_loss\"] = valid_translation_loss\n","        results[\"valid_ppl\"] = valid_ppl\n","        results[\"decoded_txt\"] = decoded_txt\n","        results[\"txt_ref\"] = txt_ref\n","        results[\"txt_hyp\"] = txt_hyp\n","\n","    return results"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1f4CVdCjH0FK"},"source":["### Metrics"]},{"cell_type":"code","metadata":{"id":"acVvcnMAuJrk"},"source":["# metrics\n","def chrf(references, hypotheses):\n","    \"\"\"\n","    Character F-score from sacrebleu\n","\n","    :param hypotheses: list of hypotheses (strings)\n","    :param references: list of references (strings)\n","    :return:\n","    \"\"\"\n","    return (\n","        sacrebleu.corpus_chrf(hypotheses=hypotheses, references=references).score * 100\n","    )\n","\n","\n","def bleu(references, hypotheses):\n","    \"\"\"\n","    Raw corpus BLEU from sacrebleu (without tokenization)\n","\n","    :param hypotheses: list of hypotheses (strings)\n","    :param references: list of references (strings)\n","    :return:\n","    \"\"\"\n","    bleu_scores = sacrebleu.raw_corpus_bleu(\n","        sys_stream=hypotheses, ref_streams=[references]\n","    ).score\n","    scores = {}\n","    scores[\"bleu1\"] = bleu_scores\n","    return scores\n","    \n","def rouge(references, hypotheses):\n","    rouge_score = 0\n","    n_seq = len(hypotheses)\n","\n","    for h, r in zip(hypotheses, references):\n","        rouge_score += mscoco_rouge.calc_score(hypotheses=[h], references=[r]) / n_seq\n","\n","    return rouge_score * 100\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mKqS9lyfH2DU"},"source":["### Run the code"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8McZvgcbb0UW","executionInfo":{"status":"ok","timestamp":1606587115896,"user_tz":480,"elapsed":6095815,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"}},"outputId":"91c1ddf1-cfb0-49b1-ee44-7b4d79373d07"},"source":["cfg = load_config(os.path.join(CONF_DIR, 'sign.yaml'))\n","\n","cfg[\"training\"][\"epochs\"] = 500\n","cfg[\"training\"][\"validation_freq\"] =400 #50\n","cfg[\"training\"][\"logging_freq\"] = 40 #10\n","cfg[\"training\"][\"use_cuda\"] = True\n","cfg[\"training\"][\"batch_size\"] = 32\n","cfg[\"training\"][\"translation_max_output_length\"] = 1\n","cfg[\"model\"][\"decoder\"][\"num_layers\"] = 1\n","cfg[\"model\"][\"encoder\"][\"num_layers\"] = 4\n","cfg[\"model\"][\"encoder\"][\"num_heads\"] = 4\n","cfg[\"model\"][\"decoder\"][\"num_heads\"] = 4\n","\n","\n","set_seed(cfg[\"training\"].get(\"random_seed\", 42))\n","train_data, dev_data, txt_vocab = load_data(\n","      data_cfg=cfg[\"data\"]\n","  )\n","\n","model = build_model(\n","      cfg=cfg[\"model\"],\n","      gls_vocab=None,\n","      txt_vocab=txt_vocab,\n","      sgn_dim=sum(cfg[\"data\"][\"feature_size\"])\n","      if isinstance(cfg[\"data\"][\"feature_size\"], list)\n","      else cfg[\"data\"][\"feature_size\"],\n","      do_recognition=False,\n","      do_translation=True,\n","  )\n","\n","version = 'v7'\n","\n","logger = make_logger(model_dir=MODEL_DIR, log_file=f\"{version}.train.log\")\n","\n","trainer = TrainManager(model=model, config=cfg, logger=logger)\n","log_cfg(cfg, trainer.logger)\n","\n","trainer.logger.info(str(model))\n","\n","trainer.train_and_validate(train_data=train_data, valid_data=dev_data)\n","del train_data, dev_data\n","ckpt = \"{}/{}.ckpt\".format(trainer.model_dir, trainer.best_ckpt_iteration)\n","output_name = \"best.IT_{:08d}\".format(trainer.best_ckpt_iteration)\n","output_path = os.path.join(trainer.model_dir, output_name)\n","logger = trainer.logger\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-11-28 16:30:53,106 - __main__ - INFO - Total params: 12065792\n","2020-11-28 16:30:53,109 - __main__ - INFO - Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight', 'txt_embed.lut.weight', 'txt_embed.norm.norm.bias', 'txt_embed.norm.norm.weight']\n","2020-11-28 16:31:03,363 - __main__ - INFO - cfg.name                           : sign_experiment\n","2020-11-28 16:31:03,364 - __main__ - INFO - cfg.data.data_path                 : ../data/\n","2020-11-28 16:31:03,366 - __main__ - INFO - cfg.data.version                   : phoenix_2014_trans\n","2020-11-28 16:31:03,367 - __main__ - INFO - cfg.data.sgn                       : sign\n","2020-11-28 16:31:03,369 - __main__ - INFO - cfg.data.txt                       : text\n","2020-11-28 16:31:03,370 - __main__ - INFO - cfg.data.gls                       : gloss\n","2020-11-28 16:31:03,371 - __main__ - INFO - cfg.data.train                     : PHOENIX2014T/phoenix14t.pami0.train\n","2020-11-28 16:31:03,372 - __main__ - INFO - cfg.data.dev                       : PHOENIX2014T/phoenix14t.pami0.dev\n","2020-11-28 16:31:03,373 - __main__ - INFO - cfg.data.test                      : PHOENIX2014T/phoenix14t.pami0.test\n","2020-11-28 16:31:03,374 - __main__ - INFO - cfg.data.feature_size              : 240\n","2020-11-28 16:31:03,375 - __main__ - INFO - cfg.data.level                     : word\n","2020-11-28 16:31:03,376 - __main__ - INFO - cfg.data.txt_lowercase             : True\n","2020-11-28 16:31:03,377 - __main__ - INFO - cfg.data.max_sent_length           : 176\n","2020-11-28 16:31:03,378 - __main__ - INFO - cfg.data.random_train_subset       : -1\n","2020-11-28 16:31:03,379 - __main__ - INFO - cfg.data.random_dev_subset         : -1\n","2020-11-28 16:31:03,381 - __main__ - INFO - cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","2020-11-28 16:31:03,382 - __main__ - INFO - cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","2020-11-28 16:31:03,383 - __main__ - INFO - cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]\n","2020-11-28 16:31:03,384 - __main__ - INFO - cfg.training.reset_best_ckpt       : False\n","2020-11-28 16:31:03,385 - __main__ - INFO - cfg.training.reset_scheduler       : False\n","2020-11-28 16:31:03,386 - __main__ - INFO - cfg.training.reset_optimizer       : False\n","2020-11-28 16:31:03,387 - __main__ - INFO - cfg.training.random_seed           : 42\n","2020-11-28 16:31:03,389 - __main__ - INFO - cfg.training.model_dir             : ./sign_sample_model\n","2020-11-28 16:31:03,390 - __main__ - INFO - cfg.training.recognition_loss_weight : 0.0\n","2020-11-28 16:31:03,391 - __main__ - INFO - cfg.training.translation_loss_weight : 1.0\n","2020-11-28 16:31:03,392 - __main__ - INFO - cfg.training.eval_metric           : bleu\n","2020-11-28 16:31:03,393 - __main__ - INFO - cfg.training.optimizer             : adam\n","2020-11-28 16:31:03,395 - __main__ - INFO - cfg.training.learning_rate         : 0.001\n","2020-11-28 16:31:03,396 - __main__ - INFO - cfg.training.batch_size            : 32\n","2020-11-28 16:31:03,397 - __main__ - INFO - cfg.training.num_valid_log         : 5\n","2020-11-28 16:31:03,398 - __main__ - INFO - cfg.training.epochs                : 500\n","2020-11-28 16:31:03,399 - __main__ - INFO - cfg.training.early_stopping_metric : eval_metric\n","2020-11-28 16:31:03,401 - __main__ - INFO - cfg.training.batch_type            : sentence\n","2020-11-28 16:31:03,402 - __main__ - INFO - cfg.training.translation_normalization : batch\n","2020-11-28 16:31:03,403 - __main__ - INFO - cfg.training.eval_recognition_beam_size : 1\n","2020-11-28 16:31:03,404 - __main__ - INFO - cfg.training.eval_translation_beam_size : 1\n","2020-11-28 16:31:03,405 - __main__ - INFO - cfg.training.eval_translation_beam_alpha : -1\n","2020-11-28 16:31:03,406 - __main__ - INFO - cfg.training.overwrite             : True\n","2020-11-28 16:31:03,409 - __main__ - INFO - cfg.training.shuffle               : True\n","2020-11-28 16:31:03,409 - __main__ - INFO - cfg.training.use_cuda              : True\n","2020-11-28 16:31:03,411 - __main__ - INFO - cfg.training.translation_max_output_length : 1\n","2020-11-28 16:31:03,412 - __main__ - INFO - cfg.training.keep_last_ckpts       : 1\n","2020-11-28 16:31:03,413 - __main__ - INFO - cfg.training.batch_multiplier      : 1\n","2020-11-28 16:31:03,414 - __main__ - INFO - cfg.training.logging_freq          : 40\n","2020-11-28 16:31:03,416 - __main__ - INFO - cfg.training.validation_freq       : 400\n","2020-11-28 16:31:03,417 - __main__ - INFO - cfg.training.betas                 : [0.9, 0.998]\n","2020-11-28 16:31:03,418 - __main__ - INFO - cfg.training.scheduling            : plateau\n","2020-11-28 16:31:03,419 - __main__ - INFO - cfg.training.learning_rate_min     : 1e-07\n","2020-11-28 16:31:03,421 - __main__ - INFO - cfg.training.weight_decay          : 0.001\n","2020-11-28 16:31:03,421 - __main__ - INFO - cfg.training.patience              : 8\n","2020-11-28 16:31:03,423 - __main__ - INFO - cfg.training.decrease_factor       : 0.7\n","2020-11-28 16:31:03,424 - __main__ - INFO - cfg.training.label_smoothing       : 0.0\n","2020-11-28 16:31:03,425 - __main__ - INFO - cfg.model.initializer              : xavier\n","2020-11-28 16:31:03,427 - __main__ - INFO - cfg.model.bias_initializer         : zeros\n","2020-11-28 16:31:03,429 - __main__ - INFO - cfg.model.init_gain                : 1.0\n","2020-11-28 16:31:03,430 - __main__ - INFO - cfg.model.embed_initializer        : xavier\n","2020-11-28 16:31:03,432 - __main__ - INFO - cfg.model.embed_init_gain          : 1.0\n","2020-11-28 16:31:03,434 - __main__ - INFO - cfg.model.tied_softmax             : False\n","2020-11-28 16:31:03,435 - __main__ - INFO - cfg.model.encoder.type             : transformer\n","2020-11-28 16:31:03,436 - __main__ - INFO - cfg.model.encoder.num_layers       : 2\n","2020-11-28 16:31:03,437 - __main__ - INFO - cfg.model.encoder.num_heads        : 2\n","2020-11-28 16:31:03,438 - __main__ - INFO - cfg.model.encoder.embeddings.embedding_dim : 512\n","2020-11-28 16:31:03,439 - __main__ - INFO - cfg.model.encoder.embeddings.scale : False\n","2020-11-28 16:31:03,440 - __main__ - INFO - cfg.model.encoder.embeddings.dropout : 0.1\n","2020-11-28 16:31:03,441 - __main__ - INFO - cfg.model.encoder.embeddings.norm_type : batch\n","2020-11-28 16:31:03,442 - __main__ - INFO - cfg.model.encoder.embeddings.activation_type : softsign\n","2020-11-28 16:31:03,444 - __main__ - INFO - cfg.model.encoder.hidden_size      : 512\n","2020-11-28 16:31:03,445 - __main__ - INFO - cfg.model.encoder.ff_size          : 2048\n","2020-11-28 16:31:03,446 - __main__ - INFO - cfg.model.encoder.dropout          : 0.1\n","2020-11-28 16:31:03,447 - __main__ - INFO - cfg.model.decoder.type             : transformer\n","2020-11-28 16:31:03,449 - __main__ - INFO - cfg.model.decoder.num_layers       : 1\n","2020-11-28 16:31:03,450 - __main__ - INFO - cfg.model.decoder.num_heads        : 2\n","2020-11-28 16:31:03,451 - __main__ - INFO - cfg.model.decoder.embeddings.embedding_dim : 512\n","2020-11-28 16:31:03,452 - __main__ - INFO - cfg.model.decoder.embeddings.scale : False\n","2020-11-28 16:31:03,453 - __main__ - INFO - cfg.model.decoder.embeddings.dropout : 0.1\n","2020-11-28 16:31:03,454 - __main__ - INFO - cfg.model.decoder.embeddings.norm_type : batch\n","2020-11-28 16:31:03,455 - __main__ - INFO - cfg.model.decoder.embeddings.activation_type : softsign\n","2020-11-28 16:31:03,456 - __main__ - INFO - cfg.model.decoder.hidden_size      : 512\n","2020-11-28 16:31:03,458 - __main__ - INFO - cfg.model.decoder.ff_size          : 2048\n","2020-11-28 16:31:03,460 - __main__ - INFO - cfg.model.decoder.dropout          : 0.1\n","2020-11-28 16:31:03,461 - __main__ - INFO - SignModel(\n","\tencoder=TransformerEncoder(num_layers=2, num_heads=2),\n","\tdecoder=TransformerDecoder(num_layers=1, num_heads=2),\n","\tsgn_embed=SpatialEmbeddings(embedding_dim=512, input_size=240),\n","\ttxt_embed=Embeddings(embedding_dim=512, vocab_size=1396))\n","2020-11-28 16:31:03,462 - __main__ - INFO - EPOCH 1\n","2020-11-28 16:31:05,693 - __main__ - INFO - [Epoch: 001 Step: 00000040] Batch Translation Loss:   7.830501 => Txt Tokens per Sec:     1149 || Lr: 0.001000\n","2020-11-28 16:31:07,851 - __main__ - INFO - [Epoch: 001 Step: 00000080] Batch Translation Loss:   7.674062 => Txt Tokens per Sec:     1188 || Lr: 0.001000\n","2020-11-28 16:31:10,257 - __main__ - INFO - [Epoch: 001 Step: 00000120] Batch Translation Loss:   8.027700 => Txt Tokens per Sec:     1065 || Lr: 0.001000\n","2020-11-28 16:31:12,304 - __main__ - INFO - [Epoch: 001 Step: 00000160] Batch Translation Loss:   7.600580 => Txt Tokens per Sec:     1251 || Lr: 0.001000\n","2020-11-28 16:31:14,437 - __main__ - INFO - [Epoch: 001 Step: 00000200] Batch Translation Loss:   7.594675 => Txt Tokens per Sec:     1202 || Lr: 0.001000\n","2020-11-28 16:31:16,677 - __main__ - INFO - [Epoch: 001 Step: 00000240] Batch Translation Loss:   7.434433 => Txt Tokens per Sec:     1143 || Lr: 0.001000\n","2020-11-28 16:31:18,744 - __main__ - INFO - [Epoch: 001 Step: 00000280] Batch Translation Loss:   7.375077 => Txt Tokens per Sec:     1239 || Lr: 0.001000\n","2020-11-28 16:31:21,012 - __main__ - INFO - Epoch   1: Total Training Recognition Loss -1.00  Total Training Translation Loss 2437.59 \n","2020-11-28 16:31:21,013 - __main__ - INFO - EPOCH 2\n","2020-11-28 16:31:21,191 - __main__ - INFO - [Epoch: 002 Step: 00000320] Batch Translation Loss:   7.314014 => Txt Tokens per Sec:     1093 || Lr: 0.001000\n","2020-11-28 16:31:23,306 - __main__ - INFO - [Epoch: 002 Step: 00000360] Batch Translation Loss:   7.424371 => Txt Tokens per Sec:     1211 || Lr: 0.001000\n","2020-11-28 16:31:25,479 - __main__ - INFO - [Epoch: 002 Step: 00000400] Batch Translation Loss:   7.198124 => Txt Tokens per Sec:     1179 || Lr: 0.001000\n","2020-11-28 16:31:49,161 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:31:49,163 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:31:49,729 - __main__ - INFO - Validation result at epoch   2, step      400: duration: 24.2478s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 17731.92773\tPPL: 33.72501\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 0.36\n","\tCHRF 4.93\tROUGE 0.36\n","2020-11-28 16:31:51,793 - __main__ - INFO - [Epoch: 002 Step: 00000440] Batch Translation Loss:   6.902562 => Txt Tokens per Sec:     1240 || Lr: 0.001000\n","2020-11-28 16:31:53,997 - __main__ - INFO - [Epoch: 002 Step: 00000480] Batch Translation Loss:   6.850016 => Txt Tokens per Sec:     1162 || Lr: 0.001000\n","2020-11-28 16:31:56,161 - __main__ - INFO - [Epoch: 002 Step: 00000520] Batch Translation Loss:   6.726170 => Txt Tokens per Sec:     1184 || Lr: 0.001000\n","2020-11-28 16:31:58,289 - __main__ - INFO - [Epoch: 002 Step: 00000560] Batch Translation Loss:   6.828644 => Txt Tokens per Sec:     1204 || Lr: 0.001000\n","2020-11-28 16:32:00,733 - __main__ - INFO - [Epoch: 002 Step: 00000600] Batch Translation Loss:   6.909552 => Txt Tokens per Sec:     1048 || Lr: 0.001000\n","2020-11-28 16:32:02,697 - __main__ - INFO - Epoch   2: Total Training Recognition Loss -1.00  Total Training Translation Loss 2223.17 \n","2020-11-28 16:32:02,699 - __main__ - INFO - EPOCH 3\n","2020-11-28 16:32:03,179 - __main__ - INFO - [Epoch: 003 Step: 00000640] Batch Translation Loss:   6.927182 => Txt Tokens per Sec:      801 || Lr: 0.001000\n","2020-11-28 16:32:05,179 - __main__ - INFO - [Epoch: 003 Step: 00000680] Batch Translation Loss:   6.732128 => Txt Tokens per Sec:     1282 || Lr: 0.001000\n","2020-11-28 16:32:07,338 - __main__ - INFO - [Epoch: 003 Step: 00000720] Batch Translation Loss:   6.510309 => Txt Tokens per Sec:     1186 || Lr: 0.001000\n","2020-11-28 16:32:09,335 - __main__ - INFO - [Epoch: 003 Step: 00000760] Batch Translation Loss:   6.826761 => Txt Tokens per Sec:     1283 || Lr: 0.001000\n","2020-11-28 16:32:11,518 - __main__ - INFO - [Epoch: 003 Step: 00000800] Batch Translation Loss:   6.788461 => Txt Tokens per Sec:     1174 || Lr: 0.001000\n","2020-11-28 16:32:35,172 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:32:35,174 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:32:35,706 - __main__ - INFO - Validation result at epoch   3, step      800: duration: 24.1870s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 16215.46777\tPPL: 24.96200\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 0.67\n","\tCHRF 5.60\tROUGE 0.67\n","2020-11-28 16:32:37,797 - __main__ - INFO - [Epoch: 003 Step: 00000840] Batch Translation Loss:   6.992199 => Txt Tokens per Sec:     1224 || Lr: 0.001000\n","2020-11-28 16:32:40,075 - __main__ - INFO - [Epoch: 003 Step: 00000880] Batch Translation Loss:   6.298888 => Txt Tokens per Sec:     1125 || Lr: 0.001000\n","2020-11-28 16:32:42,141 - __main__ - INFO - [Epoch: 003 Step: 00000920] Batch Translation Loss:   6.545059 => Txt Tokens per Sec:     1239 || Lr: 0.001000\n","2020-11-28 16:32:43,923 - __main__ - INFO - Epoch   3: Total Training Recognition Loss -1.00  Total Training Translation Loss 2097.39 \n","2020-11-28 16:32:43,925 - __main__ - INFO - EPOCH 4\n","2020-11-28 16:32:44,449 - __main__ - INFO - [Epoch: 004 Step: 00000960] Batch Translation Loss:   6.157660 => Txt Tokens per Sec:     1101 || Lr: 0.001000\n","2020-11-28 16:32:46,839 - __main__ - INFO - [Epoch: 004 Step: 00001000] Batch Translation Loss:   6.472497 => Txt Tokens per Sec:     1072 || Lr: 0.001000\n","2020-11-28 16:32:48,866 - __main__ - INFO - [Epoch: 004 Step: 00001040] Batch Translation Loss:   6.000279 => Txt Tokens per Sec:     1264 || Lr: 0.001000\n","2020-11-28 16:32:50,898 - __main__ - INFO - [Epoch: 004 Step: 00001080] Batch Translation Loss:   6.369301 => Txt Tokens per Sec:     1261 || Lr: 0.001000\n","2020-11-28 16:32:53,077 - __main__ - INFO - [Epoch: 004 Step: 00001120] Batch Translation Loss:   6.664527 => Txt Tokens per Sec:     1175 || Lr: 0.001000\n","2020-11-28 16:32:55,380 - __main__ - INFO - [Epoch: 004 Step: 00001160] Batch Translation Loss:   6.548921 => Txt Tokens per Sec:     1112 || Lr: 0.001000\n","2020-11-28 16:32:57,713 - __main__ - INFO - [Epoch: 004 Step: 00001200] Batch Translation Loss:   6.314559 => Txt Tokens per Sec:     1098 || Lr: 0.001000\n","2020-11-28 16:33:21,283 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:33:21,285 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:33:21,856 - __main__ - INFO - Validation result at epoch   4, step     1200: duration: 24.1422s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 15779.18359\tPPL: 22.89207\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 1.39\n","\tCHRF 5.95\tROUGE 1.39\n","2020-11-28 16:33:23,860 - __main__ - INFO - [Epoch: 004 Step: 00001240] Batch Translation Loss:   6.172820 => Txt Tokens per Sec:     1278 || Lr: 0.001000\n","2020-11-28 16:33:25,637 - __main__ - INFO - Epoch   4: Total Training Recognition Loss -1.00  Total Training Translation Loss 2024.27 \n","2020-11-28 16:33:25,638 - __main__ - INFO - EPOCH 5\n","2020-11-28 16:33:26,385 - __main__ - INFO - [Epoch: 005 Step: 00001280] Batch Translation Loss:   6.137060 => Txt Tokens per Sec:     1031 || Lr: 0.001000\n","2020-11-28 16:33:28,480 - __main__ - INFO - [Epoch: 005 Step: 00001320] Batch Translation Loss:   6.259144 => Txt Tokens per Sec:     1223 || Lr: 0.001000\n","2020-11-28 16:33:30,881 - __main__ - INFO - [Epoch: 005 Step: 00001360] Batch Translation Loss:   6.367305 => Txt Tokens per Sec:     1067 || Lr: 0.001000\n","2020-11-28 16:33:32,855 - __main__ - INFO - [Epoch: 005 Step: 00001400] Batch Translation Loss:   5.940085 => Txt Tokens per Sec:     1298 || Lr: 0.001000\n","2020-11-28 16:33:35,332 - __main__ - INFO - [Epoch: 005 Step: 00001440] Batch Translation Loss:   6.274300 => Txt Tokens per Sec:     1034 || Lr: 0.001000\n","2020-11-28 16:33:37,336 - __main__ - INFO - [Epoch: 005 Step: 00001480] Batch Translation Loss:   6.331757 => Txt Tokens per Sec:     1278 || Lr: 0.001000\n","2020-11-28 16:33:39,460 - __main__ - INFO - [Epoch: 005 Step: 00001520] Batch Translation Loss:   6.265876 => Txt Tokens per Sec:     1206 || Lr: 0.001000\n","2020-11-28 16:33:41,545 - __main__ - INFO - [Epoch: 005 Step: 00001560] Batch Translation Loss:   6.046908 => Txt Tokens per Sec:     1229 || Lr: 0.001000\n","2020-11-28 16:33:43,041 - __main__ - INFO - Epoch   5: Total Training Recognition Loss -1.00  Total Training Translation Loss 1973.99 \n","2020-11-28 16:33:43,042 - __main__ - INFO - EPOCH 6\n","2020-11-28 16:33:43,851 - __main__ - INFO - [Epoch: 006 Step: 00001600] Batch Translation Loss:   5.770831 => Txt Tokens per Sec:     1189 || Lr: 0.001000\n","2020-11-28 16:34:07,144 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:34:07,145 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:34:07,821 - __main__ - INFO - Validation result at epoch   6, step     1600: duration: 23.9682s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 15398.81934\tPPL: 21.22801\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 1.47\n","\tCHRF 5.61\tROUGE 1.47\n","2020-11-28 16:34:10,011 - __main__ - INFO - [Epoch: 006 Step: 00001640] Batch Translation Loss:   6.118024 => Txt Tokens per Sec:     1169 || Lr: 0.001000\n","2020-11-28 16:34:12,104 - __main__ - INFO - [Epoch: 006 Step: 00001680] Batch Translation Loss:   6.250540 => Txt Tokens per Sec:     1224 || Lr: 0.001000\n","2020-11-28 16:34:14,465 - __main__ - INFO - [Epoch: 006 Step: 00001720] Batch Translation Loss:   5.804100 => Txt Tokens per Sec:     1085 || Lr: 0.001000\n","2020-11-28 16:34:16,774 - __main__ - INFO - [Epoch: 006 Step: 00001760] Batch Translation Loss:   5.797535 => Txt Tokens per Sec:     1109 || Lr: 0.001000\n","2020-11-28 16:34:18,813 - __main__ - INFO - [Epoch: 006 Step: 00001800] Batch Translation Loss:   6.100383 => Txt Tokens per Sec:     1256 || Lr: 0.001000\n","2020-11-28 16:34:20,872 - __main__ - INFO - [Epoch: 006 Step: 00001840] Batch Translation Loss:   6.124429 => Txt Tokens per Sec:     1244 || Lr: 0.001000\n","2020-11-28 16:34:22,918 - __main__ - INFO - [Epoch: 006 Step: 00001880] Batch Translation Loss:   6.287000 => Txt Tokens per Sec:     1252 || Lr: 0.001000\n","2020-11-28 16:34:24,382 - __main__ - INFO - Epoch   6: Total Training Recognition Loss -1.00  Total Training Translation Loss 1928.45 \n","2020-11-28 16:34:24,383 - __main__ - INFO - EPOCH 7\n","2020-11-28 16:34:25,391 - __main__ - INFO - [Epoch: 007 Step: 00001920] Batch Translation Loss:   6.136363 => Txt Tokens per Sec:     1145 || Lr: 0.001000\n","2020-11-28 16:34:27,452 - __main__ - INFO - [Epoch: 007 Step: 00001960] Batch Translation Loss:   5.847818 => Txt Tokens per Sec:     1243 || Lr: 0.001000\n","2020-11-28 16:34:29,548 - __main__ - INFO - [Epoch: 007 Step: 00002000] Batch Translation Loss:   6.157789 => Txt Tokens per Sec:     1222 || Lr: 0.001000\n","2020-11-28 16:34:52,796 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:34:52,798 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:34:53,371 - __main__ - INFO - Validation result at epoch   7, step     2000: duration: 23.8220s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 14998.12988\tPPL: 19.60568\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 2.10\n","\tCHRF 6.41\tROUGE 2.10\n","2020-11-28 16:34:55,541 - __main__ - INFO - [Epoch: 007 Step: 00002040] Batch Translation Loss:   6.270041 => Txt Tokens per Sec:     1180 || Lr: 0.001000\n","2020-11-28 16:34:57,610 - __main__ - INFO - [Epoch: 007 Step: 00002080] Batch Translation Loss:   6.226610 => Txt Tokens per Sec:     1238 || Lr: 0.001000\n","2020-11-28 16:34:59,918 - __main__ - INFO - [Epoch: 007 Step: 00002120] Batch Translation Loss:   6.380189 => Txt Tokens per Sec:     1110 || Lr: 0.001000\n","2020-11-28 16:35:02,300 - __main__ - INFO - [Epoch: 007 Step: 00002160] Batch Translation Loss:   5.748797 => Txt Tokens per Sec:     1075 || Lr: 0.001000\n","2020-11-28 16:35:04,412 - __main__ - INFO - [Epoch: 007 Step: 00002200] Batch Translation Loss:   5.735349 => Txt Tokens per Sec:     1214 || Lr: 0.001000\n","2020-11-28 16:35:05,581 - __main__ - INFO - Epoch   7: Total Training Recognition Loss -1.00  Total Training Translation Loss 1888.75 \n","2020-11-28 16:35:05,584 - __main__ - INFO - EPOCH 8\n","2020-11-28 16:35:06,670 - __main__ - INFO - [Epoch: 008 Step: 00002240] Batch Translation Loss:   5.351246 => Txt Tokens per Sec:     1239 || Lr: 0.001000\n","2020-11-28 16:35:08,690 - __main__ - INFO - [Epoch: 008 Step: 00002280] Batch Translation Loss:   5.743515 => Txt Tokens per Sec:     1268 || Lr: 0.001000\n","2020-11-28 16:35:10,905 - __main__ - INFO - [Epoch: 008 Step: 00002320] Batch Translation Loss:   5.725379 => Txt Tokens per Sec:     1156 || Lr: 0.001000\n","2020-11-28 16:35:13,010 - __main__ - INFO - [Epoch: 008 Step: 00002360] Batch Translation Loss:   5.533868 => Txt Tokens per Sec:     1217 || Lr: 0.001000\n","2020-11-28 16:35:15,216 - __main__ - INFO - [Epoch: 008 Step: 00002400] Batch Translation Loss:   5.860116 => Txt Tokens per Sec:     1161 || Lr: 0.001000\n","2020-11-28 16:35:38,650 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:35:38,652 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:35:39,218 - __main__ - INFO - Validation result at epoch   8, step     2400: duration: 24.0001s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 14671.26660\tPPL: 18.37453\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 2.98\n","\tCHRF 7.18\tROUGE 2.98\n","2020-11-28 16:35:41,198 - __main__ - INFO - [Epoch: 008 Step: 00002440] Batch Translation Loss:   5.934447 => Txt Tokens per Sec:     1293 || Lr: 0.001000\n","2020-11-28 16:35:43,355 - __main__ - INFO - [Epoch: 008 Step: 00002480] Batch Translation Loss:   5.739273 => Txt Tokens per Sec:     1188 || Lr: 0.001000\n","2020-11-28 16:35:45,504 - __main__ - INFO - [Epoch: 008 Step: 00002520] Batch Translation Loss:   5.708296 => Txt Tokens per Sec:     1193 || Lr: 0.001000\n","2020-11-28 16:35:46,614 - __main__ - INFO - Epoch   8: Total Training Recognition Loss -1.00  Total Training Translation Loss 1844.26 \n","2020-11-28 16:35:46,615 - __main__ - INFO - EPOCH 9\n","2020-11-28 16:35:47,911 - __main__ - INFO - [Epoch: 009 Step: 00002560] Batch Translation Loss:   5.527566 => Txt Tokens per Sec:     1187 || Lr: 0.001000\n","2020-11-28 16:35:50,007 - __main__ - INFO - [Epoch: 009 Step: 00002600] Batch Translation Loss:   5.239039 => Txt Tokens per Sec:     1222 || Lr: 0.001000\n","2020-11-28 16:35:52,359 - __main__ - INFO - [Epoch: 009 Step: 00002640] Batch Translation Loss:   5.750331 => Txt Tokens per Sec:     1089 || Lr: 0.001000\n","2020-11-28 16:35:54,376 - __main__ - INFO - [Epoch: 009 Step: 00002680] Batch Translation Loss:   5.954770 => Txt Tokens per Sec:     1270 || Lr: 0.001000\n","2020-11-28 16:35:56,584 - __main__ - INFO - [Epoch: 009 Step: 00002720] Batch Translation Loss:   6.018105 => Txt Tokens per Sec:     1160 || Lr: 0.001000\n","2020-11-28 16:35:58,650 - __main__ - INFO - [Epoch: 009 Step: 00002760] Batch Translation Loss:   5.837795 => Txt Tokens per Sec:     1240 || Lr: 0.001000\n","2020-11-28 16:36:00,705 - __main__ - INFO - [Epoch: 009 Step: 00002800] Batch Translation Loss:   5.850651 => Txt Tokens per Sec:     1247 || Lr: 0.001000\n","2020-11-28 16:36:24,237 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:36:24,239 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:36:24,814 - __main__ - INFO - Validation result at epoch   9, step     2800: duration: 24.1084s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 14282.40527\tPPL: 17.01016\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 3.13\n","\tCHRF 7.64\tROUGE 3.13\n","2020-11-28 16:36:27,039 - __main__ - INFO - [Epoch: 009 Step: 00002840] Batch Translation Loss:   5.276289 => Txt Tokens per Sec:     1141 || Lr: 0.001000\n","2020-11-28 16:36:27,821 - __main__ - INFO - Epoch   9: Total Training Recognition Loss -1.00  Total Training Translation Loss 1795.77 \n","2020-11-28 16:36:27,823 - __main__ - INFO - EPOCH 10\n","2020-11-28 16:36:29,233 - __main__ - INFO - [Epoch: 010 Step: 00002880] Batch Translation Loss:   4.922239 => Txt Tokens per Sec:     1226 || Lr: 0.001000\n","2020-11-28 16:36:31,327 - __main__ - INFO - [Epoch: 010 Step: 00002920] Batch Translation Loss:   5.525689 => Txt Tokens per Sec:     1224 || Lr: 0.001000\n","2020-11-28 16:36:33,631 - __main__ - INFO - [Epoch: 010 Step: 00002960] Batch Translation Loss:   5.493839 => Txt Tokens per Sec:     1112 || Lr: 0.001000\n","2020-11-28 16:36:36,060 - __main__ - INFO - [Epoch: 010 Step: 00003000] Batch Translation Loss:   5.586241 => Txt Tokens per Sec:     1055 || Lr: 0.001000\n","2020-11-28 16:36:38,188 - __main__ - INFO - [Epoch: 010 Step: 00003040] Batch Translation Loss:   6.178605 => Txt Tokens per Sec:     1204 || Lr: 0.001000\n","2020-11-28 16:36:40,329 - __main__ - INFO - [Epoch: 010 Step: 00003080] Batch Translation Loss:   5.142683 => Txt Tokens per Sec:     1197 || Lr: 0.001000\n","2020-11-28 16:36:42,416 - __main__ - INFO - [Epoch: 010 Step: 00003120] Batch Translation Loss:   5.863524 => Txt Tokens per Sec:     1227 || Lr: 0.001000\n","2020-11-28 16:36:44,507 - __main__ - INFO - [Epoch: 010 Step: 00003160] Batch Translation Loss:   6.113958 => Txt Tokens per Sec:     1226 || Lr: 0.001000\n","2020-11-28 16:36:45,250 - __main__ - INFO - Epoch  10: Total Training Recognition Loss -1.00  Total Training Translation Loss 1740.57 \n","2020-11-28 16:36:45,251 - __main__ - INFO - EPOCH 11\n","2020-11-28 16:36:46,927 - __main__ - INFO - [Epoch: 011 Step: 00003200] Batch Translation Loss:   5.817394 => Txt Tokens per Sec:     1147 || Lr: 0.001000\n","2020-11-28 16:37:10,593 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:37:10,595 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:37:11,158 - __main__ - INFO - Validation result at epoch  11, step     3200: duration: 24.2297s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 13645.07910\tPPL: 14.98960\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 4.56\n","\tCHRF 9.44\tROUGE 4.56\n","2020-11-28 16:37:13,245 - __main__ - INFO - [Epoch: 011 Step: 00003240] Batch Translation Loss:   5.542006 => Txt Tokens per Sec:     1227 || Lr: 0.001000\n","2020-11-28 16:37:15,262 - __main__ - INFO - [Epoch: 011 Step: 00003280] Batch Translation Loss:   5.467526 => Txt Tokens per Sec:     1270 || Lr: 0.001000\n","2020-11-28 16:37:17,285 - __main__ - INFO - [Epoch: 011 Step: 00003320] Batch Translation Loss:   5.116813 => Txt Tokens per Sec:     1267 || Lr: 0.001000\n","2020-11-28 16:37:19,759 - __main__ - INFO - [Epoch: 011 Step: 00003360] Batch Translation Loss:   5.390514 => Txt Tokens per Sec:     1036 || Lr: 0.001000\n","2020-11-28 16:37:21,922 - __main__ - INFO - [Epoch: 011 Step: 00003400] Batch Translation Loss:   5.111679 => Txt Tokens per Sec:     1184 || Lr: 0.001000\n","2020-11-28 16:37:24,179 - __main__ - INFO - [Epoch: 011 Step: 00003440] Batch Translation Loss:   5.305490 => Txt Tokens per Sec:     1135 || Lr: 0.001000\n","2020-11-28 16:37:26,341 - __main__ - INFO - [Epoch: 011 Step: 00003480] Batch Translation Loss:   5.320129 => Txt Tokens per Sec:     1185 || Lr: 0.001000\n","2020-11-28 16:37:26,863 - __main__ - INFO - Epoch  11: Total Training Recognition Loss -1.00  Total Training Translation Loss 1701.55 \n","2020-11-28 16:37:26,864 - __main__ - INFO - EPOCH 12\n","2020-11-28 16:37:28,808 - __main__ - INFO - [Epoch: 012 Step: 00003520] Batch Translation Loss:   5.320666 => Txt Tokens per Sec:     1088 || Lr: 0.001000\n","2020-11-28 16:37:30,897 - __main__ - INFO - [Epoch: 012 Step: 00003560] Batch Translation Loss:   5.441601 => Txt Tokens per Sec:     1226 || Lr: 0.001000\n","2020-11-28 16:37:33,001 - __main__ - INFO - [Epoch: 012 Step: 00003600] Batch Translation Loss:   5.347069 => Txt Tokens per Sec:     1218 || Lr: 0.001000\n","2020-11-28 16:37:57,055 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:37:57,056 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:37:57,593 - __main__ - INFO - Validation result at epoch  12, step     3600: duration: 24.5912s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 13418.92871\tPPL: 14.33187\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 5.40\n","\tCHRF 9.91\tROUGE 5.40\n","2020-11-28 16:37:59,797 - __main__ - INFO - [Epoch: 012 Step: 00003640] Batch Translation Loss:   5.189300 => Txt Tokens per Sec:     1161 || Lr: 0.001000\n","2020-11-28 16:38:01,878 - __main__ - INFO - [Epoch: 012 Step: 00003680] Batch Translation Loss:   5.400654 => Txt Tokens per Sec:     1231 || Lr: 0.001000\n","2020-11-28 16:38:03,922 - __main__ - INFO - [Epoch: 012 Step: 00003720] Batch Translation Loss:   5.240634 => Txt Tokens per Sec:     1253 || Lr: 0.001000\n","2020-11-28 16:38:06,390 - __main__ - INFO - [Epoch: 012 Step: 00003760] Batch Translation Loss:   6.035747 => Txt Tokens per Sec:     1038 || Lr: 0.001000\n","2020-11-28 16:38:08,668 - __main__ - INFO - [Epoch: 012 Step: 00003800] Batch Translation Loss:   5.172313 => Txt Tokens per Sec:     1115 || Lr: 0.001000\n","2020-11-28 16:38:08,888 - __main__ - INFO - Epoch  12: Total Training Recognition Loss -1.00  Total Training Translation Loss 1667.43 \n","2020-11-28 16:38:08,890 - __main__ - INFO - EPOCH 13\n","2020-11-28 16:38:10,980 - __main__ - INFO - [Epoch: 013 Step: 00003840] Batch Translation Loss:   5.470476 => Txt Tokens per Sec:     1103 || Lr: 0.001000\n","2020-11-28 16:38:12,955 - __main__ - INFO - [Epoch: 013 Step: 00003880] Batch Translation Loss:   5.196431 => Txt Tokens per Sec:     1298 || Lr: 0.001000\n","2020-11-28 16:38:15,159 - __main__ - INFO - [Epoch: 013 Step: 00003920] Batch Translation Loss:   5.224664 => Txt Tokens per Sec:     1162 || Lr: 0.001000\n","2020-11-28 16:38:17,385 - __main__ - INFO - [Epoch: 013 Step: 00003960] Batch Translation Loss:   5.655806 => Txt Tokens per Sec:     1151 || Lr: 0.001000\n","2020-11-28 16:38:19,363 - __main__ - INFO - [Epoch: 013 Step: 00004000] Batch Translation Loss:   4.934144 => Txt Tokens per Sec:     1295 || Lr: 0.001000\n","2020-11-28 16:38:42,703 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:38:42,704 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:38:43,271 - __main__ - INFO - Validation result at epoch  13, step     4000: duration: 23.9068s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 13120.60059\tPPL: 13.50816\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 7.14\n","\tCHRF 10.92\tROUGE 7.14\n","2020-11-28 16:38:45,218 - __main__ - INFO - [Epoch: 013 Step: 00004040] Batch Translation Loss:   4.613373 => Txt Tokens per Sec:     1315 || Lr: 0.001000\n","2020-11-28 16:38:47,345 - __main__ - INFO - [Epoch: 013 Step: 00004080] Batch Translation Loss:   4.970966 => Txt Tokens per Sec:     1204 || Lr: 0.001000\n","2020-11-28 16:38:49,856 - __main__ - INFO - [Epoch: 013 Step: 00004120] Batch Translation Loss:   5.349431 => Txt Tokens per Sec:     1011 || Lr: 0.001000\n","2020-11-28 16:38:49,921 - __main__ - INFO - Epoch  13: Total Training Recognition Loss -1.00  Total Training Translation Loss 1634.59 \n","2020-11-28 16:38:49,922 - __main__ - INFO - EPOCH 14\n","2020-11-28 16:38:52,272 - __main__ - INFO - [Epoch: 014 Step: 00004160] Batch Translation Loss:   5.447907 => Txt Tokens per Sec:     1063 || Lr: 0.001000\n","2020-11-28 16:38:54,303 - __main__ - INFO - [Epoch: 014 Step: 00004200] Batch Translation Loss:   5.149911 => Txt Tokens per Sec:     1261 || Lr: 0.001000\n","2020-11-28 16:38:56,385 - __main__ - INFO - [Epoch: 014 Step: 00004240] Batch Translation Loss:   4.972223 => Txt Tokens per Sec:     1231 || Lr: 0.001000\n","2020-11-28 16:38:58,469 - __main__ - INFO - [Epoch: 014 Step: 00004280] Batch Translation Loss:   4.987078 => Txt Tokens per Sec:     1229 || Lr: 0.001000\n","2020-11-28 16:39:00,807 - __main__ - INFO - [Epoch: 014 Step: 00004320] Batch Translation Loss:   5.355734 => Txt Tokens per Sec:     1096 || Lr: 0.001000\n","2020-11-28 16:39:02,924 - __main__ - INFO - [Epoch: 014 Step: 00004360] Batch Translation Loss:   5.272201 => Txt Tokens per Sec:     1211 || Lr: 0.001000\n","2020-11-28 16:39:05,002 - __main__ - INFO - [Epoch: 014 Step: 00004400] Batch Translation Loss:   5.144767 => Txt Tokens per Sec:     1233 || Lr: 0.001000\n","2020-11-28 16:39:28,219 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:39:28,220 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:39:28,777 - __main__ - INFO - Validation result at epoch  14, step     4400: duration: 23.7743s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 12923.39648\tPPL: 12.98982\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 7.66\n","\tCHRF 12.51\tROUGE 7.66\n","2020-11-28 16:39:30,977 - __main__ - INFO - Epoch  14: Total Training Recognition Loss -1.00  Total Training Translation Loss 1604.50 \n","2020-11-28 16:39:30,979 - __main__ - INFO - EPOCH 15\n","2020-11-28 16:39:31,107 - __main__ - INFO - [Epoch: 015 Step: 00004440] Batch Translation Loss:   4.410927 => Txt Tokens per Sec:     1010 || Lr: 0.001000\n","2020-11-28 16:39:33,041 - __main__ - INFO - [Epoch: 015 Step: 00004480] Batch Translation Loss:   4.606199 => Txt Tokens per Sec:     1324 || Lr: 0.001000\n","2020-11-28 16:39:35,261 - __main__ - INFO - [Epoch: 015 Step: 00004520] Batch Translation Loss:   4.671861 => Txt Tokens per Sec:     1154 || Lr: 0.001000\n","2020-11-28 16:39:37,263 - __main__ - INFO - [Epoch: 015 Step: 00004560] Batch Translation Loss:   4.899718 => Txt Tokens per Sec:     1280 || Lr: 0.001000\n","2020-11-28 16:39:39,541 - __main__ - INFO - [Epoch: 015 Step: 00004600] Batch Translation Loss:   5.115727 => Txt Tokens per Sec:     1125 || Lr: 0.001000\n","2020-11-28 16:39:41,826 - __main__ - INFO - [Epoch: 015 Step: 00004640] Batch Translation Loss:   4.716861 => Txt Tokens per Sec:     1121 || Lr: 0.001000\n","2020-11-28 16:39:43,940 - __main__ - INFO - [Epoch: 015 Step: 00004680] Batch Translation Loss:   5.263180 => Txt Tokens per Sec:     1212 || Lr: 0.001000\n","2020-11-28 16:39:46,001 - __main__ - INFO - [Epoch: 015 Step: 00004720] Batch Translation Loss:   4.613242 => Txt Tokens per Sec:     1243 || Lr: 0.001000\n","2020-11-28 16:39:48,130 - __main__ - INFO - Epoch  15: Total Training Recognition Loss -1.00  Total Training Translation Loss 1575.08 \n","2020-11-28 16:39:48,131 - __main__ - INFO - EPOCH 16\n","2020-11-28 16:39:48,399 - __main__ - INFO - [Epoch: 016 Step: 00004760] Batch Translation Loss:   4.315185 => Txt Tokens per Sec:     1204 || Lr: 0.001000\n","2020-11-28 16:39:50,597 - __main__ - INFO - [Epoch: 016 Step: 00004800] Batch Translation Loss:   4.926029 => Txt Tokens per Sec:     1166 || Lr: 0.001000\n","2020-11-28 16:40:13,447 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:40:13,449 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:40:14,028 - __main__ - INFO - Validation result at epoch  16, step     4800: duration: 23.4299s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 12809.86523\tPPL: 12.70048\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 7.74\n","\tCHRF 11.60\tROUGE 7.74\n","2020-11-28 16:40:16,124 - __main__ - INFO - [Epoch: 016 Step: 00004840] Batch Translation Loss:   5.161681 => Txt Tokens per Sec:     1221 || Lr: 0.001000\n","2020-11-28 16:40:18,108 - __main__ - INFO - [Epoch: 016 Step: 00004880] Batch Translation Loss:   5.074895 => Txt Tokens per Sec:     1291 || Lr: 0.001000\n","2020-11-28 16:40:20,266 - __main__ - INFO - [Epoch: 016 Step: 00004920] Batch Translation Loss:   4.711809 => Txt Tokens per Sec:     1187 || Lr: 0.001000\n","2020-11-28 16:40:22,605 - __main__ - INFO - [Epoch: 016 Step: 00004960] Batch Translation Loss:   4.671061 => Txt Tokens per Sec:     1095 || Lr: 0.001000\n","2020-11-28 16:40:24,887 - __main__ - INFO - [Epoch: 016 Step: 00005000] Batch Translation Loss:   4.906789 => Txt Tokens per Sec:     1122 || Lr: 0.001000\n","2020-11-28 16:40:27,414 - __main__ - INFO - [Epoch: 016 Step: 00005040] Batch Translation Loss:   4.953269 => Txt Tokens per Sec:     1014 || Lr: 0.001000\n","2020-11-28 16:40:29,254 - __main__ - INFO - Epoch  16: Total Training Recognition Loss -1.00  Total Training Translation Loss 1540.84 \n","2020-11-28 16:40:29,256 - __main__ - INFO - EPOCH 17\n","2020-11-28 16:40:29,701 - __main__ - INFO - [Epoch: 017 Step: 00005080] Batch Translation Loss:   4.826089 => Txt Tokens per Sec:     1152 || Lr: 0.001000\n","2020-11-28 16:40:31,875 - __main__ - INFO - [Epoch: 017 Step: 00005120] Batch Translation Loss:   5.054628 => Txt Tokens per Sec:     1178 || Lr: 0.001000\n","2020-11-28 16:40:33,980 - __main__ - INFO - [Epoch: 017 Step: 00005160] Batch Translation Loss:   4.012756 => Txt Tokens per Sec:     1217 || Lr: 0.001000\n","2020-11-28 16:40:36,128 - __main__ - INFO - [Epoch: 017 Step: 00005200] Batch Translation Loss:   5.260947 => Txt Tokens per Sec:     1192 || Lr: 0.001000\n","2020-11-28 16:40:59,591 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:40:59,592 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:41:00,185 - __main__ - INFO - Validation result at epoch  17, step     5200: duration: 24.0559s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 12563.94238\tPPL: 12.09565\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 9.37\n","\tCHRF 13.59\tROUGE 9.37\n","2020-11-28 16:41:02,166 - __main__ - INFO - [Epoch: 017 Step: 00005240] Batch Translation Loss:   4.503747 => Txt Tokens per Sec:     1292 || Lr: 0.001000\n","2020-11-28 16:41:04,149 - __main__ - INFO - [Epoch: 017 Step: 00005280] Batch Translation Loss:   4.742750 => Txt Tokens per Sec:     1292 || Lr: 0.001000\n","2020-11-28 16:41:06,219 - __main__ - INFO - [Epoch: 017 Step: 00005320] Batch Translation Loss:   4.508258 => Txt Tokens per Sec:     1237 || Lr: 0.001000\n","2020-11-28 16:41:08,264 - __main__ - INFO - [Epoch: 017 Step: 00005360] Batch Translation Loss:   5.215917 => Txt Tokens per Sec:     1253 || Lr: 0.001000\n","2020-11-28 16:41:10,388 - __main__ - INFO - Epoch  17: Total Training Recognition Loss -1.00  Total Training Translation Loss 1502.96 \n","2020-11-28 16:41:10,389 - __main__ - INFO - EPOCH 18\n","2020-11-28 16:41:11,094 - __main__ - INFO - [Epoch: 018 Step: 00005400] Batch Translation Loss:   4.687713 => Txt Tokens per Sec:     1001 || Lr: 0.001000\n","2020-11-28 16:41:13,287 - __main__ - INFO - [Epoch: 018 Step: 00005440] Batch Translation Loss:   4.647963 => Txt Tokens per Sec:     1168 || Lr: 0.001000\n","2020-11-28 16:41:15,408 - __main__ - INFO - [Epoch: 018 Step: 00005480] Batch Translation Loss:   4.739819 => Txt Tokens per Sec:     1208 || Lr: 0.001000\n","2020-11-28 16:41:17,594 - __main__ - INFO - [Epoch: 018 Step: 00005520] Batch Translation Loss:   4.682614 => Txt Tokens per Sec:     1172 || Lr: 0.001000\n","2020-11-28 16:41:19,713 - __main__ - INFO - [Epoch: 018 Step: 00005560] Batch Translation Loss:   5.520018 => Txt Tokens per Sec:     1209 || Lr: 0.001000\n","2020-11-28 16:41:21,744 - __main__ - INFO - [Epoch: 018 Step: 00005600] Batch Translation Loss:   4.767617 => Txt Tokens per Sec:     1261 || Lr: 0.001000\n","2020-11-28 16:41:46,058 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:41:46,059 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:41:46,625 - __main__ - INFO - Validation result at epoch  18, step     5600: duration: 24.8803s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 12257.94922\tPPL: 11.38313\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 9.84\n","\tCHRF 13.78\tROUGE 9.84\n","2020-11-28 16:41:48,694 - __main__ - INFO - [Epoch: 018 Step: 00005640] Batch Translation Loss:   5.001902 => Txt Tokens per Sec:     1238 || Lr: 0.001000\n","2020-11-28 16:41:50,956 - __main__ - INFO - [Epoch: 018 Step: 00005680] Batch Translation Loss:   4.798494 => Txt Tokens per Sec:     1132 || Lr: 0.001000\n","2020-11-28 16:41:52,614 - __main__ - INFO - Epoch  18: Total Training Recognition Loss -1.00  Total Training Translation Loss 1476.07 \n","2020-11-28 16:41:52,615 - __main__ - INFO - EPOCH 19\n","2020-11-28 16:41:53,330 - __main__ - INFO - [Epoch: 019 Step: 00005720] Batch Translation Loss:   4.781604 => Txt Tokens per Sec:     1257 || Lr: 0.001000\n","2020-11-28 16:41:55,645 - __main__ - INFO - [Epoch: 019 Step: 00005760] Batch Translation Loss:   4.580265 => Txt Tokens per Sec:     1106 || Lr: 0.001000\n","2020-11-28 16:41:57,917 - __main__ - INFO - [Epoch: 019 Step: 00005800] Batch Translation Loss:   4.271420 => Txt Tokens per Sec:     1128 || Lr: 0.001000\n","2020-11-28 16:41:59,993 - __main__ - INFO - [Epoch: 019 Step: 00005840] Batch Translation Loss:   4.235181 => Txt Tokens per Sec:     1235 || Lr: 0.001000\n","2020-11-28 16:42:02,224 - __main__ - INFO - [Epoch: 019 Step: 00005880] Batch Translation Loss:   4.793168 => Txt Tokens per Sec:     1148 || Lr: 0.001000\n","2020-11-28 16:42:04,257 - __main__ - INFO - [Epoch: 019 Step: 00005920] Batch Translation Loss:   4.352346 => Txt Tokens per Sec:     1260 || Lr: 0.001000\n","2020-11-28 16:42:06,416 - __main__ - INFO - [Epoch: 019 Step: 00005960] Batch Translation Loss:   4.944693 => Txt Tokens per Sec:     1187 || Lr: 0.001000\n","2020-11-28 16:42:08,530 - __main__ - INFO - [Epoch: 019 Step: 00006000] Batch Translation Loss:   5.012402 => Txt Tokens per Sec:     1212 || Lr: 0.001000\n","2020-11-28 16:42:32,113 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:42:32,114 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:42:32,689 - __main__ - INFO - Validation result at epoch  19, step     6000: duration: 24.1583s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 11908.11230\tPPL: 10.61981\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 11.07\n","\tCHRF 15.28\tROUGE 11.07\n","2020-11-28 16:42:34,196 - __main__ - INFO - Epoch  19: Total Training Recognition Loss -1.00  Total Training Translation Loss 1437.78 \n","2020-11-28 16:42:34,197 - __main__ - INFO - EPOCH 20\n","2020-11-28 16:42:35,085 - __main__ - INFO - [Epoch: 020 Step: 00006040] Batch Translation Loss:   4.292237 => Txt Tokens per Sec:     1228 || Lr: 0.001000\n","2020-11-28 16:42:37,140 - __main__ - INFO - [Epoch: 020 Step: 00006080] Batch Translation Loss:   3.887709 => Txt Tokens per Sec:     1247 || Lr: 0.001000\n","2020-11-28 16:42:39,171 - __main__ - INFO - [Epoch: 020 Step: 00006120] Batch Translation Loss:   4.087523 => Txt Tokens per Sec:     1261 || Lr: 0.001000\n","2020-11-28 16:42:41,833 - __main__ - INFO - [Epoch: 020 Step: 00006160] Batch Translation Loss:   3.998110 => Txt Tokens per Sec:      962 || Lr: 0.001000\n","2020-11-28 16:42:43,927 - __main__ - INFO - [Epoch: 020 Step: 00006200] Batch Translation Loss:   4.021288 => Txt Tokens per Sec:     1223 || Lr: 0.001000\n","2020-11-28 16:42:46,088 - __main__ - INFO - [Epoch: 020 Step: 00006240] Batch Translation Loss:   4.225543 => Txt Tokens per Sec:     1186 || Lr: 0.001000\n","2020-11-28 16:42:48,433 - __main__ - INFO - [Epoch: 020 Step: 00006280] Batch Translation Loss:   4.487014 => Txt Tokens per Sec:     1092 || Lr: 0.001000\n","2020-11-28 16:42:50,619 - __main__ - INFO - [Epoch: 020 Step: 00006320] Batch Translation Loss:   4.379756 => Txt Tokens per Sec:     1172 || Lr: 0.001000\n","2020-11-28 16:42:51,946 - __main__ - INFO - Epoch  20: Total Training Recognition Loss -1.00  Total Training Translation Loss 1421.89 \n","2020-11-28 16:42:51,947 - __main__ - INFO - EPOCH 21\n","2020-11-28 16:42:53,096 - __main__ - INFO - [Epoch: 021 Step: 00006360] Batch Translation Loss:   3.833733 => Txt Tokens per Sec:     1116 || Lr: 0.001000\n","2020-11-28 16:42:55,195 - __main__ - INFO - [Epoch: 021 Step: 00006400] Batch Translation Loss:   4.102710 => Txt Tokens per Sec:     1221 || Lr: 0.001000\n","2020-11-28 16:43:18,845 - __main__ - INFO - Validation result at epoch  21, step     6400: duration: 23.6489s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 11943.44141\tPPL: 10.69451\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 10.63\n","\tCHRF 15.37\tROUGE 10.63\n","2020-11-28 16:43:21,055 - __main__ - INFO - [Epoch: 021 Step: 00006440] Batch Translation Loss:   3.974946 => Txt Tokens per Sec:     1158 || Lr: 0.001000\n","2020-11-28 16:43:23,158 - __main__ - INFO - [Epoch: 021 Step: 00006480] Batch Translation Loss:   4.056211 => Txt Tokens per Sec:     1218 || Lr: 0.001000\n","2020-11-28 16:43:25,379 - __main__ - INFO - [Epoch: 021 Step: 00006520] Batch Translation Loss:   4.877815 => Txt Tokens per Sec:     1154 || Lr: 0.001000\n","2020-11-28 16:43:27,334 - __main__ - INFO - [Epoch: 021 Step: 00006560] Batch Translation Loss:   5.077996 => Txt Tokens per Sec:     1310 || Lr: 0.001000\n","2020-11-28 16:43:29,625 - __main__ - INFO - [Epoch: 021 Step: 00006600] Batch Translation Loss:   4.150253 => Txt Tokens per Sec:     1118 || Lr: 0.001000\n","2020-11-28 16:43:31,726 - __main__ - INFO - [Epoch: 021 Step: 00006640] Batch Translation Loss:   4.883111 => Txt Tokens per Sec:     1219 || Lr: 0.001000\n","2020-11-28 16:43:32,874 - __main__ - INFO - Epoch  21: Total Training Recognition Loss -1.00  Total Training Translation Loss 1401.90 \n","2020-11-28 16:43:32,875 - __main__ - INFO - EPOCH 22\n","2020-11-28 16:43:34,149 - __main__ - INFO - [Epoch: 022 Step: 00006680] Batch Translation Loss:   3.547150 => Txt Tokens per Sec:     1158 || Lr: 0.001000\n","2020-11-28 16:43:36,408 - __main__ - INFO - [Epoch: 022 Step: 00006720] Batch Translation Loss:   4.185022 => Txt Tokens per Sec:     1134 || Lr: 0.001000\n","2020-11-28 16:43:38,466 - __main__ - INFO - [Epoch: 022 Step: 00006760] Batch Translation Loss:   5.204620 => Txt Tokens per Sec:     1245 || Lr: 0.001000\n","2020-11-28 16:43:40,522 - __main__ - INFO - [Epoch: 022 Step: 00006800] Batch Translation Loss:   4.499095 => Txt Tokens per Sec:     1246 || Lr: 0.001000\n","2020-11-28 16:44:03,940 - __main__ - INFO - Validation result at epoch  22, step     6800: duration: 23.4166s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 11937.54883\tPPL: 10.68201\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 10.75\n","\tCHRF 15.43\tROUGE 10.75\n","2020-11-28 16:44:06,026 - __main__ - INFO - [Epoch: 022 Step: 00006840] Batch Translation Loss:   4.412655 => Txt Tokens per Sec:     1227 || Lr: 0.001000\n","2020-11-28 16:44:08,233 - __main__ - INFO - [Epoch: 022 Step: 00006880] Batch Translation Loss:   5.075077 => Txt Tokens per Sec:     1161 || Lr: 0.001000\n","2020-11-28 16:44:10,374 - __main__ - INFO - [Epoch: 022 Step: 00006920] Batch Translation Loss:   4.637486 => Txt Tokens per Sec:     1197 || Lr: 0.001000\n","2020-11-28 16:44:12,604 - __main__ - INFO - [Epoch: 022 Step: 00006960] Batch Translation Loss:   4.653646 => Txt Tokens per Sec:     1148 || Lr: 0.001000\n","2020-11-28 16:44:13,592 - __main__ - INFO - Epoch  22: Total Training Recognition Loss -1.00  Total Training Translation Loss 1378.90 \n","2020-11-28 16:44:13,594 - __main__ - INFO - EPOCH 23\n","2020-11-28 16:44:15,073 - __main__ - INFO - [Epoch: 023 Step: 00007000] Batch Translation Loss:   3.987105 => Txt Tokens per Sec:     1127 || Lr: 0.001000\n","2020-11-28 16:44:17,151 - __main__ - INFO - [Epoch: 023 Step: 00007040] Batch Translation Loss:   4.895252 => Txt Tokens per Sec:     1233 || Lr: 0.001000\n","2020-11-28 16:44:19,321 - __main__ - INFO - [Epoch: 023 Step: 00007080] Batch Translation Loss:   5.091018 => Txt Tokens per Sec:     1180 || Lr: 0.001000\n","2020-11-28 16:44:21,369 - __main__ - INFO - [Epoch: 023 Step: 00007120] Batch Translation Loss:   4.862495 => Txt Tokens per Sec:     1251 || Lr: 0.001000\n","2020-11-28 16:44:23,457 - __main__ - INFO - [Epoch: 023 Step: 00007160] Batch Translation Loss:   4.008894 => Txt Tokens per Sec:     1227 || Lr: 0.001000\n","2020-11-28 16:44:25,954 - __main__ - INFO - [Epoch: 023 Step: 00007200] Batch Translation Loss:   4.511047 => Txt Tokens per Sec:     1026 || Lr: 0.001000\n","2020-11-28 16:44:49,537 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:44:49,538 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:44:50,130 - __main__ - INFO - Validation result at epoch  23, step     7200: duration: 24.1747s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 11620.07031\tPPL: 10.02989\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 11.86\n","\tCHRF 16.21\tROUGE 11.87\n","2020-11-28 16:44:52,157 - __main__ - INFO - [Epoch: 023 Step: 00007240] Batch Translation Loss:   4.904274 => Txt Tokens per Sec:     1263 || Lr: 0.001000\n","2020-11-28 16:44:54,210 - __main__ - INFO - [Epoch: 023 Step: 00007280] Batch Translation Loss:   4.938612 => Txt Tokens per Sec:     1247 || Lr: 0.001000\n","2020-11-28 16:44:55,023 - __main__ - INFO - Epoch  23: Total Training Recognition Loss -1.00  Total Training Translation Loss 1360.29 \n","2020-11-28 16:44:55,024 - __main__ - INFO - EPOCH 24\n","2020-11-28 16:44:56,418 - __main__ - INFO - [Epoch: 024 Step: 00007320] Batch Translation Loss:   3.927175 => Txt Tokens per Sec:     1334 || Lr: 0.001000\n","2020-11-28 16:44:58,683 - __main__ - INFO - [Epoch: 024 Step: 00007360] Batch Translation Loss:   3.895525 => Txt Tokens per Sec:     1131 || Lr: 0.001000\n","2020-11-28 16:45:00,898 - __main__ - INFO - [Epoch: 024 Step: 00007400] Batch Translation Loss:   3.737744 => Txt Tokens per Sec:     1157 || Lr: 0.001000\n","2020-11-28 16:45:03,223 - __main__ - INFO - [Epoch: 024 Step: 00007440] Batch Translation Loss:   4.227423 => Txt Tokens per Sec:     1102 || Lr: 0.001000\n","2020-11-28 16:45:05,446 - __main__ - INFO - [Epoch: 024 Step: 00007480] Batch Translation Loss:   4.221360 => Txt Tokens per Sec:     1152 || Lr: 0.001000\n","2020-11-28 16:45:07,552 - __main__ - INFO - [Epoch: 024 Step: 00007520] Batch Translation Loss:   3.830861 => Txt Tokens per Sec:     1216 || Lr: 0.001000\n","2020-11-28 16:45:09,777 - __main__ - INFO - [Epoch: 024 Step: 00007560] Batch Translation Loss:   4.505238 => Txt Tokens per Sec:     1151 || Lr: 0.001000\n","2020-11-28 16:45:11,969 - __main__ - INFO - [Epoch: 024 Step: 00007600] Batch Translation Loss:   3.747216 => Txt Tokens per Sec:     1159 || Lr: 0.001000\n","2020-11-28 16:45:35,201 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:45:35,202 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:45:35,761 - __main__ - INFO - Validation result at epoch  24, step     7600: duration: 23.7902s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 11447.35156\tPPL: 9.69199\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 12.46\n","\tCHRF 16.97\tROUGE 12.46\n","2020-11-28 16:45:36,286 - __main__ - INFO - Epoch  24: Total Training Recognition Loss -1.00  Total Training Translation Loss 1352.48 \n","2020-11-28 16:45:36,287 - __main__ - INFO - EPOCH 25\n","2020-11-28 16:45:37,868 - __main__ - INFO - [Epoch: 025 Step: 00007640] Batch Translation Loss:   4.199199 => Txt Tokens per Sec:     1297 || Lr: 0.001000\n","2020-11-28 16:45:40,059 - __main__ - INFO - [Epoch: 025 Step: 00007680] Batch Translation Loss:   3.971581 => Txt Tokens per Sec:     1169 || Lr: 0.001000\n","2020-11-28 16:45:42,195 - __main__ - INFO - [Epoch: 025 Step: 00007720] Batch Translation Loss:   3.901586 => Txt Tokens per Sec:     1199 || Lr: 0.001000\n","2020-11-28 16:45:44,556 - __main__ - INFO - [Epoch: 025 Step: 00007760] Batch Translation Loss:   3.905246 => Txt Tokens per Sec:     1085 || Lr: 0.001000\n","2020-11-28 16:45:46,746 - __main__ - INFO - [Epoch: 025 Step: 00007800] Batch Translation Loss:   4.327600 => Txt Tokens per Sec:     1170 || Lr: 0.001000\n","2020-11-28 16:45:48,867 - __main__ - INFO - [Epoch: 025 Step: 00007840] Batch Translation Loss:   4.493814 => Txt Tokens per Sec:     1208 || Lr: 0.001000\n","2020-11-28 16:45:50,985 - __main__ - INFO - [Epoch: 025 Step: 00007880] Batch Translation Loss:   4.304632 => Txt Tokens per Sec:     1209 || Lr: 0.001000\n","2020-11-28 16:45:53,175 - __main__ - INFO - [Epoch: 025 Step: 00007920] Batch Translation Loss:   4.591339 => Txt Tokens per Sec:     1170 || Lr: 0.001000\n","2020-11-28 16:45:53,572 - __main__ - INFO - Epoch  25: Total Training Recognition Loss -1.00  Total Training Translation Loss 1334.19 \n","2020-11-28 16:45:53,573 - __main__ - INFO - EPOCH 26\n","2020-11-28 16:45:55,329 - __main__ - INFO - [Epoch: 026 Step: 00007960] Batch Translation Loss:   3.828347 => Txt Tokens per Sec:     1277 || Lr: 0.001000\n","2020-11-28 16:45:57,468 - __main__ - INFO - [Epoch: 026 Step: 00008000] Batch Translation Loss:   3.714020 => Txt Tokens per Sec:     1198 || Lr: 0.001000\n","2020-11-28 16:46:20,239 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:46:20,241 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:46:20,787 - __main__ - INFO - Validation result at epoch  26, step     8000: duration: 23.3183s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 11592.45605\tPPL: 9.97509\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 12.74\n","\tCHRF 17.30\tROUGE 12.74\n","2020-11-28 16:46:23,015 - __main__ - INFO - [Epoch: 026 Step: 00008040] Batch Translation Loss:   5.529545 => Txt Tokens per Sec:     1149 || Lr: 0.001000\n","2020-11-28 16:46:25,141 - __main__ - INFO - [Epoch: 026 Step: 00008080] Batch Translation Loss:   4.097223 => Txt Tokens per Sec:     1205 || Lr: 0.001000\n","2020-11-28 16:46:27,102 - __main__ - INFO - [Epoch: 026 Step: 00008120] Batch Translation Loss:   3.848834 => Txt Tokens per Sec:     1306 || Lr: 0.001000\n","2020-11-28 16:46:29,222 - __main__ - INFO - [Epoch: 026 Step: 00008160] Batch Translation Loss:   3.932926 => Txt Tokens per Sec:     1208 || Lr: 0.001000\n","2020-11-28 16:46:31,443 - __main__ - INFO - [Epoch: 026 Step: 00008200] Batch Translation Loss:   4.169704 => Txt Tokens per Sec:     1153 || Lr: 0.001000\n","2020-11-28 16:46:33,887 - __main__ - INFO - [Epoch: 026 Step: 00008240] Batch Translation Loss:   4.060877 => Txt Tokens per Sec:     1039 || Lr: 0.001000\n","2020-11-28 16:46:34,012 - __main__ - INFO - Epoch  26: Total Training Recognition Loss -1.00  Total Training Translation Loss 1312.89 \n","2020-11-28 16:46:34,013 - __main__ - INFO - EPOCH 27\n","2020-11-28 16:46:35,820 - __main__ - INFO - [Epoch: 027 Step: 00008280] Batch Translation Loss:   3.527498 => Txt Tokens per Sec:     1347 || Lr: 0.001000\n","2020-11-28 16:46:37,962 - __main__ - INFO - [Epoch: 027 Step: 00008320] Batch Translation Loss:   3.923087 => Txt Tokens per Sec:     1196 || Lr: 0.001000\n","2020-11-28 16:46:40,136 - __main__ - INFO - [Epoch: 027 Step: 00008360] Batch Translation Loss:   4.858049 => Txt Tokens per Sec:     1178 || Lr: 0.001000\n","2020-11-28 16:46:42,082 - __main__ - INFO - [Epoch: 027 Step: 00008400] Batch Translation Loss:   4.004936 => Txt Tokens per Sec:     1316 || Lr: 0.001000\n","2020-11-28 16:47:05,093 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:47:05,096 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:47:05,723 - __main__ - INFO - Validation result at epoch  27, step     8400: duration: 23.6395s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 11347.02637\tPPL: 9.50097\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 14.21\n","\tCHRF 18.26\tROUGE 14.21\n","2020-11-28 16:47:08,017 - __main__ - INFO - [Epoch: 027 Step: 00008440] Batch Translation Loss:   4.318283 => Txt Tokens per Sec:     1116 || Lr: 0.001000\n","2020-11-28 16:47:10,056 - __main__ - INFO - [Epoch: 027 Step: 00008480] Batch Translation Loss:   3.659376 => Txt Tokens per Sec:     1256 || Lr: 0.001000\n","2020-11-28 16:47:12,224 - __main__ - INFO - [Epoch: 027 Step: 00008520] Batch Translation Loss:   3.821119 => Txt Tokens per Sec:     1182 || Lr: 0.001000\n","2020-11-28 16:47:14,520 - __main__ - INFO - Epoch  27: Total Training Recognition Loss -1.00  Total Training Translation Loss 1296.07 \n","2020-11-28 16:47:14,522 - __main__ - INFO - EPOCH 28\n","2020-11-28 16:47:14,584 - __main__ - INFO - [Epoch: 028 Step: 00008560] Batch Translation Loss:   3.527978 => Txt Tokens per Sec:     1049 || Lr: 0.001000\n","2020-11-28 16:47:17,091 - __main__ - INFO - [Epoch: 028 Step: 00008600] Batch Translation Loss:   4.611896 => Txt Tokens per Sec:     1022 || Lr: 0.001000\n","2020-11-28 16:47:19,296 - __main__ - INFO - [Epoch: 028 Step: 00008640] Batch Translation Loss:   4.641612 => Txt Tokens per Sec:     1162 || Lr: 0.001000\n","2020-11-28 16:47:21,165 - __main__ - INFO - [Epoch: 028 Step: 00008680] Batch Translation Loss:   4.311175 => Txt Tokens per Sec:     1370 || Lr: 0.001000\n","2020-11-28 16:47:23,203 - __main__ - INFO - [Epoch: 028 Step: 00008720] Batch Translation Loss:   3.735478 => Txt Tokens per Sec:     1257 || Lr: 0.001000\n","2020-11-28 16:47:25,473 - __main__ - INFO - [Epoch: 028 Step: 00008760] Batch Translation Loss:   4.661866 => Txt Tokens per Sec:     1129 || Lr: 0.001000\n","2020-11-28 16:47:27,697 - __main__ - INFO - [Epoch: 028 Step: 00008800] Batch Translation Loss:   5.035982 => Txt Tokens per Sec:     1151 || Lr: 0.001000\n","2020-11-28 16:47:51,089 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:47:51,090 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:47:51,668 - __main__ - INFO - Validation result at epoch  28, step     8800: duration: 23.9691s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 11128.19629\tPPL: 9.09728\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 14.72\n","\tCHRF 19.86\tROUGE 14.72\n","2020-11-28 16:47:53,682 - __main__ - INFO - [Epoch: 028 Step: 00008840] Batch Translation Loss:   3.818071 => Txt Tokens per Sec:     1271 || Lr: 0.001000\n","2020-11-28 16:47:55,852 - __main__ - INFO - Epoch  28: Total Training Recognition Loss -1.00  Total Training Translation Loss 1277.28 \n","2020-11-28 16:47:55,853 - __main__ - INFO - EPOCH 29\n","2020-11-28 16:47:56,135 - __main__ - INFO - [Epoch: 029 Step: 00008880] Batch Translation Loss:   3.312943 => Txt Tokens per Sec:      915 || Lr: 0.001000\n","2020-11-28 16:47:58,391 - __main__ - INFO - [Epoch: 029 Step: 00008920] Batch Translation Loss:   3.636902 => Txt Tokens per Sec:     1136 || Lr: 0.001000\n","2020-11-28 16:48:00,581 - __main__ - INFO - [Epoch: 029 Step: 00008960] Batch Translation Loss:   3.252313 => Txt Tokens per Sec:     1169 || Lr: 0.001000\n","2020-11-28 16:48:02,894 - __main__ - INFO - [Epoch: 029 Step: 00009000] Batch Translation Loss:   3.554569 => Txt Tokens per Sec:     1109 || Lr: 0.001000\n","2020-11-28 16:48:05,169 - __main__ - INFO - [Epoch: 029 Step: 00009040] Batch Translation Loss:   3.813915 => Txt Tokens per Sec:     1126 || Lr: 0.001000\n","2020-11-28 16:48:07,302 - __main__ - INFO - [Epoch: 029 Step: 00009080] Batch Translation Loss:   3.542117 => Txt Tokens per Sec:     1201 || Lr: 0.001000\n","2020-11-28 16:48:09,488 - __main__ - INFO - [Epoch: 029 Step: 00009120] Batch Translation Loss:   4.578747 => Txt Tokens per Sec:     1172 || Lr: 0.001000\n","2020-11-28 16:48:11,492 - __main__ - INFO - [Epoch: 029 Step: 00009160] Batch Translation Loss:   4.367571 => Txt Tokens per Sec:     1278 || Lr: 0.001000\n","2020-11-28 16:48:13,550 - __main__ - INFO - Epoch  29: Total Training Recognition Loss -1.00  Total Training Translation Loss 1260.00 \n","2020-11-28 16:48:13,551 - __main__ - INFO - EPOCH 30\n","2020-11-28 16:48:13,909 - __main__ - INFO - [Epoch: 030 Step: 00009200] Batch Translation Loss:   4.233803 => Txt Tokens per Sec:     1259 || Lr: 0.001000\n","2020-11-28 16:48:37,177 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:48:37,179 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:48:37,743 - __main__ - INFO - Validation result at epoch  30, step     9200: duration: 23.8328s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10879.73047\tPPL: 8.65967\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 15.91\n","\tCHRF 19.71\tROUGE 15.91\n","2020-11-28 16:48:39,927 - __main__ - INFO - [Epoch: 030 Step: 00009240] Batch Translation Loss:   3.549073 => Txt Tokens per Sec:     1172 || Lr: 0.001000\n","2020-11-28 16:48:41,925 - __main__ - INFO - [Epoch: 030 Step: 00009280] Batch Translation Loss:   4.656984 => Txt Tokens per Sec:     1282 || Lr: 0.001000\n","2020-11-28 16:48:44,005 - __main__ - INFO - [Epoch: 030 Step: 00009320] Batch Translation Loss:   4.563379 => Txt Tokens per Sec:     1232 || Lr: 0.001000\n","2020-11-28 16:48:46,371 - __main__ - INFO - [Epoch: 030 Step: 00009360] Batch Translation Loss:   3.747561 => Txt Tokens per Sec:     1082 || Lr: 0.001000\n","2020-11-28 16:48:48,605 - __main__ - INFO - [Epoch: 030 Step: 00009400] Batch Translation Loss:   3.878067 => Txt Tokens per Sec:     1146 || Lr: 0.001000\n","2020-11-28 16:48:50,603 - __main__ - INFO - [Epoch: 030 Step: 00009440] Batch Translation Loss:   4.058155 => Txt Tokens per Sec:     1282 || Lr: 0.001000\n","2020-11-28 16:48:52,837 - __main__ - INFO - [Epoch: 030 Step: 00009480] Batch Translation Loss:   3.668077 => Txt Tokens per Sec:     1147 || Lr: 0.001000\n","2020-11-28 16:48:54,641 - __main__ - INFO - Epoch  30: Total Training Recognition Loss -1.00  Total Training Translation Loss 1246.53 \n","2020-11-28 16:48:54,642 - __main__ - INFO - EPOCH 31\n","2020-11-28 16:48:55,166 - __main__ - INFO - [Epoch: 031 Step: 00009520] Batch Translation Loss:   3.195524 => Txt Tokens per Sec:     1226 || Lr: 0.001000\n","2020-11-28 16:48:57,303 - __main__ - INFO - [Epoch: 031 Step: 00009560] Batch Translation Loss:   4.050259 => Txt Tokens per Sec:     1199 || Lr: 0.001000\n","2020-11-28 16:48:59,276 - __main__ - INFO - [Epoch: 031 Step: 00009600] Batch Translation Loss:   3.597967 => Txt Tokens per Sec:     1298 || Lr: 0.001000\n","2020-11-28 16:49:22,692 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:49:22,694 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:49:23,264 - __main__ - INFO - Validation result at epoch  31, step     9600: duration: 23.9868s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 11280.61133\tPPL: 9.37659\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 15.99\n","\tCHRF 20.57\tROUGE 15.99\n","2020-11-28 16:49:25,614 - __main__ - INFO - [Epoch: 031 Step: 00009640] Batch Translation Loss:   3.572024 => Txt Tokens per Sec:     1090 || Lr: 0.001000\n","2020-11-28 16:49:27,728 - __main__ - INFO - [Epoch: 031 Step: 00009680] Batch Translation Loss:   3.232957 => Txt Tokens per Sec:     1212 || Lr: 0.001000\n","2020-11-28 16:49:29,838 - __main__ - INFO - [Epoch: 031 Step: 00009720] Batch Translation Loss:   4.401064 => Txt Tokens per Sec:     1214 || Lr: 0.001000\n","2020-11-28 16:49:32,075 - __main__ - INFO - [Epoch: 031 Step: 00009760] Batch Translation Loss:   4.472985 => Txt Tokens per Sec:     1145 || Lr: 0.001000\n","2020-11-28 16:49:34,477 - __main__ - INFO - [Epoch: 031 Step: 00009800] Batch Translation Loss:   4.090372 => Txt Tokens per Sec:     1066 || Lr: 0.001000\n","2020-11-28 16:49:36,077 - __main__ - INFO - Epoch  31: Total Training Recognition Loss -1.00  Total Training Translation Loss 1224.81 \n","2020-11-28 16:49:36,078 - __main__ - INFO - EPOCH 32\n","2020-11-28 16:49:36,855 - __main__ - INFO - [Epoch: 032 Step: 00009840] Batch Translation Loss:   3.714212 => Txt Tokens per Sec:     1073 || Lr: 0.001000\n","2020-11-28 16:49:38,881 - __main__ - INFO - [Epoch: 032 Step: 00009880] Batch Translation Loss:   3.429621 => Txt Tokens per Sec:     1264 || Lr: 0.001000\n","2020-11-28 16:49:41,217 - __main__ - INFO - [Epoch: 032 Step: 00009920] Batch Translation Loss:   4.145980 => Txt Tokens per Sec:     1097 || Lr: 0.001000\n","2020-11-28 16:49:43,437 - __main__ - INFO - [Epoch: 032 Step: 00009960] Batch Translation Loss:   4.559979 => Txt Tokens per Sec:     1154 || Lr: 0.001000\n","2020-11-28 16:49:45,587 - __main__ - INFO - [Epoch: 032 Step: 00010000] Batch Translation Loss:   3.860990 => Txt Tokens per Sec:     1192 || Lr: 0.001000\n","2020-11-28 16:50:08,798 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:50:08,800 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:50:09,370 - __main__ - INFO - Validation result at epoch  32, step    10000: duration: 23.7820s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10873.79785\tPPL: 8.64948\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 16.19\n","\tCHRF 20.46\tROUGE 16.19\n","2020-11-28 16:50:11,574 - __main__ - INFO - [Epoch: 032 Step: 00010040] Batch Translation Loss:   4.682642 => Txt Tokens per Sec:     1162 || Lr: 0.001000\n","2020-11-28 16:50:13,854 - __main__ - INFO - [Epoch: 032 Step: 00010080] Batch Translation Loss:   3.740562 => Txt Tokens per Sec:     1123 || Lr: 0.001000\n","2020-11-28 16:50:16,125 - __main__ - INFO - [Epoch: 032 Step: 00010120] Batch Translation Loss:   3.507873 => Txt Tokens per Sec:     1128 || Lr: 0.001000\n","2020-11-28 16:50:17,701 - __main__ - INFO - Epoch  32: Total Training Recognition Loss -1.00  Total Training Translation Loss 1208.13 \n","2020-11-28 16:50:17,702 - __main__ - INFO - EPOCH 33\n","2020-11-28 16:50:18,708 - __main__ - INFO - [Epoch: 033 Step: 00010160] Batch Translation Loss:   2.664420 => Txt Tokens per Sec:     1019 || Lr: 0.001000\n","2020-11-28 16:50:20,792 - __main__ - INFO - [Epoch: 033 Step: 00010200] Batch Translation Loss:   3.325528 => Txt Tokens per Sec:     1229 || Lr: 0.001000\n","2020-11-28 16:50:22,956 - __main__ - INFO - [Epoch: 033 Step: 00010240] Batch Translation Loss:   3.276643 => Txt Tokens per Sec:     1184 || Lr: 0.001000\n","2020-11-28 16:50:25,058 - __main__ - INFO - [Epoch: 033 Step: 00010280] Batch Translation Loss:   3.250653 => Txt Tokens per Sec:     1218 || Lr: 0.001000\n","2020-11-28 16:50:27,038 - __main__ - INFO - [Epoch: 033 Step: 00010320] Batch Translation Loss:   4.065156 => Txt Tokens per Sec:     1294 || Lr: 0.001000\n","2020-11-28 16:50:29,207 - __main__ - INFO - [Epoch: 033 Step: 00010360] Batch Translation Loss:   4.003265 => Txt Tokens per Sec:     1181 || Lr: 0.001000\n","2020-11-28 16:50:31,241 - __main__ - INFO - [Epoch: 033 Step: 00010400] Batch Translation Loss:   3.599625 => Txt Tokens per Sec:     1259 || Lr: 0.001000\n","2020-11-28 16:50:54,850 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:50:54,851 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:50:55,407 - __main__ - INFO - Validation result at epoch  33, step    10400: duration: 24.1648s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10829.75098\tPPL: 8.57422\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 16.63\n","\tCHRF 21.58\tROUGE 16.63\n","2020-11-28 16:50:57,427 - __main__ - INFO - [Epoch: 033 Step: 00010440] Batch Translation Loss:   3.982754 => Txt Tokens per Sec:     1267 || Lr: 0.001000\n","2020-11-28 16:50:58,776 - __main__ - INFO - Epoch  33: Total Training Recognition Loss -1.00  Total Training Translation Loss 1194.45 \n","2020-11-28 16:50:58,777 - __main__ - INFO - EPOCH 34\n","2020-11-28 16:50:59,724 - __main__ - INFO - [Epoch: 034 Step: 00010480] Batch Translation Loss:   2.901865 => Txt Tokens per Sec:     1287 || Lr: 0.001000\n","2020-11-28 16:51:01,852 - __main__ - INFO - [Epoch: 034 Step: 00010520] Batch Translation Loss:   3.323204 => Txt Tokens per Sec:     1204 || Lr: 0.001000\n","2020-11-28 16:51:03,948 - __main__ - INFO - [Epoch: 034 Step: 00010560] Batch Translation Loss:   3.058835 => Txt Tokens per Sec:     1223 || Lr: 0.001000\n","2020-11-28 16:51:06,277 - __main__ - INFO - [Epoch: 034 Step: 00010600] Batch Translation Loss:   3.960018 => Txt Tokens per Sec:     1099 || Lr: 0.001000\n","2020-11-28 16:51:08,450 - __main__ - INFO - [Epoch: 034 Step: 00010640] Batch Translation Loss:   4.163757 => Txt Tokens per Sec:     1180 || Lr: 0.001000\n","2020-11-28 16:51:10,572 - __main__ - INFO - [Epoch: 034 Step: 00010680] Batch Translation Loss:   4.161123 => Txt Tokens per Sec:     1207 || Lr: 0.001000\n","2020-11-28 16:51:12,681 - __main__ - INFO - [Epoch: 034 Step: 00010720] Batch Translation Loss:   4.069632 => Txt Tokens per Sec:     1215 || Lr: 0.001000\n","2020-11-28 16:51:14,710 - __main__ - INFO - [Epoch: 034 Step: 00010760] Batch Translation Loss:   3.832948 => Txt Tokens per Sec:     1263 || Lr: 0.001000\n","2020-11-28 16:51:15,911 - __main__ - INFO - Epoch  34: Total Training Recognition Loss -1.00  Total Training Translation Loss 1175.96 \n","2020-11-28 16:51:15,912 - __main__ - INFO - EPOCH 35\n","2020-11-28 16:51:17,260 - __main__ - INFO - [Epoch: 035 Step: 00010800] Batch Translation Loss:   3.256684 => Txt Tokens per Sec:     1046 || Lr: 0.001000\n","2020-11-28 16:51:40,415 - __main__ - INFO - Validation result at epoch  35, step    10800: duration: 23.1534s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10883.28906\tPPL: 8.66579\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 15.87\n","\tCHRF 19.26\tROUGE 15.87\n","2020-11-28 16:51:42,546 - __main__ - INFO - [Epoch: 035 Step: 00010840] Batch Translation Loss:   2.866793 => Txt Tokens per Sec:     1201 || Lr: 0.001000\n","2020-11-28 16:51:44,569 - __main__ - INFO - [Epoch: 035 Step: 00010880] Batch Translation Loss:   3.656677 => Txt Tokens per Sec:     1267 || Lr: 0.001000\n","2020-11-28 16:51:46,544 - __main__ - INFO - [Epoch: 035 Step: 00010920] Batch Translation Loss:   4.120080 => Txt Tokens per Sec:     1297 || Lr: 0.001000\n","2020-11-28 16:51:48,815 - __main__ - INFO - [Epoch: 035 Step: 00010960] Batch Translation Loss:   3.584133 => Txt Tokens per Sec:     1128 || Lr: 0.001000\n","2020-11-28 16:51:50,819 - __main__ - INFO - [Epoch: 035 Step: 00011000] Batch Translation Loss:   4.405821 => Txt Tokens per Sec:     1278 || Lr: 0.001000\n","2020-11-28 16:51:52,964 - __main__ - INFO - [Epoch: 035 Step: 00011040] Batch Translation Loss:   3.986361 => Txt Tokens per Sec:     1194 || Lr: 0.001000\n","2020-11-28 16:51:55,074 - __main__ - INFO - [Epoch: 035 Step: 00011080] Batch Translation Loss:   3.961186 => Txt Tokens per Sec:     1215 || Lr: 0.001000\n","2020-11-28 16:51:56,056 - __main__ - INFO - Epoch  35: Total Training Recognition Loss -1.00  Total Training Translation Loss 1159.92 \n","2020-11-28 16:51:56,057 - __main__ - INFO - EPOCH 36\n","2020-11-28 16:51:57,353 - __main__ - INFO - [Epoch: 036 Step: 00011120] Batch Translation Loss:   3.202589 => Txt Tokens per Sec:     1236 || Lr: 0.001000\n","2020-11-28 16:51:59,561 - __main__ - INFO - [Epoch: 036 Step: 00011160] Batch Translation Loss:   3.543117 => Txt Tokens per Sec:     1160 || Lr: 0.001000\n","2020-11-28 16:52:01,635 - __main__ - INFO - [Epoch: 036 Step: 00011200] Batch Translation Loss:   3.423795 => Txt Tokens per Sec:     1235 || Lr: 0.001000\n","2020-11-28 16:52:25,084 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:52:25,085 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:52:25,675 - __main__ - INFO - Validation result at epoch  36, step    11200: duration: 24.0374s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10810.50000\tPPL: 8.54153\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 17.50\n","\tCHRF 21.11\tROUGE 17.50\n","2020-11-28 16:52:27,969 - __main__ - INFO - [Epoch: 036 Step: 00011240] Batch Translation Loss:   3.299533 => Txt Tokens per Sec:     1116 || Lr: 0.001000\n","2020-11-28 16:52:29,949 - __main__ - INFO - [Epoch: 036 Step: 00011280] Batch Translation Loss:   3.198530 => Txt Tokens per Sec:     1294 || Lr: 0.001000\n","2020-11-28 16:52:32,243 - __main__ - INFO - [Epoch: 036 Step: 00011320] Batch Translation Loss:   3.501264 => Txt Tokens per Sec:     1117 || Lr: 0.001000\n","2020-11-28 16:52:34,294 - __main__ - INFO - [Epoch: 036 Step: 00011360] Batch Translation Loss:   3.487816 => Txt Tokens per Sec:     1248 || Lr: 0.001000\n","2020-11-28 16:52:36,742 - __main__ - INFO - [Epoch: 036 Step: 00011400] Batch Translation Loss:   3.543561 => Txt Tokens per Sec:     1046 || Lr: 0.001000\n","2020-11-28 16:52:37,725 - __main__ - INFO - Epoch  36: Total Training Recognition Loss -1.00  Total Training Translation Loss 1146.00 \n","2020-11-28 16:52:37,726 - __main__ - INFO - EPOCH 37\n","2020-11-28 16:52:39,164 - __main__ - INFO - [Epoch: 037 Step: 00011440] Batch Translation Loss:   3.288753 => Txt Tokens per Sec:     1248 || Lr: 0.001000\n","2020-11-28 16:52:41,394 - __main__ - INFO - [Epoch: 037 Step: 00011480] Batch Translation Loss:   3.447601 => Txt Tokens per Sec:     1149 || Lr: 0.001000\n","2020-11-28 16:52:43,521 - __main__ - INFO - [Epoch: 037 Step: 00011520] Batch Translation Loss:   4.338635 => Txt Tokens per Sec:     1204 || Lr: 0.001000\n","2020-11-28 16:52:45,483 - __main__ - INFO - [Epoch: 037 Step: 00011560] Batch Translation Loss:   3.531739 => Txt Tokens per Sec:     1306 || Lr: 0.001000\n","2020-11-28 16:52:47,821 - __main__ - INFO - [Epoch: 037 Step: 00011600] Batch Translation Loss:   3.366517 => Txt Tokens per Sec:     1096 || Lr: 0.001000\n","2020-11-28 16:53:11,422 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:53:11,423 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:53:12,043 - __main__ - INFO - Validation result at epoch  37, step    11600: duration: 24.2213s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10567.46680\tPPL: 8.13943\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 18.41\n","\tCHRF 21.47\tROUGE 18.41\n","2020-11-28 16:53:14,380 - __main__ - INFO - [Epoch: 037 Step: 00011640] Batch Translation Loss:   3.833615 => Txt Tokens per Sec:     1096 || Lr: 0.001000\n","2020-11-28 16:53:16,458 - __main__ - INFO - [Epoch: 037 Step: 00011680] Batch Translation Loss:   3.702443 => Txt Tokens per Sec:     1233 || Lr: 0.001000\n","2020-11-28 16:53:18,809 - __main__ - INFO - [Epoch: 037 Step: 00011720] Batch Translation Loss:   2.994343 => Txt Tokens per Sec:     1089 || Lr: 0.001000\n","2020-11-28 16:53:19,402 - __main__ - INFO - Epoch  37: Total Training Recognition Loss -1.00  Total Training Translation Loss 1138.82 \n","2020-11-28 16:53:19,403 - __main__ - INFO - EPOCH 38\n","2020-11-28 16:53:21,275 - __main__ - INFO - [Epoch: 038 Step: 00011760] Batch Translation Loss:   2.953801 => Txt Tokens per Sec:     1061 || Lr: 0.001000\n","2020-11-28 16:53:23,627 - __main__ - INFO - [Epoch: 038 Step: 00011800] Batch Translation Loss:   4.277178 => Txt Tokens per Sec:     1089 || Lr: 0.001000\n","2020-11-28 16:53:25,642 - __main__ - INFO - [Epoch: 038 Step: 00011840] Batch Translation Loss:   3.903517 => Txt Tokens per Sec:     1271 || Lr: 0.001000\n","2020-11-28 16:53:27,932 - __main__ - INFO - [Epoch: 038 Step: 00011880] Batch Translation Loss:   3.527870 => Txt Tokens per Sec:     1118 || Lr: 0.001000\n","2020-11-28 16:53:29,941 - __main__ - INFO - [Epoch: 038 Step: 00011920] Batch Translation Loss:   3.553226 => Txt Tokens per Sec:     1275 || Lr: 0.001000\n","2020-11-28 16:53:32,303 - __main__ - INFO - [Epoch: 038 Step: 00011960] Batch Translation Loss:   3.562607 => Txt Tokens per Sec:     1085 || Lr: 0.001000\n","2020-11-28 16:53:34,334 - __main__ - INFO - [Epoch: 038 Step: 00012000] Batch Translation Loss:   4.109840 => Txt Tokens per Sec:     1261 || Lr: 0.001000\n","2020-11-28 16:53:57,746 - __main__ - INFO - Validation result at epoch  38, step    12000: duration: 23.4113s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10595.85938\tPPL: 8.18541\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 18.06\n","\tCHRF 22.66\tROUGE 18.06\n","2020-11-28 16:54:00,024 - __main__ - INFO - [Epoch: 038 Step: 00012040] Batch Translation Loss:   3.993318 => Txt Tokens per Sec:     1114 || Lr: 0.001000\n","2020-11-28 16:54:00,376 - __main__ - INFO - Epoch  38: Total Training Recognition Loss -1.00  Total Training Translation Loss 1128.06 \n","2020-11-28 16:54:00,377 - __main__ - INFO - EPOCH 39\n","2020-11-28 16:54:02,262 - __main__ - INFO - [Epoch: 039 Step: 00012080] Batch Translation Loss:   3.863711 => Txt Tokens per Sec:     1155 || Lr: 0.001000\n","2020-11-28 16:54:04,489 - __main__ - INFO - [Epoch: 039 Step: 00012120] Batch Translation Loss:   4.394597 => Txt Tokens per Sec:     1151 || Lr: 0.001000\n","2020-11-28 16:54:06,509 - __main__ - INFO - [Epoch: 039 Step: 00012160] Batch Translation Loss:   3.645517 => Txt Tokens per Sec:     1268 || Lr: 0.001000\n","2020-11-28 16:54:08,632 - __main__ - INFO - [Epoch: 039 Step: 00012200] Batch Translation Loss:   4.000366 => Txt Tokens per Sec:     1207 || Lr: 0.001000\n","2020-11-28 16:54:10,688 - __main__ - INFO - [Epoch: 039 Step: 00012240] Batch Translation Loss:   4.176885 => Txt Tokens per Sec:     1246 || Lr: 0.001000\n","2020-11-28 16:54:13,022 - __main__ - INFO - [Epoch: 039 Step: 00012280] Batch Translation Loss:   3.186236 => Txt Tokens per Sec:     1098 || Lr: 0.001000\n","2020-11-28 16:54:14,969 - __main__ - INFO - [Epoch: 039 Step: 00012320] Batch Translation Loss:   3.755589 => Txt Tokens per Sec:     1316 || Lr: 0.001000\n","2020-11-28 16:54:17,701 - __main__ - INFO - [Epoch: 039 Step: 00012360] Batch Translation Loss:   4.897441 => Txt Tokens per Sec:      929 || Lr: 0.001000\n","2020-11-28 16:54:17,890 - __main__ - INFO - Epoch  39: Total Training Recognition Loss -1.00  Total Training Translation Loss 1120.16 \n","2020-11-28 16:54:17,891 - __main__ - INFO - EPOCH 40\n","2020-11-28 16:54:19,783 - __main__ - INFO - [Epoch: 040 Step: 00012400] Batch Translation Loss:   2.975012 => Txt Tokens per Sec:     1253 || Lr: 0.001000\n","2020-11-28 16:54:43,306 - __main__ - INFO - Validation result at epoch  40, step    12400: duration: 23.5222s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10620.01660\tPPL: 8.22474\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 18.33\n","\tCHRF 22.77\tROUGE 18.33\n","2020-11-28 16:54:45,448 - __main__ - INFO - [Epoch: 040 Step: 00012440] Batch Translation Loss:   3.544563 => Txt Tokens per Sec:     1195 || Lr: 0.001000\n","2020-11-28 16:54:47,655 - __main__ - INFO - [Epoch: 040 Step: 00012480] Batch Translation Loss:   2.993179 => Txt Tokens per Sec:     1161 || Lr: 0.001000\n","2020-11-28 16:54:49,928 - __main__ - INFO - [Epoch: 040 Step: 00012520] Batch Translation Loss:   3.839758 => Txt Tokens per Sec:     1127 || Lr: 0.001000\n","2020-11-28 16:54:51,921 - __main__ - INFO - [Epoch: 040 Step: 00012560] Batch Translation Loss:   3.793816 => Txt Tokens per Sec:     1286 || Lr: 0.001000\n","2020-11-28 16:54:54,143 - __main__ - INFO - [Epoch: 040 Step: 00012600] Batch Translation Loss:   3.489792 => Txt Tokens per Sec:     1153 || Lr: 0.001000\n","2020-11-28 16:54:56,190 - __main__ - INFO - [Epoch: 040 Step: 00012640] Batch Translation Loss:   3.983117 => Txt Tokens per Sec:     1251 || Lr: 0.001000\n","2020-11-28 16:54:58,661 - __main__ - INFO - [Epoch: 040 Step: 00012680] Batch Translation Loss:   3.830624 => Txt Tokens per Sec:     1028 || Lr: 0.001000\n","2020-11-28 16:54:58,662 - __main__ - INFO - Epoch  40: Total Training Recognition Loss -1.00  Total Training Translation Loss 1106.45 \n","2020-11-28 16:54:58,664 - __main__ - INFO - EPOCH 41\n","2020-11-28 16:55:00,814 - __main__ - INFO - [Epoch: 041 Step: 00012720] Batch Translation Loss:   3.457314 => Txt Tokens per Sec:     1192 || Lr: 0.001000\n","2020-11-28 16:55:03,014 - __main__ - INFO - [Epoch: 041 Step: 00012760] Batch Translation Loss:   3.223148 => Txt Tokens per Sec:     1164 || Lr: 0.001000\n","2020-11-28 16:55:05,089 - __main__ - INFO - [Epoch: 041 Step: 00012800] Batch Translation Loss:   3.086215 => Txt Tokens per Sec:     1234 || Lr: 0.001000\n","2020-11-28 16:55:28,703 - __main__ - INFO - Validation result at epoch  41, step    12800: duration: 23.6125s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 11025.99512\tPPL: 8.91466\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 16.35\n","\tCHRF 20.74\tROUGE 16.35\n","2020-11-28 16:55:30,801 - __main__ - INFO - [Epoch: 041 Step: 00012840] Batch Translation Loss:   3.249213 => Txt Tokens per Sec:     1220 || Lr: 0.001000\n","2020-11-28 16:55:33,104 - __main__ - INFO - [Epoch: 041 Step: 00012880] Batch Translation Loss:   3.379605 => Txt Tokens per Sec:     1112 || Lr: 0.001000\n","2020-11-28 16:55:35,177 - __main__ - INFO - [Epoch: 041 Step: 00012920] Batch Translation Loss:   3.586703 => Txt Tokens per Sec:     1236 || Lr: 0.001000\n","2020-11-28 16:55:37,380 - __main__ - INFO - [Epoch: 041 Step: 00012960] Batch Translation Loss:   3.401986 => Txt Tokens per Sec:     1163 || Lr: 0.001000\n","2020-11-28 16:55:39,621 - __main__ - INFO - Epoch  41: Total Training Recognition Loss -1.00  Total Training Translation Loss 1096.51 \n","2020-11-28 16:55:39,622 - __main__ - INFO - EPOCH 42\n","2020-11-28 16:55:39,770 - __main__ - INFO - [Epoch: 042 Step: 00013000] Batch Translation Loss:   3.343431 => Txt Tokens per Sec:     1312 || Lr: 0.001000\n","2020-11-28 16:55:42,119 - __main__ - INFO - [Epoch: 042 Step: 00013040] Batch Translation Loss:   2.781190 => Txt Tokens per Sec:     1091 || Lr: 0.001000\n","2020-11-28 16:55:44,242 - __main__ - INFO - [Epoch: 042 Step: 00013080] Batch Translation Loss:   3.153128 => Txt Tokens per Sec:     1207 || Lr: 0.001000\n","2020-11-28 16:55:46,419 - __main__ - INFO - [Epoch: 042 Step: 00013120] Batch Translation Loss:   3.426731 => Txt Tokens per Sec:     1177 || Lr: 0.001000\n","2020-11-28 16:55:48,732 - __main__ - INFO - [Epoch: 042 Step: 00013160] Batch Translation Loss:   3.208160 => Txt Tokens per Sec:     1107 || Lr: 0.001000\n","2020-11-28 16:55:50,743 - __main__ - INFO - [Epoch: 042 Step: 00013200] Batch Translation Loss:   3.165056 => Txt Tokens per Sec:     1274 || Lr: 0.001000\n","2020-11-28 16:56:14,288 - __main__ - INFO - Validation result at epoch  42, step    13200: duration: 23.5445s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10624.45410\tPPL: 8.23198\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 18.41\n","\tCHRF 22.65\tROUGE 18.41\n","2020-11-28 16:56:16,441 - __main__ - INFO - [Epoch: 042 Step: 00013240] Batch Translation Loss:   4.663344 => Txt Tokens per Sec:     1189 || Lr: 0.001000\n","2020-11-28 16:56:18,514 - __main__ - INFO - [Epoch: 042 Step: 00013280] Batch Translation Loss:   3.502319 => Txt Tokens per Sec:     1236 || Lr: 0.001000\n","2020-11-28 16:56:20,686 - __main__ - INFO - Epoch  42: Total Training Recognition Loss -1.00  Total Training Translation Loss 1090.27 \n","2020-11-28 16:56:20,688 - __main__ - INFO - EPOCH 43\n","2020-11-28 16:56:21,061 - __main__ - INFO - [Epoch: 043 Step: 00013320] Batch Translation Loss:   3.636343 => Txt Tokens per Sec:     1035 || Lr: 0.001000\n","2020-11-28 16:56:23,207 - __main__ - INFO - [Epoch: 043 Step: 00013360] Batch Translation Loss:   3.539981 => Txt Tokens per Sec:     1194 || Lr: 0.001000\n","2020-11-28 16:56:25,385 - __main__ - INFO - [Epoch: 043 Step: 00013400] Batch Translation Loss:   3.535264 => Txt Tokens per Sec:     1176 || Lr: 0.001000\n","2020-11-28 16:56:27,476 - __main__ - INFO - [Epoch: 043 Step: 00013440] Batch Translation Loss:   3.191012 => Txt Tokens per Sec:     1225 || Lr: 0.001000\n","2020-11-28 16:56:29,814 - __main__ - INFO - [Epoch: 043 Step: 00013480] Batch Translation Loss:   3.233877 => Txt Tokens per Sec:     1096 || Lr: 0.001000\n","2020-11-28 16:56:31,946 - __main__ - INFO - [Epoch: 043 Step: 00013520] Batch Translation Loss:   2.844743 => Txt Tokens per Sec:     1202 || Lr: 0.001000\n","2020-11-28 16:56:34,281 - __main__ - INFO - [Epoch: 043 Step: 00013560] Batch Translation Loss:   4.019298 => Txt Tokens per Sec:     1097 || Lr: 0.001000\n","2020-11-28 16:56:36,376 - __main__ - INFO - [Epoch: 043 Step: 00013600] Batch Translation Loss:   3.139459 => Txt Tokens per Sec:     1223 || Lr: 0.001000\n","2020-11-28 16:57:00,102 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:57:00,103 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:57:00,663 - __main__ - INFO - Validation result at epoch  43, step    13600: duration: 24.2862s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10343.04590\tPPL: 7.78495\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 19.68\n","\tCHRF 23.65\tROUGE 19.68\n","2020-11-28 16:57:02,512 - __main__ - INFO - Epoch  43: Total Training Recognition Loss -1.00  Total Training Translation Loss 1081.93 \n","2020-11-28 16:57:02,514 - __main__ - INFO - EPOCH 44\n","2020-11-28 16:57:03,001 - __main__ - INFO - [Epoch: 044 Step: 00013640] Batch Translation Loss:   3.291837 => Txt Tokens per Sec:     1186 || Lr: 0.001000\n","2020-11-28 16:57:05,030 - __main__ - INFO - [Epoch: 044 Step: 00013680] Batch Translation Loss:   3.014635 => Txt Tokens per Sec:     1263 || Lr: 0.001000\n","2020-11-28 16:57:07,179 - __main__ - INFO - [Epoch: 044 Step: 00013720] Batch Translation Loss:   2.851367 => Txt Tokens per Sec:     1192 || Lr: 0.001000\n","2020-11-28 16:57:09,359 - __main__ - INFO - [Epoch: 044 Step: 00013760] Batch Translation Loss:   3.373763 => Txt Tokens per Sec:     1175 || Lr: 0.001000\n","2020-11-28 16:57:11,518 - __main__ - INFO - [Epoch: 044 Step: 00013800] Batch Translation Loss:   2.940761 => Txt Tokens per Sec:     1186 || Lr: 0.001000\n","2020-11-28 16:57:13,805 - __main__ - INFO - [Epoch: 044 Step: 00013840] Batch Translation Loss:   2.833496 => Txt Tokens per Sec:     1120 || Lr: 0.001000\n","2020-11-28 16:57:15,986 - __main__ - INFO - [Epoch: 044 Step: 00013880] Batch Translation Loss:   3.792636 => Txt Tokens per Sec:     1175 || Lr: 0.001000\n","2020-11-28 16:57:18,041 - __main__ - INFO - [Epoch: 044 Step: 00013920] Batch Translation Loss:   3.381982 => Txt Tokens per Sec:     1246 || Lr: 0.001000\n","2020-11-28 16:57:19,656 - __main__ - INFO - Epoch  44: Total Training Recognition Loss -1.00  Total Training Translation Loss 1077.56 \n","2020-11-28 16:57:19,657 - __main__ - INFO - EPOCH 45\n","2020-11-28 16:57:20,400 - __main__ - INFO - [Epoch: 045 Step: 00013960] Batch Translation Loss:   2.805917 => Txt Tokens per Sec:     1036 || Lr: 0.001000\n","2020-11-28 16:57:22,448 - __main__ - INFO - [Epoch: 045 Step: 00014000] Batch Translation Loss:   3.283023 => Txt Tokens per Sec:     1251 || Lr: 0.001000\n","2020-11-28 16:57:45,890 - __main__ - INFO - Validation result at epoch  45, step    14000: duration: 23.4408s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10604.35547\tPPL: 8.19922\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 19.37\n","\tCHRF 23.36\tROUGE 19.37\n","2020-11-28 16:57:47,994 - __main__ - INFO - [Epoch: 045 Step: 00014040] Batch Translation Loss:   3.408622 => Txt Tokens per Sec:     1217 || Lr: 0.001000\n","2020-11-28 16:57:50,124 - __main__ - INFO - [Epoch: 045 Step: 00014080] Batch Translation Loss:   3.376662 => Txt Tokens per Sec:     1203 || Lr: 0.001000\n","2020-11-28 16:57:52,345 - __main__ - INFO - [Epoch: 045 Step: 00014120] Batch Translation Loss:   3.048319 => Txt Tokens per Sec:     1154 || Lr: 0.001000\n","2020-11-28 16:57:54,334 - __main__ - INFO - [Epoch: 045 Step: 00014160] Batch Translation Loss:   3.315765 => Txt Tokens per Sec:     1289 || Lr: 0.001000\n","2020-11-28 16:57:56,509 - __main__ - INFO - [Epoch: 045 Step: 00014200] Batch Translation Loss:   3.194712 => Txt Tokens per Sec:     1178 || Lr: 0.001000\n","2020-11-28 16:57:58,682 - __main__ - INFO - [Epoch: 045 Step: 00014240] Batch Translation Loss:   3.724954 => Txt Tokens per Sec:     1179 || Lr: 0.001000\n","2020-11-28 16:58:00,191 - __main__ - INFO - Epoch  45: Total Training Recognition Loss -1.00  Total Training Translation Loss 1067.50 \n","2020-11-28 16:58:00,192 - __main__ - INFO - EPOCH 46\n","2020-11-28 16:58:01,012 - __main__ - INFO - [Epoch: 046 Step: 00014280] Batch Translation Loss:   2.617493 => Txt Tokens per Sec:     1174 || Lr: 0.001000\n","2020-11-28 16:58:02,977 - __main__ - INFO - [Epoch: 046 Step: 00014320] Batch Translation Loss:   2.783778 => Txt Tokens per Sec:     1304 || Lr: 0.001000\n","2020-11-28 16:58:05,224 - __main__ - INFO - [Epoch: 046 Step: 00014360] Batch Translation Loss:   3.123888 => Txt Tokens per Sec:     1140 || Lr: 0.001000\n","2020-11-28 16:58:07,324 - __main__ - INFO - [Epoch: 046 Step: 00014400] Batch Translation Loss:   2.920136 => Txt Tokens per Sec:     1220 || Lr: 0.001000\n","2020-11-28 16:58:30,891 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:58:30,892 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:58:31,482 - __main__ - INFO - Validation result at epoch  46, step    14400: duration: 24.1568s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10449.19336\tPPL: 7.95064\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 19.72\n","\tCHRF 23.89\tROUGE 19.72\n","2020-11-28 16:58:33,716 - __main__ - INFO - [Epoch: 046 Step: 00014440] Batch Translation Loss:   3.113089 => Txt Tokens per Sec:     1146 || Lr: 0.001000\n","2020-11-28 16:58:35,787 - __main__ - INFO - [Epoch: 046 Step: 00014480] Batch Translation Loss:   2.828846 => Txt Tokens per Sec:     1237 || Lr: 0.001000\n","2020-11-28 16:58:38,054 - __main__ - INFO - [Epoch: 046 Step: 00014520] Batch Translation Loss:   3.043678 => Txt Tokens per Sec:     1130 || Lr: 0.001000\n","2020-11-28 16:58:40,163 - __main__ - INFO - [Epoch: 046 Step: 00014560] Batch Translation Loss:   3.438526 => Txt Tokens per Sec:     1215 || Lr: 0.001000\n","2020-11-28 16:58:41,728 - __main__ - INFO - Epoch  46: Total Training Recognition Loss -1.00  Total Training Translation Loss 1057.99 \n","2020-11-28 16:58:41,730 - __main__ - INFO - EPOCH 47\n","2020-11-28 16:58:42,782 - __main__ - INFO - [Epoch: 047 Step: 00014600] Batch Translation Loss:   2.695308 => Txt Tokens per Sec:     1096 || Lr: 0.001000\n","2020-11-28 16:58:45,034 - __main__ - INFO - [Epoch: 047 Step: 00014640] Batch Translation Loss:   3.183038 => Txt Tokens per Sec:     1138 || Lr: 0.001000\n","2020-11-28 16:58:47,009 - __main__ - INFO - [Epoch: 047 Step: 00014680] Batch Translation Loss:   3.370849 => Txt Tokens per Sec:     1297 || Lr: 0.001000\n","2020-11-28 16:58:49,171 - __main__ - INFO - [Epoch: 047 Step: 00014720] Batch Translation Loss:   3.679383 => Txt Tokens per Sec:     1185 || Lr: 0.001000\n","2020-11-28 16:58:51,294 - __main__ - INFO - [Epoch: 047 Step: 00014760] Batch Translation Loss:   3.216828 => Txt Tokens per Sec:     1206 || Lr: 0.001000\n","2020-11-28 16:58:53,892 - __main__ - INFO - [Epoch: 047 Step: 00014800] Batch Translation Loss:   3.048786 => Txt Tokens per Sec:      986 || Lr: 0.001000\n","2020-11-28 16:59:17,519 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 16:59:17,520 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 16:59:18,121 - __main__ - INFO - Validation result at epoch  47, step    14800: duration: 24.2276s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10094.37988\tPPL: 7.41017\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 22.34\n","\tCHRF 25.85\tROUGE 22.34\n","2020-11-28 16:59:20,149 - __main__ - INFO - [Epoch: 047 Step: 00014840] Batch Translation Loss:   3.515915 => Txt Tokens per Sec:     1262 || Lr: 0.001000\n","2020-11-28 16:59:22,159 - __main__ - INFO - [Epoch: 047 Step: 00014880] Batch Translation Loss:   3.419314 => Txt Tokens per Sec:     1274 || Lr: 0.001000\n","2020-11-28 16:59:23,412 - __main__ - INFO - Epoch  47: Total Training Recognition Loss -1.00  Total Training Translation Loss 1050.34 \n","2020-11-28 16:59:23,413 - __main__ - INFO - EPOCH 48\n","2020-11-28 16:59:24,758 - __main__ - INFO - [Epoch: 048 Step: 00014920] Batch Translation Loss:   3.006858 => Txt Tokens per Sec:     1001 || Lr: 0.001000\n","2020-11-28 16:59:26,972 - __main__ - INFO - [Epoch: 048 Step: 00014960] Batch Translation Loss:   3.696021 => Txt Tokens per Sec:     1157 || Lr: 0.001000\n","2020-11-28 16:59:29,200 - __main__ - INFO - [Epoch: 048 Step: 00015000] Batch Translation Loss:   3.426522 => Txt Tokens per Sec:     1150 || Lr: 0.001000\n","2020-11-28 16:59:31,332 - __main__ - INFO - [Epoch: 048 Step: 00015040] Batch Translation Loss:   3.086863 => Txt Tokens per Sec:     1202 || Lr: 0.001000\n","2020-11-28 16:59:33,407 - __main__ - INFO - [Epoch: 048 Step: 00015080] Batch Translation Loss:   3.179597 => Txt Tokens per Sec:     1235 || Lr: 0.001000\n","2020-11-28 16:59:35,461 - __main__ - INFO - [Epoch: 048 Step: 00015120] Batch Translation Loss:   3.633412 => Txt Tokens per Sec:     1247 || Lr: 0.001000\n","2020-11-28 16:59:37,460 - __main__ - INFO - [Epoch: 048 Step: 00015160] Batch Translation Loss:   3.874410 => Txt Tokens per Sec:     1281 || Lr: 0.001000\n","2020-11-28 16:59:39,834 - __main__ - INFO - [Epoch: 048 Step: 00015200] Batch Translation Loss:   3.505225 => Txt Tokens per Sec:     1070 || Lr: 0.001000\n","2020-11-28 17:00:03,328 - __main__ - INFO - Validation result at epoch  48, step    15200: duration: 23.4931s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10165.00000\tPPL: 7.51473\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 21.79\n","\tCHRF 26.29\tROUGE 21.79\n","2020-11-28 17:00:04,308 - __main__ - INFO - Epoch  48: Total Training Recognition Loss -1.00  Total Training Translation Loss 1042.84 \n","2020-11-28 17:00:04,309 - __main__ - INFO - EPOCH 49\n","2020-11-28 17:00:05,571 - __main__ - INFO - [Epoch: 049 Step: 00015240] Batch Translation Loss:   2.260590 => Txt Tokens per Sec:     1219 || Lr: 0.001000\n","2020-11-28 17:00:07,841 - __main__ - INFO - [Epoch: 049 Step: 00015280] Batch Translation Loss:   3.255076 => Txt Tokens per Sec:     1128 || Lr: 0.001000\n","2020-11-28 17:00:09,816 - __main__ - INFO - [Epoch: 049 Step: 00015320] Batch Translation Loss:   3.405597 => Txt Tokens per Sec:     1297 || Lr: 0.001000\n","2020-11-28 17:00:11,840 - __main__ - INFO - [Epoch: 049 Step: 00015360] Batch Translation Loss:   3.577910 => Txt Tokens per Sec:     1266 || Lr: 0.001000\n","2020-11-28 17:00:13,879 - __main__ - INFO - [Epoch: 049 Step: 00015400] Batch Translation Loss:   2.833116 => Txt Tokens per Sec:     1256 || Lr: 0.001000\n","2020-11-28 17:00:16,023 - __main__ - INFO - [Epoch: 049 Step: 00015440] Batch Translation Loss:   3.643791 => Txt Tokens per Sec:     1195 || Lr: 0.001000\n","2020-11-28 17:00:18,167 - __main__ - INFO - [Epoch: 049 Step: 00015480] Batch Translation Loss:   3.226257 => Txt Tokens per Sec:     1194 || Lr: 0.001000\n","2020-11-28 17:00:20,673 - __main__ - INFO - [Epoch: 049 Step: 00015520] Batch Translation Loss:   3.927290 => Txt Tokens per Sec:     1013 || Lr: 0.001000\n","2020-11-28 17:00:21,496 - __main__ - INFO - Epoch  49: Total Training Recognition Loss -1.00  Total Training Translation Loss 1028.64 \n","2020-11-28 17:00:21,497 - __main__ - INFO - EPOCH 50\n","2020-11-28 17:00:22,957 - __main__ - INFO - [Epoch: 050 Step: 00015560] Batch Translation Loss:   3.847254 => Txt Tokens per Sec:     1185 || Lr: 0.001000\n","2020-11-28 17:00:25,115 - __main__ - INFO - [Epoch: 050 Step: 00015600] Batch Translation Loss:   2.867600 => Txt Tokens per Sec:     1187 || Lr: 0.001000\n","2020-11-28 17:00:48,845 - __main__ - INFO - Validation result at epoch  50, step    15600: duration: 23.7281s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10533.59277\tPPL: 8.08490\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 19.84\n","\tCHRF 24.30\tROUGE 19.84\n","2020-11-28 17:00:51,055 - __main__ - INFO - [Epoch: 050 Step: 00015640] Batch Translation Loss:   2.418973 => Txt Tokens per Sec:     1158 || Lr: 0.001000\n","2020-11-28 17:00:52,968 - __main__ - INFO - [Epoch: 050 Step: 00015680] Batch Translation Loss:   3.961918 => Txt Tokens per Sec:     1339 || Lr: 0.001000\n","2020-11-28 17:00:55,321 - __main__ - INFO - [Epoch: 050 Step: 00015720] Batch Translation Loss:   3.243535 => Txt Tokens per Sec:     1089 || Lr: 0.001000\n","2020-11-28 17:00:57,369 - __main__ - INFO - [Epoch: 050 Step: 00015760] Batch Translation Loss:   3.102149 => Txt Tokens per Sec:     1251 || Lr: 0.001000\n","2020-11-28 17:00:59,457 - __main__ - INFO - [Epoch: 050 Step: 00015800] Batch Translation Loss:   3.370201 => Txt Tokens per Sec:     1227 || Lr: 0.001000\n","2020-11-28 17:01:01,657 - __main__ - INFO - [Epoch: 050 Step: 00015840] Batch Translation Loss:   3.309834 => Txt Tokens per Sec:     1164 || Lr: 0.001000\n","2020-11-28 17:01:02,359 - __main__ - INFO - Epoch  50: Total Training Recognition Loss -1.00  Total Training Translation Loss 1022.10 \n","2020-11-28 17:01:02,360 - __main__ - INFO - EPOCH 51\n","2020-11-28 17:01:04,037 - __main__ - INFO - [Epoch: 051 Step: 00015880] Batch Translation Loss:   2.751506 => Txt Tokens per Sec:     1146 || Lr: 0.001000\n","2020-11-28 17:01:06,239 - __main__ - INFO - [Epoch: 051 Step: 00015920] Batch Translation Loss:   3.026735 => Txt Tokens per Sec:     1163 || Lr: 0.001000\n","2020-11-28 17:01:08,409 - __main__ - INFO - [Epoch: 051 Step: 00015960] Batch Translation Loss:   3.918409 => Txt Tokens per Sec:     1181 || Lr: 0.001000\n","2020-11-28 17:01:10,423 - __main__ - INFO - [Epoch: 051 Step: 00016000] Batch Translation Loss:   2.671094 => Txt Tokens per Sec:     1272 || Lr: 0.001000\n","2020-11-28 17:01:33,787 - __main__ - INFO - Validation result at epoch  51, step    16000: duration: 23.3630s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10527.58789\tPPL: 8.07528\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 20.04\n","\tCHRF 24.53\tROUGE 20.04\n","2020-11-28 17:01:35,920 - __main__ - INFO - [Epoch: 051 Step: 00016040] Batch Translation Loss:   3.091918 => Txt Tokens per Sec:     1201 || Lr: 0.001000\n","2020-11-28 17:01:38,049 - __main__ - INFO - [Epoch: 051 Step: 00016080] Batch Translation Loss:   3.406331 => Txt Tokens per Sec:     1203 || Lr: 0.001000\n","2020-11-28 17:01:40,313 - __main__ - INFO - [Epoch: 051 Step: 00016120] Batch Translation Loss:   3.458683 => Txt Tokens per Sec:     1131 || Lr: 0.001000\n","2020-11-28 17:01:42,541 - __main__ - INFO - [Epoch: 051 Step: 00016160] Batch Translation Loss:   3.283033 => Txt Tokens per Sec:     1140 || Lr: 0.001000\n","2020-11-28 17:01:42,968 - __main__ - INFO - Epoch  51: Total Training Recognition Loss -1.00  Total Training Translation Loss 1007.45 \n","2020-11-28 17:01:42,970 - __main__ - INFO - EPOCH 52\n","2020-11-28 17:01:44,842 - __main__ - INFO - [Epoch: 052 Step: 00016200] Batch Translation Loss:   3.044960 => Txt Tokens per Sec:     1129 || Lr: 0.001000\n","2020-11-28 17:01:46,923 - __main__ - INFO - [Epoch: 052 Step: 00016240] Batch Translation Loss:   2.600436 => Txt Tokens per Sec:     1231 || Lr: 0.001000\n","2020-11-28 17:01:48,946 - __main__ - INFO - [Epoch: 052 Step: 00016280] Batch Translation Loss:   3.005550 => Txt Tokens per Sec:     1266 || Lr: 0.001000\n","2020-11-28 17:01:51,057 - __main__ - INFO - [Epoch: 052 Step: 00016320] Batch Translation Loss:   2.604573 => Txt Tokens per Sec:     1214 || Lr: 0.001000\n","2020-11-28 17:01:53,355 - __main__ - INFO - [Epoch: 052 Step: 00016360] Batch Translation Loss:   3.884412 => Txt Tokens per Sec:     1114 || Lr: 0.001000\n","2020-11-28 17:01:55,546 - __main__ - INFO - [Epoch: 052 Step: 00016400] Batch Translation Loss:   3.374995 => Txt Tokens per Sec:     1169 || Lr: 0.001000\n","2020-11-28 17:02:19,033 - __main__ - INFO - Validation result at epoch  52, step    16400: duration: 23.4851s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10191.91895\tPPL: 7.55497\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 21.51\n","\tCHRF 26.36\tROUGE 21.51\n","2020-11-28 17:02:21,071 - __main__ - INFO - [Epoch: 052 Step: 00016440] Batch Translation Loss:   3.851360 => Txt Tokens per Sec:     1256 || Lr: 0.001000\n","2020-11-28 17:02:23,396 - __main__ - INFO - [Epoch: 052 Step: 00016480] Batch Translation Loss:   3.471104 => Txt Tokens per Sec:     1092 || Lr: 0.001000\n","2020-11-28 17:02:23,635 - __main__ - INFO - Epoch  52: Total Training Recognition Loss -1.00  Total Training Translation Loss 999.72 \n","2020-11-28 17:02:23,638 - __main__ - INFO - EPOCH 53\n","2020-11-28 17:02:25,671 - __main__ - INFO - [Epoch: 053 Step: 00016520] Batch Translation Loss:   2.713733 => Txt Tokens per Sec:     1136 || Lr: 0.001000\n","2020-11-28 17:02:27,669 - __main__ - INFO - [Epoch: 053 Step: 00016560] Batch Translation Loss:   2.928797 => Txt Tokens per Sec:     1282 || Lr: 0.001000\n","2020-11-28 17:02:29,840 - __main__ - INFO - [Epoch: 053 Step: 00016600] Batch Translation Loss:   2.566937 => Txt Tokens per Sec:     1180 || Lr: 0.001000\n","2020-11-28 17:02:31,899 - __main__ - INFO - [Epoch: 053 Step: 00016640] Batch Translation Loss:   2.794321 => Txt Tokens per Sec:     1244 || Lr: 0.001000\n","2020-11-28 17:02:34,015 - __main__ - INFO - [Epoch: 053 Step: 00016680] Batch Translation Loss:   3.243184 => Txt Tokens per Sec:     1211 || Lr: 0.001000\n","2020-11-28 17:02:36,146 - __main__ - INFO - [Epoch: 053 Step: 00016720] Batch Translation Loss:   4.548641 => Txt Tokens per Sec:     1202 || Lr: 0.001000\n","2020-11-28 17:02:38,139 - __main__ - INFO - [Epoch: 053 Step: 00016760] Batch Translation Loss:   2.972161 => Txt Tokens per Sec:     1286 || Lr: 0.001000\n","2020-11-28 17:02:40,479 - __main__ - INFO - [Epoch: 053 Step: 00016800] Batch Translation Loss:   3.760425 => Txt Tokens per Sec:     1085 || Lr: 0.001000\n","2020-11-28 17:03:04,109 - __main__ - INFO - Validation result at epoch  53, step    16800: duration: 23.6286s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10174.60840\tPPL: 7.52907\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 21.55\n","\tCHRF 25.76\tROUGE 21.55\n","2020-11-28 17:03:04,167 - __main__ - INFO - Epoch  53: Total Training Recognition Loss -1.00  Total Training Translation Loss 987.48 \n","2020-11-28 17:03:04,168 - __main__ - INFO - EPOCH 54\n","2020-11-28 17:03:06,126 - __main__ - INFO - [Epoch: 054 Step: 00016840] Batch Translation Loss:   2.554100 => Txt Tokens per Sec:     1276 || Lr: 0.001000\n","2020-11-28 17:03:08,254 - __main__ - INFO - [Epoch: 054 Step: 00016880] Batch Translation Loss:   3.224694 => Txt Tokens per Sec:     1204 || Lr: 0.001000\n","2020-11-28 17:03:10,566 - __main__ - INFO - [Epoch: 054 Step: 00016920] Batch Translation Loss:   2.913954 => Txt Tokens per Sec:     1108 || Lr: 0.001000\n","2020-11-28 17:03:12,730 - __main__ - INFO - [Epoch: 054 Step: 00016960] Batch Translation Loss:   2.920491 => Txt Tokens per Sec:     1184 || Lr: 0.001000\n","2020-11-28 17:03:14,974 - __main__ - INFO - [Epoch: 054 Step: 00017000] Batch Translation Loss:   3.144784 => Txt Tokens per Sec:     1142 || Lr: 0.001000\n","2020-11-28 17:03:17,078 - __main__ - INFO - [Epoch: 054 Step: 00017040] Batch Translation Loss:   3.392247 => Txt Tokens per Sec:     1218 || Lr: 0.001000\n","2020-11-28 17:03:19,319 - __main__ - INFO - [Epoch: 054 Step: 00017080] Batch Translation Loss:   4.013230 => Txt Tokens per Sec:     1143 || Lr: 0.001000\n","2020-11-28 17:03:21,720 - __main__ - INFO - Epoch  54: Total Training Recognition Loss -1.00  Total Training Translation Loss 981.18 \n","2020-11-28 17:03:21,721 - __main__ - INFO - EPOCH 55\n","2020-11-28 17:03:21,845 - __main__ - INFO - [Epoch: 055 Step: 00017120] Batch Translation Loss:   2.895544 => Txt Tokens per Sec:     1043 || Lr: 0.001000\n","2020-11-28 17:03:24,114 - __main__ - INFO - [Epoch: 055 Step: 00017160] Batch Translation Loss:   2.688418 => Txt Tokens per Sec:     1129 || Lr: 0.001000\n","2020-11-28 17:03:26,266 - __main__ - INFO - [Epoch: 055 Step: 00017200] Batch Translation Loss:   2.700445 => Txt Tokens per Sec:     1190 || Lr: 0.001000\n","2020-11-28 17:03:50,656 - __main__ - INFO - Validation result at epoch  55, step    17200: duration: 24.3890s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10586.35547\tPPL: 8.16999\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 20.20\n","\tCHRF 24.20\tROUGE 20.20\n","2020-11-28 17:03:52,683 - __main__ - INFO - [Epoch: 055 Step: 00017240] Batch Translation Loss:   3.576044 => Txt Tokens per Sec:     1263 || Lr: 0.001000\n","2020-11-28 17:03:54,837 - __main__ - INFO - [Epoch: 055 Step: 00017280] Batch Translation Loss:   2.867047 => Txt Tokens per Sec:     1189 || Lr: 0.001000\n","2020-11-28 17:03:57,322 - __main__ - INFO - [Epoch: 055 Step: 00017320] Batch Translation Loss:   3.790172 => Txt Tokens per Sec:     1031 || Lr: 0.001000\n","2020-11-28 17:03:59,598 - __main__ - INFO - [Epoch: 055 Step: 00017360] Batch Translation Loss:   3.785023 => Txt Tokens per Sec:     1125 || Lr: 0.001000\n","2020-11-28 17:04:01,900 - __main__ - INFO - [Epoch: 055 Step: 00017400] Batch Translation Loss:   2.959539 => Txt Tokens per Sec:     1113 || Lr: 0.001000\n","2020-11-28 17:04:03,956 - __main__ - INFO - Epoch  55: Total Training Recognition Loss -1.00  Total Training Translation Loss 972.72 \n","2020-11-28 17:04:03,957 - __main__ - INFO - EPOCH 56\n","2020-11-28 17:04:04,220 - __main__ - INFO - [Epoch: 056 Step: 00017440] Batch Translation Loss:   2.600179 => Txt Tokens per Sec:     1224 || Lr: 0.001000\n","2020-11-28 17:04:06,506 - __main__ - INFO - [Epoch: 056 Step: 00017480] Batch Translation Loss:   2.802468 => Txt Tokens per Sec:     1121 || Lr: 0.001000\n","2020-11-28 17:04:08,682 - __main__ - INFO - [Epoch: 056 Step: 00017520] Batch Translation Loss:   2.965398 => Txt Tokens per Sec:     1177 || Lr: 0.001000\n","2020-11-28 17:04:11,219 - __main__ - INFO - [Epoch: 056 Step: 00017560] Batch Translation Loss:   2.746830 => Txt Tokens per Sec:     1010 || Lr: 0.001000\n","2020-11-28 17:04:13,442 - __main__ - INFO - [Epoch: 056 Step: 00017600] Batch Translation Loss:   4.001042 => Txt Tokens per Sec:     1152 || Lr: 0.001000\n","2020-11-28 17:04:38,355 - __main__ - INFO - Validation result at epoch  56, step    17600: duration: 24.9108s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10264.12793\tPPL: 7.66399\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 22.26\n","\tCHRF 26.13\tROUGE 22.26\n","2020-11-28 17:04:40,365 - __main__ - INFO - [Epoch: 056 Step: 00017640] Batch Translation Loss:   3.764129 => Txt Tokens per Sec:     1274 || Lr: 0.001000\n","2020-11-28 17:04:42,596 - __main__ - INFO - [Epoch: 056 Step: 00017680] Batch Translation Loss:   4.457811 => Txt Tokens per Sec:     1148 || Lr: 0.001000\n","2020-11-28 17:04:44,756 - __main__ - INFO - [Epoch: 056 Step: 00017720] Batch Translation Loss:   3.009019 => Txt Tokens per Sec:     1186 || Lr: 0.001000\n","2020-11-28 17:04:46,715 - __main__ - INFO - Epoch  56: Total Training Recognition Loss -1.00  Total Training Translation Loss 961.00 \n","2020-11-28 17:04:46,717 - __main__ - INFO - EPOCH 57\n","2020-11-28 17:04:47,145 - __main__ - INFO - [Epoch: 057 Step: 00017760] Batch Translation Loss:   2.933876 => Txt Tokens per Sec:     1202 || Lr: 0.001000\n","2020-11-28 17:04:49,256 - __main__ - INFO - [Epoch: 057 Step: 00017800] Batch Translation Loss:   2.210718 => Txt Tokens per Sec:     1213 || Lr: 0.001000\n","2020-11-28 17:04:51,390 - __main__ - INFO - [Epoch: 057 Step: 00017840] Batch Translation Loss:   2.472413 => Txt Tokens per Sec:     1200 || Lr: 0.001000\n","2020-11-28 17:04:53,602 - __main__ - INFO - [Epoch: 057 Step: 00017880] Batch Translation Loss:   2.723753 => Txt Tokens per Sec:     1158 || Lr: 0.001000\n","2020-11-28 17:04:55,788 - __main__ - INFO - [Epoch: 057 Step: 00017920] Batch Translation Loss:   2.739564 => Txt Tokens per Sec:     1172 || Lr: 0.001000\n","2020-11-28 17:04:57,943 - __main__ - INFO - [Epoch: 057 Step: 00017960] Batch Translation Loss:   2.699521 => Txt Tokens per Sec:     1188 || Lr: 0.001000\n","2020-11-28 17:05:00,053 - __main__ - INFO - [Epoch: 057 Step: 00018000] Batch Translation Loss:   2.591919 => Txt Tokens per Sec:     1214 || Lr: 0.001000\n","2020-11-28 17:05:24,704 - __main__ - INFO - Validation result at epoch  57, step    18000: duration: 24.6490s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10027.51855\tPPL: 7.31251\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 22.02\n","\tCHRF 26.48\tROUGE 22.02\n","2020-11-28 17:05:26,956 - __main__ - INFO - [Epoch: 057 Step: 00018040] Batch Translation Loss:   3.416548 => Txt Tokens per Sec:     1137 || Lr: 0.001000\n","2020-11-28 17:05:28,682 - __main__ - INFO - Epoch  57: Total Training Recognition Loss -1.00  Total Training Translation Loss 951.48 \n","2020-11-28 17:05:28,685 - __main__ - INFO - EPOCH 58\n","2020-11-28 17:05:29,296 - __main__ - INFO - [Epoch: 058 Step: 00018080] Batch Translation Loss:   2.315428 => Txt Tokens per Sec:     1156 || Lr: 0.001000\n","2020-11-28 17:05:31,636 - __main__ - INFO - [Epoch: 058 Step: 00018120] Batch Translation Loss:   2.308500 => Txt Tokens per Sec:     1095 || Lr: 0.001000\n","2020-11-28 17:05:33,790 - __main__ - INFO - [Epoch: 058 Step: 00018160] Batch Translation Loss:   3.591317 => Txt Tokens per Sec:     1189 || Lr: 0.001000\n","2020-11-28 17:05:36,114 - __main__ - INFO - [Epoch: 058 Step: 00018200] Batch Translation Loss:   2.311182 => Txt Tokens per Sec:     1102 || Lr: 0.001000\n","2020-11-28 17:05:38,169 - __main__ - INFO - [Epoch: 058 Step: 00018240] Batch Translation Loss:   3.213753 => Txt Tokens per Sec:     1247 || Lr: 0.001000\n","2020-11-28 17:05:40,646 - __main__ - INFO - [Epoch: 058 Step: 00018280] Batch Translation Loss:   3.011197 => Txt Tokens per Sec:     1034 || Lr: 0.001000\n","2020-11-28 17:05:42,874 - __main__ - INFO - [Epoch: 058 Step: 00018320] Batch Translation Loss:   3.046119 => Txt Tokens per Sec:     1150 || Lr: 0.001000\n","2020-11-28 17:05:44,978 - __main__ - INFO - [Epoch: 058 Step: 00018360] Batch Translation Loss:   3.487243 => Txt Tokens per Sec:     1218 || Lr: 0.001000\n","2020-11-28 17:05:46,631 - __main__ - INFO - Epoch  58: Total Training Recognition Loss -1.00  Total Training Translation Loss 934.56 \n","2020-11-28 17:05:46,632 - __main__ - INFO - EPOCH 59\n","2020-11-28 17:05:47,445 - __main__ - INFO - [Epoch: 059 Step: 00018400] Batch Translation Loss:   1.965186 => Txt Tokens per Sec:     1105 || Lr: 0.001000\n","2020-11-28 17:06:12,247 - __main__ - INFO - Validation result at epoch  59, step    18400: duration: 24.8016s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9977.08691\tPPL: 7.23971\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 22.26\n","\tCHRF 26.76\tROUGE 22.26\n","2020-11-28 17:06:14,623 - __main__ - INFO - [Epoch: 059 Step: 00018440] Batch Translation Loss:   2.798824 => Txt Tokens per Sec:     1078 || Lr: 0.000700\n","2020-11-28 17:06:16,759 - __main__ - INFO - [Epoch: 059 Step: 00018480] Batch Translation Loss:   2.820223 => Txt Tokens per Sec:     1199 || Lr: 0.000700\n","2020-11-28 17:06:18,957 - __main__ - INFO - [Epoch: 059 Step: 00018520] Batch Translation Loss:   2.872344 => Txt Tokens per Sec:     1166 || Lr: 0.000700\n","2020-11-28 17:06:21,164 - __main__ - INFO - [Epoch: 059 Step: 00018560] Batch Translation Loss:   3.091800 => Txt Tokens per Sec:     1160 || Lr: 0.000700\n","2020-11-28 17:06:23,561 - __main__ - INFO - [Epoch: 059 Step: 00018600] Batch Translation Loss:   2.518737 => Txt Tokens per Sec:     1069 || Lr: 0.000700\n","2020-11-28 17:06:25,750 - __main__ - INFO - [Epoch: 059 Step: 00018640] Batch Translation Loss:   3.031998 => Txt Tokens per Sec:     1170 || Lr: 0.000700\n","2020-11-28 17:06:27,976 - __main__ - INFO - [Epoch: 059 Step: 00018680] Batch Translation Loss:   3.273759 => Txt Tokens per Sec:     1151 || Lr: 0.000700\n","2020-11-28 17:06:29,562 - __main__ - INFO - Epoch  59: Total Training Recognition Loss -1.00  Total Training Translation Loss 876.04 \n","2020-11-28 17:06:29,563 - __main__ - INFO - EPOCH 60\n","2020-11-28 17:06:30,624 - __main__ - INFO - [Epoch: 060 Step: 00018720] Batch Translation Loss:   2.449909 => Txt Tokens per Sec:     1027 || Lr: 0.000700\n","2020-11-28 17:06:32,955 - __main__ - INFO - [Epoch: 060 Step: 00018760] Batch Translation Loss:   2.332714 => Txt Tokens per Sec:     1102 || Lr: 0.000700\n","2020-11-28 17:06:35,042 - __main__ - INFO - [Epoch: 060 Step: 00018800] Batch Translation Loss:   2.188013 => Txt Tokens per Sec:     1227 || Lr: 0.000700\n","2020-11-28 17:07:00,276 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 17:07:00,277 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 17:07:00,907 - __main__ - INFO - Validation result at epoch  60, step    18800: duration: 25.8637s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9751.70312\tPPL: 6.92309\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 25.24\n","\tCHRF 29.09\tROUGE 25.24\n","2020-11-28 17:07:03,295 - __main__ - INFO - [Epoch: 060 Step: 00018840] Batch Translation Loss:   2.581963 => Txt Tokens per Sec:     1072 || Lr: 0.000700\n","2020-11-28 17:07:05,533 - __main__ - INFO - [Epoch: 060 Step: 00018880] Batch Translation Loss:   3.107105 => Txt Tokens per Sec:     1145 || Lr: 0.000700\n","2020-11-28 17:07:07,686 - __main__ - INFO - [Epoch: 060 Step: 00018920] Batch Translation Loss:   3.003003 => Txt Tokens per Sec:     1190 || Lr: 0.000700\n","2020-11-28 17:07:10,076 - __main__ - INFO - [Epoch: 060 Step: 00018960] Batch Translation Loss:   2.115979 => Txt Tokens per Sec:     1072 || Lr: 0.000700\n","2020-11-28 17:07:12,373 - __main__ - INFO - [Epoch: 060 Step: 00019000] Batch Translation Loss:   2.586711 => Txt Tokens per Sec:     1115 || Lr: 0.000700\n","2020-11-28 17:07:13,844 - __main__ - INFO - Epoch  60: Total Training Recognition Loss -1.00  Total Training Translation Loss 857.00 \n","2020-11-28 17:07:13,846 - __main__ - INFO - EPOCH 61\n","2020-11-28 17:07:15,021 - __main__ - INFO - [Epoch: 061 Step: 00019040] Batch Translation Loss:   2.533955 => Txt Tokens per Sec:     1091 || Lr: 0.000700\n","2020-11-28 17:07:17,327 - __main__ - INFO - [Epoch: 061 Step: 00019080] Batch Translation Loss:   2.535065 => Txt Tokens per Sec:     1111 || Lr: 0.000700\n","2020-11-28 17:07:19,757 - __main__ - INFO - [Epoch: 061 Step: 00019120] Batch Translation Loss:   3.045940 => Txt Tokens per Sec:     1054 || Lr: 0.000700\n","2020-11-28 17:07:21,905 - __main__ - INFO - [Epoch: 061 Step: 00019160] Batch Translation Loss:   2.441906 => Txt Tokens per Sec:     1193 || Lr: 0.000700\n","2020-11-28 17:07:24,327 - __main__ - INFO - [Epoch: 061 Step: 00019200] Batch Translation Loss:   2.764917 => Txt Tokens per Sec:     1058 || Lr: 0.000700\n","2020-11-28 17:07:49,231 - __main__ - INFO - Validation result at epoch  61, step    19200: duration: 24.9032s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9761.26367\tPPL: 6.93623\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 25.20\n","\tCHRF 29.17\tROUGE 25.20\n","2020-11-28 17:07:51,394 - __main__ - INFO - [Epoch: 061 Step: 00019240] Batch Translation Loss:   1.910779 => Txt Tokens per Sec:     1184 || Lr: 0.000700\n","2020-11-28 17:07:53,534 - __main__ - INFO - [Epoch: 061 Step: 00019280] Batch Translation Loss:   2.528044 => Txt Tokens per Sec:     1197 || Lr: 0.000700\n","2020-11-28 17:07:56,162 - __main__ - INFO - [Epoch: 061 Step: 00019320] Batch Translation Loss:   2.481348 => Txt Tokens per Sec:      975 || Lr: 0.000700\n","2020-11-28 17:07:57,403 - __main__ - INFO - Epoch  61: Total Training Recognition Loss -1.00  Total Training Translation Loss 848.83 \n","2020-11-28 17:07:57,405 - __main__ - INFO - EPOCH 62\n","2020-11-28 17:07:58,738 - __main__ - INFO - [Epoch: 062 Step: 00019360] Batch Translation Loss:   2.380372 => Txt Tokens per Sec:     1105 || Lr: 0.000700\n","2020-11-28 17:08:00,942 - __main__ - INFO - [Epoch: 062 Step: 00019400] Batch Translation Loss:   2.519291 => Txt Tokens per Sec:     1162 || Lr: 0.000700\n","2020-11-28 17:08:03,313 - __main__ - INFO - [Epoch: 062 Step: 00019440] Batch Translation Loss:   3.067663 => Txt Tokens per Sec:     1081 || Lr: 0.000700\n","2020-11-28 17:08:05,695 - __main__ - INFO - [Epoch: 062 Step: 00019480] Batch Translation Loss:   2.596471 => Txt Tokens per Sec:     1075 || Lr: 0.000700\n","2020-11-28 17:08:07,846 - __main__ - INFO - [Epoch: 062 Step: 00019520] Batch Translation Loss:   2.414560 => Txt Tokens per Sec:     1191 || Lr: 0.000700\n","2020-11-28 17:08:10,066 - __main__ - INFO - [Epoch: 062 Step: 00019560] Batch Translation Loss:   2.793226 => Txt Tokens per Sec:     1154 || Lr: 0.000700\n","2020-11-28 17:08:12,219 - __main__ - INFO - [Epoch: 062 Step: 00019600] Batch Translation Loss:   3.045786 => Txt Tokens per Sec:     1190 || Lr: 0.000700\n","2020-11-28 17:08:37,394 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 17:08:37,395 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 17:08:37,981 - __main__ - INFO - Validation result at epoch  62, step    19600: duration: 25.7598s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9628.96777\tPPL: 6.75653\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 25.52\n","\tCHRF 29.53\tROUGE 25.52\n","2020-11-28 17:08:40,467 - __main__ - INFO - [Epoch: 062 Step: 00019640] Batch Translation Loss:   2.419292 => Txt Tokens per Sec:     1021 || Lr: 0.000700\n","2020-11-28 17:08:41,388 - __main__ - INFO - Epoch  62: Total Training Recognition Loss -1.00  Total Training Translation Loss 835.31 \n","2020-11-28 17:08:41,390 - __main__ - INFO - EPOCH 63\n","2020-11-28 17:08:42,900 - __main__ - INFO - [Epoch: 063 Step: 00019680] Batch Translation Loss:   2.831770 => Txt Tokens per Sec:     1104 || Lr: 0.000700\n","2020-11-28 17:08:45,349 - __main__ - INFO - [Epoch: 063 Step: 00019720] Batch Translation Loss:   3.462886 => Txt Tokens per Sec:     1046 || Lr: 0.000700\n","2020-11-28 17:08:47,981 - __main__ - INFO - [Epoch: 063 Step: 00019760] Batch Translation Loss:   2.088054 => Txt Tokens per Sec:      973 || Lr: 0.000700\n","2020-11-28 17:08:50,418 - __main__ - INFO - [Epoch: 063 Step: 00019800] Batch Translation Loss:   2.365072 => Txt Tokens per Sec:     1051 || Lr: 0.000700\n","2020-11-28 17:08:52,647 - __main__ - INFO - [Epoch: 063 Step: 00019840] Batch Translation Loss:   2.285669 => Txt Tokens per Sec:     1149 || Lr: 0.000700\n","2020-11-28 17:08:55,028 - __main__ - INFO - [Epoch: 063 Step: 00019880] Batch Translation Loss:   2.373692 => Txt Tokens per Sec:     1076 || Lr: 0.000700\n","2020-11-28 17:08:57,235 - __main__ - INFO - [Epoch: 063 Step: 00019920] Batch Translation Loss:   3.292822 => Txt Tokens per Sec:     1161 || Lr: 0.000700\n","2020-11-28 17:08:59,778 - __main__ - INFO - [Epoch: 063 Step: 00019960] Batch Translation Loss:   2.924965 => Txt Tokens per Sec:     1007 || Lr: 0.000700\n","2020-11-28 17:09:00,609 - __main__ - INFO - Epoch  63: Total Training Recognition Loss -1.00  Total Training Translation Loss 831.39 \n","2020-11-28 17:09:00,611 - __main__ - INFO - EPOCH 64\n","2020-11-28 17:09:02,206 - __main__ - INFO - [Epoch: 064 Step: 00020000] Batch Translation Loss:   2.415192 => Txt Tokens per Sec:     1165 || Lr: 0.000700\n","2020-11-28 17:09:26,962 - __main__ - INFO - Validation result at epoch  64, step    20000: duration: 24.7550s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9758.88770\tPPL: 6.93296\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 25.12\n","\tCHRF 29.20\tROUGE 25.12\n","2020-11-28 17:09:29,364 - __main__ - INFO - [Epoch: 064 Step: 00020040] Batch Translation Loss:   2.935722 => Txt Tokens per Sec:     1066 || Lr: 0.000700\n","2020-11-28 17:09:31,738 - __main__ - INFO - [Epoch: 064 Step: 00020080] Batch Translation Loss:   3.258419 => Txt Tokens per Sec:     1079 || Lr: 0.000700\n","2020-11-28 17:09:33,956 - __main__ - INFO - [Epoch: 064 Step: 00020120] Batch Translation Loss:   3.055253 => Txt Tokens per Sec:     1155 || Lr: 0.000700\n","2020-11-28 17:09:36,337 - __main__ - INFO - [Epoch: 064 Step: 00020160] Batch Translation Loss:   2.417444 => Txt Tokens per Sec:     1076 || Lr: 0.000700\n","2020-11-28 17:09:38,540 - __main__ - INFO - [Epoch: 064 Step: 00020200] Batch Translation Loss:   2.920130 => Txt Tokens per Sec:     1163 || Lr: 0.000700\n","2020-11-28 17:09:40,786 - __main__ - INFO - [Epoch: 064 Step: 00020240] Batch Translation Loss:   3.234406 => Txt Tokens per Sec:     1140 || Lr: 0.000700\n","2020-11-28 17:09:43,262 - __main__ - INFO - [Epoch: 064 Step: 00020280] Batch Translation Loss:   3.087879 => Txt Tokens per Sec:     1026 || Lr: 0.000700\n","2020-11-28 17:09:43,805 - __main__ - INFO - Epoch  64: Total Training Recognition Loss -1.00  Total Training Translation Loss 820.92 \n","2020-11-28 17:09:43,807 - __main__ - INFO - EPOCH 65\n","2020-11-28 17:09:45,651 - __main__ - INFO - [Epoch: 065 Step: 00020320] Batch Translation Loss:   2.511141 => Txt Tokens per Sec:     1111 || Lr: 0.000700\n","2020-11-28 17:09:47,857 - __main__ - INFO - [Epoch: 065 Step: 00020360] Batch Translation Loss:   2.003230 => Txt Tokens per Sec:     1161 || Lr: 0.000700\n","2020-11-28 17:09:50,382 - __main__ - INFO - [Epoch: 065 Step: 00020400] Batch Translation Loss:   2.738098 => Txt Tokens per Sec:     1014 || Lr: 0.000700\n","2020-11-28 17:10:14,757 - __main__ - INFO - Validation result at epoch  65, step    20400: duration: 24.3737s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9971.97656\tPPL: 7.23237\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 25.08\n","\tCHRF 29.68\tROUGE 25.08\n","2020-11-28 17:10:16,928 - __main__ - INFO - [Epoch: 065 Step: 00020440] Batch Translation Loss:   2.751069 => Txt Tokens per Sec:     1179 || Lr: 0.000700\n","2020-11-28 17:10:19,163 - __main__ - INFO - [Epoch: 065 Step: 00020480] Batch Translation Loss:   2.648109 => Txt Tokens per Sec:     1146 || Lr: 0.000700\n","2020-11-28 17:10:21,358 - __main__ - INFO - [Epoch: 065 Step: 00020520] Batch Translation Loss:   2.504615 => Txt Tokens per Sec:     1167 || Lr: 0.000700\n","2020-11-28 17:10:23,738 - __main__ - INFO - [Epoch: 065 Step: 00020560] Batch Translation Loss:   2.587193 => Txt Tokens per Sec:     1076 || Lr: 0.000700\n","2020-11-28 17:10:25,977 - __main__ - INFO - [Epoch: 065 Step: 00020600] Batch Translation Loss:   3.592977 => Txt Tokens per Sec:     1134 || Lr: 0.000700\n","2020-11-28 17:10:26,289 - __main__ - INFO - Epoch  65: Total Training Recognition Loss -1.00  Total Training Translation Loss 811.01 \n","2020-11-28 17:10:26,291 - __main__ - INFO - EPOCH 66\n","2020-11-28 17:10:28,180 - __main__ - INFO - [Epoch: 066 Step: 00020640] Batch Translation Loss:   2.282369 => Txt Tokens per Sec:     1187 || Lr: 0.000700\n","2020-11-28 17:10:30,415 - __main__ - INFO - [Epoch: 066 Step: 00020680] Batch Translation Loss:   2.123955 => Txt Tokens per Sec:     1146 || Lr: 0.000700\n","2020-11-28 17:10:32,539 - __main__ - INFO - [Epoch: 066 Step: 00020720] Batch Translation Loss:   2.667960 => Txt Tokens per Sec:     1206 || Lr: 0.000700\n","2020-11-28 17:10:34,629 - __main__ - INFO - [Epoch: 066 Step: 00020760] Batch Translation Loss:   2.395508 => Txt Tokens per Sec:     1226 || Lr: 0.000700\n","2020-11-28 17:10:36,883 - __main__ - INFO - [Epoch: 066 Step: 00020800] Batch Translation Loss:   2.585243 => Txt Tokens per Sec:     1136 || Lr: 0.000700\n","2020-11-28 17:11:01,428 - __main__ - INFO - Validation result at epoch  66, step    20800: duration: 24.5420s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9806.99512\tPPL: 6.99946\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 25.44\n","\tCHRF 29.50\tROUGE 25.44\n","2020-11-28 17:11:03,737 - __main__ - INFO - [Epoch: 066 Step: 00020840] Batch Translation Loss:   3.085902 => Txt Tokens per Sec:     1109 || Lr: 0.000700\n","2020-11-28 17:11:06,042 - __main__ - INFO - [Epoch: 066 Step: 00020880] Batch Translation Loss:   3.721283 => Txt Tokens per Sec:     1111 || Lr: 0.000700\n","2020-11-28 17:11:08,537 - __main__ - INFO - [Epoch: 066 Step: 00020920] Batch Translation Loss:   2.809528 => Txt Tokens per Sec:     1018 || Lr: 0.000700\n","2020-11-28 17:11:08,681 - __main__ - INFO - Epoch  66: Total Training Recognition Loss -1.00  Total Training Translation Loss 802.57 \n","2020-11-28 17:11:08,682 - __main__ - INFO - EPOCH 67\n","2020-11-28 17:11:10,920 - __main__ - INFO - [Epoch: 067 Step: 00020960] Batch Translation Loss:   2.214561 => Txt Tokens per Sec:     1088 || Lr: 0.000700\n","2020-11-28 17:11:13,126 - __main__ - INFO - [Epoch: 067 Step: 00021000] Batch Translation Loss:   2.420006 => Txt Tokens per Sec:     1161 || Lr: 0.000700\n","2020-11-28 17:11:15,381 - __main__ - INFO - [Epoch: 067 Step: 00021040] Batch Translation Loss:   1.803669 => Txt Tokens per Sec:     1136 || Lr: 0.000700\n","2020-11-28 17:11:17,653 - __main__ - INFO - [Epoch: 067 Step: 00021080] Batch Translation Loss:   2.430847 => Txt Tokens per Sec:     1128 || Lr: 0.000700\n","2020-11-28 17:11:20,177 - __main__ - INFO - [Epoch: 067 Step: 00021120] Batch Translation Loss:   2.322799 => Txt Tokens per Sec:     1015 || Lr: 0.000700\n","2020-11-28 17:11:22,538 - __main__ - INFO - [Epoch: 067 Step: 00021160] Batch Translation Loss:   3.084026 => Txt Tokens per Sec:     1085 || Lr: 0.000700\n","2020-11-28 17:11:24,774 - __main__ - INFO - [Epoch: 067 Step: 00021200] Batch Translation Loss:   2.582530 => Txt Tokens per Sec:     1146 || Lr: 0.000700\n","2020-11-28 17:11:49,440 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 17:11:49,441 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 17:11:50,051 - __main__ - INFO - Validation result at epoch  67, step    21200: duration: 25.2755s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9619.44531\tPPL: 6.74378\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 26.55\n","\tCHRF 31.08\tROUGE 26.55\n","2020-11-28 17:11:52,518 - __main__ - INFO - Epoch  67: Total Training Recognition Loss -1.00  Total Training Translation Loss 798.35 \n","2020-11-28 17:11:52,520 - __main__ - INFO - EPOCH 68\n","2020-11-28 17:11:52,598 - __main__ - INFO - [Epoch: 068 Step: 00021240] Batch Translation Loss:   2.592189 => Txt Tokens per Sec:      835 || Lr: 0.000700\n","2020-11-28 17:11:54,830 - __main__ - INFO - [Epoch: 068 Step: 00021280] Batch Translation Loss:   2.752517 => Txt Tokens per Sec:     1148 || Lr: 0.000700\n","2020-11-28 17:11:57,305 - __main__ - INFO - [Epoch: 068 Step: 00021320] Batch Translation Loss:   1.956493 => Txt Tokens per Sec:     1035 || Lr: 0.000700\n","2020-11-28 17:11:59,652 - __main__ - INFO - [Epoch: 068 Step: 00021360] Batch Translation Loss:   2.995672 => Txt Tokens per Sec:     1091 || Lr: 0.000700\n","2020-11-28 17:12:01,945 - __main__ - INFO - [Epoch: 068 Step: 00021400] Batch Translation Loss:   2.667071 => Txt Tokens per Sec:     1117 || Lr: 0.000700\n","2020-11-28 17:12:04,196 - __main__ - INFO - [Epoch: 068 Step: 00021440] Batch Translation Loss:   2.274949 => Txt Tokens per Sec:     1138 || Lr: 0.000700\n","2020-11-28 17:12:06,554 - __main__ - INFO - [Epoch: 068 Step: 00021480] Batch Translation Loss:   2.475663 => Txt Tokens per Sec:     1086 || Lr: 0.000700\n","2020-11-28 17:12:08,826 - __main__ - INFO - [Epoch: 068 Step: 00021520] Batch Translation Loss:   2.933291 => Txt Tokens per Sec:     1128 || Lr: 0.000700\n","2020-11-28 17:12:11,055 - __main__ - INFO - Epoch  68: Total Training Recognition Loss -1.00  Total Training Translation Loss 784.22 \n","2020-11-28 17:12:11,056 - __main__ - INFO - EPOCH 69\n","2020-11-28 17:12:11,282 - __main__ - INFO - [Epoch: 069 Step: 00021560] Batch Translation Loss:   2.857733 => Txt Tokens per Sec:     1141 || Lr: 0.000700\n","2020-11-28 17:12:13,523 - __main__ - INFO - [Epoch: 069 Step: 00021600] Batch Translation Loss:   2.473931 => Txt Tokens per Sec:     1143 || Lr: 0.000700\n","2020-11-28 17:12:38,553 - __main__ - INFO - Validation result at epoch  69, step    21600: duration: 25.0280s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9705.12891\tPPL: 6.85941\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 26.35\n","\tCHRF 31.13\tROUGE 26.35\n","2020-11-28 17:12:40,873 - __main__ - INFO - [Epoch: 069 Step: 00021640] Batch Translation Loss:   1.942411 => Txt Tokens per Sec:     1104 || Lr: 0.000700\n","2020-11-28 17:12:43,237 - __main__ - INFO - [Epoch: 069 Step: 00021680] Batch Translation Loss:   2.039042 => Txt Tokens per Sec:     1084 || Lr: 0.000700\n","2020-11-28 17:12:45,500 - __main__ - INFO - [Epoch: 069 Step: 00021720] Batch Translation Loss:   2.249173 => Txt Tokens per Sec:     1132 || Lr: 0.000700\n","2020-11-28 17:12:47,607 - __main__ - INFO - [Epoch: 069 Step: 00021760] Batch Translation Loss:   2.076471 => Txt Tokens per Sec:     1216 || Lr: 0.000700\n","2020-11-28 17:12:49,738 - __main__ - INFO - [Epoch: 069 Step: 00021800] Batch Translation Loss:   2.026532 => Txt Tokens per Sec:     1202 || Lr: 0.000700\n","2020-11-28 17:12:51,945 - __main__ - INFO - [Epoch: 069 Step: 00021840] Batch Translation Loss:   3.128764 => Txt Tokens per Sec:     1161 || Lr: 0.000700\n","2020-11-28 17:12:54,057 - __main__ - INFO - Epoch  69: Total Training Recognition Loss -1.00  Total Training Translation Loss 780.68 \n","2020-11-28 17:12:54,058 - __main__ - INFO - EPOCH 70\n","2020-11-28 17:12:54,429 - __main__ - INFO - [Epoch: 070 Step: 00021880] Batch Translation Loss:   2.011532 => Txt Tokens per Sec:     1213 || Lr: 0.000700\n","2020-11-28 17:12:56,727 - __main__ - INFO - [Epoch: 070 Step: 00021920] Batch Translation Loss:   1.759615 => Txt Tokens per Sec:     1115 || Lr: 0.000700\n","2020-11-28 17:12:58,963 - __main__ - INFO - [Epoch: 070 Step: 00021960] Batch Translation Loss:   2.372140 => Txt Tokens per Sec:     1146 || Lr: 0.000700\n","2020-11-28 17:13:01,167 - __main__ - INFO - [Epoch: 070 Step: 00022000] Batch Translation Loss:   2.955205 => Txt Tokens per Sec:     1162 || Lr: 0.000700\n","2020-11-28 17:13:25,992 - __main__ - INFO - Validation result at epoch  70, step    22000: duration: 24.8231s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9942.85840\tPPL: 7.19071\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 25.12\n","\tCHRF 29.47\tROUGE 25.12\n","2020-11-28 17:13:28,201 - __main__ - INFO - [Epoch: 070 Step: 00022040] Batch Translation Loss:   2.707037 => Txt Tokens per Sec:     1159 || Lr: 0.000700\n","2020-11-28 17:13:30,638 - __main__ - INFO - [Epoch: 070 Step: 00022080] Batch Translation Loss:   2.902140 => Txt Tokens per Sec:     1051 || Lr: 0.000700\n","2020-11-28 17:13:32,869 - __main__ - INFO - [Epoch: 070 Step: 00022120] Batch Translation Loss:   2.875660 => Txt Tokens per Sec:     1148 || Lr: 0.000700\n","2020-11-28 17:13:35,167 - __main__ - INFO - [Epoch: 070 Step: 00022160] Batch Translation Loss:   2.334226 => Txt Tokens per Sec:     1115 || Lr: 0.000700\n","2020-11-28 17:13:37,112 - __main__ - INFO - Epoch  70: Total Training Recognition Loss -1.00  Total Training Translation Loss 771.49 \n","2020-11-28 17:13:37,113 - __main__ - INFO - EPOCH 71\n","2020-11-28 17:13:37,676 - __main__ - INFO - [Epoch: 071 Step: 00022200] Batch Translation Loss:   2.353733 => Txt Tokens per Sec:     1140 || Lr: 0.000700\n","2020-11-28 17:13:39,849 - __main__ - INFO - [Epoch: 071 Step: 00022240] Batch Translation Loss:   2.359729 => Txt Tokens per Sec:     1179 || Lr: 0.000700\n","2020-11-28 17:13:42,153 - __main__ - INFO - [Epoch: 071 Step: 00022280] Batch Translation Loss:   2.195207 => Txt Tokens per Sec:     1112 || Lr: 0.000700\n","2020-11-28 17:13:44,415 - __main__ - INFO - [Epoch: 071 Step: 00022320] Batch Translation Loss:   2.392214 => Txt Tokens per Sec:     1132 || Lr: 0.000700\n","2020-11-28 17:13:46,595 - __main__ - INFO - [Epoch: 071 Step: 00022360] Batch Translation Loss:   2.616498 => Txt Tokens per Sec:     1175 || Lr: 0.000700\n","2020-11-28 17:13:48,985 - __main__ - INFO - [Epoch: 071 Step: 00022400] Batch Translation Loss:   2.149554 => Txt Tokens per Sec:     1071 || Lr: 0.000700\n","2020-11-28 17:14:13,968 - __main__ - INFO - Validation result at epoch  71, step    22400: duration: 24.9814s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9578.12305\tPPL: 6.68871\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 26.47\n","\tCHRF 31.44\tROUGE 26.47\n","2020-11-28 17:14:16,300 - __main__ - INFO - [Epoch: 071 Step: 00022440] Batch Translation Loss:   3.112006 => Txt Tokens per Sec:     1098 || Lr: 0.000700\n","2020-11-28 17:14:18,406 - __main__ - INFO - [Epoch: 071 Step: 00022480] Batch Translation Loss:   2.641505 => Txt Tokens per Sec:     1216 || Lr: 0.000700\n","2020-11-28 17:14:20,129 - __main__ - INFO - Epoch  71: Total Training Recognition Loss -1.00  Total Training Translation Loss 761.51 \n","2020-11-28 17:14:20,130 - __main__ - INFO - EPOCH 72\n","2020-11-28 17:14:20,932 - __main__ - INFO - [Epoch: 072 Step: 00022520] Batch Translation Loss:   1.792637 => Txt Tokens per Sec:     1039 || Lr: 0.000700\n","2020-11-28 17:14:23,116 - __main__ - INFO - [Epoch: 072 Step: 00022560] Batch Translation Loss:   2.266076 => Txt Tokens per Sec:     1173 || Lr: 0.000700\n","2020-11-28 17:14:25,459 - __main__ - INFO - [Epoch: 072 Step: 00022600] Batch Translation Loss:   2.237485 => Txt Tokens per Sec:     1093 || Lr: 0.000700\n","2020-11-28 17:14:27,772 - __main__ - INFO - [Epoch: 072 Step: 00022640] Batch Translation Loss:   1.804395 => Txt Tokens per Sec:     1108 || Lr: 0.000700\n","2020-11-28 17:14:30,230 - __main__ - INFO - [Epoch: 072 Step: 00022680] Batch Translation Loss:   2.316419 => Txt Tokens per Sec:     1042 || Lr: 0.000700\n","2020-11-28 17:14:32,326 - __main__ - INFO - [Epoch: 072 Step: 00022720] Batch Translation Loss:   2.363865 => Txt Tokens per Sec:     1222 || Lr: 0.000700\n","2020-11-28 17:14:34,568 - __main__ - INFO - [Epoch: 072 Step: 00022760] Batch Translation Loss:   3.372874 => Txt Tokens per Sec:     1143 || Lr: 0.000700\n","2020-11-28 17:14:36,785 - __main__ - INFO - [Epoch: 072 Step: 00022800] Batch Translation Loss:   2.404077 => Txt Tokens per Sec:     1155 || Lr: 0.000700\n","2020-11-28 17:15:02,032 - __main__ - INFO - Validation result at epoch  72, step    22800: duration: 25.2450s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9761.43457\tPPL: 6.93647\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 26.11\n","\tCHRF 30.25\tROUGE 26.11\n","2020-11-28 17:15:03,645 - __main__ - INFO - Epoch  72: Total Training Recognition Loss -1.00  Total Training Translation Loss 746.94 \n","2020-11-28 17:15:03,647 - __main__ - INFO - EPOCH 73\n","2020-11-28 17:15:04,535 - __main__ - INFO - [Epoch: 073 Step: 00022840] Batch Translation Loss:   2.178248 => Txt Tokens per Sec:     1155 || Lr: 0.000700\n","2020-11-28 17:15:06,680 - __main__ - INFO - [Epoch: 073 Step: 00022880] Batch Translation Loss:   2.194512 => Txt Tokens per Sec:     1194 || Lr: 0.000700\n","2020-11-28 17:15:09,005 - __main__ - INFO - [Epoch: 073 Step: 00022920] Batch Translation Loss:   2.476585 => Txt Tokens per Sec:     1102 || Lr: 0.000700\n","2020-11-28 17:15:11,382 - __main__ - INFO - [Epoch: 073 Step: 00022960] Batch Translation Loss:   2.081116 => Txt Tokens per Sec:     1078 || Lr: 0.000700\n","2020-11-28 17:15:13,510 - __main__ - INFO - [Epoch: 073 Step: 00023000] Batch Translation Loss:   2.529367 => Txt Tokens per Sec:     1204 || Lr: 0.000700\n","2020-11-28 17:15:15,888 - __main__ - INFO - [Epoch: 073 Step: 00023040] Batch Translation Loss:   2.027841 => Txt Tokens per Sec:     1077 || Lr: 0.000700\n","2020-11-28 17:15:18,083 - __main__ - INFO - [Epoch: 073 Step: 00023080] Batch Translation Loss:   2.462423 => Txt Tokens per Sec:     1167 || Lr: 0.000700\n","2020-11-28 17:15:20,459 - __main__ - INFO - [Epoch: 073 Step: 00023120] Batch Translation Loss:   2.265734 => Txt Tokens per Sec:     1078 || Lr: 0.000700\n","2020-11-28 17:15:21,910 - __main__ - INFO - Epoch  73: Total Training Recognition Loss -1.00  Total Training Translation Loss 744.30 \n","2020-11-28 17:15:21,911 - __main__ - INFO - EPOCH 74\n","2020-11-28 17:15:23,091 - __main__ - INFO - [Epoch: 074 Step: 00023160] Batch Translation Loss:   2.229074 => Txt Tokens per Sec:     1033 || Lr: 0.000700\n","2020-11-28 17:15:25,390 - __main__ - INFO - [Epoch: 074 Step: 00023200] Batch Translation Loss:   2.403360 => Txt Tokens per Sec:     1114 || Lr: 0.000700\n","2020-11-28 17:15:50,861 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 17:15:50,862 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 17:15:51,479 - __main__ - INFO - Validation result at epoch  74, step    23200: duration: 26.0872s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9684.82520\tPPL: 6.83183\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 26.90\n","\tCHRF 31.58\tROUGE 26.90\n","2020-11-28 17:15:53,701 - __main__ - INFO - [Epoch: 074 Step: 00023240] Batch Translation Loss:   1.909173 => Txt Tokens per Sec:     1152 || Lr: 0.000700\n","2020-11-28 17:15:56,257 - __main__ - INFO - [Epoch: 074 Step: 00023280] Batch Translation Loss:   2.732294 => Txt Tokens per Sec:     1002 || Lr: 0.000700\n","2020-11-28 17:15:58,452 - __main__ - INFO - [Epoch: 074 Step: 00023320] Batch Translation Loss:   2.377738 => Txt Tokens per Sec:     1167 || Lr: 0.000700\n","2020-11-28 17:16:00,585 - __main__ - INFO - [Epoch: 074 Step: 00023360] Batch Translation Loss:   2.744944 => Txt Tokens per Sec:     1201 || Lr: 0.000700\n","2020-11-28 17:16:03,274 - __main__ - INFO - [Epoch: 074 Step: 00023400] Batch Translation Loss:   1.815995 => Txt Tokens per Sec:      953 || Lr: 0.000700\n","2020-11-28 17:16:05,714 - __main__ - INFO - [Epoch: 074 Step: 00023440] Batch Translation Loss:   2.617925 => Txt Tokens per Sec:     1050 || Lr: 0.000700\n","2020-11-28 17:16:07,081 - __main__ - INFO - Epoch  74: Total Training Recognition Loss -1.00  Total Training Translation Loss 731.72 \n","2020-11-28 17:16:07,082 - __main__ - INFO - EPOCH 75\n","2020-11-28 17:16:08,287 - __main__ - INFO - [Epoch: 075 Step: 00023480] Batch Translation Loss:   2.181084 => Txt Tokens per Sec:     1170 || Lr: 0.000700\n","2020-11-28 17:16:10,680 - __main__ - INFO - [Epoch: 075 Step: 00023520] Batch Translation Loss:   1.855040 => Txt Tokens per Sec:     1070 || Lr: 0.000700\n","2020-11-28 17:16:12,956 - __main__ - INFO - [Epoch: 075 Step: 00023560] Batch Translation Loss:   2.153272 => Txt Tokens per Sec:     1125 || Lr: 0.000700\n","2020-11-28 17:16:15,085 - __main__ - INFO - [Epoch: 075 Step: 00023600] Batch Translation Loss:   1.774810 => Txt Tokens per Sec:     1203 || Lr: 0.000700\n","2020-11-28 17:16:40,548 - __main__ - INFO - Validation result at epoch  75, step    23600: duration: 25.4616s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9822.61719\tPPL: 7.02118\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 26.87\n","\tCHRF 31.11\tROUGE 26.87\n","2020-11-28 17:16:42,961 - __main__ - INFO - [Epoch: 075 Step: 00023640] Batch Translation Loss:   2.397763 => Txt Tokens per Sec:     1061 || Lr: 0.000700\n","2020-11-28 17:16:45,368 - __main__ - INFO - [Epoch: 075 Step: 00023680] Batch Translation Loss:   2.153907 => Txt Tokens per Sec:     1064 || Lr: 0.000700\n","2020-11-28 17:16:47,706 - __main__ - INFO - [Epoch: 075 Step: 00023720] Batch Translation Loss:   2.465192 => Txt Tokens per Sec:     1096 || Lr: 0.000700\n","2020-11-28 17:16:49,882 - __main__ - INFO - [Epoch: 075 Step: 00023760] Batch Translation Loss:   2.596540 => Txt Tokens per Sec:     1177 || Lr: 0.000700\n","2020-11-28 17:16:50,950 - __main__ - INFO - Epoch  75: Total Training Recognition Loss -1.00  Total Training Translation Loss 729.35 \n","2020-11-28 17:16:50,952 - __main__ - INFO - EPOCH 76\n","2020-11-28 17:16:52,199 - __main__ - INFO - [Epoch: 076 Step: 00023800] Batch Translation Loss:   2.347811 => Txt Tokens per Sec:     1285 || Lr: 0.000700\n","2020-11-28 17:16:54,513 - __main__ - INFO - [Epoch: 076 Step: 00023840] Batch Translation Loss:   2.020560 => Txt Tokens per Sec:     1107 || Lr: 0.000700\n","2020-11-28 17:16:57,029 - __main__ - INFO - [Epoch: 076 Step: 00023880] Batch Translation Loss:   1.914621 => Txt Tokens per Sec:     1018 || Lr: 0.000700\n","2020-11-28 17:16:59,346 - __main__ - INFO - [Epoch: 076 Step: 00023920] Batch Translation Loss:   1.868862 => Txt Tokens per Sec:     1106 || Lr: 0.000700\n","2020-11-28 17:17:01,724 - __main__ - INFO - [Epoch: 076 Step: 00023960] Batch Translation Loss:   3.044784 => Txt Tokens per Sec:     1077 || Lr: 0.000700\n","2020-11-28 17:17:03,849 - __main__ - INFO - [Epoch: 076 Step: 00024000] Batch Translation Loss:   3.029474 => Txt Tokens per Sec:     1205 || Lr: 0.000700\n","2020-11-28 17:17:28,753 - __main__ - INFO - Validation result at epoch  76, step    24000: duration: 24.9023s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9774.71387\tPPL: 6.95477\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 26.15\n","\tCHRF 30.59\tROUGE 26.15\n","2020-11-28 17:17:30,961 - __main__ - INFO - [Epoch: 076 Step: 00024040] Batch Translation Loss:   2.227181 => Txt Tokens per Sec:     1159 || Lr: 0.000700\n","2020-11-28 17:17:33,469 - __main__ - INFO - [Epoch: 076 Step: 00024080] Batch Translation Loss:   2.508468 => Txt Tokens per Sec:     1021 || Lr: 0.000700\n","2020-11-28 17:17:34,424 - __main__ - INFO - Epoch  76: Total Training Recognition Loss -1.00  Total Training Translation Loss 716.37 \n","2020-11-28 17:17:34,425 - __main__ - INFO - EPOCH 77\n","2020-11-28 17:17:35,857 - __main__ - INFO - [Epoch: 077 Step: 00024120] Batch Translation Loss:   1.512460 => Txt Tokens per Sec:     1253 || Lr: 0.000700\n","2020-11-28 17:17:38,219 - __main__ - INFO - [Epoch: 077 Step: 00024160] Batch Translation Loss:   2.617604 => Txt Tokens per Sec:     1085 || Lr: 0.000700\n","2020-11-28 17:17:40,571 - __main__ - INFO - [Epoch: 077 Step: 00024200] Batch Translation Loss:   2.206856 => Txt Tokens per Sec:     1089 || Lr: 0.000700\n","2020-11-28 17:17:42,824 - __main__ - INFO - [Epoch: 077 Step: 00024240] Batch Translation Loss:   2.250067 => Txt Tokens per Sec:     1137 || Lr: 0.000700\n","2020-11-28 17:17:45,267 - __main__ - INFO - [Epoch: 077 Step: 00024280] Batch Translation Loss:   1.345052 => Txt Tokens per Sec:     1048 || Lr: 0.000700\n","2020-11-28 17:17:47,396 - __main__ - INFO - [Epoch: 077 Step: 00024320] Batch Translation Loss:   2.446539 => Txt Tokens per Sec:     1204 || Lr: 0.000700\n","2020-11-28 17:17:49,699 - __main__ - INFO - [Epoch: 077 Step: 00024360] Batch Translation Loss:   2.313732 => Txt Tokens per Sec:     1112 || Lr: 0.000700\n","2020-11-28 17:17:52,071 - __main__ - INFO - [Epoch: 077 Step: 00024400] Batch Translation Loss:   2.160034 => Txt Tokens per Sec:     1080 || Lr: 0.000700\n","2020-11-28 17:18:16,818 - __main__ - INFO - Validation result at epoch  77, step    24400: duration: 24.7451s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9668.91895\tPPL: 6.81030\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 26.79\n","\tCHRF 30.77\tROUGE 26.79\n","2020-11-28 17:18:17,487 - __main__ - INFO - Epoch  77: Total Training Recognition Loss -1.00  Total Training Translation Loss 703.80 \n","2020-11-28 17:18:17,489 - __main__ - INFO - EPOCH 78\n","2020-11-28 17:18:19,221 - __main__ - INFO - [Epoch: 078 Step: 00024440] Batch Translation Loss:   1.738762 => Txt Tokens per Sec:     1147 || Lr: 0.000700\n","2020-11-28 17:18:21,435 - __main__ - INFO - [Epoch: 078 Step: 00024480] Batch Translation Loss:   1.666122 => Txt Tokens per Sec:     1157 || Lr: 0.000700\n","2020-11-28 17:18:23,835 - __main__ - INFO - [Epoch: 078 Step: 00024520] Batch Translation Loss:   2.025669 => Txt Tokens per Sec:     1067 || Lr: 0.000700\n","2020-11-28 17:18:26,074 - __main__ - INFO - [Epoch: 078 Step: 00024560] Batch Translation Loss:   1.856942 => Txt Tokens per Sec:     1144 || Lr: 0.000700\n","2020-11-28 17:18:28,501 - __main__ - INFO - [Epoch: 078 Step: 00024600] Batch Translation Loss:   2.239960 => Txt Tokens per Sec:     1055 || Lr: 0.000700\n","2020-11-28 17:18:30,681 - __main__ - INFO - [Epoch: 078 Step: 00024640] Batch Translation Loss:   2.199075 => Txt Tokens per Sec:     1175 || Lr: 0.000700\n","2020-11-28 17:18:32,886 - __main__ - INFO - [Epoch: 078 Step: 00024680] Batch Translation Loss:   1.856064 => Txt Tokens per Sec:     1162 || Lr: 0.000700\n","2020-11-28 17:18:35,430 - __main__ - INFO - [Epoch: 078 Step: 00024720] Batch Translation Loss:   2.682824 => Txt Tokens per Sec:      998 || Lr: 0.000700\n","2020-11-28 17:18:35,837 - __main__ - INFO - Epoch  78: Total Training Recognition Loss -1.00  Total Training Translation Loss 683.81 \n","2020-11-28 17:18:35,839 - __main__ - INFO - EPOCH 79\n","2020-11-28 17:18:37,800 - __main__ - INFO - [Epoch: 079 Step: 00024760] Batch Translation Loss:   1.594016 => Txt Tokens per Sec:     1110 || Lr: 0.000700\n","2020-11-28 17:18:39,909 - __main__ - INFO - [Epoch: 079 Step: 00024800] Batch Translation Loss:   2.336226 => Txt Tokens per Sec:     1215 || Lr: 0.000700\n","2020-11-28 17:19:04,739 - __main__ - INFO - Validation result at epoch  79, step    24800: duration: 24.8288s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9824.68945\tPPL: 7.02407\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 26.67\n","\tCHRF 30.93\tROUGE 26.67\n","2020-11-28 17:19:07,199 - __main__ - INFO - [Epoch: 079 Step: 00024840] Batch Translation Loss:   1.997262 => Txt Tokens per Sec:     1041 || Lr: 0.000700\n","2020-11-28 17:19:09,627 - __main__ - INFO - [Epoch: 079 Step: 00024880] Batch Translation Loss:   2.014705 => Txt Tokens per Sec:     1055 || Lr: 0.000700\n","2020-11-28 17:19:11,884 - __main__ - INFO - [Epoch: 079 Step: 00024920] Batch Translation Loss:   1.727505 => Txt Tokens per Sec:     1135 || Lr: 0.000700\n","2020-11-28 17:19:14,442 - __main__ - INFO - [Epoch: 079 Step: 00024960] Batch Translation Loss:   2.698091 => Txt Tokens per Sec:     1002 || Lr: 0.000700\n","2020-11-28 17:19:16,668 - __main__ - INFO - [Epoch: 079 Step: 00025000] Batch Translation Loss:   2.402969 => Txt Tokens per Sec:     1151 || Lr: 0.000700\n","2020-11-28 17:19:19,157 - __main__ - INFO - [Epoch: 079 Step: 00025040] Batch Translation Loss:   2.959944 => Txt Tokens per Sec:     1020 || Lr: 0.000700\n","2020-11-28 17:19:19,346 - __main__ - INFO - Epoch  79: Total Training Recognition Loss -1.00  Total Training Translation Loss 681.31 \n","2020-11-28 17:19:19,347 - __main__ - INFO - EPOCH 80\n","2020-11-28 17:19:21,392 - __main__ - INFO - [Epoch: 080 Step: 00025080] Batch Translation Loss:   1.979403 => Txt Tokens per Sec:     1159 || Lr: 0.000700\n","2020-11-28 17:19:23,792 - __main__ - INFO - [Epoch: 080 Step: 00025120] Batch Translation Loss:   1.869592 => Txt Tokens per Sec:     1067 || Lr: 0.000700\n","2020-11-28 17:19:25,853 - __main__ - INFO - [Epoch: 080 Step: 00025160] Batch Translation Loss:   2.671731 => Txt Tokens per Sec:     1243 || Lr: 0.000700\n","2020-11-28 17:19:28,161 - __main__ - INFO - [Epoch: 080 Step: 00025200] Batch Translation Loss:   1.502613 => Txt Tokens per Sec:     1110 || Lr: 0.000700\n","2020-11-28 17:19:53,010 - __main__ - INFO - Validation result at epoch  80, step    25200: duration: 24.8482s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10008.65234\tPPL: 7.28519\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 26.35\n","\tCHRF 30.69\tROUGE 26.35\n","2020-11-28 17:19:55,232 - __main__ - INFO - [Epoch: 080 Step: 00025240] Batch Translation Loss:   2.165843 => Txt Tokens per Sec:     1152 || Lr: 0.000700\n","2020-11-28 17:19:57,389 - __main__ - INFO - [Epoch: 080 Step: 00025280] Batch Translation Loss:   2.948040 => Txt Tokens per Sec:     1188 || Lr: 0.000700\n","2020-11-28 17:19:59,800 - __main__ - INFO - [Epoch: 080 Step: 00025320] Batch Translation Loss:   2.531021 => Txt Tokens per Sec:     1062 || Lr: 0.000700\n","2020-11-28 17:20:02,359 - __main__ - INFO - [Epoch: 080 Step: 00025360] Batch Translation Loss:   1.876253 => Txt Tokens per Sec:      992 || Lr: 0.000700\n","2020-11-28 17:20:02,360 - __main__ - INFO - Epoch  80: Total Training Recognition Loss -1.00  Total Training Translation Loss 665.82 \n","2020-11-28 17:20:02,361 - __main__ - INFO - EPOCH 81\n","2020-11-28 17:20:04,590 - __main__ - INFO - [Epoch: 081 Step: 00025400] Batch Translation Loss:   2.609302 => Txt Tokens per Sec:     1149 || Lr: 0.000700\n","2020-11-28 17:20:06,719 - __main__ - INFO - [Epoch: 081 Step: 00025440] Batch Translation Loss:   2.357637 => Txt Tokens per Sec:     1203 || Lr: 0.000700\n","2020-11-28 17:20:08,986 - __main__ - INFO - [Epoch: 081 Step: 00025480] Batch Translation Loss:   1.657246 => Txt Tokens per Sec:     1130 || Lr: 0.000700\n","2020-11-28 17:20:11,296 - __main__ - INFO - [Epoch: 081 Step: 00025520] Batch Translation Loss:   1.639119 => Txt Tokens per Sec:     1109 || Lr: 0.000700\n","2020-11-28 17:20:13,501 - __main__ - INFO - [Epoch: 081 Step: 00025560] Batch Translation Loss:   1.586292 => Txt Tokens per Sec:     1162 || Lr: 0.000700\n","2020-11-28 17:20:15,630 - __main__ - INFO - [Epoch: 081 Step: 00025600] Batch Translation Loss:   2.290066 => Txt Tokens per Sec:     1203 || Lr: 0.000700\n","2020-11-28 17:20:40,374 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 17:20:40,376 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 17:20:41,009 - __main__ - INFO - Validation result at epoch  81, step    25600: duration: 25.3776s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9743.51562\tPPL: 6.91185\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 27.26\n","\tCHRF 31.63\tROUGE 27.26\n","2020-11-28 17:20:43,321 - __main__ - INFO - [Epoch: 081 Step: 00025640] Batch Translation Loss:   2.445242 => Txt Tokens per Sec:     1107 || Lr: 0.000700\n","2020-11-28 17:20:45,716 - __main__ - INFO - Epoch  81: Total Training Recognition Loss -1.00  Total Training Translation Loss 666.69 \n","2020-11-28 17:20:45,717 - __main__ - INFO - EPOCH 82\n","2020-11-28 17:20:45,898 - __main__ - INFO - [Epoch: 082 Step: 00025680] Batch Translation Loss:   1.953824 => Txt Tokens per Sec:     1068 || Lr: 0.000700\n","2020-11-28 17:20:48,498 - __main__ - INFO - [Epoch: 082 Step: 00025720] Batch Translation Loss:   1.635614 => Txt Tokens per Sec:      985 || Lr: 0.000700\n","2020-11-28 17:20:50,920 - __main__ - INFO - [Epoch: 082 Step: 00025760] Batch Translation Loss:   1.416267 => Txt Tokens per Sec:     1058 || Lr: 0.000700\n","2020-11-28 17:20:53,151 - __main__ - INFO - [Epoch: 082 Step: 00025800] Batch Translation Loss:   2.240454 => Txt Tokens per Sec:     1148 || Lr: 0.000700\n","2020-11-28 17:20:55,341 - __main__ - INFO - [Epoch: 082 Step: 00025840] Batch Translation Loss:   2.685250 => Txt Tokens per Sec:     1170 || Lr: 0.000700\n","2020-11-28 17:20:57,777 - __main__ - INFO - [Epoch: 082 Step: 00025880] Batch Translation Loss:   2.347535 => Txt Tokens per Sec:     1052 || Lr: 0.000700\n","2020-11-28 17:20:59,893 - __main__ - INFO - [Epoch: 082 Step: 00025920] Batch Translation Loss:   1.441133 => Txt Tokens per Sec:     1210 || Lr: 0.000700\n","2020-11-28 17:21:02,032 - __main__ - INFO - [Epoch: 082 Step: 00025960] Batch Translation Loss:   2.131272 => Txt Tokens per Sec:     1198 || Lr: 0.000700\n","2020-11-28 17:21:04,430 - __main__ - INFO - Epoch  82: Total Training Recognition Loss -1.00  Total Training Translation Loss 642.90 \n","2020-11-28 17:21:04,432 - __main__ - INFO - EPOCH 83\n","2020-11-28 17:21:04,731 - __main__ - INFO - [Epoch: 083 Step: 00026000] Batch Translation Loss:   1.595101 => Txt Tokens per Sec:     1289 || Lr: 0.000700\n","2020-11-28 17:21:29,844 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 17:21:29,845 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 17:21:30,464 - __main__ - INFO - Validation result at epoch  83, step    26000: duration: 25.7317s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 9794.61719\tPPL: 6.98229\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 27.82\n","\tCHRF 31.73\tROUGE 27.82\n","2020-11-28 17:21:32,815 - __main__ - INFO - [Epoch: 083 Step: 00026040] Batch Translation Loss:   1.819303 => Txt Tokens per Sec:     1089 || Lr: 0.000700\n","2020-11-28 17:21:35,148 - __main__ - INFO - [Epoch: 083 Step: 00026080] Batch Translation Loss:   1.969322 => Txt Tokens per Sec:     1098 || Lr: 0.000700\n","2020-11-28 17:21:37,548 - __main__ - INFO - [Epoch: 083 Step: 00026120] Batch Translation Loss:   1.875244 => Txt Tokens per Sec:     1067 || Lr: 0.000700\n","2020-11-28 17:21:40,008 - __main__ - INFO - [Epoch: 083 Step: 00026160] Batch Translation Loss:   1.882690 => Txt Tokens per Sec:     1041 || Lr: 0.000700\n","2020-11-28 17:21:42,522 - __main__ - INFO - [Epoch: 083 Step: 00026200] Batch Translation Loss:   2.291203 => Txt Tokens per Sec:     1019 || Lr: 0.000700\n","2020-11-28 17:21:44,888 - __main__ - INFO - [Epoch: 083 Step: 00026240] Batch Translation Loss:   1.902093 => Txt Tokens per Sec:     1082 || Lr: 0.000700\n","2020-11-28 17:21:47,118 - __main__ - INFO - [Epoch: 083 Step: 00026280] Batch Translation Loss:   2.010545 => Txt Tokens per Sec:     1149 || Lr: 0.000700\n","2020-11-28 17:21:49,219 - __main__ - INFO - Epoch  83: Total Training Recognition Loss -1.00  Total Training Translation Loss 632.92 \n","2020-11-28 17:21:49,220 - __main__ - INFO - EPOCH 84\n","2020-11-28 17:21:49,737 - __main__ - INFO - [Epoch: 084 Step: 00026320] Batch Translation Loss:   1.727261 => Txt Tokens per Sec:     1119 || Lr: 0.000700\n","2020-11-28 17:21:52,153 - __main__ - INFO - [Epoch: 084 Step: 00026360] Batch Translation Loss:   1.897714 => Txt Tokens per Sec:     1060 || Lr: 0.000700\n","2020-11-28 17:21:54,397 - __main__ - INFO - [Epoch: 084 Step: 00026400] Batch Translation Loss:   1.613796 => Txt Tokens per Sec:     1142 || Lr: 0.000700\n","2020-11-28 17:22:19,540 - __main__ - INFO - Validation result at epoch  84, step    26400: duration: 25.1417s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10371.91406\tPPL: 7.82966\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 25.71\n","\tCHRF 30.00\tROUGE 25.71\n","2020-11-28 17:22:21,888 - __main__ - INFO - [Epoch: 084 Step: 00026440] Batch Translation Loss:   1.450058 => Txt Tokens per Sec:     1091 || Lr: 0.000700\n","2020-11-28 17:22:24,188 - __main__ - INFO - [Epoch: 084 Step: 00026480] Batch Translation Loss:   2.038980 => Txt Tokens per Sec:     1113 || Lr: 0.000700\n","2020-11-28 17:22:26,633 - __main__ - INFO - [Epoch: 084 Step: 00026520] Batch Translation Loss:   1.683274 => Txt Tokens per Sec:     1048 || Lr: 0.000700\n","2020-11-28 17:22:28,843 - __main__ - INFO - [Epoch: 084 Step: 00026560] Batch Translation Loss:   1.630039 => Txt Tokens per Sec:     1159 || Lr: 0.000700\n","2020-11-28 17:22:31,059 - __main__ - INFO - [Epoch: 084 Step: 00026600] Batch Translation Loss:   2.281658 => Txt Tokens per Sec:     1156 || Lr: 0.000700\n","2020-11-28 17:22:33,120 - __main__ - INFO - Epoch  84: Total Training Recognition Loss -1.00  Total Training Translation Loss 628.76 \n","2020-11-28 17:22:33,121 - __main__ - INFO - EPOCH 85\n","2020-11-28 17:22:33,834 - __main__ - INFO - [Epoch: 085 Step: 00026640] Batch Translation Loss:   1.512277 => Txt Tokens per Sec:     1080 || Lr: 0.000700\n","2020-11-28 17:22:36,147 - __main__ - INFO - [Epoch: 085 Step: 00026680] Batch Translation Loss:   1.725040 => Txt Tokens per Sec:     1108 || Lr: 0.000700\n","2020-11-28 17:22:38,567 - __main__ - INFO - [Epoch: 085 Step: 00026720] Batch Translation Loss:   1.546972 => Txt Tokens per Sec:     1058 || Lr: 0.000700\n","2020-11-28 17:22:40,943 - __main__ - INFO - [Epoch: 085 Step: 00026760] Batch Translation Loss:   1.880084 => Txt Tokens per Sec:     1078 || Lr: 0.000700\n","2020-11-28 17:22:43,314 - __main__ - INFO - [Epoch: 085 Step: 00026800] Batch Translation Loss:   1.795979 => Txt Tokens per Sec:     1080 || Lr: 0.000700\n","2020-11-28 17:23:08,727 - __main__ - INFO - Validation result at epoch  85, step    26800: duration: 25.4112s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10008.11133\tPPL: 7.28441\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 26.27\n","\tCHRF 29.55\tROUGE 26.27\n","2020-11-28 17:23:11,157 - __main__ - INFO - [Epoch: 085 Step: 00026840] Batch Translation Loss:   1.842351 => Txt Tokens per Sec:     1053 || Lr: 0.000700\n","2020-11-28 17:23:13,592 - __main__ - INFO - [Epoch: 085 Step: 00026880] Batch Translation Loss:   1.663337 => Txt Tokens per Sec:     1052 || Lr: 0.000700\n","2020-11-28 17:23:15,842 - __main__ - INFO - [Epoch: 085 Step: 00026920] Batch Translation Loss:   1.999371 => Txt Tokens per Sec:     1138 || Lr: 0.000700\n","2020-11-28 17:23:17,643 - __main__ - INFO - Epoch  85: Total Training Recognition Loss -1.00  Total Training Translation Loss 611.93 \n","2020-11-28 17:23:17,644 - __main__ - INFO - EPOCH 86\n","2020-11-28 17:23:18,515 - __main__ - INFO - [Epoch: 086 Step: 00026960] Batch Translation Loss:   1.456590 => Txt Tokens per Sec:     1104 || Lr: 0.000700\n","2020-11-28 17:23:20,751 - __main__ - INFO - [Epoch: 086 Step: 00027000] Batch Translation Loss:   2.196440 => Txt Tokens per Sec:     1146 || Lr: 0.000700\n","2020-11-28 17:23:23,242 - __main__ - INFO - [Epoch: 086 Step: 00027040] Batch Translation Loss:   1.972845 => Txt Tokens per Sec:     1028 || Lr: 0.000700\n","2020-11-28 17:23:25,489 - __main__ - INFO - [Epoch: 086 Step: 00027080] Batch Translation Loss:   1.912531 => Txt Tokens per Sec:     1140 || Lr: 0.000700\n","2020-11-28 17:23:27,819 - __main__ - INFO - [Epoch: 086 Step: 00027120] Batch Translation Loss:   1.946803 => Txt Tokens per Sec:     1099 || Lr: 0.000700\n","2020-11-28 17:23:30,353 - __main__ - INFO - [Epoch: 086 Step: 00027160] Batch Translation Loss:   2.078484 => Txt Tokens per Sec:     1011 || Lr: 0.000700\n","2020-11-28 17:23:32,592 - __main__ - INFO - [Epoch: 086 Step: 00027200] Batch Translation Loss:   1.564095 => Txt Tokens per Sec:     1144 || Lr: 0.000700\n","2020-11-28 17:23:58,344 - __main__ - INFO - Validation result at epoch  86, step    27200: duration: 25.7508s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10196.74414\tPPL: 7.56221\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 26.31\n","\tCHRF 30.55\tROUGE 26.31\n","2020-11-28 17:24:00,911 - __main__ - INFO - [Epoch: 086 Step: 00027240] Batch Translation Loss:   2.088822 => Txt Tokens per Sec:      998 || Lr: 0.000700\n","2020-11-28 17:24:02,503 - __main__ - INFO - Epoch  86: Total Training Recognition Loss -1.00  Total Training Translation Loss 600.91 \n","2020-11-28 17:24:02,504 - __main__ - INFO - EPOCH 87\n","2020-11-28 17:24:03,549 - __main__ - INFO - [Epoch: 087 Step: 00027280] Batch Translation Loss:   1.388422 => Txt Tokens per Sec:     1104 || Lr: 0.000700\n","2020-11-28 17:24:05,964 - __main__ - INFO - [Epoch: 087 Step: 00027320] Batch Translation Loss:   1.262675 => Txt Tokens per Sec:     1061 || Lr: 0.000700\n","2020-11-28 17:24:08,260 - __main__ - INFO - [Epoch: 087 Step: 00027360] Batch Translation Loss:   1.695425 => Txt Tokens per Sec:     1116 || Lr: 0.000700\n","2020-11-28 17:24:10,771 - __main__ - INFO - [Epoch: 087 Step: 00027400] Batch Translation Loss:   2.362319 => Txt Tokens per Sec:     1020 || Lr: 0.000700\n","2020-11-28 17:24:13,060 - __main__ - INFO - [Epoch: 087 Step: 00027440] Batch Translation Loss:   2.119565 => Txt Tokens per Sec:     1119 || Lr: 0.000700\n","2020-11-28 17:24:15,350 - __main__ - INFO - [Epoch: 087 Step: 00027480] Batch Translation Loss:   2.080693 => Txt Tokens per Sec:     1119 || Lr: 0.000700\n","2020-11-28 17:24:17,973 - __main__ - INFO - [Epoch: 087 Step: 00027520] Batch Translation Loss:   2.318845 => Txt Tokens per Sec:      976 || Lr: 0.000700\n","2020-11-28 17:24:20,179 - __main__ - INFO - [Epoch: 087 Step: 00027560] Batch Translation Loss:   2.332385 => Txt Tokens per Sec:     1161 || Lr: 0.000700\n","2020-11-28 17:24:21,506 - __main__ - INFO - Epoch  87: Total Training Recognition Loss -1.00  Total Training Translation Loss 589.18 \n","2020-11-28 17:24:21,507 - __main__ - INFO - EPOCH 88\n","2020-11-28 17:24:22,861 - __main__ - INFO - [Epoch: 088 Step: 00027600] Batch Translation Loss:   1.527058 => Txt Tokens per Sec:      994 || Lr: 0.000700\n","2020-11-28 17:24:48,579 - __main__ - INFO - Validation result at epoch  88, step    27600: duration: 25.7164s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10314.33398\tPPL: 7.74072\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 26.27\n","\tCHRF 30.47\tROUGE 26.27\n","2020-11-28 17:24:50,921 - __main__ - INFO - [Epoch: 088 Step: 00027640] Batch Translation Loss:   1.823080 => Txt Tokens per Sec:     1093 || Lr: 0.000700\n","2020-11-28 17:24:53,273 - __main__ - INFO - [Epoch: 088 Step: 00027680] Batch Translation Loss:   1.614537 => Txt Tokens per Sec:     1089 || Lr: 0.000700\n","2020-11-28 17:24:55,655 - __main__ - INFO - [Epoch: 088 Step: 00027720] Batch Translation Loss:   2.279592 => Txt Tokens per Sec:     1076 || Lr: 0.000700\n","2020-11-28 17:24:58,057 - __main__ - INFO - [Epoch: 088 Step: 00027760] Batch Translation Loss:   2.096192 => Txt Tokens per Sec:     1066 || Lr: 0.000700\n","2020-11-28 17:25:00,636 - __main__ - INFO - [Epoch: 088 Step: 00027800] Batch Translation Loss:   2.416089 => Txt Tokens per Sec:      993 || Lr: 0.000700\n","2020-11-28 17:25:02,898 - __main__ - INFO - [Epoch: 088 Step: 00027840] Batch Translation Loss:   2.636756 => Txt Tokens per Sec:     1133 || Lr: 0.000700\n","2020-11-28 17:25:05,325 - __main__ - INFO - [Epoch: 088 Step: 00027880] Batch Translation Loss:   1.520788 => Txt Tokens per Sec:     1055 || Lr: 0.000700\n","2020-11-28 17:25:06,442 - __main__ - INFO - Epoch  88: Total Training Recognition Loss -1.00  Total Training Translation Loss 587.88 \n","2020-11-28 17:25:06,443 - __main__ - INFO - EPOCH 89\n","2020-11-28 17:25:07,907 - __main__ - INFO - [Epoch: 089 Step: 00027920] Batch Translation Loss:   1.794736 => Txt Tokens per Sec:     1050 || Lr: 0.000700\n","2020-11-28 17:25:10,145 - __main__ - INFO - [Epoch: 089 Step: 00027960] Batch Translation Loss:   1.867065 => Txt Tokens per Sec:     1145 || Lr: 0.000700\n","2020-11-28 17:25:12,564 - __main__ - INFO - [Epoch: 089 Step: 00028000] Batch Translation Loss:   1.216292 => Txt Tokens per Sec:     1059 || Lr: 0.000700\n","2020-11-28 17:25:38,478 - __main__ - INFO - Validation result at epoch  89, step    28000: duration: 25.9123s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10193.78418\tPPL: 7.55777\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 26.87\n","\tCHRF 31.04\tROUGE 26.87\n","2020-11-28 17:25:40,997 - __main__ - INFO - [Epoch: 089 Step: 00028040] Batch Translation Loss:   1.817048 => Txt Tokens per Sec:     1016 || Lr: 0.000700\n","2020-11-28 17:25:43,239 - __main__ - INFO - [Epoch: 089 Step: 00028080] Batch Translation Loss:   1.668449 => Txt Tokens per Sec:     1143 || Lr: 0.000700\n","2020-11-28 17:25:45,520 - __main__ - INFO - [Epoch: 089 Step: 00028120] Batch Translation Loss:   1.725653 => Txt Tokens per Sec:     1123 || Lr: 0.000700\n","2020-11-28 17:25:47,957 - __main__ - INFO - [Epoch: 089 Step: 00028160] Batch Translation Loss:   1.994366 => Txt Tokens per Sec:     1051 || Lr: 0.000700\n","2020-11-28 17:25:50,234 - __main__ - INFO - [Epoch: 089 Step: 00028200] Batch Translation Loss:   1.581976 => Txt Tokens per Sec:     1125 || Lr: 0.000700\n","2020-11-28 17:25:51,259 - __main__ - INFO - Epoch  89: Total Training Recognition Loss -1.00  Total Training Translation Loss 573.19 \n","2020-11-28 17:25:51,261 - __main__ - INFO - EPOCH 90\n","2020-11-28 17:25:52,766 - __main__ - INFO - [Epoch: 090 Step: 00028240] Batch Translation Loss:   1.395903 => Txt Tokens per Sec:     1149 || Lr: 0.000700\n","2020-11-28 17:25:54,978 - __main__ - INFO - [Epoch: 090 Step: 00028280] Batch Translation Loss:   0.957102 => Txt Tokens per Sec:     1159 || Lr: 0.000700\n","2020-11-28 17:25:57,386 - __main__ - INFO - [Epoch: 090 Step: 00028320] Batch Translation Loss:   1.988671 => Txt Tokens per Sec:     1064 || Lr: 0.000700\n","2020-11-28 17:25:59,820 - __main__ - INFO - [Epoch: 090 Step: 00028360] Batch Translation Loss:   1.981040 => Txt Tokens per Sec:     1052 || Lr: 0.000700\n","2020-11-28 17:26:02,078 - __main__ - INFO - [Epoch: 090 Step: 00028400] Batch Translation Loss:   2.065765 => Txt Tokens per Sec:     1134 || Lr: 0.000700\n","2020-11-28 17:26:28,295 - __main__ - INFO - Validation result at epoch  90, step    28400: duration: 26.2159s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10341.09863\tPPL: 7.78194\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 25.91\n","\tCHRF 30.04\tROUGE 25.91\n","2020-11-28 17:26:30,712 - __main__ - INFO - [Epoch: 090 Step: 00028440] Batch Translation Loss:   1.802900 => Txt Tokens per Sec:     1059 || Lr: 0.000700\n","2020-11-28 17:26:33,194 - __main__ - INFO - [Epoch: 090 Step: 00028480] Batch Translation Loss:   2.476046 => Txt Tokens per Sec:     1032 || Lr: 0.000700\n","2020-11-28 17:26:35,648 - __main__ - INFO - [Epoch: 090 Step: 00028520] Batch Translation Loss:   2.516063 => Txt Tokens per Sec:     1035 || Lr: 0.000700\n","2020-11-28 17:26:36,347 - __main__ - INFO - Epoch  90: Total Training Recognition Loss -1.00  Total Training Translation Loss 568.71 \n","2020-11-28 17:26:36,348 - __main__ - INFO - EPOCH 91\n","2020-11-28 17:26:38,010 - __main__ - INFO - [Epoch: 091 Step: 00028560] Batch Translation Loss:   1.624853 => Txt Tokens per Sec:     1156 || Lr: 0.000700\n","2020-11-28 17:26:40,335 - __main__ - INFO - [Epoch: 091 Step: 00028600] Batch Translation Loss:   0.989914 => Txt Tokens per Sec:     1102 || Lr: 0.000700\n","2020-11-28 17:26:42,732 - __main__ - INFO - [Epoch: 091 Step: 00028640] Batch Translation Loss:   1.519020 => Txt Tokens per Sec:     1068 || Lr: 0.000700\n","2020-11-28 17:26:44,987 - __main__ - INFO - [Epoch: 091 Step: 00028680] Batch Translation Loss:   1.915549 => Txt Tokens per Sec:     1136 || Lr: 0.000700\n","2020-11-28 17:26:47,389 - __main__ - INFO - [Epoch: 091 Step: 00028720] Batch Translation Loss:   2.134952 => Txt Tokens per Sec:     1067 || Lr: 0.000700\n","2020-11-28 17:26:49,679 - __main__ - INFO - [Epoch: 091 Step: 00028760] Batch Translation Loss:   2.282925 => Txt Tokens per Sec:     1119 || Lr: 0.000700\n","2020-11-28 17:26:52,166 - __main__ - INFO - [Epoch: 091 Step: 00028800] Batch Translation Loss:   1.964931 => Txt Tokens per Sec:     1030 || Lr: 0.000700\n","2020-11-28 17:27:17,733 - __main__ - INFO - Validation result at epoch  91, step    28800: duration: 25.5664s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10351.15625\tPPL: 7.79748\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 27.26\n","\tCHRF 31.49\tROUGE 27.26\n","2020-11-28 17:27:20,078 - __main__ - INFO - [Epoch: 091 Step: 00028840] Batch Translation Loss:   1.667611 => Txt Tokens per Sec:     1083 || Lr: 0.000700\n","2020-11-28 17:27:20,507 - __main__ - INFO - Epoch  91: Total Training Recognition Loss -1.00  Total Training Translation Loss 557.17 \n","2020-11-28 17:27:20,508 - __main__ - INFO - EPOCH 92\n","2020-11-28 17:27:22,399 - __main__ - INFO - [Epoch: 092 Step: 00028880] Batch Translation Loss:   1.000706 => Txt Tokens per Sec:     1118 || Lr: 0.000700\n","2020-11-28 17:27:24,805 - __main__ - INFO - [Epoch: 092 Step: 00028920] Batch Translation Loss:   1.459263 => Txt Tokens per Sec:     1065 || Lr: 0.000700\n","2020-11-28 17:27:26,967 - __main__ - INFO - [Epoch: 092 Step: 00028960] Batch Translation Loss:   1.165363 => Txt Tokens per Sec:     1185 || Lr: 0.000700\n","2020-11-28 17:27:29,366 - __main__ - INFO - [Epoch: 092 Step: 00029000] Batch Translation Loss:   1.311054 => Txt Tokens per Sec:     1068 || Lr: 0.000700\n","2020-11-28 17:27:31,641 - __main__ - INFO - [Epoch: 092 Step: 00029040] Batch Translation Loss:   1.317704 => Txt Tokens per Sec:     1126 || Lr: 0.000700\n","2020-11-28 17:27:33,871 - __main__ - INFO - [Epoch: 092 Step: 00029080] Batch Translation Loss:   1.374032 => Txt Tokens per Sec:     1148 || Lr: 0.000700\n","2020-11-28 17:27:36,268 - __main__ - INFO - [Epoch: 092 Step: 00029120] Batch Translation Loss:   1.361668 => Txt Tokens per Sec:     1069 || Lr: 0.000700\n","2020-11-28 17:27:38,574 - __main__ - INFO - [Epoch: 092 Step: 00029160] Batch Translation Loss:   1.851738 => Txt Tokens per Sec:     1110 || Lr: 0.000700\n","2020-11-28 17:27:38,953 - __main__ - INFO - Epoch  92: Total Training Recognition Loss -1.00  Total Training Translation Loss 550.35 \n","2020-11-28 17:27:38,954 - __main__ - INFO - EPOCH 93\n","2020-11-28 17:27:41,053 - __main__ - INFO - [Epoch: 093 Step: 00029200] Batch Translation Loss:   1.319692 => Txt Tokens per Sec:     1099 || Lr: 0.000700\n","2020-11-28 17:28:06,287 - __main__ - INFO - Validation result at epoch  93, step    29200: duration: 25.2326s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10370.58105\tPPL: 7.82759\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 26.94\n","\tCHRF 30.58\tROUGE 26.94\n","2020-11-28 17:28:08,700 - __main__ - INFO - [Epoch: 093 Step: 00029240] Batch Translation Loss:   1.687202 => Txt Tokens per Sec:     1061 || Lr: 0.000700\n","2020-11-28 17:28:11,058 - __main__ - INFO - [Epoch: 093 Step: 00029280] Batch Translation Loss:   1.396415 => Txt Tokens per Sec:     1086 || Lr: 0.000700\n","2020-11-28 17:28:13,358 - __main__ - INFO - [Epoch: 093 Step: 00029320] Batch Translation Loss:   1.616894 => Txt Tokens per Sec:     1114 || Lr: 0.000700\n","2020-11-28 17:28:15,575 - __main__ - INFO - [Epoch: 093 Step: 00029360] Batch Translation Loss:   1.295733 => Txt Tokens per Sec:     1155 || Lr: 0.000700\n","2020-11-28 17:28:18,175 - __main__ - INFO - [Epoch: 093 Step: 00029400] Batch Translation Loss:   1.999915 => Txt Tokens per Sec:      985 || Lr: 0.000700\n","2020-11-28 17:28:20,435 - __main__ - INFO - [Epoch: 093 Step: 00029440] Batch Translation Loss:   1.885059 => Txt Tokens per Sec:     1134 || Lr: 0.000700\n","2020-11-28 17:28:23,025 - __main__ - INFO - [Epoch: 093 Step: 00029480] Batch Translation Loss:   1.623053 => Txt Tokens per Sec:      980 || Lr: 0.000700\n","2020-11-28 17:28:23,081 - __main__ - INFO - Epoch  93: Total Training Recognition Loss -1.00  Total Training Translation Loss 542.08 \n","2020-11-28 17:28:23,082 - __main__ - INFO - EPOCH 94\n","2020-11-28 17:28:25,491 - __main__ - INFO - [Epoch: 094 Step: 00029520] Batch Translation Loss:   1.332708 => Txt Tokens per Sec:     1037 || Lr: 0.000700\n","2020-11-28 17:28:27,821 - __main__ - INFO - [Epoch: 094 Step: 00029560] Batch Translation Loss:   1.668228 => Txt Tokens per Sec:     1099 || Lr: 0.000700\n","2020-11-28 17:28:29,911 - __main__ - INFO - [Epoch: 094 Step: 00029600] Batch Translation Loss:   1.979912 => Txt Tokens per Sec:     1226 || Lr: 0.000700\n","2020-11-28 17:28:55,173 - __main__ - INFO - Validation result at epoch  94, step    29600: duration: 25.2596s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10425.79004\tPPL: 7.91381\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 27.66\n","\tCHRF 31.60\tROUGE 27.66\n","2020-11-28 17:28:57,668 - __main__ - INFO - [Epoch: 094 Step: 00029640] Batch Translation Loss:   2.641089 => Txt Tokens per Sec:     1026 || Lr: 0.000490\n","2020-11-28 17:28:59,860 - __main__ - INFO - [Epoch: 094 Step: 00029680] Batch Translation Loss:   1.455442 => Txt Tokens per Sec:     1169 || Lr: 0.000490\n","2020-11-28 17:29:02,065 - __main__ - INFO - [Epoch: 094 Step: 00029720] Batch Translation Loss:   1.228772 => Txt Tokens per Sec:     1162 || Lr: 0.000490\n","2020-11-28 17:29:04,551 - __main__ - INFO - [Epoch: 094 Step: 00029760] Batch Translation Loss:   1.964481 => Txt Tokens per Sec:     1031 || Lr: 0.000490\n","2020-11-28 17:29:06,939 - __main__ - INFO - Epoch  94: Total Training Recognition Loss -1.00  Total Training Translation Loss 510.10 \n","2020-11-28 17:29:06,940 - __main__ - INFO - EPOCH 95\n","2020-11-28 17:29:07,099 - __main__ - INFO - [Epoch: 095 Step: 00029800] Batch Translation Loss:   1.237420 => Txt Tokens per Sec:      815 || Lr: 0.000490\n","2020-11-28 17:29:09,415 - __main__ - INFO - [Epoch: 095 Step: 00029840] Batch Translation Loss:   1.123908 => Txt Tokens per Sec:     1106 || Lr: 0.000490\n","2020-11-28 17:29:11,595 - __main__ - INFO - [Epoch: 095 Step: 00029880] Batch Translation Loss:   1.492767 => Txt Tokens per Sec:     1175 || Lr: 0.000490\n","2020-11-28 17:29:14,006 - __main__ - INFO - [Epoch: 095 Step: 00029920] Batch Translation Loss:   1.331978 => Txt Tokens per Sec:     1062 || Lr: 0.000490\n","2020-11-28 17:29:16,440 - __main__ - INFO - [Epoch: 095 Step: 00029960] Batch Translation Loss:   1.889229 => Txt Tokens per Sec:     1052 || Lr: 0.000490\n","2020-11-28 17:29:18,624 - __main__ - INFO - [Epoch: 095 Step: 00030000] Batch Translation Loss:   1.530702 => Txt Tokens per Sec:     1173 || Lr: 0.000490\n","2020-11-28 17:29:44,034 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 17:29:44,035 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 17:29:44,642 - __main__ - INFO - Validation result at epoch  95, step    30000: duration: 26.0166s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10123.65918\tPPL: 7.45334\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 28.93\n","\tCHRF 33.03\tROUGE 28.93\n","2020-11-28 17:29:46,923 - __main__ - INFO - [Epoch: 095 Step: 00030040] Batch Translation Loss:   1.804635 => Txt Tokens per Sec:     1123 || Lr: 0.000490\n","2020-11-28 17:29:49,333 - __main__ - INFO - [Epoch: 095 Step: 00030080] Batch Translation Loss:   1.260425 => Txt Tokens per Sec:     1063 || Lr: 0.000490\n","2020-11-28 17:29:51,612 - __main__ - INFO - Epoch  95: Total Training Recognition Loss -1.00  Total Training Translation Loss 462.81 \n","2020-11-28 17:29:51,614 - __main__ - INFO - EPOCH 96\n","2020-11-28 17:29:51,917 - __main__ - INFO - [Epoch: 096 Step: 00030120] Batch Translation Loss:   0.918432 => Txt Tokens per Sec:     1063 || Lr: 0.000490\n","2020-11-28 17:29:54,387 - __main__ - INFO - [Epoch: 096 Step: 00030160] Batch Translation Loss:   1.019149 => Txt Tokens per Sec:     1037 || Lr: 0.000490\n","2020-11-28 17:29:56,904 - __main__ - INFO - [Epoch: 096 Step: 00030200] Batch Translation Loss:   1.231834 => Txt Tokens per Sec:     1018 || Lr: 0.000490\n","2020-11-28 17:29:59,083 - __main__ - INFO - [Epoch: 096 Step: 00030240] Batch Translation Loss:   1.271416 => Txt Tokens per Sec:     1175 || Lr: 0.000490\n","2020-11-28 17:30:01,510 - __main__ - INFO - [Epoch: 096 Step: 00030280] Batch Translation Loss:   1.378255 => Txt Tokens per Sec:     1056 || Lr: 0.000490\n","2020-11-28 17:30:03,764 - __main__ - INFO - [Epoch: 096 Step: 00030320] Batch Translation Loss:   1.218575 => Txt Tokens per Sec:     1136 || Lr: 0.000490\n","2020-11-28 17:30:06,173 - __main__ - INFO - [Epoch: 096 Step: 00030360] Batch Translation Loss:   1.430527 => Txt Tokens per Sec:     1063 || Lr: 0.000490\n","2020-11-28 17:30:08,461 - __main__ - INFO - [Epoch: 096 Step: 00030400] Batch Translation Loss:   1.364947 => Txt Tokens per Sec:     1120 || Lr: 0.000490\n","2020-11-28 17:30:33,573 - __main__ - INFO - Validation result at epoch  96, step    30400: duration: 25.1111s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10188.19824\tPPL: 7.54940\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 28.65\n","\tCHRF 32.38\tROUGE 28.65\n","2020-11-28 17:30:35,582 - __main__ - INFO - Epoch  96: Total Training Recognition Loss -1.00  Total Training Translation Loss 458.40 \n","2020-11-28 17:30:35,583 - __main__ - INFO - EPOCH 97\n","2020-11-28 17:30:36,015 - __main__ - INFO - [Epoch: 097 Step: 00030440] Batch Translation Loss:   2.091740 => Txt Tokens per Sec:     1192 || Lr: 0.000490\n","2020-11-28 17:30:38,225 - __main__ - INFO - [Epoch: 097 Step: 00030480] Batch Translation Loss:   1.535353 => Txt Tokens per Sec:     1159 || Lr: 0.000490\n","2020-11-28 17:30:40,583 - __main__ - INFO - [Epoch: 097 Step: 00030520] Batch Translation Loss:   1.110501 => Txt Tokens per Sec:     1086 || Lr: 0.000490\n","2020-11-28 17:30:42,902 - __main__ - INFO - [Epoch: 097 Step: 00030560] Batch Translation Loss:   1.566537 => Txt Tokens per Sec:     1105 || Lr: 0.000490\n","2020-11-28 17:30:45,300 - __main__ - INFO - [Epoch: 097 Step: 00030600] Batch Translation Loss:   1.561357 => Txt Tokens per Sec:     1068 || Lr: 0.000490\n","2020-11-28 17:30:47,543 - __main__ - INFO - [Epoch: 097 Step: 00030640] Batch Translation Loss:   1.456699 => Txt Tokens per Sec:     1142 || Lr: 0.000490\n","2020-11-28 17:30:49,832 - __main__ - INFO - [Epoch: 097 Step: 00030680] Batch Translation Loss:   1.050412 => Txt Tokens per Sec:     1119 || Lr: 0.000490\n","2020-11-28 17:30:52,083 - __main__ - INFO - [Epoch: 097 Step: 00030720] Batch Translation Loss:   1.939000 => Txt Tokens per Sec:     1138 || Lr: 0.000490\n","2020-11-28 17:30:54,333 - __main__ - INFO - Epoch  97: Total Training Recognition Loss -1.00  Total Training Translation Loss 449.13 \n","2020-11-28 17:30:54,334 - __main__ - INFO - EPOCH 98\n","2020-11-28 17:30:54,970 - __main__ - INFO - [Epoch: 098 Step: 00030760] Batch Translation Loss:   0.999507 => Txt Tokens per Sec:     1109 || Lr: 0.000490\n","2020-11-28 17:30:57,226 - __main__ - INFO - [Epoch: 098 Step: 00030800] Batch Translation Loss:   1.476105 => Txt Tokens per Sec:     1135 || Lr: 0.000490\n","2020-11-28 17:31:22,442 - __main__ - INFO - Validation result at epoch  98, step    30800: duration: 25.2140s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10266.51758\tPPL: 7.66763\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 28.49\n","\tCHRF 32.85\tROUGE 28.49\n","2020-11-28 17:31:24,757 - __main__ - INFO - [Epoch: 098 Step: 00030840] Batch Translation Loss:   1.589056 => Txt Tokens per Sec:     1106 || Lr: 0.000490\n","2020-11-28 17:31:26,954 - __main__ - INFO - [Epoch: 098 Step: 00030880] Batch Translation Loss:   1.311472 => Txt Tokens per Sec:     1166 || Lr: 0.000490\n","2020-11-28 17:31:29,419 - __main__ - INFO - [Epoch: 098 Step: 00030920] Batch Translation Loss:   1.334088 => Txt Tokens per Sec:     1039 || Lr: 0.000490\n","2020-11-28 17:31:31,915 - __main__ - INFO - [Epoch: 098 Step: 00030960] Batch Translation Loss:   1.018410 => Txt Tokens per Sec:     1026 || Lr: 0.000490\n","2020-11-28 17:31:34,196 - __main__ - INFO - [Epoch: 098 Step: 00031000] Batch Translation Loss:   1.178712 => Txt Tokens per Sec:     1123 || Lr: 0.000490\n","2020-11-28 17:31:36,385 - __main__ - INFO - [Epoch: 098 Step: 00031040] Batch Translation Loss:   1.677001 => Txt Tokens per Sec:     1170 || Lr: 0.000490\n","2020-11-28 17:31:38,111 - __main__ - INFO - Epoch  98: Total Training Recognition Loss -1.00  Total Training Translation Loss 439.82 \n","2020-11-28 17:31:38,112 - __main__ - INFO - EPOCH 99\n","2020-11-28 17:31:38,896 - __main__ - INFO - [Epoch: 099 Step: 00031080] Batch Translation Loss:   1.102489 => Txt Tokens per Sec:     1146 || Lr: 0.000490\n","2020-11-28 17:31:41,226 - __main__ - INFO - [Epoch: 099 Step: 00031120] Batch Translation Loss:   1.388910 => Txt Tokens per Sec:     1099 || Lr: 0.000490\n","2020-11-28 17:31:43,445 - __main__ - INFO - [Epoch: 099 Step: 00031160] Batch Translation Loss:   1.083680 => Txt Tokens per Sec:     1155 || Lr: 0.000490\n","2020-11-28 17:31:45,835 - __main__ - INFO - [Epoch: 099 Step: 00031200] Batch Translation Loss:   1.409123 => Txt Tokens per Sec:     1072 || Lr: 0.000490\n","2020-11-28 17:32:10,982 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 17:32:10,984 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 17:32:11,615 - __main__ - INFO - Validation result at epoch  99, step    31200: duration: 25.7792s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10284.80566\tPPL: 7.69550\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 29.29\n","\tCHRF 32.37\tROUGE 29.29\n","2020-11-28 17:32:13,909 - __main__ - INFO - [Epoch: 099 Step: 00031240] Batch Translation Loss:   1.533381 => Txt Tokens per Sec:     1116 || Lr: 0.000490\n","2020-11-28 17:32:16,283 - __main__ - INFO - [Epoch: 099 Step: 00031280] Batch Translation Loss:   1.456210 => Txt Tokens per Sec:     1079 || Lr: 0.000490\n","2020-11-28 17:32:18,626 - __main__ - INFO - [Epoch: 099 Step: 00031320] Batch Translation Loss:   1.812265 => Txt Tokens per Sec:     1093 || Lr: 0.000490\n","2020-11-28 17:32:21,143 - __main__ - INFO - [Epoch: 099 Step: 00031360] Batch Translation Loss:   2.228688 => Txt Tokens per Sec:     1018 || Lr: 0.000490\n","2020-11-28 17:32:22,723 - __main__ - INFO - Epoch  99: Total Training Recognition Loss -1.00  Total Training Translation Loss 436.00 \n","2020-11-28 17:32:22,725 - __main__ - INFO - EPOCH 100\n","2020-11-28 17:32:23,826 - __main__ - INFO - [Epoch: 100 Step: 00031400] Batch Translation Loss:   0.826655 => Txt Tokens per Sec:      989 || Lr: 0.000490\n","2020-11-28 17:32:26,155 - __main__ - INFO - [Epoch: 100 Step: 00031440] Batch Translation Loss:   1.093748 => Txt Tokens per Sec:     1101 || Lr: 0.000490\n","2020-11-28 17:32:28,469 - __main__ - INFO - [Epoch: 100 Step: 00031480] Batch Translation Loss:   1.412165 => Txt Tokens per Sec:     1107 || Lr: 0.000490\n","2020-11-28 17:32:30,594 - __main__ - INFO - [Epoch: 100 Step: 00031520] Batch Translation Loss:   1.320897 => Txt Tokens per Sec:     1205 || Lr: 0.000490\n","2020-11-28 17:32:33,164 - __main__ - INFO - [Epoch: 100 Step: 00031560] Batch Translation Loss:   1.622838 => Txt Tokens per Sec:      997 || Lr: 0.000490\n","2020-11-28 17:32:35,379 - __main__ - INFO - [Epoch: 100 Step: 00031600] Batch Translation Loss:   1.612327 => Txt Tokens per Sec:     1157 || Lr: 0.000490\n","2020-11-28 17:33:00,389 - __main__ - INFO - Validation result at epoch 100, step    31600: duration: 25.0089s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10297.27051\tPPL: 7.71456\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 28.85\n","\tCHRF 32.48\tROUGE 28.85\n","2020-11-28 17:33:02,896 - __main__ - INFO - [Epoch: 100 Step: 00031640] Batch Translation Loss:   1.099224 => Txt Tokens per Sec:     1021 || Lr: 0.000490\n","2020-11-28 17:33:05,022 - __main__ - INFO - [Epoch: 100 Step: 00031680] Batch Translation Loss:   1.665515 => Txt Tokens per Sec:     1205 || Lr: 0.000490\n","2020-11-28 17:33:06,422 - __main__ - INFO - Epoch 100: Total Training Recognition Loss -1.00  Total Training Translation Loss 429.41 \n","2020-11-28 17:33:06,424 - __main__ - INFO - EPOCH 101\n","2020-11-28 17:33:07,527 - __main__ - INFO - [Epoch: 101 Step: 00031720] Batch Translation Loss:   0.827738 => Txt Tokens per Sec:     1162 || Lr: 0.000490\n","2020-11-28 17:33:09,761 - __main__ - INFO - [Epoch: 101 Step: 00031760] Batch Translation Loss:   1.418303 => Txt Tokens per Sec:     1147 || Lr: 0.000490\n","2020-11-28 17:33:12,270 - __main__ - INFO - [Epoch: 101 Step: 00031800] Batch Translation Loss:   1.047827 => Txt Tokens per Sec:     1021 || Lr: 0.000490\n","2020-11-28 17:33:14,646 - __main__ - INFO - [Epoch: 101 Step: 00031840] Batch Translation Loss:   1.581211 => Txt Tokens per Sec:     1078 || Lr: 0.000490\n","2020-11-28 17:33:16,917 - __main__ - INFO - [Epoch: 101 Step: 00031880] Batch Translation Loss:   1.194890 => Txt Tokens per Sec:     1128 || Lr: 0.000490\n","2020-11-28 17:33:19,126 - __main__ - INFO - [Epoch: 101 Step: 00031920] Batch Translation Loss:   1.229014 => Txt Tokens per Sec:     1160 || Lr: 0.000490\n","2020-11-28 17:33:21,616 - __main__ - INFO - [Epoch: 101 Step: 00031960] Batch Translation Loss:   0.866100 => Txt Tokens per Sec:     1029 || Lr: 0.000490\n","2020-11-28 17:33:23,895 - __main__ - INFO - [Epoch: 101 Step: 00032000] Batch Translation Loss:   1.386474 => Txt Tokens per Sec:     1124 || Lr: 0.000490\n","2020-11-28 17:33:48,957 - __main__ - INFO - Validation result at epoch 101, step    32000: duration: 25.0605s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10474.79004\tPPL: 7.99112\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 28.17\n","\tCHRF 32.49\tROUGE 28.17\n","2020-11-28 17:33:50,229 - __main__ - INFO - Epoch 101: Total Training Recognition Loss -1.00  Total Training Translation Loss 419.58 \n","2020-11-28 17:33:50,230 - __main__ - INFO - EPOCH 102\n","2020-11-28 17:33:51,555 - __main__ - INFO - [Epoch: 102 Step: 00032040] Batch Translation Loss:   0.786186 => Txt Tokens per Sec:     1113 || Lr: 0.000490\n","2020-11-28 17:33:53,976 - __main__ - INFO - [Epoch: 102 Step: 00032080] Batch Translation Loss:   0.999783 => Txt Tokens per Sec:     1058 || Lr: 0.000490\n","2020-11-28 17:33:56,382 - __main__ - INFO - [Epoch: 102 Step: 00032120] Batch Translation Loss:   1.068135 => Txt Tokens per Sec:     1065 || Lr: 0.000490\n","2020-11-28 17:33:58,637 - __main__ - INFO - [Epoch: 102 Step: 00032160] Batch Translation Loss:   0.943559 => Txt Tokens per Sec:     1136 || Lr: 0.000490\n","2020-11-28 17:34:00,923 - __main__ - INFO - [Epoch: 102 Step: 00032200] Batch Translation Loss:   1.163946 => Txt Tokens per Sec:     1121 || Lr: 0.000490\n","2020-11-28 17:34:03,498 - __main__ - INFO - [Epoch: 102 Step: 00032240] Batch Translation Loss:   1.130837 => Txt Tokens per Sec:      995 || Lr: 0.000490\n","2020-11-28 17:34:05,760 - __main__ - INFO - [Epoch: 102 Step: 00032280] Batch Translation Loss:   1.441985 => Txt Tokens per Sec:     1133 || Lr: 0.000490\n","2020-11-28 17:34:07,873 - __main__ - INFO - [Epoch: 102 Step: 00032320] Batch Translation Loss:   1.556322 => Txt Tokens per Sec:     1213 || Lr: 0.000490\n","2020-11-28 17:34:08,916 - __main__ - INFO - Epoch 102: Total Training Recognition Loss -1.00  Total Training Translation Loss 414.79 \n","2020-11-28 17:34:08,917 - __main__ - INFO - EPOCH 103\n","2020-11-28 17:34:10,614 - __main__ - INFO - [Epoch: 103 Step: 00032360] Batch Translation Loss:   1.203064 => Txt Tokens per Sec:      982 || Lr: 0.000490\n","2020-11-28 17:34:12,935 - __main__ - INFO - [Epoch: 103 Step: 00032400] Batch Translation Loss:   0.868979 => Txt Tokens per Sec:     1103 || Lr: 0.000490\n","2020-11-28 17:34:38,099 - __main__ - INFO - Validation result at epoch 103, step    32400: duration: 25.1612s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10586.37793\tPPL: 8.17002\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 27.90\n","\tCHRF 31.77\tROUGE 27.90\n","2020-11-28 17:34:40,266 - __main__ - INFO - [Epoch: 103 Step: 00032440] Batch Translation Loss:   1.414871 => Txt Tokens per Sec:     1181 || Lr: 0.000490\n","2020-11-28 17:34:42,626 - __main__ - INFO - [Epoch: 103 Step: 00032480] Batch Translation Loss:   0.890512 => Txt Tokens per Sec:     1085 || Lr: 0.000490\n","2020-11-28 17:34:44,939 - __main__ - INFO - [Epoch: 103 Step: 00032520] Batch Translation Loss:   1.334572 => Txt Tokens per Sec:     1108 || Lr: 0.000490\n","2020-11-28 17:34:47,216 - __main__ - INFO - [Epoch: 103 Step: 00032560] Batch Translation Loss:   1.264522 => Txt Tokens per Sec:     1125 || Lr: 0.000490\n","2020-11-28 17:34:49,687 - __main__ - INFO - [Epoch: 103 Step: 00032600] Batch Translation Loss:   1.018029 => Txt Tokens per Sec:     1037 || Lr: 0.000490\n","2020-11-28 17:34:51,970 - __main__ - INFO - [Epoch: 103 Step: 00032640] Batch Translation Loss:   1.517819 => Txt Tokens per Sec:     1122 || Lr: 0.000490\n","2020-11-28 17:34:52,731 - __main__ - INFO - Epoch 103: Total Training Recognition Loss -1.00  Total Training Translation Loss 407.63 \n","2020-11-28 17:34:52,733 - __main__ - INFO - EPOCH 104\n","2020-11-28 17:34:54,560 - __main__ - INFO - [Epoch: 104 Step: 00032680] Batch Translation Loss:   1.443496 => Txt Tokens per Sec:     1016 || Lr: 0.000490\n","2020-11-28 17:34:56,796 - __main__ - INFO - [Epoch: 104 Step: 00032720] Batch Translation Loss:   1.146306 => Txt Tokens per Sec:     1146 || Lr: 0.000490\n","2020-11-28 17:34:58,976 - __main__ - INFO - [Epoch: 104 Step: 00032760] Batch Translation Loss:   1.303993 => Txt Tokens per Sec:     1175 || Lr: 0.000490\n","2020-11-28 17:35:01,347 - __main__ - INFO - [Epoch: 104 Step: 00032800] Batch Translation Loss:   1.732833 => Txt Tokens per Sec:     1080 || Lr: 0.000490\n","2020-11-28 17:35:26,549 - __main__ - INFO - Validation result at epoch 104, step    32800: duration: 25.2009s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10497.65137\tPPL: 8.02745\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 28.37\n","\tCHRF 32.68\tROUGE 28.37\n","2020-11-28 17:35:28,733 - __main__ - INFO - [Epoch: 104 Step: 00032840] Batch Translation Loss:   1.171113 => Txt Tokens per Sec:     1172 || Lr: 0.000490\n","2020-11-28 17:35:31,043 - __main__ - INFO - [Epoch: 104 Step: 00032880] Batch Translation Loss:   0.906769 => Txt Tokens per Sec:     1109 || Lr: 0.000490\n","2020-11-28 17:35:33,424 - __main__ - INFO - [Epoch: 104 Step: 00032920] Batch Translation Loss:   1.360847 => Txt Tokens per Sec:     1076 || Lr: 0.000490\n","2020-11-28 17:35:35,772 - __main__ - INFO - [Epoch: 104 Step: 00032960] Batch Translation Loss:   1.667405 => Txt Tokens per Sec:     1091 || Lr: 0.000490\n","2020-11-28 17:35:36,397 - __main__ - INFO - Epoch 104: Total Training Recognition Loss -1.00  Total Training Translation Loss 408.31 \n","2020-11-28 17:35:36,398 - __main__ - INFO - EPOCH 105\n","2020-11-28 17:35:38,042 - __main__ - INFO - [Epoch: 105 Step: 00033000] Batch Translation Loss:   1.703574 => Txt Tokens per Sec:     1247 || Lr: 0.000490\n","2020-11-28 17:35:40,444 - __main__ - INFO - [Epoch: 105 Step: 00033040] Batch Translation Loss:   1.359626 => Txt Tokens per Sec:     1066 || Lr: 0.000490\n","2020-11-28 17:35:42,776 - __main__ - INFO - [Epoch: 105 Step: 00033080] Batch Translation Loss:   1.104413 => Txt Tokens per Sec:     1099 || Lr: 0.000490\n","2020-11-28 17:35:45,109 - __main__ - INFO - [Epoch: 105 Step: 00033120] Batch Translation Loss:   1.176250 => Txt Tokens per Sec:     1098 || Lr: 0.000490\n","2020-11-28 17:35:47,408 - __main__ - INFO - [Epoch: 105 Step: 00033160] Batch Translation Loss:   1.307027 => Txt Tokens per Sec:     1114 || Lr: 0.000490\n","2020-11-28 17:35:49,478 - __main__ - INFO - [Epoch: 105 Step: 00033200] Batch Translation Loss:   1.093242 => Txt Tokens per Sec:     1238 || Lr: 0.000490\n","2020-11-28 17:36:14,341 - __main__ - INFO - Validation result at epoch 105, step    33200: duration: 24.8622s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10347.39941\tPPL: 7.79167\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 28.69\n","\tCHRF 33.15\tROUGE 28.69\n","2020-11-28 17:36:16,789 - __main__ - INFO - [Epoch: 105 Step: 00033240] Batch Translation Loss:   1.068499 => Txt Tokens per Sec:     1046 || Lr: 0.000490\n","2020-11-28 17:36:19,291 - __main__ - INFO - [Epoch: 105 Step: 00033280] Batch Translation Loss:   1.548734 => Txt Tokens per Sec:     1015 || Lr: 0.000490\n","2020-11-28 17:36:19,658 - __main__ - INFO - Epoch 105: Total Training Recognition Loss -1.00  Total Training Translation Loss 403.18 \n","2020-11-28 17:36:19,659 - __main__ - INFO - EPOCH 106\n","2020-11-28 17:36:21,715 - __main__ - INFO - [Epoch: 106 Step: 00033320] Batch Translation Loss:   1.395977 => Txt Tokens per Sec:     1090 || Lr: 0.000490\n","2020-11-28 17:36:23,965 - __main__ - INFO - [Epoch: 106 Step: 00033360] Batch Translation Loss:   1.363418 => Txt Tokens per Sec:     1139 || Lr: 0.000490\n","2020-11-28 17:36:26,362 - __main__ - INFO - [Epoch: 106 Step: 00033400] Batch Translation Loss:   1.445617 => Txt Tokens per Sec:     1069 || Lr: 0.000490\n","2020-11-28 17:36:28,749 - __main__ - INFO - [Epoch: 106 Step: 00033440] Batch Translation Loss:   0.950162 => Txt Tokens per Sec:     1073 || Lr: 0.000490\n","2020-11-28 17:36:31,063 - __main__ - INFO - [Epoch: 106 Step: 00033480] Batch Translation Loss:   0.975803 => Txt Tokens per Sec:     1107 || Lr: 0.000490\n","2020-11-28 17:36:33,396 - __main__ - INFO - [Epoch: 106 Step: 00033520] Batch Translation Loss:   1.477156 => Txt Tokens per Sec:     1098 || Lr: 0.000490\n","2020-11-28 17:36:35,606 - __main__ - INFO - [Epoch: 106 Step: 00033560] Batch Translation Loss:   0.799100 => Txt Tokens per Sec:     1159 || Lr: 0.000490\n","2020-11-28 17:36:38,218 - __main__ - INFO - [Epoch: 106 Step: 00033600] Batch Translation Loss:   1.511457 => Txt Tokens per Sec:      972 || Lr: 0.000490\n","2020-11-28 17:37:02,863 - __main__ - INFO - Validation result at epoch 106, step    33600: duration: 24.6435s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10353.68750\tPPL: 7.80140\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 28.97\n","\tCHRF 32.69\tROUGE 28.97\n","2020-11-28 17:37:02,988 - __main__ - INFO - Epoch 106: Total Training Recognition Loss -1.00  Total Training Translation Loss 398.46 \n","2020-11-28 17:37:02,989 - __main__ - INFO - EPOCH 107\n","2020-11-28 17:37:05,335 - __main__ - INFO - [Epoch: 107 Step: 00033640] Batch Translation Loss:   0.805838 => Txt Tokens per Sec:     1038 || Lr: 0.000490\n","2020-11-28 17:37:07,521 - __main__ - INFO - [Epoch: 107 Step: 00033680] Batch Translation Loss:   0.788813 => Txt Tokens per Sec:     1172 || Lr: 0.000490\n","2020-11-28 17:37:09,673 - __main__ - INFO - [Epoch: 107 Step: 00033720] Batch Translation Loss:   0.915967 => Txt Tokens per Sec:     1190 || Lr: 0.000490\n","2020-11-28 17:37:11,951 - __main__ - INFO - [Epoch: 107 Step: 00033760] Batch Translation Loss:   0.842264 => Txt Tokens per Sec:     1125 || Lr: 0.000490\n","2020-11-28 17:37:14,337 - __main__ - INFO - [Epoch: 107 Step: 00033800] Batch Translation Loss:   1.721168 => Txt Tokens per Sec:     1073 || Lr: 0.000490\n","2020-11-28 17:37:16,640 - __main__ - INFO - [Epoch: 107 Step: 00033840] Batch Translation Loss:   1.009835 => Txt Tokens per Sec:     1113 || Lr: 0.000490\n","2020-11-28 17:37:18,884 - __main__ - INFO - [Epoch: 107 Step: 00033880] Batch Translation Loss:   1.191745 => Txt Tokens per Sec:     1142 || Lr: 0.000490\n","2020-11-28 17:37:21,217 - __main__ - INFO - Epoch 107: Total Training Recognition Loss -1.00  Total Training Translation Loss 390.96 \n","2020-11-28 17:37:21,219 - __main__ - INFO - EPOCH 108\n","2020-11-28 17:37:21,283 - __main__ - INFO - [Epoch: 108 Step: 00033920] Batch Translation Loss:   0.977646 => Txt Tokens per Sec:     1021 || Lr: 0.000490\n","2020-11-28 17:37:23,546 - __main__ - INFO - [Epoch: 108 Step: 00033960] Batch Translation Loss:   1.002045 => Txt Tokens per Sec:     1132 || Lr: 0.000490\n","2020-11-28 17:37:25,805 - __main__ - INFO - [Epoch: 108 Step: 00034000] Batch Translation Loss:   1.367102 => Txt Tokens per Sec:     1134 || Lr: 0.000490\n","2020-11-28 17:37:51,027 - __main__ - INFO - Validation result at epoch 108, step    34000: duration: 25.2205s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10680.90234\tPPL: 8.32470\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 28.06\n","\tCHRF 32.15\tROUGE 28.06\n","2020-11-28 17:37:53,243 - __main__ - INFO - [Epoch: 108 Step: 00034040] Batch Translation Loss:   1.179147 => Txt Tokens per Sec:     1156 || Lr: 0.000490\n","2020-11-28 17:37:55,620 - __main__ - INFO - [Epoch: 108 Step: 00034080] Batch Translation Loss:   1.133180 => Txt Tokens per Sec:     1077 || Lr: 0.000490\n","2020-11-28 17:37:57,914 - __main__ - INFO - [Epoch: 108 Step: 00034120] Batch Translation Loss:   0.951925 => Txt Tokens per Sec:     1116 || Lr: 0.000490\n","2020-11-28 17:38:00,149 - __main__ - INFO - [Epoch: 108 Step: 00034160] Batch Translation Loss:   1.323503 => Txt Tokens per Sec:     1146 || Lr: 0.000490\n","2020-11-28 17:38:02,645 - __main__ - INFO - [Epoch: 108 Step: 00034200] Batch Translation Loss:   1.088038 => Txt Tokens per Sec:     1026 || Lr: 0.000490\n","2020-11-28 17:38:04,981 - __main__ - INFO - Epoch 108: Total Training Recognition Loss -1.00  Total Training Translation Loss 394.91 \n","2020-11-28 17:38:04,982 - __main__ - INFO - EPOCH 109\n","2020-11-28 17:38:05,211 - __main__ - INFO - [Epoch: 109 Step: 00034240] Batch Translation Loss:   0.945912 => Txt Tokens per Sec:     1127 || Lr: 0.000490\n","2020-11-28 17:38:07,696 - __main__ - INFO - [Epoch: 109 Step: 00034280] Batch Translation Loss:   1.153393 => Txt Tokens per Sec:     1031 || Lr: 0.000490\n","2020-11-28 17:38:10,058 - __main__ - INFO - [Epoch: 109 Step: 00034320] Batch Translation Loss:   1.514811 => Txt Tokens per Sec:     1085 || Lr: 0.000490\n","2020-11-28 17:38:12,200 - __main__ - INFO - [Epoch: 109 Step: 00034360] Batch Translation Loss:   1.333202 => Txt Tokens per Sec:     1196 || Lr: 0.000490\n","2020-11-28 17:38:14,565 - __main__ - INFO - [Epoch: 109 Step: 00034400] Batch Translation Loss:   1.425822 => Txt Tokens per Sec:     1083 || Lr: 0.000490\n","2020-11-28 17:38:39,655 - __main__ - INFO - Validation result at epoch 109, step    34400: duration: 25.0883s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10696.21777\tPPL: 8.35003\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 28.13\n","\tCHRF 32.00\tROUGE 28.13\n","2020-11-28 17:38:41,910 - __main__ - INFO - [Epoch: 109 Step: 00034440] Batch Translation Loss:   1.985857 => Txt Tokens per Sec:     1135 || Lr: 0.000490\n","2020-11-28 17:38:44,057 - __main__ - INFO - [Epoch: 109 Step: 00034480] Batch Translation Loss:   1.156547 => Txt Tokens per Sec:     1193 || Lr: 0.000490\n","2020-11-28 17:38:46,448 - __main__ - INFO - [Epoch: 109 Step: 00034520] Batch Translation Loss:   1.948198 => Txt Tokens per Sec:     1071 || Lr: 0.000490\n","2020-11-28 17:38:48,546 - __main__ - INFO - Epoch 109: Total Training Recognition Loss -1.00  Total Training Translation Loss 389.04 \n","2020-11-28 17:38:48,548 - __main__ - INFO - EPOCH 110\n","2020-11-28 17:38:48,921 - __main__ - INFO - [Epoch: 110 Step: 00034560] Batch Translation Loss:   1.366951 => Txt Tokens per Sec:     1205 || Lr: 0.000490\n","2020-11-28 17:38:51,228 - __main__ - INFO - [Epoch: 110 Step: 00034600] Batch Translation Loss:   0.925354 => Txt Tokens per Sec:     1111 || Lr: 0.000490\n","2020-11-28 17:38:53,576 - __main__ - INFO - [Epoch: 110 Step: 00034640] Batch Translation Loss:   1.083928 => Txt Tokens per Sec:     1091 || Lr: 0.000490\n","2020-11-28 17:38:55,766 - __main__ - INFO - [Epoch: 110 Step: 00034680] Batch Translation Loss:   1.022207 => Txt Tokens per Sec:     1170 || Lr: 0.000490\n","2020-11-28 17:38:58,009 - __main__ - INFO - [Epoch: 110 Step: 00034720] Batch Translation Loss:   0.949706 => Txt Tokens per Sec:     1142 || Lr: 0.000490\n","2020-11-28 17:39:00,514 - __main__ - INFO - [Epoch: 110 Step: 00034760] Batch Translation Loss:   1.260763 => Txt Tokens per Sec:     1023 || Lr: 0.000490\n","2020-11-28 17:39:02,861 - __main__ - INFO - [Epoch: 110 Step: 00034800] Batch Translation Loss:   0.708420 => Txt Tokens per Sec:     1092 || Lr: 0.000490\n","2020-11-28 17:39:27,490 - __main__ - INFO - Validation result at epoch 110, step    34800: duration: 24.6283s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10798.31934\tPPL: 8.52092\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 28.13\n","\tCHRF 32.38\tROUGE 28.13\n","2020-11-28 17:39:29,960 - __main__ - INFO - [Epoch: 110 Step: 00034840] Batch Translation Loss:   0.762565 => Txt Tokens per Sec:     1036 || Lr: 0.000343\n","2020-11-28 17:39:31,843 - __main__ - INFO - Epoch 110: Total Training Recognition Loss -1.00  Total Training Translation Loss 377.41 \n","2020-11-28 17:39:31,845 - __main__ - INFO - EPOCH 111\n","2020-11-28 17:39:32,491 - __main__ - INFO - [Epoch: 111 Step: 00034880] Batch Translation Loss:   0.811424 => Txt Tokens per Sec:      992 || Lr: 0.000343\n","2020-11-28 17:39:34,742 - __main__ - INFO - [Epoch: 111 Step: 00034920] Batch Translation Loss:   0.563526 => Txt Tokens per Sec:     1138 || Lr: 0.000343\n","2020-11-28 17:39:36,948 - __main__ - INFO - [Epoch: 111 Step: 00034960] Batch Translation Loss:   0.913966 => Txt Tokens per Sec:     1161 || Lr: 0.000343\n","2020-11-28 17:39:39,140 - __main__ - INFO - [Epoch: 111 Step: 00035000] Batch Translation Loss:   1.185810 => Txt Tokens per Sec:     1169 || Lr: 0.000343\n","2020-11-28 17:39:41,525 - __main__ - INFO - [Epoch: 111 Step: 00035040] Batch Translation Loss:   0.932197 => Txt Tokens per Sec:     1074 || Lr: 0.000343\n","2020-11-28 17:39:43,607 - __main__ - INFO - [Epoch: 111 Step: 00035080] Batch Translation Loss:   1.045821 => Txt Tokens per Sec:     1231 || Lr: 0.000343\n","2020-11-28 17:39:45,787 - __main__ - INFO - [Epoch: 111 Step: 00035120] Batch Translation Loss:   1.446699 => Txt Tokens per Sec:     1175 || Lr: 0.000343\n","2020-11-28 17:39:48,192 - __main__ - INFO - [Epoch: 111 Step: 00035160] Batch Translation Loss:   1.462734 => Txt Tokens per Sec:     1065 || Lr: 0.000343\n","2020-11-28 17:39:50,010 - __main__ - INFO - Epoch 111: Total Training Recognition Loss -1.00  Total Training Translation Loss 336.58 \n","2020-11-28 17:39:50,012 - __main__ - INFO - EPOCH 112\n","2020-11-28 17:39:50,726 - __main__ - INFO - [Epoch: 112 Step: 00035200] Batch Translation Loss:   0.659883 => Txt Tokens per Sec:     1168 || Lr: 0.000343\n","2020-11-28 17:40:15,721 - __main__ - INFO - Validation result at epoch 112, step    35200: duration: 24.9942s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10379.20410\tPPL: 7.84100\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 29.17\n","\tCHRF 32.67\tROUGE 29.17\n","2020-11-28 17:40:18,016 - __main__ - INFO - [Epoch: 112 Step: 00035240] Batch Translation Loss:   1.351422 => Txt Tokens per Sec:     1115 || Lr: 0.000343\n","2020-11-28 17:40:20,398 - __main__ - INFO - [Epoch: 112 Step: 00035280] Batch Translation Loss:   1.076244 => Txt Tokens per Sec:     1076 || Lr: 0.000343\n","2020-11-28 17:40:22,664 - __main__ - INFO - [Epoch: 112 Step: 00035320] Batch Translation Loss:   1.104368 => Txt Tokens per Sec:     1130 || Lr: 0.000343\n","2020-11-28 17:40:25,070 - __main__ - INFO - [Epoch: 112 Step: 00035360] Batch Translation Loss:   0.765396 => Txt Tokens per Sec:     1065 || Lr: 0.000343\n","2020-11-28 17:40:27,260 - __main__ - INFO - [Epoch: 112 Step: 00035400] Batch Translation Loss:   1.296654 => Txt Tokens per Sec:     1170 || Lr: 0.000343\n","2020-11-28 17:40:29,576 - __main__ - INFO - [Epoch: 112 Step: 00035440] Batch Translation Loss:   0.869765 => Txt Tokens per Sec:     1106 || Lr: 0.000343\n","2020-11-28 17:40:31,869 - __main__ - INFO - [Epoch: 112 Step: 00035480] Batch Translation Loss:   1.390615 => Txt Tokens per Sec:     1117 || Lr: 0.000343\n","2020-11-28 17:40:33,534 - __main__ - INFO - Epoch 112: Total Training Recognition Loss -1.00  Total Training Translation Loss 333.34 \n","2020-11-28 17:40:33,536 - __main__ - INFO - EPOCH 113\n","2020-11-28 17:40:34,542 - __main__ - INFO - [Epoch: 113 Step: 00035520] Batch Translation Loss:   1.292635 => Txt Tokens per Sec:     1020 || Lr: 0.000343\n","2020-11-28 17:40:36,826 - __main__ - INFO - [Epoch: 113 Step: 00035560] Batch Translation Loss:   0.574051 => Txt Tokens per Sec:     1121 || Lr: 0.000343\n","2020-11-28 17:40:39,124 - __main__ - INFO - [Epoch: 113 Step: 00035600] Batch Translation Loss:   1.115694 => Txt Tokens per Sec:     1115 || Lr: 0.000343\n","2020-11-28 17:41:03,899 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 17:41:03,900 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 17:41:04,514 - __main__ - INFO - Validation result at epoch 113, step    35600: duration: 25.3887s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10505.54102\tPPL: 8.04003\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.36\n","\tCHRF 33.80\tROUGE 30.36\n","2020-11-28 17:41:06,947 - __main__ - INFO - [Epoch: 113 Step: 00035640] Batch Translation Loss:   0.973342 => Txt Tokens per Sec:     1052 || Lr: 0.000343\n","2020-11-28 17:41:09,125 - __main__ - INFO - [Epoch: 113 Step: 00035680] Batch Translation Loss:   0.941562 => Txt Tokens per Sec:     1176 || Lr: 0.000343\n","2020-11-28 17:41:11,265 - __main__ - INFO - [Epoch: 113 Step: 00035720] Batch Translation Loss:   1.249169 => Txt Tokens per Sec:     1197 || Lr: 0.000343\n","2020-11-28 17:41:13,722 - __main__ - INFO - [Epoch: 113 Step: 00035760] Batch Translation Loss:   0.765610 => Txt Tokens per Sec:     1043 || Lr: 0.000343\n","2020-11-28 17:41:16,229 - __main__ - INFO - [Epoch: 113 Step: 00035800] Batch Translation Loss:   0.938823 => Txt Tokens per Sec:     1022 || Lr: 0.000343\n","2020-11-28 17:41:17,655 - __main__ - INFO - Epoch 113: Total Training Recognition Loss -1.00  Total Training Translation Loss 322.00 \n","2020-11-28 17:41:17,656 - __main__ - INFO - EPOCH 114\n","2020-11-28 17:41:18,840 - __main__ - INFO - [Epoch: 114 Step: 00035840] Batch Translation Loss:   0.854932 => Txt Tokens per Sec:     1028 || Lr: 0.000343\n","2020-11-28 17:41:21,014 - __main__ - INFO - [Epoch: 114 Step: 00035880] Batch Translation Loss:   0.904088 => Txt Tokens per Sec:     1178 || Lr: 0.000343\n","2020-11-28 17:41:23,217 - __main__ - INFO - [Epoch: 114 Step: 00035920] Batch Translation Loss:   1.146165 => Txt Tokens per Sec:     1163 || Lr: 0.000343\n","2020-11-28 17:41:25,404 - __main__ - INFO - [Epoch: 114 Step: 00035960] Batch Translation Loss:   0.789100 => Txt Tokens per Sec:     1171 || Lr: 0.000343\n","2020-11-28 17:41:27,853 - __main__ - INFO - [Epoch: 114 Step: 00036000] Batch Translation Loss:   0.990791 => Txt Tokens per Sec:     1046 || Lr: 0.000343\n","2020-11-28 17:41:52,458 - __main__ - INFO - Validation result at epoch 114, step    36000: duration: 24.6040s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10515.58398\tPPL: 8.05607\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 29.13\n","\tCHRF 32.70\tROUGE 29.13\n","2020-11-28 17:41:54,502 - __main__ - INFO - [Epoch: 114 Step: 00036040] Batch Translation Loss:   1.863638 => Txt Tokens per Sec:     1252 || Lr: 0.000343\n","2020-11-28 17:41:56,690 - __main__ - INFO - [Epoch: 114 Step: 00036080] Batch Translation Loss:   0.887424 => Txt Tokens per Sec:     1171 || Lr: 0.000343\n","2020-11-28 17:41:59,094 - __main__ - INFO - [Epoch: 114 Step: 00036120] Batch Translation Loss:   0.724533 => Txt Tokens per Sec:     1066 || Lr: 0.000343\n","2020-11-28 17:42:00,377 - __main__ - INFO - Epoch 114: Total Training Recognition Loss -1.00  Total Training Translation Loss 317.66 \n","2020-11-28 17:42:00,378 - __main__ - INFO - EPOCH 115\n","2020-11-28 17:42:01,588 - __main__ - INFO - [Epoch: 115 Step: 00036160] Batch Translation Loss:   1.048385 => Txt Tokens per Sec:     1166 || Lr: 0.000343\n","2020-11-28 17:42:04,116 - __main__ - INFO - [Epoch: 115 Step: 00036200] Batch Translation Loss:   1.079441 => Txt Tokens per Sec:     1013 || Lr: 0.000343\n","2020-11-28 17:42:06,213 - __main__ - INFO - [Epoch: 115 Step: 00036240] Batch Translation Loss:   0.705891 => Txt Tokens per Sec:     1221 || Lr: 0.000343\n","2020-11-28 17:42:08,590 - __main__ - INFO - [Epoch: 115 Step: 00036280] Batch Translation Loss:   0.690252 => Txt Tokens per Sec:     1078 || Lr: 0.000343\n","2020-11-28 17:42:10,726 - __main__ - INFO - [Epoch: 115 Step: 00036320] Batch Translation Loss:   1.063127 => Txt Tokens per Sec:     1199 || Lr: 0.000343\n","2020-11-28 17:42:12,961 - __main__ - INFO - [Epoch: 115 Step: 00036360] Batch Translation Loss:   1.081248 => Txt Tokens per Sec:     1147 || Lr: 0.000343\n","2020-11-28 17:42:15,441 - __main__ - INFO - [Epoch: 115 Step: 00036400] Batch Translation Loss:   0.973653 => Txt Tokens per Sec:     1033 || Lr: 0.000343\n","2020-11-28 17:42:40,205 - __main__ - INFO - Validation result at epoch 115, step    36400: duration: 24.7623s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10560.53418\tPPL: 8.12824\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 29.96\n","\tCHRF 33.62\tROUGE 29.96\n","2020-11-28 17:42:42,463 - __main__ - INFO - [Epoch: 115 Step: 00036440] Batch Translation Loss:   1.668208 => Txt Tokens per Sec:     1133 || Lr: 0.000343\n","2020-11-28 17:42:43,553 - __main__ - INFO - Epoch 115: Total Training Recognition Loss -1.00  Total Training Translation Loss 320.89 \n","2020-11-28 17:42:43,555 - __main__ - INFO - EPOCH 116\n","2020-11-28 17:42:45,081 - __main__ - INFO - [Epoch: 116 Step: 00036480] Batch Translation Loss:   0.852681 => Txt Tokens per Sec:     1051 || Lr: 0.000343\n","2020-11-28 17:42:47,287 - __main__ - INFO - [Epoch: 116 Step: 00036520] Batch Translation Loss:   1.269001 => Txt Tokens per Sec:     1161 || Lr: 0.000343\n","2020-11-28 17:42:49,591 - __main__ - INFO - [Epoch: 116 Step: 00036560] Batch Translation Loss:   1.540368 => Txt Tokens per Sec:     1112 || Lr: 0.000343\n","2020-11-28 17:42:51,935 - __main__ - INFO - [Epoch: 116 Step: 00036600] Batch Translation Loss:   1.508772 => Txt Tokens per Sec:     1093 || Lr: 0.000343\n","2020-11-28 17:42:54,206 - __main__ - INFO - [Epoch: 116 Step: 00036640] Batch Translation Loss:   1.001673 => Txt Tokens per Sec:     1128 || Lr: 0.000343\n","2020-11-28 17:42:56,353 - __main__ - INFO - [Epoch: 116 Step: 00036680] Batch Translation Loss:   1.045434 => Txt Tokens per Sec:     1193 || Lr: 0.000343\n","2020-11-28 17:42:58,764 - __main__ - INFO - [Epoch: 116 Step: 00036720] Batch Translation Loss:   1.290998 => Txt Tokens per Sec:     1062 || Lr: 0.000343\n","2020-11-28 17:43:00,959 - __main__ - INFO - [Epoch: 116 Step: 00036760] Batch Translation Loss:   2.127860 => Txt Tokens per Sec:     1167 || Lr: 0.000343\n","2020-11-28 17:43:01,821 - __main__ - INFO - Epoch 116: Total Training Recognition Loss -1.00  Total Training Translation Loss 322.91 \n","2020-11-28 17:43:01,823 - __main__ - INFO - EPOCH 117\n","2020-11-28 17:43:03,416 - __main__ - INFO - [Epoch: 117 Step: 00036800] Batch Translation Loss:   0.770525 => Txt Tokens per Sec:     1126 || Lr: 0.000343\n","2020-11-28 17:43:28,708 - __main__ - INFO - Validation result at epoch 117, step    36800: duration: 25.2910s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10720.40820\tPPL: 8.39021\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 29.21\n","\tCHRF 33.28\tROUGE 29.21\n","2020-11-28 17:43:31,012 - __main__ - INFO - [Epoch: 117 Step: 00036840] Batch Translation Loss:   0.709992 => Txt Tokens per Sec:     1111 || Lr: 0.000343\n","2020-11-28 17:43:33,286 - __main__ - INFO - [Epoch: 117 Step: 00036880] Batch Translation Loss:   1.210504 => Txt Tokens per Sec:     1126 || Lr: 0.000343\n","2020-11-28 17:43:35,497 - __main__ - INFO - [Epoch: 117 Step: 00036920] Batch Translation Loss:   1.312415 => Txt Tokens per Sec:     1159 || Lr: 0.000343\n","2020-11-28 17:43:37,789 - __main__ - INFO - [Epoch: 117 Step: 00036960] Batch Translation Loss:   0.945444 => Txt Tokens per Sec:     1118 || Lr: 0.000343\n","2020-11-28 17:43:39,975 - __main__ - INFO - [Epoch: 117 Step: 00037000] Batch Translation Loss:   1.071902 => Txt Tokens per Sec:     1172 || Lr: 0.000343\n","2020-11-28 17:43:42,168 - __main__ - INFO - [Epoch: 117 Step: 00037040] Batch Translation Loss:   1.190485 => Txt Tokens per Sec:     1168 || Lr: 0.000343\n","2020-11-28 17:43:44,709 - __main__ - INFO - [Epoch: 117 Step: 00037080] Batch Translation Loss:   1.000543 => Txt Tokens per Sec:      999 || Lr: 0.000343\n","2020-11-28 17:43:45,320 - __main__ - INFO - Epoch 117: Total Training Recognition Loss -1.00  Total Training Translation Loss 314.06 \n","2020-11-28 17:43:45,321 - __main__ - INFO - EPOCH 118\n","2020-11-28 17:43:47,112 - __main__ - INFO - [Epoch: 118 Step: 00037120] Batch Translation Loss:   1.079284 => Txt Tokens per Sec:     1109 || Lr: 0.000343\n","2020-11-28 17:43:49,290 - __main__ - INFO - [Epoch: 118 Step: 00037160] Batch Translation Loss:   1.146661 => Txt Tokens per Sec:     1176 || Lr: 0.000343\n","2020-11-28 17:43:51,554 - __main__ - INFO - [Epoch: 118 Step: 00037200] Batch Translation Loss:   2.284959 => Txt Tokens per Sec:     1131 || Lr: 0.000343\n","2020-11-28 17:44:16,520 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 17:44:16,521 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 17:44:17,139 - __main__ - INFO - Validation result at epoch 118, step    37200: duration: 25.5817s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10497.67969\tPPL: 8.02750\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.95\n","\tCHRF 34.30\tROUGE 30.95\n","2020-11-28 17:44:19,486 - __main__ - INFO - [Epoch: 118 Step: 00037240] Batch Translation Loss:   0.749156 => Txt Tokens per Sec:     1091 || Lr: 0.000343\n","2020-11-28 17:44:21,792 - __main__ - INFO - [Epoch: 118 Step: 00037280] Batch Translation Loss:   1.109635 => Txt Tokens per Sec:     1111 || Lr: 0.000343\n","2020-11-28 17:44:24,280 - __main__ - INFO - [Epoch: 118 Step: 00037320] Batch Translation Loss:   1.165831 => Txt Tokens per Sec:     1029 || Lr: 0.000343\n","2020-11-28 17:44:26,814 - __main__ - INFO - [Epoch: 118 Step: 00037360] Batch Translation Loss:   1.139444 => Txt Tokens per Sec:     1011 || Lr: 0.000343\n","2020-11-28 17:44:29,280 - __main__ - INFO - [Epoch: 118 Step: 00037400] Batch Translation Loss:   1.309746 => Txt Tokens per Sec:     1030 || Lr: 0.000343\n","2020-11-28 17:44:29,629 - __main__ - INFO - Epoch 118: Total Training Recognition Loss -1.00  Total Training Translation Loss 315.51 \n","2020-11-28 17:44:29,631 - __main__ - INFO - EPOCH 119\n","2020-11-28 17:44:31,616 - __main__ - INFO - [Epoch: 119 Step: 00037440] Batch Translation Loss:   0.911766 => Txt Tokens per Sec:     1098 || Lr: 0.000343\n","2020-11-28 17:44:33,926 - __main__ - INFO - [Epoch: 119 Step: 00037480] Batch Translation Loss:   0.796425 => Txt Tokens per Sec:     1109 || Lr: 0.000343\n","2020-11-28 17:44:36,207 - __main__ - INFO - [Epoch: 119 Step: 00037520] Batch Translation Loss:   0.819368 => Txt Tokens per Sec:     1123 || Lr: 0.000343\n","2020-11-28 17:44:38,631 - __main__ - INFO - [Epoch: 119 Step: 00037560] Batch Translation Loss:   0.632087 => Txt Tokens per Sec:     1057 || Lr: 0.000343\n","2020-11-28 17:44:40,747 - __main__ - INFO - [Epoch: 119 Step: 00037600] Batch Translation Loss:   1.288392 => Txt Tokens per Sec:     1211 || Lr: 0.000343\n","2020-11-28 17:45:05,516 - __main__ - INFO - Validation result at epoch 119, step    37600: duration: 24.7677s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10631.11230\tPPL: 8.24286\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 29.01\n","\tCHRF 32.90\tROUGE 29.01\n","2020-11-28 17:45:07,922 - __main__ - INFO - [Epoch: 119 Step: 00037640] Batch Translation Loss:   0.850228 => Txt Tokens per Sec:     1064 || Lr: 0.000343\n","2020-11-28 17:45:10,017 - __main__ - INFO - [Epoch: 119 Step: 00037680] Batch Translation Loss:   0.670751 => Txt Tokens per Sec:     1223 || Lr: 0.000343\n","2020-11-28 17:45:12,452 - __main__ - INFO - [Epoch: 119 Step: 00037720] Batch Translation Loss:   1.347094 => Txt Tokens per Sec:     1043 || Lr: 0.000343\n","2020-11-28 17:45:12,640 - __main__ - INFO - Epoch 119: Total Training Recognition Loss -1.00  Total Training Translation Loss 310.22 \n","2020-11-28 17:45:12,641 - __main__ - INFO - EPOCH 120\n","2020-11-28 17:45:14,696 - __main__ - INFO - [Epoch: 120 Step: 00037760] Batch Translation Loss:   1.076469 => Txt Tokens per Sec:     1154 || Lr: 0.000343\n","2020-11-28 17:45:16,927 - __main__ - INFO - [Epoch: 120 Step: 00037800] Batch Translation Loss:   0.596831 => Txt Tokens per Sec:     1148 || Lr: 0.000343\n","2020-11-28 17:45:19,406 - __main__ - INFO - [Epoch: 120 Step: 00037840] Batch Translation Loss:   0.920988 => Txt Tokens per Sec:     1034 || Lr: 0.000343\n","2020-11-28 17:45:21,602 - __main__ - INFO - [Epoch: 120 Step: 00037880] Batch Translation Loss:   0.611782 => Txt Tokens per Sec:     1166 || Lr: 0.000343\n","2020-11-28 17:45:23,970 - __main__ - INFO - [Epoch: 120 Step: 00037920] Batch Translation Loss:   0.556639 => Txt Tokens per Sec:     1082 || Lr: 0.000343\n","2020-11-28 17:45:26,271 - __main__ - INFO - [Epoch: 120 Step: 00037960] Batch Translation Loss:   1.067119 => Txt Tokens per Sec:     1113 || Lr: 0.000343\n","2020-11-28 17:45:28,448 - __main__ - INFO - [Epoch: 120 Step: 00038000] Batch Translation Loss:   0.903642 => Txt Tokens per Sec:     1177 || Lr: 0.000343\n","2020-11-28 17:45:53,192 - __main__ - INFO - Validation result at epoch 120, step    38000: duration: 24.7426s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10668.18945\tPPL: 8.30373\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 29.68\n","\tCHRF 32.72\tROUGE 29.68\n","2020-11-28 17:45:55,717 - __main__ - INFO - [Epoch: 120 Step: 00038040] Batch Translation Loss:   1.250079 => Txt Tokens per Sec:     1005 || Lr: 0.000343\n","2020-11-28 17:45:55,719 - __main__ - INFO - Epoch 120: Total Training Recognition Loss -1.00  Total Training Translation Loss 305.95 \n","2020-11-28 17:45:55,720 - __main__ - INFO - EPOCH 121\n","2020-11-28 17:45:58,026 - __main__ - INFO - [Epoch: 121 Step: 00038080] Batch Translation Loss:   0.787246 => Txt Tokens per Sec:     1112 || Lr: 0.000343\n","2020-11-28 17:46:00,357 - __main__ - INFO - [Epoch: 121 Step: 00038120] Batch Translation Loss:   0.941135 => Txt Tokens per Sec:     1099 || Lr: 0.000343\n","2020-11-28 17:46:02,616 - __main__ - INFO - [Epoch: 121 Step: 00038160] Batch Translation Loss:   1.763555 => Txt Tokens per Sec:     1134 || Lr: 0.000343\n","2020-11-28 17:46:04,875 - __main__ - INFO - [Epoch: 121 Step: 00038200] Batch Translation Loss:   0.663189 => Txt Tokens per Sec:     1134 || Lr: 0.000343\n","2020-11-28 17:46:07,248 - __main__ - INFO - [Epoch: 121 Step: 00038240] Batch Translation Loss:   0.653579 => Txt Tokens per Sec:     1079 || Lr: 0.000343\n","2020-11-28 17:46:09,379 - __main__ - INFO - [Epoch: 121 Step: 00038280] Batch Translation Loss:   1.226921 => Txt Tokens per Sec:     1202 || Lr: 0.000343\n","2020-11-28 17:46:11,847 - __main__ - INFO - [Epoch: 121 Step: 00038320] Batch Translation Loss:   0.960111 => Txt Tokens per Sec:     1038 || Lr: 0.000343\n","2020-11-28 17:46:14,266 - __main__ - INFO - Epoch 121: Total Training Recognition Loss -1.00  Total Training Translation Loss 301.38 \n","2020-11-28 17:46:14,267 - __main__ - INFO - EPOCH 122\n","2020-11-28 17:46:14,455 - __main__ - INFO - [Epoch: 122 Step: 00038360] Batch Translation Loss:   0.883488 => Txt Tokens per Sec:     1033 || Lr: 0.000343\n","2020-11-28 17:46:16,956 - __main__ - INFO - [Epoch: 122 Step: 00038400] Batch Translation Loss:   0.748247 => Txt Tokens per Sec:     1024 || Lr: 0.000343\n","2020-11-28 17:46:41,907 - __main__ - INFO - Validation result at epoch 122, step    38400: duration: 24.9501s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10537.88477\tPPL: 8.09179\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.75\n","\tCHRF 34.24\tROUGE 30.75\n","2020-11-28 17:46:44,204 - __main__ - INFO - [Epoch: 122 Step: 00038440] Batch Translation Loss:   1.239295 => Txt Tokens per Sec:     1115 || Lr: 0.000343\n","2020-11-28 17:46:46,348 - __main__ - INFO - [Epoch: 122 Step: 00038480] Batch Translation Loss:   0.987589 => Txt Tokens per Sec:     1195 || Lr: 0.000343\n","2020-11-28 17:46:48,667 - __main__ - INFO - [Epoch: 122 Step: 00038520] Batch Translation Loss:   0.903592 => Txt Tokens per Sec:     1104 || Lr: 0.000343\n","2020-11-28 17:46:50,915 - __main__ - INFO - [Epoch: 122 Step: 00038560] Batch Translation Loss:   1.096523 => Txt Tokens per Sec:     1139 || Lr: 0.000343\n","2020-11-28 17:46:53,004 - __main__ - INFO - [Epoch: 122 Step: 00038600] Batch Translation Loss:   1.517497 => Txt Tokens per Sec:     1227 || Lr: 0.000343\n","2020-11-28 17:46:55,525 - __main__ - INFO - [Epoch: 122 Step: 00038640] Batch Translation Loss:   0.998378 => Txt Tokens per Sec:     1016 || Lr: 0.000343\n","2020-11-28 17:46:57,702 - __main__ - INFO - Epoch 122: Total Training Recognition Loss -1.00  Total Training Translation Loss 299.43 \n","2020-11-28 17:46:57,703 - __main__ - INFO - EPOCH 123\n","2020-11-28 17:46:58,087 - __main__ - INFO - [Epoch: 123 Step: 00038680] Batch Translation Loss:   0.984189 => Txt Tokens per Sec:     1007 || Lr: 0.000343\n","2020-11-28 17:47:00,442 - __main__ - INFO - [Epoch: 123 Step: 00038720] Batch Translation Loss:   0.706184 => Txt Tokens per Sec:     1088 || Lr: 0.000343\n","2020-11-28 17:47:02,595 - __main__ - INFO - [Epoch: 123 Step: 00038760] Batch Translation Loss:   0.685502 => Txt Tokens per Sec:     1190 || Lr: 0.000343\n","2020-11-28 17:47:04,901 - __main__ - INFO - [Epoch: 123 Step: 00038800] Batch Translation Loss:   0.712672 => Txt Tokens per Sec:     1111 || Lr: 0.000343\n","2020-11-28 17:47:29,575 - __main__ - INFO - Validation result at epoch 123, step    38800: duration: 24.6720s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10615.56445\tPPL: 8.21747\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.32\n","\tCHRF 33.58\tROUGE 30.32\n","2020-11-28 17:47:31,796 - __main__ - INFO - [Epoch: 123 Step: 00038840] Batch Translation Loss:   0.614516 => Txt Tokens per Sec:     1153 || Lr: 0.000343\n","2020-11-28 17:47:34,130 - __main__ - INFO - [Epoch: 123 Step: 00038880] Batch Translation Loss:   1.014006 => Txt Tokens per Sec:     1097 || Lr: 0.000343\n","2020-11-28 17:47:36,524 - __main__ - INFO - [Epoch: 123 Step: 00038920] Batch Translation Loss:   0.760221 => Txt Tokens per Sec:     1070 || Lr: 0.000343\n","2020-11-28 17:47:38,739 - __main__ - INFO - [Epoch: 123 Step: 00038960] Batch Translation Loss:   1.146132 => Txt Tokens per Sec:     1156 || Lr: 0.000343\n","2020-11-28 17:47:40,715 - __main__ - INFO - Epoch 123: Total Training Recognition Loss -1.00  Total Training Translation Loss 301.96 \n","2020-11-28 17:47:40,716 - __main__ - INFO - EPOCH 124\n","2020-11-28 17:47:41,184 - __main__ - INFO - [Epoch: 124 Step: 00039000] Batch Translation Loss:   1.182586 => Txt Tokens per Sec:     1236 || Lr: 0.000343\n","2020-11-28 17:47:43,603 - __main__ - INFO - [Epoch: 124 Step: 00039040] Batch Translation Loss:   1.043398 => Txt Tokens per Sec:     1059 || Lr: 0.000343\n","2020-11-28 17:47:45,638 - __main__ - INFO - [Epoch: 124 Step: 00039080] Batch Translation Loss:   0.877622 => Txt Tokens per Sec:     1259 || Lr: 0.000343\n","2020-11-28 17:47:47,826 - __main__ - INFO - [Epoch: 124 Step: 00039120] Batch Translation Loss:   1.491134 => Txt Tokens per Sec:     1171 || Lr: 0.000343\n","2020-11-28 17:47:50,080 - __main__ - INFO - [Epoch: 124 Step: 00039160] Batch Translation Loss:   1.043638 => Txt Tokens per Sec:     1136 || Lr: 0.000343\n","2020-11-28 17:47:52,364 - __main__ - INFO - [Epoch: 124 Step: 00039200] Batch Translation Loss:   1.140344 => Txt Tokens per Sec:     1122 || Lr: 0.000343\n","2020-11-28 17:48:16,854 - __main__ - INFO - Validation result at epoch 124, step    39200: duration: 24.4881s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10838.22363\tPPL: 8.58865\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 29.25\n","\tCHRF 32.52\tROUGE 29.25\n","2020-11-28 17:48:18,972 - __main__ - INFO - [Epoch: 124 Step: 00039240] Batch Translation Loss:   0.933986 => Txt Tokens per Sec:     1209 || Lr: 0.000343\n","2020-11-28 17:48:21,217 - __main__ - INFO - [Epoch: 124 Step: 00039280] Batch Translation Loss:   1.381605 => Txt Tokens per Sec:     1141 || Lr: 0.000343\n","2020-11-28 17:48:22,977 - __main__ - INFO - Epoch 124: Total Training Recognition Loss -1.00  Total Training Translation Loss 296.42 \n","2020-11-28 17:48:22,978 - __main__ - INFO - EPOCH 125\n","2020-11-28 17:48:23,640 - __main__ - INFO - [Epoch: 125 Step: 00039320] Batch Translation Loss:   0.822407 => Txt Tokens per Sec:     1164 || Lr: 0.000343\n","2020-11-28 17:48:25,855 - __main__ - INFO - [Epoch: 125 Step: 00039360] Batch Translation Loss:   1.172676 => Txt Tokens per Sec:     1156 || Lr: 0.000343\n","2020-11-28 17:48:28,078 - __main__ - INFO - [Epoch: 125 Step: 00039400] Batch Translation Loss:   1.155600 => Txt Tokens per Sec:     1152 || Lr: 0.000343\n","2020-11-28 17:48:30,418 - __main__ - INFO - [Epoch: 125 Step: 00039440] Batch Translation Loss:   0.629624 => Txt Tokens per Sec:     1095 || Lr: 0.000343\n","2020-11-28 17:48:32,507 - __main__ - INFO - [Epoch: 125 Step: 00039480] Batch Translation Loss:   1.133105 => Txt Tokens per Sec:     1226 || Lr: 0.000343\n","2020-11-28 17:48:34,902 - __main__ - INFO - [Epoch: 125 Step: 00039520] Batch Translation Loss:   0.580244 => Txt Tokens per Sec:     1069 || Lr: 0.000343\n","2020-11-28 17:48:37,311 - __main__ - INFO - [Epoch: 125 Step: 00039560] Batch Translation Loss:   0.988414 => Txt Tokens per Sec:     1063 || Lr: 0.000343\n","2020-11-28 17:48:39,506 - __main__ - INFO - [Epoch: 125 Step: 00039600] Batch Translation Loss:   0.930436 => Txt Tokens per Sec:     1168 || Lr: 0.000343\n","2020-11-28 17:49:03,604 - __main__ - INFO - Validation result at epoch 125, step    39600: duration: 24.0972s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10743.23340\tPPL: 8.42829\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 29.60\n","\tCHRF 33.50\tROUGE 29.60\n","2020-11-28 17:49:05,227 - __main__ - INFO - Epoch 125: Total Training Recognition Loss -1.00  Total Training Translation Loss 297.52 \n","2020-11-28 17:49:05,229 - __main__ - INFO - EPOCH 126\n","2020-11-28 17:49:06,050 - __main__ - INFO - [Epoch: 126 Step: 00039640] Batch Translation Loss:   0.886629 => Txt Tokens per Sec:     1173 || Lr: 0.000343\n","2020-11-28 17:49:08,372 - __main__ - INFO - [Epoch: 126 Step: 00039680] Batch Translation Loss:   1.211558 => Txt Tokens per Sec:     1103 || Lr: 0.000343\n","2020-11-28 17:49:10,676 - __main__ - INFO - [Epoch: 126 Step: 00039720] Batch Translation Loss:   0.624191 => Txt Tokens per Sec:     1113 || Lr: 0.000343\n","2020-11-28 17:49:12,872 - __main__ - INFO - [Epoch: 126 Step: 00039760] Batch Translation Loss:   0.527040 => Txt Tokens per Sec:     1166 || Lr: 0.000343\n","2020-11-28 17:49:15,061 - __main__ - INFO - [Epoch: 126 Step: 00039800] Batch Translation Loss:   0.945311 => Txt Tokens per Sec:     1170 || Lr: 0.000343\n","2020-11-28 17:49:17,487 - __main__ - INFO - [Epoch: 126 Step: 00039840] Batch Translation Loss:   1.211901 => Txt Tokens per Sec:     1056 || Lr: 0.000343\n","2020-11-28 17:49:19,749 - __main__ - INFO - [Epoch: 126 Step: 00039880] Batch Translation Loss:   0.903828 => Txt Tokens per Sec:     1133 || Lr: 0.000343\n","2020-11-28 17:49:22,122 - __main__ - INFO - [Epoch: 126 Step: 00039920] Batch Translation Loss:   1.177399 => Txt Tokens per Sec:     1079 || Lr: 0.000343\n","2020-11-28 17:49:23,680 - __main__ - INFO - Epoch 126: Total Training Recognition Loss -1.00  Total Training Translation Loss 289.06 \n","2020-11-28 17:49:23,681 - __main__ - INFO - EPOCH 127\n","2020-11-28 17:49:24,633 - __main__ - INFO - [Epoch: 127 Step: 00039960] Batch Translation Loss:   0.774077 => Txt Tokens per Sec:     1212 || Lr: 0.000343\n","2020-11-28 17:49:26,671 - __main__ - INFO - [Epoch: 127 Step: 00040000] Batch Translation Loss:   0.926605 => Txt Tokens per Sec:     1257 || Lr: 0.000343\n","2020-11-28 17:49:50,435 - __main__ - INFO - Validation result at epoch 127, step    40000: duration: 23.7624s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10727.27637\tPPL: 8.40165\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 29.92\n","\tCHRF 33.80\tROUGE 29.92\n","2020-11-28 17:49:52,882 - __main__ - INFO - [Epoch: 127 Step: 00040040] Batch Translation Loss:   0.974964 => Txt Tokens per Sec:     1046 || Lr: 0.000343\n","2020-11-28 17:49:55,085 - __main__ - INFO - [Epoch: 127 Step: 00040080] Batch Translation Loss:   1.102223 => Txt Tokens per Sec:     1162 || Lr: 0.000343\n","2020-11-28 17:49:57,416 - __main__ - INFO - [Epoch: 127 Step: 00040120] Batch Translation Loss:   0.828790 => Txt Tokens per Sec:     1099 || Lr: 0.000343\n","2020-11-28 17:49:59,442 - __main__ - INFO - [Epoch: 127 Step: 00040160] Batch Translation Loss:   1.059867 => Txt Tokens per Sec:     1264 || Lr: 0.000343\n","2020-11-28 17:50:01,648 - __main__ - INFO - [Epoch: 127 Step: 00040200] Batch Translation Loss:   1.018152 => Txt Tokens per Sec:     1161 || Lr: 0.000343\n","2020-11-28 17:50:03,842 - __main__ - INFO - [Epoch: 127 Step: 00040240] Batch Translation Loss:   1.041288 => Txt Tokens per Sec:     1168 || Lr: 0.000343\n","2020-11-28 17:50:05,143 - __main__ - INFO - Epoch 127: Total Training Recognition Loss -1.00  Total Training Translation Loss 290.83 \n","2020-11-28 17:50:05,144 - __main__ - INFO - EPOCH 128\n","2020-11-28 17:50:06,257 - __main__ - INFO - [Epoch: 128 Step: 00040280] Batch Translation Loss:   0.863431 => Txt Tokens per Sec:     1210 || Lr: 0.000343\n","2020-11-28 17:50:08,649 - __main__ - INFO - [Epoch: 128 Step: 00040320] Batch Translation Loss:   1.316620 => Txt Tokens per Sec:     1071 || Lr: 0.000343\n","2020-11-28 17:50:10,791 - __main__ - INFO - [Epoch: 128 Step: 00040360] Batch Translation Loss:   0.690748 => Txt Tokens per Sec:     1197 || Lr: 0.000343\n","2020-11-28 17:50:12,929 - __main__ - INFO - [Epoch: 128 Step: 00040400] Batch Translation Loss:   0.538923 => Txt Tokens per Sec:     1198 || Lr: 0.000343\n","2020-11-28 17:50:36,974 - __main__ - INFO - Validation result at epoch 128, step    40400: duration: 24.0437s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10981.58105\tPPL: 8.83645\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 28.57\n","\tCHRF 32.14\tROUGE 28.57\n","2020-11-28 17:50:39,311 - __main__ - INFO - [Epoch: 128 Step: 00040440] Batch Translation Loss:   0.576756 => Txt Tokens per Sec:     1095 || Lr: 0.000343\n","2020-11-28 17:50:41,386 - __main__ - INFO - [Epoch: 128 Step: 00040480] Batch Translation Loss:   0.870186 => Txt Tokens per Sec:     1235 || Lr: 0.000343\n","2020-11-28 17:50:43,644 - __main__ - INFO - [Epoch: 128 Step: 00040520] Batch Translation Loss:   0.453512 => Txt Tokens per Sec:     1134 || Lr: 0.000343\n","2020-11-28 17:50:45,877 - __main__ - INFO - [Epoch: 128 Step: 00040560] Batch Translation Loss:   1.202291 => Txt Tokens per Sec:     1147 || Lr: 0.000343\n","2020-11-28 17:50:47,078 - __main__ - INFO - Epoch 128: Total Training Recognition Loss -1.00  Total Training Translation Loss 292.56 \n","2020-11-28 17:50:47,080 - __main__ - INFO - EPOCH 129\n","2020-11-28 17:50:48,413 - __main__ - INFO - [Epoch: 129 Step: 00040600] Batch Translation Loss:   0.770352 => Txt Tokens per Sec:     1154 || Lr: 0.000343\n","2020-11-28 17:50:50,836 - __main__ - INFO - [Epoch: 129 Step: 00040640] Batch Translation Loss:   0.871661 => Txt Tokens per Sec:     1057 || Lr: 0.000343\n","2020-11-28 17:50:53,125 - __main__ - INFO - [Epoch: 129 Step: 00040680] Batch Translation Loss:   1.100227 => Txt Tokens per Sec:     1119 || Lr: 0.000343\n","2020-11-28 17:50:55,421 - __main__ - INFO - [Epoch: 129 Step: 00040720] Batch Translation Loss:   0.617208 => Txt Tokens per Sec:     1116 || Lr: 0.000343\n","2020-11-28 17:50:57,606 - __main__ - INFO - [Epoch: 129 Step: 00040760] Batch Translation Loss:   0.765562 => Txt Tokens per Sec:     1172 || Lr: 0.000343\n","2020-11-28 17:50:59,789 - __main__ - INFO - [Epoch: 129 Step: 00040800] Batch Translation Loss:   1.075628 => Txt Tokens per Sec:     1174 || Lr: 0.000343\n","2020-11-28 17:51:24,077 - __main__ - INFO - Validation result at epoch 129, step    40800: duration: 24.2852s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10707.16211\tPPL: 8.36818\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 29.44\n","\tCHRF 32.47\tROUGE 29.44\n","2020-11-28 17:51:26,298 - __main__ - INFO - [Epoch: 129 Step: 00040840] Batch Translation Loss:   0.586093 => Txt Tokens per Sec:     1152 || Lr: 0.000240\n","2020-11-28 17:51:28,436 - __main__ - INFO - [Epoch: 129 Step: 00040880] Batch Translation Loss:   1.427772 => Txt Tokens per Sec:     1198 || Lr: 0.000240\n","2020-11-28 17:51:29,360 - __main__ - INFO - Epoch 129: Total Training Recognition Loss -1.00  Total Training Translation Loss 288.45 \n","2020-11-28 17:51:29,362 - __main__ - INFO - EPOCH 130\n","2020-11-28 17:51:30,811 - __main__ - INFO - [Epoch: 130 Step: 00040920] Batch Translation Loss:   0.521639 => Txt Tokens per Sec:     1194 || Lr: 0.000240\n","2020-11-28 17:51:32,978 - __main__ - INFO - [Epoch: 130 Step: 00040960] Batch Translation Loss:   0.596108 => Txt Tokens per Sec:     1182 || Lr: 0.000240\n","2020-11-28 17:51:35,032 - __main__ - INFO - [Epoch: 130 Step: 00041000] Batch Translation Loss:   0.919657 => Txt Tokens per Sec:     1247 || Lr: 0.000240\n","2020-11-28 17:51:37,182 - __main__ - INFO - [Epoch: 130 Step: 00041040] Batch Translation Loss:   0.641596 => Txt Tokens per Sec:     1191 || Lr: 0.000240\n","2020-11-28 17:51:39,503 - __main__ - INFO - [Epoch: 130 Step: 00041080] Batch Translation Loss:   0.617117 => Txt Tokens per Sec:     1104 || Lr: 0.000240\n","2020-11-28 17:51:41,592 - __main__ - INFO - [Epoch: 130 Step: 00041120] Batch Translation Loss:   0.857439 => Txt Tokens per Sec:     1226 || Lr: 0.000240\n","2020-11-28 17:51:43,790 - __main__ - INFO - [Epoch: 130 Step: 00041160] Batch Translation Loss:   0.704201 => Txt Tokens per Sec:     1166 || Lr: 0.000240\n","2020-11-28 17:51:46,032 - __main__ - INFO - [Epoch: 130 Step: 00041200] Batch Translation Loss:   0.893205 => Txt Tokens per Sec:     1142 || Lr: 0.000240\n","2020-11-28 17:52:10,335 - __main__ - INFO - Validation result at epoch 130, step    41200: duration: 24.3012s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10585.22070\tPPL: 8.16815\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.60\n","\tCHRF 34.31\tROUGE 30.60\n","2020-11-28 17:52:11,137 - __main__ - INFO - Epoch 130: Total Training Recognition Loss -1.00  Total Training Translation Loss 252.36 \n","2020-11-28 17:52:11,138 - __main__ - INFO - EPOCH 131\n","2020-11-28 17:52:12,844 - __main__ - INFO - [Epoch: 131 Step: 00041240] Batch Translation Loss:   0.410815 => Txt Tokens per Sec:     1127 || Lr: 0.000240\n","2020-11-28 17:52:15,024 - __main__ - INFO - [Epoch: 131 Step: 00041280] Batch Translation Loss:   0.448709 => Txt Tokens per Sec:     1175 || Lr: 0.000240\n","2020-11-28 17:52:17,341 - __main__ - INFO - [Epoch: 131 Step: 00041320] Batch Translation Loss:   0.944490 => Txt Tokens per Sec:     1106 || Lr: 0.000240\n","2020-11-28 17:52:19,509 - __main__ - INFO - [Epoch: 131 Step: 00041360] Batch Translation Loss:   0.784653 => Txt Tokens per Sec:     1182 || Lr: 0.000240\n","2020-11-28 17:52:21,879 - __main__ - INFO - [Epoch: 131 Step: 00041400] Batch Translation Loss:   0.824215 => Txt Tokens per Sec:     1081 || Lr: 0.000240\n","2020-11-28 17:52:24,023 - __main__ - INFO - [Epoch: 131 Step: 00041440] Batch Translation Loss:   0.830009 => Txt Tokens per Sec:     1195 || Lr: 0.000240\n","2020-11-28 17:52:26,284 - __main__ - INFO - [Epoch: 131 Step: 00041480] Batch Translation Loss:   0.568446 => Txt Tokens per Sec:     1133 || Lr: 0.000240\n","2020-11-28 17:52:28,671 - __main__ - INFO - [Epoch: 131 Step: 00041520] Batch Translation Loss:   1.194872 => Txt Tokens per Sec:     1064 || Lr: 0.000240\n","2020-11-28 17:52:29,181 - __main__ - INFO - Epoch 131: Total Training Recognition Loss -1.00  Total Training Translation Loss 255.30 \n","2020-11-28 17:52:29,182 - __main__ - INFO - EPOCH 132\n","2020-11-28 17:52:31,158 - __main__ - INFO - [Epoch: 132 Step: 00041560] Batch Translation Loss:   0.846210 => Txt Tokens per Sec:     1070 || Lr: 0.000240\n","2020-11-28 17:52:33,305 - __main__ - INFO - [Epoch: 132 Step: 00041600] Batch Translation Loss:   0.715891 => Txt Tokens per Sec:     1193 || Lr: 0.000240\n","2020-11-28 17:52:57,376 - __main__ - INFO - Validation result at epoch 132, step    41600: duration: 24.0692s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10582.06836\tPPL: 8.16304\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.40\n","\tCHRF 33.43\tROUGE 30.40\n","2020-11-28 17:52:59,622 - __main__ - INFO - [Epoch: 132 Step: 00041640] Batch Translation Loss:   0.422194 => Txt Tokens per Sec:     1140 || Lr: 0.000240\n","2020-11-28 17:53:01,687 - __main__ - INFO - [Epoch: 132 Step: 00041680] Batch Translation Loss:   0.674203 => Txt Tokens per Sec:     1241 || Lr: 0.000240\n","2020-11-28 17:53:03,982 - __main__ - INFO - [Epoch: 132 Step: 00041720] Batch Translation Loss:   0.958811 => Txt Tokens per Sec:     1116 || Lr: 0.000240\n","2020-11-28 17:53:06,331 - __main__ - INFO - [Epoch: 132 Step: 00041760] Batch Translation Loss:   0.595573 => Txt Tokens per Sec:     1090 || Lr: 0.000240\n","2020-11-28 17:53:08,697 - __main__ - INFO - [Epoch: 132 Step: 00041800] Batch Translation Loss:   0.704177 => Txt Tokens per Sec:     1083 || Lr: 0.000240\n","2020-11-28 17:53:11,049 - __main__ - INFO - [Epoch: 132 Step: 00041840] Batch Translation Loss:   0.779163 => Txt Tokens per Sec:     1080 || Lr: 0.000240\n","2020-11-28 17:53:11,327 - __main__ - INFO - Epoch 132: Total Training Recognition Loss -1.00  Total Training Translation Loss 248.71 \n","2020-11-28 17:53:11,330 - __main__ - INFO - EPOCH 133\n","2020-11-28 17:53:13,368 - __main__ - INFO - [Epoch: 133 Step: 00041880] Batch Translation Loss:   0.850475 => Txt Tokens per Sec:     1131 || Lr: 0.000240\n","2020-11-28 17:53:15,696 - __main__ - INFO - [Epoch: 133 Step: 00041920] Batch Translation Loss:   0.937017 => Txt Tokens per Sec:     1100 || Lr: 0.000240\n","2020-11-28 17:53:18,166 - __main__ - INFO - [Epoch: 133 Step: 00041960] Batch Translation Loss:   0.591362 => Txt Tokens per Sec:     1037 || Lr: 0.000240\n","2020-11-28 17:53:20,337 - __main__ - INFO - [Epoch: 133 Step: 00042000] Batch Translation Loss:   0.730764 => Txt Tokens per Sec:     1180 || Lr: 0.000240\n","2020-11-28 17:53:44,708 - __main__ - INFO - Validation result at epoch 133, step    42000: duration: 24.3698s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10654.90723\tPPL: 8.28187\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.36\n","\tCHRF 33.40\tROUGE 30.36\n","2020-11-28 17:53:47,003 - __main__ - INFO - [Epoch: 133 Step: 00042040] Batch Translation Loss:   1.116031 => Txt Tokens per Sec:     1116 || Lr: 0.000240\n","2020-11-28 17:53:49,573 - __main__ - INFO - [Epoch: 133 Step: 00042080] Batch Translation Loss:   1.021230 => Txt Tokens per Sec:      997 || Lr: 0.000240\n","2020-11-28 17:53:51,735 - __main__ - INFO - [Epoch: 133 Step: 00042120] Batch Translation Loss:   0.984469 => Txt Tokens per Sec:     1185 || Lr: 0.000240\n","2020-11-28 17:53:54,310 - __main__ - INFO - [Epoch: 133 Step: 00042160] Batch Translation Loss:   0.946775 => Txt Tokens per Sec:      986 || Lr: 0.000240\n","2020-11-28 17:53:54,371 - __main__ - INFO - Epoch 133: Total Training Recognition Loss -1.00  Total Training Translation Loss 253.95 \n","2020-11-28 17:53:54,373 - __main__ - INFO - EPOCH 134\n","2020-11-28 17:53:56,618 - __main__ - INFO - [Epoch: 134 Step: 00042200] Batch Translation Loss:   0.506111 => Txt Tokens per Sec:     1112 || Lr: 0.000240\n","2020-11-28 17:53:58,980 - __main__ - INFO - [Epoch: 134 Step: 00042240] Batch Translation Loss:   1.179543 => Txt Tokens per Sec:     1085 || Lr: 0.000240\n","2020-11-28 17:54:01,256 - __main__ - INFO - [Epoch: 134 Step: 00042280] Batch Translation Loss:   1.008983 => Txt Tokens per Sec:     1126 || Lr: 0.000240\n","2020-11-28 17:54:03,547 - __main__ - INFO - [Epoch: 134 Step: 00042320] Batch Translation Loss:   1.239738 => Txt Tokens per Sec:     1118 || Lr: 0.000240\n","2020-11-28 17:54:05,767 - __main__ - INFO - [Epoch: 134 Step: 00042360] Batch Translation Loss:   0.766540 => Txt Tokens per Sec:     1154 || Lr: 0.000240\n","2020-11-28 17:54:08,192 - __main__ - INFO - [Epoch: 134 Step: 00042400] Batch Translation Loss:   0.810269 => Txt Tokens per Sec:     1056 || Lr: 0.000240\n","2020-11-28 17:54:32,599 - __main__ - INFO - Validation result at epoch 134, step    42400: duration: 24.4055s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10639.81836\tPPL: 8.25711\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.95\n","\tCHRF 34.31\tROUGE 30.95\n","2020-11-28 17:54:34,728 - __main__ - INFO - [Epoch: 134 Step: 00042440] Batch Translation Loss:   0.643959 => Txt Tokens per Sec:     1202 || Lr: 0.000240\n","2020-11-28 17:54:36,995 - __main__ - INFO - Epoch 134: Total Training Recognition Loss -1.00  Total Training Translation Loss 245.34 \n","2020-11-28 17:54:36,997 - __main__ - INFO - EPOCH 135\n","2020-11-28 17:54:37,126 - __main__ - INFO - [Epoch: 135 Step: 00042480] Batch Translation Loss:   0.794622 => Txt Tokens per Sec:     1010 || Lr: 0.000240\n","2020-11-28 17:54:39,419 - __main__ - INFO - [Epoch: 135 Step: 00042520] Batch Translation Loss:   0.683009 => Txt Tokens per Sec:     1117 || Lr: 0.000240\n","2020-11-28 17:54:41,805 - __main__ - INFO - [Epoch: 135 Step: 00042560] Batch Translation Loss:   0.669945 => Txt Tokens per Sec:     1073 || Lr: 0.000240\n","2020-11-28 17:54:43,940 - __main__ - INFO - [Epoch: 135 Step: 00042600] Batch Translation Loss:   0.847020 => Txt Tokens per Sec:     1200 || Lr: 0.000240\n","2020-11-28 17:54:46,244 - __main__ - INFO - [Epoch: 135 Step: 00042640] Batch Translation Loss:   1.556219 => Txt Tokens per Sec:     1112 || Lr: 0.000240\n","2020-11-28 17:54:48,609 - __main__ - INFO - [Epoch: 135 Step: 00042680] Batch Translation Loss:   0.864249 => Txt Tokens per Sec:     1083 || Lr: 0.000240\n","2020-11-28 17:54:50,813 - __main__ - INFO - [Epoch: 135 Step: 00042720] Batch Translation Loss:   0.645698 => Txt Tokens per Sec:     1162 || Lr: 0.000240\n","2020-11-28 17:54:53,276 - __main__ - INFO - [Epoch: 135 Step: 00042760] Batch Translation Loss:   0.684131 => Txt Tokens per Sec:     1040 || Lr: 0.000240\n","2020-11-28 17:54:55,451 - __main__ - INFO - Epoch 135: Total Training Recognition Loss -1.00  Total Training Translation Loss 245.66 \n","2020-11-28 17:54:55,452 - __main__ - INFO - EPOCH 136\n","2020-11-28 17:54:55,738 - __main__ - INFO - [Epoch: 136 Step: 00042800] Batch Translation Loss:   0.841513 => Txt Tokens per Sec:     1127 || Lr: 0.000240\n","2020-11-28 17:55:20,281 - __main__ - INFO - Validation result at epoch 136, step    42800: duration: 24.5415s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10828.31152\tPPL: 8.57177\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.12\n","\tCHRF 33.64\tROUGE 30.12\n","2020-11-28 17:55:22,615 - __main__ - INFO - [Epoch: 136 Step: 00042840] Batch Translation Loss:   0.455843 => Txt Tokens per Sec:     1096 || Lr: 0.000240\n","2020-11-28 17:55:24,826 - __main__ - INFO - [Epoch: 136 Step: 00042880] Batch Translation Loss:   0.440696 => Txt Tokens per Sec:     1159 || Lr: 0.000240\n","2020-11-28 17:55:27,304 - __main__ - INFO - [Epoch: 136 Step: 00042920] Batch Translation Loss:   0.643569 => Txt Tokens per Sec:     1034 || Lr: 0.000240\n","2020-11-28 17:55:29,624 - __main__ - INFO - [Epoch: 136 Step: 00042960] Batch Translation Loss:   0.486067 => Txt Tokens per Sec:     1104 || Lr: 0.000240\n","2020-11-28 17:55:31,971 - __main__ - INFO - [Epoch: 136 Step: 00043000] Batch Translation Loss:   1.079861 => Txt Tokens per Sec:     1091 || Lr: 0.000240\n","2020-11-28 17:55:34,419 - __main__ - INFO - [Epoch: 136 Step: 00043040] Batch Translation Loss:   0.610525 => Txt Tokens per Sec:     1046 || Lr: 0.000240\n","2020-11-28 17:55:36,584 - __main__ - INFO - [Epoch: 136 Step: 00043080] Batch Translation Loss:   0.710608 => Txt Tokens per Sec:     1184 || Lr: 0.000240\n","2020-11-28 17:55:38,588 - __main__ - INFO - Epoch 136: Total Training Recognition Loss -1.00  Total Training Translation Loss 244.58 \n","2020-11-28 17:55:38,589 - __main__ - INFO - EPOCH 137\n","2020-11-28 17:55:39,071 - __main__ - INFO - [Epoch: 137 Step: 00043120] Batch Translation Loss:   0.533337 => Txt Tokens per Sec:     1068 || Lr: 0.000240\n","2020-11-28 17:55:41,434 - __main__ - INFO - [Epoch: 137 Step: 00043160] Batch Translation Loss:   0.619365 => Txt Tokens per Sec:     1084 || Lr: 0.000240\n","2020-11-28 17:55:43,611 - __main__ - INFO - [Epoch: 137 Step: 00043200] Batch Translation Loss:   0.682752 => Txt Tokens per Sec:     1177 || Lr: 0.000240\n","2020-11-28 17:56:08,225 - __main__ - INFO - Validation result at epoch 137, step    43200: duration: 24.6128s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10847.85449\tPPL: 8.60507\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 28.81\n","\tCHRF 31.77\tROUGE 28.81\n","2020-11-28 17:56:10,491 - __main__ - INFO - [Epoch: 137 Step: 00043240] Batch Translation Loss:   1.102343 => Txt Tokens per Sec:     1130 || Lr: 0.000240\n","2020-11-28 17:56:12,756 - __main__ - INFO - [Epoch: 137 Step: 00043280] Batch Translation Loss:   0.529408 => Txt Tokens per Sec:     1131 || Lr: 0.000240\n","2020-11-28 17:56:14,895 - __main__ - INFO - [Epoch: 137 Step: 00043320] Batch Translation Loss:   0.747337 => Txt Tokens per Sec:     1198 || Lr: 0.000240\n","2020-11-28 17:56:17,208 - __main__ - INFO - [Epoch: 137 Step: 00043360] Batch Translation Loss:   0.744452 => Txt Tokens per Sec:     1108 || Lr: 0.000240\n","2020-11-28 17:56:19,578 - __main__ - INFO - [Epoch: 137 Step: 00043400] Batch Translation Loss:   0.784796 => Txt Tokens per Sec:     1081 || Lr: 0.000240\n","2020-11-28 17:56:21,456 - __main__ - INFO - Epoch 137: Total Training Recognition Loss -1.00  Total Training Translation Loss 245.10 \n","2020-11-28 17:56:21,457 - __main__ - INFO - EPOCH 138\n","2020-11-28 17:56:22,103 - __main__ - INFO - [Epoch: 138 Step: 00043440] Batch Translation Loss:   0.586644 => Txt Tokens per Sec:     1094 || Lr: 0.000240\n","2020-11-28 17:56:24,357 - __main__ - INFO - [Epoch: 138 Step: 00043480] Batch Translation Loss:   0.529884 => Txt Tokens per Sec:     1136 || Lr: 0.000240\n","2020-11-28 17:56:26,712 - __main__ - INFO - [Epoch: 138 Step: 00043520] Batch Translation Loss:   1.199140 => Txt Tokens per Sec:     1088 || Lr: 0.000240\n","2020-11-28 17:56:29,012 - __main__ - INFO - [Epoch: 138 Step: 00043560] Batch Translation Loss:   0.583814 => Txt Tokens per Sec:     1114 || Lr: 0.000240\n","2020-11-28 17:56:31,508 - __main__ - INFO - [Epoch: 138 Step: 00043600] Batch Translation Loss:   0.863464 => Txt Tokens per Sec:     1026 || Lr: 0.000240\n","2020-11-28 17:56:55,518 - __main__ - INFO - Validation result at epoch 138, step    43600: duration: 24.0088s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10719.93848\tPPL: 8.38942\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.63\n","\tCHRF 34.14\tROUGE 30.63\n","2020-11-28 17:56:57,529 - __main__ - INFO - [Epoch: 138 Step: 00043640] Batch Translation Loss:   0.709497 => Txt Tokens per Sec:     1273 || Lr: 0.000240\n","2020-11-28 17:56:59,789 - __main__ - INFO - [Epoch: 138 Step: 00043680] Batch Translation Loss:   0.786242 => Txt Tokens per Sec:     1134 || Lr: 0.000240\n","2020-11-28 17:57:02,051 - __main__ - INFO - [Epoch: 138 Step: 00043720] Batch Translation Loss:   1.272283 => Txt Tokens per Sec:     1132 || Lr: 0.000240\n","2020-11-28 17:57:03,707 - __main__ - INFO - Epoch 138: Total Training Recognition Loss -1.00  Total Training Translation Loss 244.01 \n","2020-11-28 17:57:03,710 - __main__ - INFO - EPOCH 139\n","2020-11-28 17:57:04,521 - __main__ - INFO - [Epoch: 139 Step: 00043760] Batch Translation Loss:   0.406202 => Txt Tokens per Sec:     1108 || Lr: 0.000240\n","2020-11-28 17:57:06,715 - __main__ - INFO - [Epoch: 139 Step: 00043800] Batch Translation Loss:   0.517256 => Txt Tokens per Sec:     1168 || Lr: 0.000240\n","2020-11-28 17:57:09,142 - __main__ - INFO - [Epoch: 139 Step: 00043840] Batch Translation Loss:   0.735894 => Txt Tokens per Sec:     1055 || Lr: 0.000240\n","2020-11-28 17:57:11,471 - __main__ - INFO - [Epoch: 139 Step: 00043880] Batch Translation Loss:   0.441169 => Txt Tokens per Sec:     1100 || Lr: 0.000240\n","2020-11-28 17:57:13,696 - __main__ - INFO - [Epoch: 139 Step: 00043920] Batch Translation Loss:   0.492912 => Txt Tokens per Sec:     1152 || Lr: 0.000240\n","2020-11-28 17:57:16,063 - __main__ - INFO - [Epoch: 139 Step: 00043960] Batch Translation Loss:   0.851586 => Txt Tokens per Sec:     1082 || Lr: 0.000240\n","2020-11-28 17:57:18,390 - __main__ - INFO - [Epoch: 139 Step: 00044000] Batch Translation Loss:   0.902496 => Txt Tokens per Sec:     1101 || Lr: 0.000240\n","2020-11-28 17:57:42,666 - __main__ - INFO - Hooray! New best validation result [eval_metric]!\n","2020-11-28 17:57:42,667 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 17:57:43,279 - __main__ - INFO - Validation result at epoch 139, step    44000: duration: 24.8873s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10792.70117\tPPL: 8.51142\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 31.27\n","\tCHRF 35.06\tROUGE 31.27\n","2020-11-28 17:57:45,457 - __main__ - INFO - [Epoch: 139 Step: 00044040] Batch Translation Loss:   0.783729 => Txt Tokens per Sec:     1176 || Lr: 0.000240\n","2020-11-28 17:57:47,019 - __main__ - INFO - Epoch 139: Total Training Recognition Loss -1.00  Total Training Translation Loss 241.11 \n","2020-11-28 17:57:47,021 - __main__ - INFO - EPOCH 140\n","2020-11-28 17:57:47,968 - __main__ - INFO - [Epoch: 140 Step: 00044080] Batch Translation Loss:   0.631545 => Txt Tokens per Sec:     1150 || Lr: 0.000240\n","2020-11-28 17:57:50,352 - __main__ - INFO - [Epoch: 140 Step: 00044120] Batch Translation Loss:   0.762728 => Txt Tokens per Sec:     1075 || Lr: 0.000240\n","2020-11-28 17:57:52,661 - __main__ - INFO - [Epoch: 140 Step: 00044160] Batch Translation Loss:   0.775690 => Txt Tokens per Sec:     1109 || Lr: 0.000240\n","2020-11-28 17:57:55,052 - __main__ - INFO - [Epoch: 140 Step: 00044200] Batch Translation Loss:   0.870165 => Txt Tokens per Sec:     1071 || Lr: 0.000240\n","2020-11-28 17:57:57,193 - __main__ - INFO - [Epoch: 140 Step: 00044240] Batch Translation Loss:   0.465332 => Txt Tokens per Sec:     1197 || Lr: 0.000240\n","2020-11-28 17:57:59,482 - __main__ - INFO - [Epoch: 140 Step: 00044280] Batch Translation Loss:   0.391799 => Txt Tokens per Sec:     1119 || Lr: 0.000240\n","2020-11-28 17:58:01,692 - __main__ - INFO - [Epoch: 140 Step: 00044320] Batch Translation Loss:   0.731451 => Txt Tokens per Sec:     1159 || Lr: 0.000240\n","2020-11-28 17:58:04,147 - __main__ - INFO - [Epoch: 140 Step: 00044360] Batch Translation Loss:   0.633228 => Txt Tokens per Sec:     1043 || Lr: 0.000240\n","2020-11-28 17:58:05,543 - __main__ - INFO - Epoch 140: Total Training Recognition Loss -1.00  Total Training Translation Loss 235.93 \n","2020-11-28 17:58:05,544 - __main__ - INFO - EPOCH 141\n","2020-11-28 17:58:06,692 - __main__ - INFO - [Epoch: 141 Step: 00044400] Batch Translation Loss:   0.446314 => Txt Tokens per Sec:     1117 || Lr: 0.000240\n","2020-11-28 17:58:30,778 - __main__ - INFO - Validation result at epoch 141, step    44400: duration: 24.0844s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10686.86621\tPPL: 8.33455\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.83\n","\tCHRF 34.34\tROUGE 30.83\n","2020-11-28 17:58:32,940 - __main__ - INFO - [Epoch: 141 Step: 00044440] Batch Translation Loss:   1.113066 => Txt Tokens per Sec:     1184 || Lr: 0.000240\n","2020-11-28 17:58:35,289 - __main__ - INFO - [Epoch: 141 Step: 00044480] Batch Translation Loss:   0.782329 => Txt Tokens per Sec:     1091 || Lr: 0.000240\n","2020-11-28 17:58:37,532 - __main__ - INFO - [Epoch: 141 Step: 00044520] Batch Translation Loss:   0.496774 => Txt Tokens per Sec:     1142 || Lr: 0.000240\n","2020-11-28 17:58:39,840 - __main__ - INFO - [Epoch: 141 Step: 00044560] Batch Translation Loss:   0.541727 => Txt Tokens per Sec:     1110 || Lr: 0.000240\n","2020-11-28 17:58:42,121 - __main__ - INFO - [Epoch: 141 Step: 00044600] Batch Translation Loss:   1.208464 => Txt Tokens per Sec:     1123 || Lr: 0.000240\n","2020-11-28 17:58:44,385 - __main__ - INFO - [Epoch: 141 Step: 00044640] Batch Translation Loss:   0.389952 => Txt Tokens per Sec:     1131 || Lr: 0.000240\n","2020-11-28 17:58:46,568 - __main__ - INFO - [Epoch: 141 Step: 00044680] Batch Translation Loss:   0.616298 => Txt Tokens per Sec:     1174 || Lr: 0.000240\n","2020-11-28 17:58:47,710 - __main__ - INFO - Epoch 141: Total Training Recognition Loss -1.00  Total Training Translation Loss 229.88 \n","2020-11-28 17:58:47,711 - __main__ - INFO - EPOCH 142\n","2020-11-28 17:58:48,952 - __main__ - INFO - [Epoch: 142 Step: 00044720] Batch Translation Loss:   0.732423 => Txt Tokens per Sec:     1188 || Lr: 0.000240\n","2020-11-28 17:58:51,151 - __main__ - INFO - [Epoch: 142 Step: 00044760] Batch Translation Loss:   0.968643 => Txt Tokens per Sec:     1165 || Lr: 0.000240\n","2020-11-28 17:58:53,381 - __main__ - INFO - [Epoch: 142 Step: 00044800] Batch Translation Loss:   1.137262 => Txt Tokens per Sec:     1149 || Lr: 0.000240\n","2020-11-28 17:59:17,733 - __main__ - INFO - Validation result at epoch 142, step    44800: duration: 24.3507s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10876.05664\tPPL: 8.65336\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 29.56\n","\tCHRF 33.54\tROUGE 29.56\n","2020-11-28 17:59:19,855 - __main__ - INFO - [Epoch: 142 Step: 00044840] Batch Translation Loss:   0.591577 => Txt Tokens per Sec:     1206 || Lr: 0.000240\n","2020-11-28 17:59:22,048 - __main__ - INFO - [Epoch: 142 Step: 00044880] Batch Translation Loss:   0.732853 => Txt Tokens per Sec:     1168 || Lr: 0.000240\n","2020-11-28 17:59:24,418 - __main__ - INFO - [Epoch: 142 Step: 00044920] Batch Translation Loss:   0.798087 => Txt Tokens per Sec:     1081 || Lr: 0.000240\n","2020-11-28 17:59:26,609 - __main__ - INFO - [Epoch: 142 Step: 00044960] Batch Translation Loss:   0.701352 => Txt Tokens per Sec:     1169 || Lr: 0.000240\n","2020-11-28 17:59:28,955 - __main__ - INFO - [Epoch: 142 Step: 00045000] Batch Translation Loss:   0.689276 => Txt Tokens per Sec:     1083 || Lr: 0.000240\n","2020-11-28 17:59:29,856 - __main__ - INFO - Epoch 142: Total Training Recognition Loss -1.00  Total Training Translation Loss 234.73 \n","2020-11-28 17:59:29,858 - __main__ - INFO - EPOCH 143\n","2020-11-28 17:59:31,295 - __main__ - INFO - [Epoch: 143 Step: 00045040] Batch Translation Loss:   0.753073 => Txt Tokens per Sec:     1159 || Lr: 0.000240\n","2020-11-28 17:59:33,554 - __main__ - INFO - [Epoch: 143 Step: 00045080] Batch Translation Loss:   1.007976 => Txt Tokens per Sec:     1134 || Lr: 0.000240\n","2020-11-28 17:59:35,740 - __main__ - INFO - [Epoch: 143 Step: 00045120] Batch Translation Loss:   0.473038 => Txt Tokens per Sec:     1171 || Lr: 0.000240\n","2020-11-28 17:59:37,986 - __main__ - INFO - [Epoch: 143 Step: 00045160] Batch Translation Loss:   0.918998 => Txt Tokens per Sec:     1141 || Lr: 0.000240\n","2020-11-28 17:59:40,292 - __main__ - INFO - [Epoch: 143 Step: 00045200] Batch Translation Loss:   0.703762 => Txt Tokens per Sec:     1111 || Lr: 0.000240\n","2020-11-28 18:00:04,505 - __main__ - INFO - Validation result at epoch 143, step    45200: duration: 24.2118s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10996.60547\tPPL: 8.86283\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 28.85\n","\tCHRF 32.48\tROUGE 28.85\n","2020-11-28 18:00:06,899 - __main__ - INFO - [Epoch: 143 Step: 00045240] Batch Translation Loss:   0.769672 => Txt Tokens per Sec:     1070 || Lr: 0.000240\n","2020-11-28 18:00:09,103 - __main__ - INFO - [Epoch: 143 Step: 00045280] Batch Translation Loss:   0.559673 => Txt Tokens per Sec:     1162 || Lr: 0.000240\n","2020-11-28 18:00:11,324 - __main__ - INFO - [Epoch: 143 Step: 00045320] Batch Translation Loss:   0.973578 => Txt Tokens per Sec:     1153 || Lr: 0.000240\n","2020-11-28 18:00:12,233 - __main__ - INFO - Epoch 143: Total Training Recognition Loss -1.00  Total Training Translation Loss 236.77 \n","2020-11-28 18:00:12,234 - __main__ - INFO - EPOCH 144\n","2020-11-28 18:00:13,811 - __main__ - INFO - [Epoch: 144 Step: 00045360] Batch Translation Loss:   0.440133 => Txt Tokens per Sec:     1178 || Lr: 0.000240\n","2020-11-28 18:00:16,129 - __main__ - INFO - [Epoch: 144 Step: 00045400] Batch Translation Loss:   0.595720 => Txt Tokens per Sec:     1105 || Lr: 0.000240\n","2020-11-28 18:00:18,236 - __main__ - INFO - [Epoch: 144 Step: 00045440] Batch Translation Loss:   0.797698 => Txt Tokens per Sec:     1216 || Lr: 0.000240\n","2020-11-28 18:00:20,503 - __main__ - INFO - [Epoch: 144 Step: 00045480] Batch Translation Loss:   0.946083 => Txt Tokens per Sec:     1130 || Lr: 0.000240\n","2020-11-28 18:00:22,804 - __main__ - INFO - [Epoch: 144 Step: 00045520] Batch Translation Loss:   0.943415 => Txt Tokens per Sec:     1113 || Lr: 0.000240\n","2020-11-28 18:00:24,981 - __main__ - INFO - [Epoch: 144 Step: 00045560] Batch Translation Loss:   0.832828 => Txt Tokens per Sec:     1177 || Lr: 0.000240\n","2020-11-28 18:00:27,205 - __main__ - INFO - [Epoch: 144 Step: 00045600] Batch Translation Loss:   0.934049 => Txt Tokens per Sec:     1152 || Lr: 0.000240\n","2020-11-28 18:00:51,564 - __main__ - INFO - Validation result at epoch 144, step    45600: duration: 24.3577s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10859.82324\tPPL: 8.62554\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.40\n","\tCHRF 33.63\tROUGE 30.40\n","2020-11-28 18:00:53,880 - __main__ - INFO - [Epoch: 144 Step: 00045640] Batch Translation Loss:   0.934493 => Txt Tokens per Sec:     1105 || Lr: 0.000240\n","2020-11-28 18:00:54,500 - __main__ - INFO - Epoch 144: Total Training Recognition Loss -1.00  Total Training Translation Loss 227.17 \n","2020-11-28 18:00:54,502 - __main__ - INFO - EPOCH 145\n","2020-11-28 18:00:56,390 - __main__ - INFO - [Epoch: 145 Step: 00045680] Batch Translation Loss:   0.762059 => Txt Tokens per Sec:     1085 || Lr: 0.000240\n","2020-11-28 18:00:58,487 - __main__ - INFO - [Epoch: 145 Step: 00045720] Batch Translation Loss:   0.911814 => Txt Tokens per Sec:     1222 || Lr: 0.000240\n","2020-11-28 18:01:00,700 - __main__ - INFO - [Epoch: 145 Step: 00045760] Batch Translation Loss:   0.600972 => Txt Tokens per Sec:     1157 || Lr: 0.000240\n","2020-11-28 18:01:03,088 - __main__ - INFO - [Epoch: 145 Step: 00045800] Batch Translation Loss:   0.438933 => Txt Tokens per Sec:     1073 || Lr: 0.000240\n","2020-11-28 18:01:05,348 - __main__ - INFO - [Epoch: 145 Step: 00045840] Batch Translation Loss:   0.617381 => Txt Tokens per Sec:     1133 || Lr: 0.000240\n","2020-11-28 18:01:07,423 - __main__ - INFO - [Epoch: 145 Step: 00045880] Batch Translation Loss:   0.658545 => Txt Tokens per Sec:     1235 || Lr: 0.000240\n","2020-11-28 18:01:09,823 - __main__ - INFO - [Epoch: 145 Step: 00045920] Batch Translation Loss:   0.501122 => Txt Tokens per Sec:     1067 || Lr: 0.000240\n","2020-11-28 18:01:12,224 - __main__ - INFO - [Epoch: 145 Step: 00045960] Batch Translation Loss:   0.945556 => Txt Tokens per Sec:     1058 || Lr: 0.000240\n","2020-11-28 18:01:12,569 - __main__ - INFO - Epoch 145: Total Training Recognition Loss -1.00  Total Training Translation Loss 229.10 \n","2020-11-28 18:01:12,570 - __main__ - INFO - EPOCH 146\n","2020-11-28 18:01:14,681 - __main__ - INFO - [Epoch: 146 Step: 00046000] Batch Translation Loss:   0.622522 => Txt Tokens per Sec:     1062 || Lr: 0.000240\n","2020-11-28 18:01:38,974 - __main__ - INFO - Validation result at epoch 146, step    46000: duration: 24.2914s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 11058.72852\tPPL: 8.97275\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.75\n","\tCHRF 34.22\tROUGE 30.75\n","2020-11-28 18:01:41,094 - __main__ - INFO - [Epoch: 146 Step: 00046040] Batch Translation Loss:   0.582859 => Txt Tokens per Sec:     1208 || Lr: 0.000240\n","2020-11-28 18:01:43,374 - __main__ - INFO - [Epoch: 146 Step: 00046080] Batch Translation Loss:   0.539661 => Txt Tokens per Sec:     1124 || Lr: 0.000240\n","2020-11-28 18:01:45,632 - __main__ - INFO - [Epoch: 146 Step: 00046120] Batch Translation Loss:   0.823222 => Txt Tokens per Sec:     1134 || Lr: 0.000240\n","2020-11-28 18:01:47,992 - __main__ - INFO - [Epoch: 146 Step: 00046160] Batch Translation Loss:   0.683853 => Txt Tokens per Sec:     1086 || Lr: 0.000240\n","2020-11-28 18:01:50,208 - __main__ - INFO - [Epoch: 146 Step: 00046200] Batch Translation Loss:   0.607584 => Txt Tokens per Sec:     1156 || Lr: 0.000240\n","2020-11-28 18:01:52,415 - __main__ - INFO - [Epoch: 146 Step: 00046240] Batch Translation Loss:   0.967433 => Txt Tokens per Sec:     1160 || Lr: 0.000240\n","2020-11-28 18:01:54,934 - __main__ - INFO - [Epoch: 146 Step: 00046280] Batch Translation Loss:   1.212406 => Txt Tokens per Sec:     1008 || Lr: 0.000240\n","2020-11-28 18:01:55,065 - __main__ - INFO - Epoch 146: Total Training Recognition Loss -1.00  Total Training Translation Loss 222.75 \n","2020-11-28 18:01:55,066 - __main__ - INFO - EPOCH 147\n","2020-11-28 18:01:57,147 - __main__ - INFO - [Epoch: 147 Step: 00046320] Batch Translation Loss:   0.563505 => Txt Tokens per Sec:     1170 || Lr: 0.000240\n","2020-11-28 18:01:59,450 - __main__ - INFO - [Epoch: 147 Step: 00046360] Batch Translation Loss:   0.596304 => Txt Tokens per Sec:     1112 || Lr: 0.000240\n","2020-11-28 18:02:01,650 - __main__ - INFO - [Epoch: 147 Step: 00046400] Batch Translation Loss:   0.592913 => Txt Tokens per Sec:     1165 || Lr: 0.000240\n","2020-11-28 18:02:26,069 - __main__ - INFO - Validation result at epoch 147, step    46400: duration: 24.4180s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10904.57227\tPPL: 8.70246\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 29.17\n","\tCHRF 32.46\tROUGE 29.17\n","2020-11-28 18:02:28,321 - __main__ - INFO - [Epoch: 147 Step: 00046440] Batch Translation Loss:   0.521466 => Txt Tokens per Sec:     1137 || Lr: 0.000240\n","2020-11-28 18:02:30,626 - __main__ - INFO - [Epoch: 147 Step: 00046480] Batch Translation Loss:   1.044792 => Txt Tokens per Sec:     1111 || Lr: 0.000240\n","2020-11-28 18:02:33,001 - __main__ - INFO - [Epoch: 147 Step: 00046520] Batch Translation Loss:   0.984906 => Txt Tokens per Sec:     1079 || Lr: 0.000240\n","2020-11-28 18:02:35,191 - __main__ - INFO - [Epoch: 147 Step: 00046560] Batch Translation Loss:   1.250279 => Txt Tokens per Sec:     1169 || Lr: 0.000240\n","2020-11-28 18:02:37,595 - __main__ - INFO - Epoch 147: Total Training Recognition Loss -1.00  Total Training Translation Loss 226.83 \n","2020-11-28 18:02:37,597 - __main__ - INFO - EPOCH 148\n","2020-11-28 18:02:37,662 - __main__ - INFO - [Epoch: 148 Step: 00046600] Batch Translation Loss:   0.622199 => Txt Tokens per Sec:     1016 || Lr: 0.000240\n","2020-11-28 18:02:39,782 - __main__ - INFO - [Epoch: 148 Step: 00046640] Batch Translation Loss:   0.403223 => Txt Tokens per Sec:     1208 || Lr: 0.000240\n","2020-11-28 18:02:42,127 - __main__ - INFO - [Epoch: 148 Step: 00046680] Batch Translation Loss:   0.469419 => Txt Tokens per Sec:     1093 || Lr: 0.000240\n","2020-11-28 18:02:44,511 - __main__ - INFO - [Epoch: 148 Step: 00046720] Batch Translation Loss:   0.414479 => Txt Tokens per Sec:     1074 || Lr: 0.000240\n","2020-11-28 18:02:46,759 - __main__ - INFO - [Epoch: 148 Step: 00046760] Batch Translation Loss:   0.350341 => Txt Tokens per Sec:     1140 || Lr: 0.000240\n","2020-11-28 18:02:49,092 - __main__ - INFO - [Epoch: 148 Step: 00046800] Batch Translation Loss:   0.641778 => Txt Tokens per Sec:     1098 || Lr: 0.000240\n","2020-11-28 18:03:13,601 - __main__ - INFO - Validation result at epoch 148, step    46800: duration: 24.5073s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10931.11816\tPPL: 8.74841\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 29.92\n","\tCHRF 33.66\tROUGE 29.92\n","2020-11-28 18:03:15,884 - __main__ - INFO - [Epoch: 148 Step: 00046840] Batch Translation Loss:   0.559984 => Txt Tokens per Sec:     1121 || Lr: 0.000240\n","2020-11-28 18:03:18,001 - __main__ - INFO - [Epoch: 148 Step: 00046880] Batch Translation Loss:   0.959745 => Txt Tokens per Sec:     1210 || Lr: 0.000240\n","2020-11-28 18:03:20,372 - __main__ - INFO - Epoch 148: Total Training Recognition Loss -1.00  Total Training Translation Loss 222.25 \n","2020-11-28 18:03:20,373 - __main__ - INFO - EPOCH 149\n","2020-11-28 18:03:20,608 - __main__ - INFO - [Epoch: 149 Step: 00046920] Batch Translation Loss:   0.403849 => Txt Tokens per Sec:     1095 || Lr: 0.000240\n","2020-11-28 18:03:22,676 - __main__ - INFO - [Epoch: 149 Step: 00046960] Batch Translation Loss:   0.701805 => Txt Tokens per Sec:     1239 || Lr: 0.000240\n","2020-11-28 18:03:24,949 - __main__ - INFO - [Epoch: 149 Step: 00047000] Batch Translation Loss:   0.624087 => Txt Tokens per Sec:     1127 || Lr: 0.000240\n","2020-11-28 18:03:27,428 - __main__ - INFO - [Epoch: 149 Step: 00047040] Batch Translation Loss:   0.412141 => Txt Tokens per Sec:     1033 || Lr: 0.000240\n","2020-11-28 18:03:29,688 - __main__ - INFO - [Epoch: 149 Step: 00047080] Batch Translation Loss:   0.688354 => Txt Tokens per Sec:     1134 || Lr: 0.000240\n","2020-11-28 18:03:32,065 - __main__ - INFO - [Epoch: 149 Step: 00047120] Batch Translation Loss:   0.566997 => Txt Tokens per Sec:     1078 || Lr: 0.000240\n","2020-11-28 18:03:34,206 - __main__ - INFO - [Epoch: 149 Step: 00047160] Batch Translation Loss:   0.758551 => Txt Tokens per Sec:     1196 || Lr: 0.000240\n","2020-11-28 18:03:36,473 - __main__ - INFO - [Epoch: 149 Step: 00047200] Batch Translation Loss:   0.792189 => Txt Tokens per Sec:     1130 || Lr: 0.000240\n","2020-11-28 18:04:01,085 - __main__ - INFO - Validation result at epoch 149, step    47200: duration: 24.6107s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10864.08398\tPPL: 8.63283\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.52\n","\tCHRF 33.71\tROUGE 30.52\n","2020-11-28 18:04:03,213 - __main__ - INFO - Epoch 149: Total Training Recognition Loss -1.00  Total Training Translation Loss 228.32 \n","2020-11-28 18:04:03,215 - __main__ - INFO - EPOCH 150\n","2020-11-28 18:04:03,553 - __main__ - INFO - [Epoch: 150 Step: 00047240] Batch Translation Loss:   0.638241 => Txt Tokens per Sec:     1328 || Lr: 0.000240\n","2020-11-28 18:04:05,849 - __main__ - INFO - [Epoch: 150 Step: 00047280] Batch Translation Loss:   0.398236 => Txt Tokens per Sec:     1116 || Lr: 0.000240\n","2020-11-28 18:04:08,337 - __main__ - INFO - [Epoch: 150 Step: 00047320] Batch Translation Loss:   0.726125 => Txt Tokens per Sec:     1030 || Lr: 0.000240\n","2020-11-28 18:04:10,533 - __main__ - INFO - [Epoch: 150 Step: 00047360] Batch Translation Loss:   0.643086 => Txt Tokens per Sec:     1167 || Lr: 0.000240\n","2020-11-28 18:04:12,743 - __main__ - INFO - [Epoch: 150 Step: 00047400] Batch Translation Loss:   0.945586 => Txt Tokens per Sec:     1159 || Lr: 0.000240\n","2020-11-28 18:04:15,186 - __main__ - INFO - [Epoch: 150 Step: 00047440] Batch Translation Loss:   0.759734 => Txt Tokens per Sec:     1049 || Lr: 0.000240\n","2020-11-28 18:04:17,412 - __main__ - INFO - [Epoch: 150 Step: 00047480] Batch Translation Loss:   0.783271 => Txt Tokens per Sec:     1151 || Lr: 0.000240\n","2020-11-28 18:04:19,671 - __main__ - INFO - [Epoch: 150 Step: 00047520] Batch Translation Loss:   0.763158 => Txt Tokens per Sec:     1134 || Lr: 0.000240\n","2020-11-28 18:04:21,649 - __main__ - INFO - Epoch 150: Total Training Recognition Loss -1.00  Total Training Translation Loss 222.21 \n","2020-11-28 18:04:21,650 - __main__ - INFO - EPOCH 151\n","2020-11-28 18:04:22,249 - __main__ - INFO - [Epoch: 151 Step: 00047560] Batch Translation Loss:   0.998969 => Txt Tokens per Sec:     1072 || Lr: 0.000240\n","2020-11-28 18:04:24,523 - __main__ - INFO - [Epoch: 151 Step: 00047600] Batch Translation Loss:   0.427819 => Txt Tokens per Sec:     1126 || Lr: 0.000240\n","2020-11-28 18:04:49,190 - __main__ - INFO - Validation result at epoch 151, step    47600: duration: 24.6654s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10891.57031\tPPL: 8.68004\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 29.56\n","\tCHRF 32.63\tROUGE 29.56\n","2020-11-28 18:04:51,434 - __main__ - INFO - [Epoch: 151 Step: 00047640] Batch Translation Loss:   0.377496 => Txt Tokens per Sec:     1141 || Lr: 0.000168\n","2020-11-28 18:04:53,768 - __main__ - INFO - [Epoch: 151 Step: 00047680] Batch Translation Loss:   0.480817 => Txt Tokens per Sec:     1098 || Lr: 0.000168\n","2020-11-28 18:04:55,901 - __main__ - INFO - [Epoch: 151 Step: 00047720] Batch Translation Loss:   1.001390 => Txt Tokens per Sec:     1201 || Lr: 0.000168\n","2020-11-28 18:04:58,279 - __main__ - INFO - [Epoch: 151 Step: 00047760] Batch Translation Loss:   0.563099 => Txt Tokens per Sec:     1077 || Lr: 0.000168\n","2020-11-28 18:05:00,752 - __main__ - INFO - [Epoch: 151 Step: 00047800] Batch Translation Loss:   0.379934 => Txt Tokens per Sec:     1036 || Lr: 0.000168\n","2020-11-28 18:05:02,874 - __main__ - INFO - [Epoch: 151 Step: 00047840] Batch Translation Loss:   0.805661 => Txt Tokens per Sec:     1207 || Lr: 0.000168\n","2020-11-28 18:05:04,693 - __main__ - INFO - Epoch 151: Total Training Recognition Loss -1.00  Total Training Translation Loss 210.54 \n","2020-11-28 18:05:04,694 - __main__ - INFO - EPOCH 152\n","2020-11-28 18:05:05,449 - __main__ - INFO - [Epoch: 152 Step: 00047880] Batch Translation Loss:   0.491069 => Txt Tokens per Sec:     1105 || Lr: 0.000168\n","2020-11-28 18:05:07,628 - __main__ - INFO - [Epoch: 152 Step: 00047920] Batch Translation Loss:   0.492460 => Txt Tokens per Sec:     1176 || Lr: 0.000168\n","2020-11-28 18:05:09,935 - __main__ - INFO - [Epoch: 152 Step: 00047960] Batch Translation Loss:   0.876625 => Txt Tokens per Sec:     1110 || Lr: 0.000168\n","2020-11-28 18:05:12,196 - __main__ - INFO - [Epoch: 152 Step: 00048000] Batch Translation Loss:   0.526503 => Txt Tokens per Sec:     1133 || Lr: 0.000168\n","2020-11-28 18:05:36,798 - __main__ - INFO - Validation result at epoch 152, step    48000: duration: 24.6007s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10901.46387\tPPL: 8.69709\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 29.88\n","\tCHRF 33.17\tROUGE 29.88\n","2020-11-28 18:05:39,221 - __main__ - INFO - [Epoch: 152 Step: 00048040] Batch Translation Loss:   0.499100 => Txt Tokens per Sec:     1057 || Lr: 0.000168\n","2020-11-28 18:05:41,440 - __main__ - INFO - [Epoch: 152 Step: 00048080] Batch Translation Loss:   0.379912 => Txt Tokens per Sec:     1154 || Lr: 0.000168\n","2020-11-28 18:05:43,817 - __main__ - INFO - [Epoch: 152 Step: 00048120] Batch Translation Loss:   0.425731 => Txt Tokens per Sec:     1078 || Lr: 0.000168\n","2020-11-28 18:05:45,971 - __main__ - INFO - [Epoch: 152 Step: 00048160] Batch Translation Loss:   0.719748 => Txt Tokens per Sec:     1189 || Lr: 0.000168\n","2020-11-28 18:05:47,598 - __main__ - INFO - Epoch 152: Total Training Recognition Loss -1.00  Total Training Translation Loss 203.55 \n","2020-11-28 18:05:47,599 - __main__ - INFO - EPOCH 153\n","2020-11-28 18:05:48,566 - __main__ - INFO - [Epoch: 153 Step: 00048200] Batch Translation Loss:   0.756711 => Txt Tokens per Sec:     1062 || Lr: 0.000168\n","2020-11-28 18:05:51,153 - __main__ - INFO - [Epoch: 153 Step: 00048240] Batch Translation Loss:   0.851048 => Txt Tokens per Sec:      990 || Lr: 0.000168\n","2020-11-28 18:05:53,194 - __main__ - INFO - [Epoch: 153 Step: 00048280] Batch Translation Loss:   0.534862 => Txt Tokens per Sec:     1255 || Lr: 0.000168\n","2020-11-28 18:05:55,371 - __main__ - INFO - [Epoch: 153 Step: 00048320] Batch Translation Loss:   1.122445 => Txt Tokens per Sec:     1177 || Lr: 0.000168\n","2020-11-28 18:05:57,563 - __main__ - INFO - [Epoch: 153 Step: 00048360] Batch Translation Loss:   0.896540 => Txt Tokens per Sec:     1169 || Lr: 0.000168\n","2020-11-28 18:05:59,842 - __main__ - INFO - [Epoch: 153 Step: 00048400] Batch Translation Loss:   0.875158 => Txt Tokens per Sec:     1124 || Lr: 0.000168\n","2020-11-28 18:06:24,043 - __main__ - INFO - Validation result at epoch 153, step    48400: duration: 24.1991s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10791.73047\tPPL: 8.50978\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.20\n","\tCHRF 33.91\tROUGE 30.20\n","2020-11-28 18:06:26,349 - __main__ - INFO - [Epoch: 153 Step: 00048440] Batch Translation Loss:   0.779403 => Txt Tokens per Sec:     1110 || Lr: 0.000168\n","2020-11-28 18:06:28,509 - __main__ - INFO - [Epoch: 153 Step: 00048480] Batch Translation Loss:   0.483995 => Txt Tokens per Sec:     1189 || Lr: 0.000168\n","2020-11-28 18:06:29,969 - __main__ - INFO - Epoch 153: Total Training Recognition Loss -1.00  Total Training Translation Loss 202.08 \n","2020-11-28 18:06:29,970 - __main__ - INFO - EPOCH 154\n","2020-11-28 18:06:31,025 - __main__ - INFO - [Epoch: 154 Step: 00048520] Batch Translation Loss:   0.737437 => Txt Tokens per Sec:     1155 || Lr: 0.000168\n","2020-11-28 18:06:33,227 - __main__ - INFO - [Epoch: 154 Step: 00048560] Batch Translation Loss:   1.423649 => Txt Tokens per Sec:     1163 || Lr: 0.000168\n","2020-11-28 18:06:35,730 - __main__ - INFO - [Epoch: 154 Step: 00048600] Batch Translation Loss:   0.814909 => Txt Tokens per Sec:     1024 || Lr: 0.000168\n","2020-11-28 18:06:38,092 - __main__ - INFO - [Epoch: 154 Step: 00048640] Batch Translation Loss:   0.347841 => Txt Tokens per Sec:     1084 || Lr: 0.000168\n","2020-11-28 18:06:40,358 - __main__ - INFO - [Epoch: 154 Step: 00048680] Batch Translation Loss:   0.578230 => Txt Tokens per Sec:     1131 || Lr: 0.000168\n","2020-11-28 18:06:42,460 - __main__ - INFO - [Epoch: 154 Step: 00048720] Batch Translation Loss:   0.885282 => Txt Tokens per Sec:     1219 || Lr: 0.000168\n","2020-11-28 18:06:44,730 - __main__ - INFO - [Epoch: 154 Step: 00048760] Batch Translation Loss:   0.582517 => Txt Tokens per Sec:     1129 || Lr: 0.000168\n","2020-11-28 18:06:46,967 - __main__ - INFO - [Epoch: 154 Step: 00048800] Batch Translation Loss:   1.031668 => Txt Tokens per Sec:     1145 || Lr: 0.000168\n","2020-11-28 18:07:11,854 - __main__ - INFO - Validation result at epoch 154, step    48800: duration: 24.8854s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10893.45508\tPPL: 8.68328\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.99\n","\tCHRF 33.91\tROUGE 30.99\n","2020-11-28 18:07:13,137 - __main__ - INFO - Epoch 154: Total Training Recognition Loss -1.00  Total Training Translation Loss 198.95 \n","2020-11-28 18:07:13,139 - __main__ - INFO - EPOCH 155\n","2020-11-28 18:07:14,361 - __main__ - INFO - [Epoch: 155 Step: 00048840] Batch Translation Loss:   0.626290 => Txt Tokens per Sec:     1154 || Lr: 0.000168\n","2020-11-28 18:07:16,724 - __main__ - INFO - [Epoch: 155 Step: 00048880] Batch Translation Loss:   0.734203 => Txt Tokens per Sec:     1084 || Lr: 0.000168\n","2020-11-28 18:07:19,010 - __main__ - INFO - [Epoch: 155 Step: 00048920] Batch Translation Loss:   0.671310 => Txt Tokens per Sec:     1121 || Lr: 0.000168\n","2020-11-28 18:07:21,124 - __main__ - INFO - [Epoch: 155 Step: 00048960] Batch Translation Loss:   0.818987 => Txt Tokens per Sec:     1212 || Lr: 0.000168\n","2020-11-28 18:07:23,577 - __main__ - INFO - [Epoch: 155 Step: 00049000] Batch Translation Loss:   0.300133 => Txt Tokens per Sec:     1044 || Lr: 0.000168\n","2020-11-28 18:07:25,827 - __main__ - INFO - [Epoch: 155 Step: 00049040] Batch Translation Loss:   0.765115 => Txt Tokens per Sec:     1139 || Lr: 0.000168\n","2020-11-28 18:07:28,028 - __main__ - INFO - [Epoch: 155 Step: 00049080] Batch Translation Loss:   0.675302 => Txt Tokens per Sec:     1164 || Lr: 0.000168\n","2020-11-28 18:07:30,297 - __main__ - INFO - [Epoch: 155 Step: 00049120] Batch Translation Loss:   0.981588 => Txt Tokens per Sec:     1129 || Lr: 0.000168\n","2020-11-28 18:07:31,422 - __main__ - INFO - Epoch 155: Total Training Recognition Loss -1.00  Total Training Translation Loss 200.71 \n","2020-11-28 18:07:31,423 - __main__ - INFO - EPOCH 156\n","2020-11-28 18:07:32,802 - __main__ - INFO - [Epoch: 156 Step: 00049160] Batch Translation Loss:   0.605849 => Txt Tokens per Sec:     1162 || Lr: 0.000168\n","2020-11-28 18:07:35,023 - __main__ - INFO - [Epoch: 156 Step: 00049200] Batch Translation Loss:   0.541501 => Txt Tokens per Sec:     1153 || Lr: 0.000168\n","2020-11-28 18:07:59,566 - __main__ - INFO - Validation result at epoch 156, step    49200: duration: 24.5417s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10770.84961\tPPL: 8.47460\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.48\n","\tCHRF 33.37\tROUGE 30.48\n","2020-11-28 18:08:01,825 - __main__ - INFO - [Epoch: 156 Step: 00049240] Batch Translation Loss:   0.427528 => Txt Tokens per Sec:     1133 || Lr: 0.000168\n","2020-11-28 18:08:04,029 - __main__ - INFO - [Epoch: 156 Step: 00049280] Batch Translation Loss:   0.707752 => Txt Tokens per Sec:     1163 || Lr: 0.000168\n","2020-11-28 18:08:06,340 - __main__ - INFO - [Epoch: 156 Step: 00049320] Batch Translation Loss:   0.729711 => Txt Tokens per Sec:     1108 || Lr: 0.000168\n","2020-11-28 18:08:08,751 - __main__ - INFO - [Epoch: 156 Step: 00049360] Batch Translation Loss:   0.604068 => Txt Tokens per Sec:     1062 || Lr: 0.000168\n","2020-11-28 18:08:10,953 - __main__ - INFO - [Epoch: 156 Step: 00049400] Batch Translation Loss:   0.755606 => Txt Tokens per Sec:     1164 || Lr: 0.000168\n","2020-11-28 18:08:13,237 - __main__ - INFO - [Epoch: 156 Step: 00049440] Batch Translation Loss:   0.975973 => Txt Tokens per Sec:     1121 || Lr: 0.000168\n","2020-11-28 18:08:14,089 - __main__ - INFO - Epoch 156: Total Training Recognition Loss -1.00  Total Training Translation Loss 197.22 \n","2020-11-28 18:08:14,091 - __main__ - INFO - EPOCH 157\n","2020-11-28 18:08:15,701 - __main__ - INFO - [Epoch: 157 Step: 00049480] Batch Translation Loss:   1.018999 => Txt Tokens per Sec:     1114 || Lr: 0.000168\n","2020-11-28 18:08:17,853 - __main__ - INFO - [Epoch: 157 Step: 00049520] Batch Translation Loss:   0.464628 => Txt Tokens per Sec:     1190 || Lr: 0.000168\n","2020-11-28 18:08:20,327 - __main__ - INFO - [Epoch: 157 Step: 00049560] Batch Translation Loss:   0.487360 => Txt Tokens per Sec:     1035 || Lr: 0.000168\n","2020-11-28 18:08:22,595 - __main__ - INFO - [Epoch: 157 Step: 00049600] Batch Translation Loss:   0.495790 => Txt Tokens per Sec:     1130 || Lr: 0.000168\n","2020-11-28 18:08:46,914 - __main__ - INFO - Validation result at epoch 157, step    49600: duration: 24.3173s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10965.08691\tPPL: 8.80758\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.71\n","\tCHRF 34.18\tROUGE 30.71\n","2020-11-28 18:08:49,070 - __main__ - INFO - [Epoch: 157 Step: 00049640] Batch Translation Loss:   0.489441 => Txt Tokens per Sec:     1187 || Lr: 0.000168\n","2020-11-28 18:08:51,613 - __main__ - INFO - [Epoch: 157 Step: 00049680] Batch Translation Loss:   0.760623 => Txt Tokens per Sec:     1007 || Lr: 0.000168\n","2020-11-28 18:08:53,799 - __main__ - INFO - [Epoch: 157 Step: 00049720] Batch Translation Loss:   0.500121 => Txt Tokens per Sec:     1172 || Lr: 0.000168\n","2020-11-28 18:08:56,203 - __main__ - INFO - [Epoch: 157 Step: 00049760] Batch Translation Loss:   0.870766 => Txt Tokens per Sec:     1066 || Lr: 0.000168\n","2020-11-28 18:08:56,866 - __main__ - INFO - Epoch 157: Total Training Recognition Loss -1.00  Total Training Translation Loss 197.27 \n","2020-11-28 18:08:56,868 - __main__ - INFO - EPOCH 158\n","2020-11-28 18:08:58,549 - __main__ - INFO - [Epoch: 158 Step: 00049800] Batch Translation Loss:   0.316826 => Txt Tokens per Sec:     1181 || Lr: 0.000168\n","2020-11-28 18:09:00,751 - __main__ - INFO - [Epoch: 158 Step: 00049840] Batch Translation Loss:   0.453224 => Txt Tokens per Sec:     1164 || Lr: 0.000168\n","2020-11-28 18:09:03,201 - __main__ - INFO - [Epoch: 158 Step: 00049880] Batch Translation Loss:   0.392517 => Txt Tokens per Sec:     1045 || Lr: 0.000168\n","2020-11-28 18:09:05,357 - __main__ - INFO - [Epoch: 158 Step: 00049920] Batch Translation Loss:   0.507663 => Txt Tokens per Sec:     1188 || Lr: 0.000168\n","2020-11-28 18:09:07,819 - __main__ - INFO - [Epoch: 158 Step: 00049960] Batch Translation Loss:   0.454181 => Txt Tokens per Sec:     1040 || Lr: 0.000168\n","2020-11-28 18:09:10,159 - __main__ - INFO - [Epoch: 158 Step: 00050000] Batch Translation Loss:   0.335397 => Txt Tokens per Sec:     1095 || Lr: 0.000168\n","2020-11-28 18:09:34,298 - __main__ - INFO - Validation result at epoch 158, step    50000: duration: 24.1379s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10843.82617\tPPL: 8.59820\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.67\n","\tCHRF 33.93\tROUGE 30.67\n","2020-11-28 18:09:36,457 - __main__ - INFO - [Epoch: 158 Step: 00050040] Batch Translation Loss:   0.541016 => Txt Tokens per Sec:     1186 || Lr: 0.000168\n","2020-11-28 18:09:38,794 - __main__ - INFO - [Epoch: 158 Step: 00050080] Batch Translation Loss:   1.150192 => Txt Tokens per Sec:     1087 || Lr: 0.000168\n","2020-11-28 18:09:39,245 - __main__ - INFO - Epoch 158: Total Training Recognition Loss -1.00  Total Training Translation Loss 192.89 \n","2020-11-28 18:09:39,247 - __main__ - INFO - EPOCH 159\n","2020-11-28 18:09:41,195 - __main__ - INFO - [Epoch: 159 Step: 00050120] Batch Translation Loss:   0.397866 => Txt Tokens per Sec:     1118 || Lr: 0.000168\n","2020-11-28 18:09:43,440 - __main__ - INFO - [Epoch: 159 Step: 00050160] Batch Translation Loss:   0.631273 => Txt Tokens per Sec:     1141 || Lr: 0.000168\n","2020-11-28 18:09:45,769 - __main__ - INFO - [Epoch: 159 Step: 00050200] Batch Translation Loss:   0.632715 => Txt Tokens per Sec:     1100 || Lr: 0.000168\n","2020-11-28 18:09:48,077 - __main__ - INFO - [Epoch: 159 Step: 00050240] Batch Translation Loss:   0.427293 => Txt Tokens per Sec:     1110 || Lr: 0.000168\n","2020-11-28 18:09:50,271 - __main__ - INFO - [Epoch: 159 Step: 00050280] Batch Translation Loss:   0.699728 => Txt Tokens per Sec:     1168 || Lr: 0.000168\n","2020-11-28 18:09:52,422 - __main__ - INFO - [Epoch: 159 Step: 00050320] Batch Translation Loss:   1.169686 => Txt Tokens per Sec:     1191 || Lr: 0.000168\n","2020-11-28 18:09:54,511 - __main__ - INFO - [Epoch: 159 Step: 00050360] Batch Translation Loss:   0.596798 => Txt Tokens per Sec:     1226 || Lr: 0.000168\n","2020-11-28 18:09:57,214 - __main__ - INFO - [Epoch: 159 Step: 00050400] Batch Translation Loss:   1.080447 => Txt Tokens per Sec:      939 || Lr: 0.000168\n","2020-11-28 18:10:21,314 - __main__ - INFO - Validation result at epoch 159, step    50400: duration: 24.0988s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10843.81738\tPPL: 8.59818\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 31.19\n","\tCHRF 34.27\tROUGE 31.19\n","2020-11-28 18:10:21,488 - __main__ - INFO - Epoch 159: Total Training Recognition Loss -1.00  Total Training Translation Loss 196.34 \n","2020-11-28 18:10:21,489 - __main__ - INFO - EPOCH 160\n","2020-11-28 18:10:23,605 - __main__ - INFO - [Epoch: 160 Step: 00050440] Batch Translation Loss:   0.535707 => Txt Tokens per Sec:     1120 || Lr: 0.000168\n","2020-11-28 18:10:25,878 - __main__ - INFO - [Epoch: 160 Step: 00050480] Batch Translation Loss:   0.752200 => Txt Tokens per Sec:     1127 || Lr: 0.000168\n","2020-11-28 18:10:28,083 - __main__ - INFO - [Epoch: 160 Step: 00050520] Batch Translation Loss:   0.365248 => Txt Tokens per Sec:     1161 || Lr: 0.000168\n","2020-11-28 18:10:30,342 - __main__ - INFO - [Epoch: 160 Step: 00050560] Batch Translation Loss:   0.607473 => Txt Tokens per Sec:     1134 || Lr: 0.000168\n","2020-11-28 18:10:32,644 - __main__ - INFO - [Epoch: 160 Step: 00050600] Batch Translation Loss:   0.653287 => Txt Tokens per Sec:     1113 || Lr: 0.000168\n","2020-11-28 18:10:34,892 - __main__ - INFO - [Epoch: 160 Step: 00050640] Batch Translation Loss:   0.856007 => Txt Tokens per Sec:     1139 || Lr: 0.000168\n","2020-11-28 18:10:37,140 - __main__ - INFO - [Epoch: 160 Step: 00050680] Batch Translation Loss:   0.571583 => Txt Tokens per Sec:     1140 || Lr: 0.000168\n","2020-11-28 18:10:39,601 - __main__ - INFO - [Epoch: 160 Step: 00050720] Batch Translation Loss:   0.949597 => Txt Tokens per Sec:     1032 || Lr: 0.000168\n","2020-11-28 18:10:39,603 - __main__ - INFO - Epoch 160: Total Training Recognition Loss -1.00  Total Training Translation Loss 198.19 \n","2020-11-28 18:10:39,605 - __main__ - INFO - EPOCH 161\n","2020-11-28 18:10:42,042 - __main__ - INFO - [Epoch: 161 Step: 00050760] Batch Translation Loss:   0.344581 => Txt Tokens per Sec:     1052 || Lr: 0.000168\n","2020-11-28 18:10:44,264 - __main__ - INFO - [Epoch: 161 Step: 00050800] Batch Translation Loss:   0.618355 => Txt Tokens per Sec:     1153 || Lr: 0.000168\n","2020-11-28 18:11:08,711 - __main__ - INFO - Validation result at epoch 161, step    50800: duration: 24.4459s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10789.96484\tPPL: 8.50680\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 30.95\n","\tCHRF 33.75\tROUGE 30.95\n","2020-11-28 18:11:10,933 - __main__ - INFO - [Epoch: 161 Step: 00050840] Batch Translation Loss:   0.655697 => Txt Tokens per Sec:     1152 || Lr: 0.000168\n","2020-11-28 18:11:12,984 - __main__ - INFO - [Epoch: 161 Step: 00050880] Batch Translation Loss:   0.541184 => Txt Tokens per Sec:     1249 || Lr: 0.000168\n","2020-11-28 18:11:15,377 - __main__ - INFO - [Epoch: 161 Step: 00050920] Batch Translation Loss:   0.813846 => Txt Tokens per Sec:     1070 || Lr: 0.000168\n","2020-11-28 18:11:17,441 - __main__ - INFO - [Epoch: 161 Step: 00050960] Batch Translation Loss:   0.472971 => Txt Tokens per Sec:     1242 || Lr: 0.000168\n","2020-11-28 18:11:19,668 - __main__ - INFO - [Epoch: 161 Step: 00051000] Batch Translation Loss:   0.504101 => Txt Tokens per Sec:     1150 || Lr: 0.000168\n","2020-11-28 18:11:22,083 - __main__ - INFO - Epoch 161: Total Training Recognition Loss -1.00  Total Training Translation Loss 193.22 \n","2020-11-28 18:11:22,084 - __main__ - INFO - EPOCH 162\n","2020-11-28 18:11:22,269 - __main__ - INFO - [Epoch: 162 Step: 00051040] Batch Translation Loss:   0.330474 => Txt Tokens per Sec:     1049 || Lr: 0.000168\n","2020-11-28 18:11:24,566 - __main__ - INFO - [Epoch: 162 Step: 00051080] Batch Translation Loss:   0.635719 => Txt Tokens per Sec:     1115 || Lr: 0.000168\n","2020-11-28 18:11:26,734 - __main__ - INFO - [Epoch: 162 Step: 00051120] Batch Translation Loss:   0.798993 => Txt Tokens per Sec:     1181 || Lr: 0.000168\n","2020-11-28 18:11:28,960 - __main__ - INFO - [Epoch: 162 Step: 00051160] Batch Translation Loss:   1.383434 => Txt Tokens per Sec:     1151 || Lr: 0.000168\n","2020-11-28 18:11:31,332 - __main__ - INFO - [Epoch: 162 Step: 00051200] Batch Translation Loss:   0.627659 => Txt Tokens per Sec:     1080 || Lr: 0.000168\n","2020-11-28 18:11:55,351 - __main__ - INFO - Validation result at epoch 162, step    51200: duration: 24.0181s\n","\tRecognition Beam Size: -1\tTranslation Beam Size: 1\tTranslation Beam Alpha: -1\n","\tRecognition Loss: -1.00000\tTranslation Loss: 10744.24707\tPPL: 8.42999\n","\tEval Metric: BLEU\n","\tWER -1.00\t(DEL: -1.00,\tINS: -1.00,\tSUB: -1.00)\n","\tBLEU-1 31.23\n","\tCHRF 34.36\tROUGE 31.23\n","2020-11-28 18:11:55,355 - __main__ - INFO - Training ended since there were no improvements inthe last learning rate step: 0.000168\n","2020-11-28 18:11:55,358 - __main__ - INFO - Best validation result at step    44000:  31.27 eval_metric.\n"],"name":"stderr"}]}]}