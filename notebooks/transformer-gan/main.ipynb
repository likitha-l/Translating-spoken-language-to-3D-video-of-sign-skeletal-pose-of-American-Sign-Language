{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":["rCrvrN30tHa3","A6F9FE6tTVig","a-aRdpmlTanv","wgalc53TTiWV","KMqh4f17vW5p","HFFCa2koFv26","y3goUK5zTusO"],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7AMKmmdQpI16","executionInfo":{"elapsed":1444,"status":"ok","timestamp":1606608168560,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"},"user_tz":480},"outputId":"f16b9863-73a6-4e16-fe6b-75ea6a569c98"},"source":["import os \n","from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j3yqvRko3s8c"},"source":["### Basic Imports"]},{"cell_type":"code","metadata":{"id":"wX4s0cGrpiCb"},"source":["MAIN_DIR = '/content/drive/My Drive/Colab Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer'\n","DATA_DIR = '/content/drive/My Drive/Colab Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/backtranslation/data'\n","MODEL_DIR = os.path.join(MAIN_DIR, 'model')\n","CONF_DIR = os.path.join(MAIN_DIR, 'conf')\n","\n","UNK_TOKEN = '<unk>'\n","PAD_TOKEN = '<pad>'\n","EOS_TOKEN = '</s>'\n","BOS_TOKEN = '<s>'\n","\n","TARGET_PAD = 0.0\n","\n","DEFAULT_UNK_ID = lambda: 0\n","\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer/vocabulary.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer/initialization.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer/transformer_layers.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer/batch.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer/loss.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer/builders.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer/dtw.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer/plot_videos.py .\n","\n","\n","import yaml\n","import numpy as np\n","import random\n","import pickle\n","import sys\n","from typing import Optional\n","import queue\n","import glob\n","import time\n","from logging import Logger\n","import logging\n","\n","import torch\n","from torch import nn, Tensor\n","import torch.nn.functional as F\n","from torchtext.data import Dataset, Example, Field, BucketIterator, Iterator\n","\n","from vocabulary import build_vocab\n","from initialization import initialize_model\n","from transformer_layers import TransformerEncoderLayer, PositionalEncoding, TransformerDecoderLayer\n","from vocabulary import Vocabulary\n","from batch import Batch\n","from loss import RegLoss\n","from builders import build_optimizer, build_scheduler, build_gradient_clipper\n","from dtw import dtw\n","from plot_videos import plot_video, alter_DTW_timing"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rCrvrN30tHa3"},"source":["### Helper functions"]},{"cell_type":"code","metadata":{"id":"WEZP6CDXtJnM"},"source":["def load_config(path=\"model.yaml\") -> dict:\n","    \"\"\"\n","    Loads and parses a YAML configuration file.\n","\n","    :param path: path to YAML configuration file\n","    :return: configuration dictionary\n","    \"\"\"\n","    with open(os.path.join(CONF_DIR, path), 'r') as ymlfile:\n","        cfg = yaml.safe_load(ymlfile)\n","    return cfg\n","\n","def set_seed(seed: int) -> None:\n","    \"\"\"\n","    Set the random seed for modules torch, numpy and random.\n","\n","    :param seed: random seed\n","    \"\"\"\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","def freeze_params(module: nn.Module) -> None:\n","    \"\"\"\n","    Freeze the parameters of this module,\n","    i.e. do not update them during training\n","\n","    :param module: freeze parameters of this module\n","    \"\"\"\n","    for _, p in module.named_parameters():\n","        p.requires_grad = False\n","\n","def subsequent_mask(size: int) -> Tensor:\n","    \"\"\"\n","    Mask out subsequent positions (to prevent attending to future positions)\n","    Transformer helper function.\n","\n","    :param size: size of mask (2nd and 3rd dim)\n","    :return: Tensor with 0s and 1s of shape (1, size, size)\n","    \"\"\"\n","    mask = np.triu(np.ones((1, size, size)), k=1).astype('uint8')\n","\n","    return torch.from_numpy(mask) == 0 # Turns it into True and False's\n","\n","def symlink_update(target, link_name):\n","    try:\n","        os.symlink(target, link_name)\n","    except FileExistsError as e:\n","        if e.errno == errno.EEXIST:\n","            os.remove(link_name)\n","            os.symlink(target, link_name)\n","        else:\n","            raise e\n","\n","def load_checkpoint(path: str, use_cuda: bool = True) -> dict:\n","    \"\"\"\n","    Load model from saved checkpoint.\n","\n","    :param path: path to checkpoint\n","    :param use_cuda: using cuda or not\n","    :return: checkpoint (dict)\n","    \"\"\"\n","    assert os.path.isfile(path), \"Checkpoint %s not found\" % path\n","    checkpoint = torch.load(path, map_location='cuda' if use_cuda else 'cpu')\n","    return checkpoint\n","\n","class ConfigurationError(Exception):\n","    \"\"\" Custom exception for misspecifications of configuration \"\"\"\n","\n","\n","def get_latest_checkpoint(ckpt_dir, post_fix=\"_every\" ) -> Optional[str]:\n","    \"\"\"\n","    Returns the latest checkpoint (by time) from the given directory, of either every validation step or best\n","    If there is no checkpoint in this directory, returns None\n","\n","    :param ckpt_dir: directory of checkpoint\n","    :param post_fixe: type of checkpoint, either \"_every\" or \"_best\"\n","\n","    :return: latest checkpoint file\n","    \"\"\"\n","    # Find all the every validation checkpoints\n","    list_of_files = glob.glob(\"{}/*{}.ckpt\".format(ckpt_dir,post_fix))\n","    latest_checkpoint = None\n","    if list_of_files:\n","        latest_checkpoint = max(list_of_files, key=os.path.getctime)\n","    return latest_checkpoint\n","\n","def log_cfg(cfg: dict, logger: Logger, prefix: str = \"cfg\"):\n","    \"\"\"\n","    Write configuration to log.\n","\n","    :param cfg: configuration to log\n","    :param logger: logger that defines where log is written to\n","    :param prefix: prefix for logging\n","    \"\"\"\n","    for k, v in cfg.items():\n","        if isinstance(v, dict):\n","            p = \".\".join([prefix, k])\n","            log_cfg(v, logger, prefix=p)\n","        else:\n","            p = \".\".join([prefix, k])\n","            logger.info(\"{:34s} : {}\".format(p, v))\n","\n","def make_logger(model_dir: str, log_file: str = \"train.log\") -> Logger:\n","    \"\"\"\n","    Create a logger for logging the training process.\n","\n","    :param model_dir: path to logging directory\n","    :param log_file: path to logging file\n","    :return: logger object\n","    \"\"\"\n","    #if not logger.handlers:\n","    logger = logging.getLogger(__name__)\n","    while len(logger.handlers) > 0:\n","        h = logger.handlers[0]\n","        print('removing {}'.format(h))\n","        logger.removeHandler(h)\n","    logger.propagate = False\n","    logger.setLevel(logging.INFO)\n","    # Create handlers\n","    c_handler = logging.StreamHandler()\n","    f_handler = logging.FileHandler(os.path.join(model_dir, log_file), mode='w')\n","\n","    # Create formatters and add it to handlers\n","    c_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n","    f_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n","    c_handler.setFormatter(c_format)\n","    f_handler.setFormatter(f_format)\n","\n","    # Add handlers to the logger\n","    logger.addHandler(c_handler)\n","    logger.addHandler(f_handler)\n","\n","    return logger"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IUgSFmiTrwU8"},"source":["### Data Loading"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"O-i9NBfQruOe"},"source":["def load_data(cfg: dict):\n","    \n","    # read parsed data\n","    # list of ['video_id', 'skeletons', 'frame_cnt', 'word', 'embedding']\n","    # skeleton shape [frame #, skeleton + counter = 151]\n","\n","    train_path = os.path.join(DATA_DIR, 'train.pkl')\n","    val_path = os.path.join(DATA_DIR, 'val.pkl')\n","    level = \"word\"\n","    data_cfg = cfg[\"data\"]\n","    src_lang = data_cfg[\"src\"] #gloss\n","    trg_lang = data_cfg[\"trg\"] #skels\n","    lowercase = False\n","    max_sent_length = data_cfg[\"max_sent_length\"] # 1\n","    trg_size = cfg[\"model\"][\"trg_size\"] + 1 # to account for counter\n","    skip_frames = data_cfg.get(\"skip_frames\", 1)\n","\n","    EOS_TOKEN = '</s>'\n","    tok_fun = lambda s: list(s) if level == \"char\" else s.split()\n","    \n","    src_field = Field(init_token=None,\n","                      pad_token=PAD_TOKEN, tokenize=tok_fun,\n","                      batch_first=True, lower=lowercase,\n","                      unk_token=UNK_TOKEN,\n","                      include_lengths=True)\n","        \n","\n","    reg_trg_field = Field(sequential=True,\n","                          use_vocab=False,\n","                          dtype=torch.float32,\n","                          batch_first=True,\n","                          include_lengths=False,\n","                          pad_token=torch.ones((trg_size))*TARGET_PAD)\n","\n","\n","    train_data = SignProdDataset(fields=(src_field, reg_trg_field),\n","                                 path=train_path,\n","                                 trg_size=trg_size,\n","                                 skip_frames=skip_frames)\n","    \n","    src_vocab = build_vocab(field=\"src\", min_freq=1,\n","                            max_size=sys.maxsize,\n","                            dataset=train_data, vocab_file=None)\n","    \n","    src_field.vocab = src_vocab\n","    trg_vocab = [None]*(trg_size)\n","\n","      # Create the Validation Data\n","    dev_data = SignProdDataset(fields=(src_field, reg_trg_field),\n","                               path=val_path,\n","                               trg_size=trg_size,\n","                               skip_frames=skip_frames)\n","    \n","    return train_data, dev_data, src_vocab, trg_vocab\n","\n","global max_src_in_batch, max_tgt_in_batch\n","\n","\n","# pylint: disable=unused-argument,global-variable-undefined\n","def token_batch_size_fn(new, count, sofar):\n","    \"\"\"Compute batch size based on number of tokens (+padding).\"\"\"\n","    global max_src_in_batch, max_tgt_in_batch\n","    if count == 1:\n","        max_src_in_batch = 0\n","        max_tgt_in_batch = 0\n","    max_src_in_batch = max(max_src_in_batch, len(new.src))\n","    src_elements = count * max_src_in_batch\n","    if hasattr(new, 'trg'):  # for monolingual data sets (\"translate\" mode)\n","        max_tgt_in_batch = max(max_tgt_in_batch, len(new.trg) + 2)\n","        tgt_elements = count * max_tgt_in_batch\n","    else:\n","        tgt_elements = 0\n","    return max(src_elements, tgt_elements)\n","\n","class SignProdDataset(Dataset):\n","    def __init__(self, \n","                 fields,\n","                 path,\n","                 trg_size,\n","                 skip_frames=1,\n","                 **kwargs):\n","        if not isinstance(fields[0], (tuple, list)):\n","            fields = [('src', fields[0]), ('trg', fields[1])]\n","        \n","        examples = []\n","        with open(path, 'rb') as data_file:\n","            dataset = pickle.load(data_file)\n","\n","        for i, skeleton in enumerate(dataset[\"skeleton\"]):\n","            src_line = dataset[\"gloss\"][i].replace(' ', '')\n","            # add start frame (zeros)\n","            start_frame = np.zeros((1, skeleton.shape[-1]))\n","            with_start_frame = np.concatenate((start_frame, skeleton))\n","            print(with_start_frame.shape)\n","            normalized = skeleton + 1e-8\n","\n","            if skip_frames > 1:\n","              normalized = normalized[0::skip_frames]\n","\n","            \n","            # add counter here\n","            counters = np.arange(0,len(normalized),1)/len(normalized)\n","\n","            with_counter = np.concatenate((normalized, counters[:, np.newaxis]), axis=1)\n","            examples.append(Example.fromlist([src_line, with_counter], fields))\n","            super(SignProdDataset, self).__init__(examples, fields, **kwargs)\n","         \n","            \n","def make_data_iter(dataset: Dataset,\n","                   batch_size: int,\n","                   batch_type: str = \"sentence\",\n","                   train: bool = False,\n","                   shuffle: bool = False) -> Iterator:\n","    \"\"\"\n","    Returns a torchtext iterator for a torchtext dataset.\n","\n","    :param dataset: torchtext dataset containing src and optionally trg\n","    :param batch_size: size of the batches the iterator prepares\n","    :param batch_type: measure batch size by sentence count or by token count\n","    :param train: whether it's training time, when turned off,\n","        bucketing, sorting within batches and shuffling is disabled\n","    :param shuffle: whether to shuffle the data before each epoch\n","        (no effect if set to True for testing)\n","    :return: torchtext iterator\n","    \"\"\"\n","\n","    batch_size_fn = token_batch_size_fn if batch_type == \"token\" else None\n","\n","    if train:\n","        # optionally shuffle and sort during training\n","        data_iter = BucketIterator(\n","            repeat=False, sort=False, dataset=dataset,\n","            batch_size=batch_size, batch_size_fn=batch_size_fn,\n","            train=True, sort_within_batch=True,\n","            sort_key=lambda x: len(x.src), shuffle=shuffle)\n","    else:\n","        # don't sort/shuffle for validation/inference\n","        data_iter = BucketIterator(\n","            repeat=False, dataset=dataset,\n","            batch_size=batch_size, batch_size_fn=batch_size_fn,\n","            train=False, sort=False)\n","\n","    return data_iter\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A6F9FE6tTVig"},"source":["### Building blocks of the Model"]},{"cell_type":"code","metadata":{"id":"7VFATXOht3GB"},"source":["class Embeddings(nn.Module):\n","\n","    \"\"\"\n","    Simple embeddings class\n","    \"\"\"\n","\n","    # pylint: disable=unused-argument\n","    def __init__(self,\n","                 embedding_dim: int = 64,\n","                 scale: bool = False,\n","                 vocab_size: int = 0,\n","                 padding_idx: int = 1,\n","                 freeze: bool = False,\n","                 **kwargs):\n","        \"\"\"\n","        Create new embeddings for the vocabulary.\n","        Use scaling for the Transformer.\n","\n","        :param embedding_dim:\n","        :param scale:\n","        :param vocab_size:\n","        :param padding_idx:\n","        :param freeze: freeze the embeddings during training\n","        \"\"\"\n","        super(Embeddings, self).__init__()\n","\n","        self.embedding_dim = embedding_dim\n","        self.scale = scale\n","        self.vocab_size = vocab_size\n","        self.lut = nn.Embedding(vocab_size, self.embedding_dim,\n","                                padding_idx=padding_idx)\n","\n","        if freeze:\n","            freeze_params(self)\n","\n","    # pylint: disable=arguments-differ\n","    def forward(self, x: Tensor) -> Tensor:\n","        \"\"\"\n","        Perform lookup for input `x` in the embedding table.\n","\n","        :param x: index in the vocabulary\n","        :return: embedded representation for `x`\n","        \"\"\"\n","        if self.scale:\n","            return self.lut(x) * math.sqrt(self.embedding_dim)\n","        return self.lut(x)\n","\n","    def __repr__(self):\n","        return \"%s(embedding_dim=%d, vocab_size=%d)\" % (\n","            self.__class__.__name__, self.embedding_dim, self.vocab_size)\n","        \n","class Decoder(nn.Module):\n","    \"\"\"\n","    Base decoder class\n","    \"\"\"\n","\n","    @property\n","    def output_size(self):\n","        \"\"\"\n","        Return the output size (size of the target vocabulary)\n","\n","        :return:\n","        \"\"\"\n","        return self._output_size\n","\n","class TransformerDecoder(Decoder):\n","    \"\"\"\n","    A transformer decoder with N masked layers.\n","    Decoder layers are masked so that an attention head cannot see the future.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 num_layers: int = 4,\n","                 num_heads: int = 8,\n","                 hidden_size: int = 512,\n","                 ff_size: int = 2048,\n","                 dropout: float = 0.1,\n","                 emb_dropout: float = 0.1,\n","                 vocab_size: int = 1,\n","                 freeze: bool = False,\n","                 trg_size: int = 97,\n","                 decoder_trg_trg_: bool = True,\n","                 **kwargs):\n","        \"\"\"\n","        Initialize a Transformer decoder.\n","\n","        :param num_layers: number of Transformer layers\n","        :param num_heads: number of heads for each layer\n","        :param hidden_size: hidden size\n","        :param ff_size: position-wise feed-forward size\n","        :param dropout: dropout probability (1-keep)\n","        :param emb_dropout: dropout probability for embeddings\n","        :param vocab_size: size of the output vocabulary\n","        :param freeze: set to True keep all decoder parameters fixed\n","        :param kwargs:\n","        \"\"\"\n","        super(TransformerDecoder, self).__init__()\n","\n","        self._hidden_size = hidden_size\n","\n","        # Dynamic output size depending on the target size\n","        self._output_size = trg_size\n","\n","        # create num_layers decoder layers and put them in a list\n","        self.layers = nn.ModuleList([TransformerDecoderLayer(\n","                size=hidden_size, ff_size=ff_size, num_heads=num_heads,\n","                dropout=dropout, decoder_trg_trg=decoder_trg_trg_) for _ in range(num_layers)])\n","\n","        self.pe = PositionalEncoding(hidden_size,mask_count=True)\n","        self.layer_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n","\n","        self.emb_dropout = nn.Dropout(p=emb_dropout)\n","\n","        # Output layer to be the size of joints vector + 1 for counter (total is trg_size)\n","        self.output_layer = nn.Linear(hidden_size, trg_size, bias=False)\n","\n","        if freeze:\n","            freeze_params(self)\n","\n","    def forward(self,\n","                trg_embed: Tensor = None,\n","                encoder_output: Tensor = None,\n","                src_mask: Tensor = None,\n","                trg_mask: Tensor = None,\n","                **kwargs):\n","        \"\"\"\n","        Transformer decoder forward pass.\n","\n","        :param trg_embed: embedded targets\n","        :param encoder_output: source representations\n","        :param encoder_hidden: unused\n","        :param src_mask:\n","        :param unroll_steps: unused\n","        :param hidden: unused\n","        :param trg_mask: to mask out target paddings\n","                         Note that a subsequent mask is applied here.\n","        :param kwargs:\n","        :return:\n","        \"\"\"\n","        assert trg_mask is not None, \"trg_mask required for Transformer\"\n","\n","        # add position encoding to word embedding\n","        x = self.pe(trg_embed)\n","        # Dropout if given\n","        x = self.emb_dropout(x)\n","\n","        padding_mask = trg_mask\n","        # Create subsequent mask for decoding\n","        sub_mask = subsequent_mask(\n","            trg_embed.size(1)).type_as(trg_mask)\n","\n","        # Apply each layer to the input\n","        for layer in self.layers:\n","            x = layer(x=x, memory=encoder_output,\n","                      src_mask=src_mask, trg_mask=sub_mask, padding_mask=padding_mask)\n","\n","        # Apply a layer normalisation\n","        x = self.layer_norm(x)\n","        # Output layer turns it back into vectors of size trg_size\n","        output = self.output_layer(x)\n","\n","        return output, x, None, None\n","\n","    def __repr__(self):\n","        return \"%s(num_layers=%r, num_heads=%r)\" % (\n","            self.__class__.__name__, len(self.layers),\n","            self.layers[0].trg_trg_att.num_heads)\n","\n","class Encoder(nn.Module):\n","    \"\"\"\n","    Base encoder class\n","    \"\"\"\n","    @property\n","    def output_size(self):\n","        \"\"\"\n","        Return the output size\n","\n","        :return:\n","        \"\"\"\n","        return self._output_size\n","\n","class TransformerEncoder(Encoder):\n","    \"\"\"\n","    Transformer Encoder\n","    \"\"\"\n","\n","    #pylint: disable=unused-argument\n","    def __init__(self,\n","                 hidden_size: int = 512,\n","                 ff_size: int = 2048,\n","                 num_layers: int = 8,\n","                 num_heads: int = 4,\n","                 dropout: float = 0.1,\n","                 emb_dropout: float = 0.1,\n","                 freeze: bool = False,\n","                 **kwargs):\n","        \"\"\"\n","        Initializes the Transformer.\n","        :param hidden_size: hidden size and size of embeddings\n","        :param ff_size: position-wise feed-forward layer size.\n","          (Typically this is 2*hidden_size.)\n","        :param num_layers: number of layers\n","        :param num_heads: number of heads for multi-headed attention\n","        :param dropout: dropout probability for Transformer layers\n","        :param emb_dropout: Is applied to the input (word embeddings).\n","        :param freeze: freeze the parameters of the encoder during training\n","        :param kwargs:\n","        \"\"\"\n","        super(TransformerEncoder, self).__init__()\n","\n","        # build all (num_layers) layers\n","        self.layers = nn.ModuleList([\n","            TransformerEncoderLayer(size=hidden_size, ff_size=ff_size,\n","                                    num_heads=num_heads, dropout=dropout)\n","            for _ in range(num_layers)])\n","\n","        self.layer_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n","        self.pe = PositionalEncoding(hidden_size)\n","        self.emb_dropout = nn.Dropout(p=emb_dropout)\n","        self._output_size = hidden_size\n","\n","        if freeze:\n","            freeze_params(self)\n","\n","    #pylint: disable=arguments-differ\n","    def forward(self,\n","                embed_src: Tensor,\n","                src_length: Tensor,\n","                mask: Tensor) -> (Tensor, Tensor):\n","        \"\"\"\n","        Pass the input (and mask) through each layer in turn.\n","        Applies a Transformer encoder to sequence of embeddings x.\n","        The input mini-batch x needs to be sorted by src length.\n","        x and mask should have the same dimensions [batch, time, dim].\n","\n","        :param embed_src: embedded src inputs,\n","            shape (batch_size, src_len, embed_size)\n","        :param src_length: length of src inputs\n","            (counting tokens before padding), shape (batch_size)\n","        :param mask: indicates padding areas (zeros where padding), shape\n","            (batch_size, src_len, embed_size)\n","        :return:\n","            - output: hidden states with\n","                shape (batch_size, max_length, directions*hidden),\n","            - hidden_concat: last hidden state with\n","                shape (batch_size, directions*hidden)\n","        \"\"\"\n","\n","        x = embed_src\n","        # Add position encoding to word embeddings\n","        x = self.pe(x)\n","        # Add Dropout\n","        x = self.emb_dropout(x)\n","\n","        # Apply each layer to the input\n","        for layer in self.layers:\n","            x = layer(x, mask)\n","\n","        return self.layer_norm(x), None\n","\n","    def __repr__(self):\n","        return \"%s(num_layers=%r, num_heads=%r)\" % (\n","            self.__class__.__name__, len(self.layers),\n","            self.layers[0].src_src_att.num_heads)\n","\n","\n","class RegLoss(nn.Module):\n","    \"\"\"\n","    Regression Loss\n","    \"\"\"\n","\n","    def __init__(self, cfg, target_pad=0.0):\n","        super(RegLoss, self).__init__()\n","\n","        self.loss = cfg[\"training\"][\"loss\"].lower()\n","\n","        if self.loss == \"l1\":\n","            self.criterion = nn.L1Loss()\n","        elif self.loss == \"mse\":\n","            self.criterion = nn.MSELoss()\n","\n","        else:\n","            print(\"Loss not found - revert to default L1 loss\")\n","            self.criterion = nn.L1Loss()\n","\n","        model_cfg = cfg[\"model\"]\n","\n","        self.target_pad = target_pad\n","        self.loss_scale = model_cfg.get(\"loss_scale\", 1.0)\n","\n","    # pylint: disable=arguments-differ\n","    def forward(self, preds, targets):\n","\n","        loss_mask = (targets != self.target_pad)\n","       \n","        # Find the masked predictions and targets using loss mask\n","        preds_masked = preds * loss_mask\n","        targets_masked = targets * loss_mask\n","\n","        # Calculate loss just over the masked predictions\n","        loss = self.criterion(preds_masked, targets_masked)\n","\n","        # Multiply loss by the loss scale\n","        if self.loss_scale != 1.0:\n","            loss = loss * self.loss_scale\n","\n","        return loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a-aRdpmlTanv"},"source":["### Main Model"]},{"cell_type":"code","metadata":{"id":"N32V5ozAtFQx"},"source":["class Model(nn.Module):\n","    \"\"\"\n","    Base Model class\n","    \"\"\"\n","\n","    def __init__(self,\n","                 encoder: Encoder,\n","                 decoder: Decoder,\n","                 src_embed: Embeddings,\n","                 trg_embed: Embeddings,\n","                 src_vocab: Vocabulary,\n","                 trg_vocab: Vocabulary,\n","                 cfg: dict,\n","                 in_trg_size: int,\n","                 out_trg_size: int,\n","                 ) -> None:\n","        \"\"\"\n","        Create a new encoder-decoder model\n","\n","        :param encoder: encoder\n","        :param decoder: decoder\n","        :param src_embed: source embedding\n","        :param trg_embed: target embedding\n","        :param src_vocab: source vocabulary\n","        :param trg_vocab: target vocabulary\n","        \"\"\"\n","        super(Model, self).__init__()\n","\n","        model_cfg = cfg[\"model\"]\n","\n","        self.src_embed = src_embed\n","        self.trg_embed = trg_embed\n","\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.src_vocab = src_vocab\n","        self.trg_vocab = trg_vocab\n","        self.bos_index = self.src_vocab.stoi[BOS_TOKEN]\n","        self.pad_index = self.src_vocab.stoi[PAD_TOKEN]\n","        self.eos_index = self.src_vocab.stoi[EOS_TOKEN]\n","        self.target_pad = TARGET_PAD\n","\n","        self.use_cuda = cfg[\"training\"][\"use_cuda\"]\n","\n","        self.in_trg_size = in_trg_size\n","        self.out_trg_size = out_trg_size\n","        self.count_in = model_cfg.get(\"count_in\",True)\n","        # Just Counter\n","        self.just_count_in = model_cfg.get(\"just_count_in\",False)\n","        # Gaussian Noise\n","        self.gaussian_noise = model_cfg.get(\"gaussian_noise\",False)\n","        # Gaussian Noise\n","        if self.gaussian_noise:\n","            self.noise_rate = model_cfg.get(\"noise_rate\", 1.0)\n","\n","        # Future Prediction - predict for this many frames in the future\n","        self.future_prediction = model_cfg.get(\"future_prediction\", 0)\n","\n","    # pylint: disable=arguments-differ\n","    def forward(self,\n","                src: Tensor,\n","                trg_input: Tensor,\n","                src_mask: Tensor,\n","                src_lengths: Tensor,\n","                trg_mask: Tensor = None) -> (\n","        Tensor, Tensor, Tensor, Tensor):\n","        \"\"\"\n","        First encodes the source sentence.\n","        Then produces the target one word at a time.\n","\n","        :param src: source input\n","        :param trg_input: target input\n","        :param src_mask: source mask\n","        :param src_lengths: length of source inputs\n","        :param trg_mask: target mask\n","        :return: decoder outputs\n","        \"\"\"\n","\n","        # Encode the source sequence\n","        encoder_output, encoder_hidden = self.encode(src=src,\n","                                                     src_length=src_lengths,\n","                                                     src_mask=src_mask)\n","        unroll_steps = trg_input.size(1)\n","\n","        # Add gaussian noise to the target inputs, if in training\n","        if (self.gaussian_noise) and (self.training) and (self.out_stds is not None):\n","\n","            # Create a normal distribution of random numbers between 0-1\n","            noise = trg_input.data.new(trg_input.size()).normal_(0, 1)\n","            # Zero out the noise over the counter\n","            noise[:,:,-1] = torch.zeros_like(noise[:, :, -1])\n","\n","            # Need to add a zero on the end of\n","            if self.future_prediction != 0:\n","                self.out_stds = torch.cat((self.out_stds,torch.zeros_like(self.out_stds)))[:trg_input.shape[-1]]\n","\n","            # Need to multiply by the standard deviations\n","            noise = noise * self.out_stds\n","\n","            # Add to trg_input multiplied by the noise rate\n","            trg_input = trg_input + self.noise_rate*noise\n","\n","        # Decode the target sequence\n","        skel_out, dec_hidden, _, _ = self.decode(encoder_output=encoder_output,\n","                                                 src_mask=src_mask, trg_input=trg_input,\n","                                                 trg_mask=trg_mask)\n","\n","        gloss_out = None\n","\n","        return skel_out, gloss_out\n","\n","    def encode(self, src: Tensor, src_length: Tensor, src_mask: Tensor) \\\n","        -> (Tensor, Tensor):\n","        \"\"\"\n","        Encodes the source sentence.\n","\n","        :param src:\n","        :param src_length:\n","        :param src_mask:\n","        :return: encoder outputs (output, hidden_concat)\n","        \"\"\"\n","        # Encode an embedded source\n","        encode_output = self.encoder(self.src_embed(src), src_length, src_mask)\n","\n","        return encode_output\n","\n","\n","    def decode(self, encoder_output: Tensor,\n","               src_mask: Tensor, trg_input: Tensor,\n","               trg_mask: Tensor = None) \\\n","        -> (Tensor, Tensor, Tensor, Tensor):\n","\n","        \"\"\"\n","        Decode, given an encoded source sentence.\n","\n","        :param encoder_output: encoder states for attention computation\n","        :param encoder_hidden: last encoder state for decoder initialization\n","        :param src_mask: source mask, 1 at valid tokens\n","        :param trg_input: target inputs\n","        :param unroll_steps: number of steps to unrol the decoder for\n","        :param decoder_hidden: decoder hidden state (optional)\n","        :param trg_mask: mask for target steps\n","        :return: decoder outputs (outputs, hidden, att_probs, att_vectors)\n","        \"\"\"\n","\n","        # Enbed the target using a linear layer\n","        trg_embed = self.trg_embed(trg_input)\n","        # Apply decoder to the embedded target\n","        decoder_output = self.decoder(trg_embed=trg_embed, encoder_output=encoder_output,\n","                               src_mask=src_mask,trg_mask=trg_mask)\n","\n","        return decoder_output\n","\n","    def get_loss_for_batch(self, batch: Batch, loss_function: nn.Module):\n","        \"\"\"\n","        Compute non-normalized loss and number of tokens for a batch\n","\n","        :param batch: batch to compute loss for\n","        :param loss_function: loss function, computes for input and target\n","            a scalar loss for the complete batch\n","        :return: batch_loss: sum of losses over non-pad elements in the batch\n","        \"\"\"\n","        # Forward through the batch input\n","        skel_out, _ = self.forward(\n","            src=batch.src, trg_input=batch.trg_input,\n","            src_mask=batch.src_mask, src_lengths=batch.src_lengths,\n","            trg_mask=batch.trg_mask)\n","\n","        # compute batch loss using skel_out and the batch target\n","        # do it by weight\n","        torso_loss = loss_function(skel_out[:, :, 0:16], batch.trg[:, :, 0:16])\n","        hand_loss = loss_function(skel_out[:, :, 16:16+84], batch.trg[:, :, 16:16+84])\n","        face_loss = loss_function(skel_out[:, :, 16+84:], batch.trg[:, :, 16+84:])\n","        \n","        #batch_loss = loss_function(skel_out, batch.trg)\n","        batch_loss = torso_loss * 0.4 + hand_loss * 0.5 + face_loss * 0.1\n","\n","        # If gaussian noise, find the noise for the next epoch\n","        if self.gaussian_noise:\n","            # Calculate the difference between prediction and GT, to find STDs of error\n","            with torch.no_grad():\n","                noise = skel_out.detach() - batch.trg.detach()\n","\n","            if self.future_prediction != 0:\n","                # Cut to only the first frame prediction + add the counter\n","                noise = noise[:, :, :noise.shape[2] // (self.future_prediction)]\n","\n","        else:\n","            noise = None\n","\n","        dtw = 0 #calculate_dtw(batch.trg, skel_out)\n","        # return batch loss = sum over all elements in batch that are not pad\n","        return batch_loss, torso_loss.item(), hand_loss.item(), face_loss.item(), noise\n","\n","    def run_batch(self, batch: Batch, max_output_length: int,) -> (np.array, np.array):\n","        \"\"\"\n","        Get outputs and attentions scores for a given batch\n","\n","        :param batch: batch to generate hypotheses for\n","        :param max_output_length: maximum length of hypotheses\n","        :param beam_size: size of the beam for beam search, if 0 use greedy\n","        :param beam_alpha: alpha value for beam search\n","        :return: stacked_output: hypotheses for batch,\n","            stacked_attention_scores: attention scores for batch\n","        \"\"\"\n","        # First encode the batch, as this can be done in all one go\n","        encoder_output, encoder_hidden = self.encode(\n","            batch.src, batch.src_lengths,\n","            batch.src_mask)\n","\n","        # if maximum output length is not globally specified, adapt to src len\n","        if max_output_length is None:\n","            max_output_length = int(max(batch.src_lengths.cpu().numpy()) * 1.5)\n","\n","        # Then decode the batch separately, as needs to be done iteratively\n","        # greedy decoding\n","        stacked_output, stacked_attention_scores = greedy(\n","                encoder_output=encoder_output,\n","                src_mask=batch.src_mask,\n","                embed=self.trg_embed,\n","                decoder=self.decoder,\n","                trg_input=batch.trg_input,\n","                model=self)\n","\n","        return stacked_output, stacked_attention_scores\n","\n","    def __repr__(self) -> str:\n","        \"\"\"\n","        String representation: a description of encoder, decoder and embeddings\n","\n","        :return: string representation\n","        \"\"\"\n","        return \"%s(\\n\" \\\n","               \"\\tencoder=%s,\\n\" \\\n","               \"\\tdecoder=%s,\\n\" \\\n","               \"\\tsrc_embed=%s,\\n\" \\\n","               \"\\ttrg_embed=%s)\" % (self.__class__.__name__, self.encoder,\n","                   self.decoder, self.src_embed, self.trg_embed)\n","               \n","def build_model(cfg: dict = None,\n","                src_vocab = None,\n","                trg_vocab = None) -> Model:\n","    \"\"\"\n","    Build and initialize the model according to the configuration.\n","\n","    :param cfg: dictionary configuration containing model specifications\n","    :param src_vocab: source vocabulary\n","    :param trg_vocab: target vocabulary\n","    :return: built and initialized model\n","    \"\"\"\n","\n","    full_cfg = cfg\n","    cfg = cfg[\"model\"]\n","\n","    src_padding_idx = None\n","    trg_padding_idx = 0\n","\n","    # Input target size is the joint vector length plus one for counter\n","    in_trg_size = cfg[\"trg_size\"] + 1\n","    # Output target size is the joint vector length plus one for counter\n","    out_trg_size = cfg[\"trg_size\"] + 1\n","\n","    just_count_in = cfg.get(\"just_count_in\", False)\n","    future_prediction = cfg.get(\"future_prediction\", 0)\n","\n","    #  Just count in limits the in target size to 1\n","    if just_count_in:\n","        in_trg_size = 1\n","\n","    # Future Prediction increases the output target size\n","    if future_prediction != 0:\n","        # Times the trg_size (minus counter) by amount of predicted frames, and then add back counter\n","        out_trg_size = (out_trg_size - 1 ) * future_prediction + 1\n","\n","    # Define source embedding\n","    src_embed = Embeddings(\n","        **cfg[\"encoder\"][\"embeddings\"], vocab_size=len(src_vocab),\n","        padding_idx=src_padding_idx)\n","\n","    # Define target linear\n","    # Linear layer replaces an embedding layer - as this takes in the joints size as opposed to a token\n","    trg_linear = nn.Linear(in_trg_size, cfg[\"decoder\"][\"embeddings\"][\"embedding_dim\"])\n","\n","    ## Encoder -------\n","    enc_dropout = cfg[\"encoder\"].get(\"dropout\", 0.) # Dropout\n","    enc_emb_dropout = cfg[\"encoder\"][\"embeddings\"].get(\"dropout\", enc_dropout)\n","    assert cfg[\"encoder\"][\"embeddings\"][\"embedding_dim\"] == \\\n","           cfg[\"encoder\"][\"hidden_size\"], \\\n","           \"for transformer, emb_size must be hidden_size\"\n","\n","    # Transformer Encoder\n","    encoder = TransformerEncoder(**cfg[\"encoder\"],\n","                                 emb_size=src_embed.embedding_dim,\n","                                 emb_dropout=enc_emb_dropout)\n","\n","    ## Decoder -------\n","    dec_dropout = cfg[\"decoder\"].get(\"dropout\", 0.) # Dropout\n","    dec_emb_dropout = cfg[\"decoder\"][\"embeddings\"].get(\"dropout\", dec_dropout)\n","    decoder_trg_trg = cfg[\"decoder\"].get(\"decoder_trg_trg\", True)\n","    # Transformer Decoder\n","    decoder = TransformerDecoder(\n","        **cfg[\"decoder\"], encoder=encoder, vocab_size=len(trg_vocab),\n","        emb_size=trg_linear.out_features, emb_dropout=dec_emb_dropout,\n","        trg_size=out_trg_size, decoder_trg_trg_=decoder_trg_trg)\n","\n","    # Define the model\n","    model = Model(encoder=encoder,\n","                  decoder=decoder,\n","                  src_embed=src_embed,\n","                  trg_embed=trg_linear,\n","                  src_vocab=src_vocab,\n","                  trg_vocab=trg_vocab,\n","                  cfg=full_cfg,\n","                  in_trg_size=in_trg_size,\n","                  out_trg_size=out_trg_size)\n","\n","    # Custom initialization of model parameters\n","    initialize_model(model, cfg, src_padding_idx, trg_padding_idx)\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6xnnemWTTdmc"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"wgalc53TTiWV"},"source":["### Main Train Call"]},{"cell_type":"code","metadata":{"id":"uPS0rTD2xRzq"},"source":["class TrainManager:\n","\n","    def __init__(self, model: Model, config: dict, test=False) -> None:\n","\n","        train_config = config[\"training\"]\n","        model_dir = os.path.join(MODEL_DIR, version)\n","        # If model continue, continues model from the latest checkpoint\n","        model_continue = train_config.get(\"continue\", True)\n","        # If the directory has not been created, can't continue from anything\n","        if not os.path.isdir(model_dir):\n","            model_continue = False\n","        if test:\n","            model_continue = True\n","\n","        # files for logging and storing\n","        self.model_dir = model_dir\n","        \n","        # Build validation files\n","        self.valid_report_file = \"{}/validations.txt\".format(self.model_dir)\n","        self.logger = make_logger(model_dir=self.model_dir)\n","        self.logging_freq = train_config.get('logging_freq', 100)\n","\n","        # model\n","        self.model = model\n","        self.pad_index = self.model.pad_index\n","        self.bos_index = self.model.bos_index\n","        self._log_parameters_list()\n","        self.target_pad = TARGET_PAD\n","\n","        # New Regression loss - depending on config\n","        self.loss = RegLoss(cfg = config,\n","                            target_pad=self.target_pad)\n","\n","        self.normalization = \"batch\"\n","\n","        # optimization\n","        self.learning_rate_min = train_config.get(\"learning_rate_min\", 1.0e-8)\n","        self.clip_grad_fun = build_gradient_clipper(config=train_config)\n","        self.optimizer = build_optimizer(config=train_config, parameters=model.parameters())\n","\n","        # validation & early stopping\n","        self.validation_freq = train_config.get(\"validation_freq\", 1000)\n","        self.ckpt_best_queue = queue.Queue(maxsize=train_config.get(\"keep_last_ckpts\", 1))\n","        self.ckpt_queue = queue.Queue(maxsize=1)\n","\n","        self.val_on_train = config[\"data\"].get(\"val_on_train\", True)\n","\n","        # TODO - Include Back Translation\n","        self.eval_metric = train_config.get(\"eval_metric\", \"dtw\").lower()\n","        if self.eval_metric not in ['bleu', 'chrf', \"dtw\"]:\n","            raise ConfigurationError(\"Invalid setting for 'eval_metric', \"\n","                                     \"valid options: 'bleu', 'chrf', 'DTW'\")\n","        self.early_stopping_metric = train_config.get(\"early_stopping_metric\",\n","                                                       \"eval_metric\")\n","\n","        # if we schedule after BLEU/chrf, we want to maximize it, else minimize\n","        # early_stopping_metric decides on how to find the early stopping point:\n","        # ckpts are written when there's a new high/low score for this metric\n","        if self.early_stopping_metric in [\"loss\",\"dtw\"]:\n","            self.minimize_metric = True\n","        else:\n","            raise ConfigurationError(\"Invalid setting for 'early_stopping_metric', \"\n","                                    \"valid options: 'loss', 'dtw',.\")\n","\n","        # learning rate scheduling\n","        self.scheduler, self.scheduler_step_at = build_scheduler(\n","            config=train_config,\n","            scheduler_mode=\"min\" if self.minimize_metric else \"max\",\n","            optimizer=self.optimizer,\n","            hidden_size=config[\"model\"][\"encoder\"][\"hidden_size\"])\n","\n","        # data & batch handling\n","        self.level = \"word\"\n","        self.shuffle = train_config.get(\"shuffle\", True)\n","        self.epochs = train_config.get('epochs')\n","        self.batch_size = train_config[\"batch_size\"]\n","        self.batch_type = \"sentence\"\n","        self.eval_batch_size = train_config.get(\"eval_batch_size\",self.batch_size)\n","        self.eval_batch_type = train_config.get(\"eval_batch_type\",self.batch_type)\n","        self.batch_multiplier = train_config.get(\"batch_multiplier\", 1)\n","\n","        # generation\n","        self.max_output_length = train_config.get(\"max_output_length\", None)\n","\n","        # CPU / GPU\n","        self.use_cuda = train_config[\"use_cuda\"]\n","        if self.use_cuda:\n","            self.model.cuda()\n","            self.loss.cuda()\n","\n","        # initialize training statistics\n","        self.steps = 0\n","        # stop training if this flag is True by reaching learning rate minimum\n","        self.stop = False\n","        self.total_tokens = 0\n","        self.best_ckpt_iteration = 0\n","        # initial values for best scores\n","        self.best_ckpt_score = np.inf if self.minimize_metric else -np.inf\n","        # comparison function for scores\n","        self.is_best = lambda score: score < self.best_ckpt_score \\\n","            if self.minimize_metric else score > self.best_ckpt_score\n","\n","        ## Checkpoint restart\n","        # If continuing\n","        if model_continue:\n","            # Get the latest checkpoint\n","            ckpt = get_latest_checkpoint(model_dir)\n","            if ckpt is None:\n","                self.logger.info(f\"Can't find checkpoint in directory {ckpt}\")\n","            else:\n","                self.logger.info(f\"Continuing model from {ckpt}\", )\n","                self.init_from_checkpoint(ckpt)\n","\n","        # Skip frames\n","        self.skip_frames = config[\"data\"].get(\"skip_frames\", 1)\n","\n","        ## -- Data augmentation --\n","        # Just Counter\n","        self.just_count_in = config[\"model\"].get(\"just_count_in\",False)\n","        # Gaussian Noise\n","        self.gaussian_noise = config[\"model\"].get(\"gaussian_noise\", False)\n","        \n","        if self.gaussian_noise:\n","            # How much the noise is added in\n","            self.noise_rate = config[\"model\"].get(\"noise_rate\", 1.0)\n","\n","        if self.just_count_in and (self.gaussian_noise):\n","            raise ConfigurationError(\"Can't have both just_count_in and gaussian_noise as True\")\n","\n","        self.future_prediction = config[\"model\"].get(\"future_prediction\", 0)\n","        if self.future_prediction != 0:\n","            frames_predicted = [i for i in range(self.future_prediction)]\n","            print(f\"Future prediction. Frames predicted: {frames_predicted}\")\n","\n","    # Save a checkpoint\n","    def _save_checkpoint(self, type=\"every\") -> None:\n","        # Define model path\n","        model_path = \"{}/{}_{}.ckpt\".format(self.model_dir, self.steps, type)\n","        # Define State\n","        state = {\n","            \"steps\": self.steps,\n","            \"total_tokens\": self.total_tokens,\n","            \"best_ckpt_score\": self.best_ckpt_score,\n","            \"best_ckpt_iteration\": self.best_ckpt_iteration,\n","            \"model_state\": self.model.state_dict(),\n","            \"optimizer_state\": self.optimizer.state_dict(),\n","            \"scheduler_state\": self.scheduler.state_dict() if \\\n","            self.scheduler is not None else None,\n","        }\n","        torch.save(state, model_path)\n","        # If this is the best checkpoint\n","        if type == \"best\":\n","            if self.ckpt_best_queue.full():\n","              to_delete = self.ckpt_best_queue.get()  # delete oldest ckpt\n","              try:\n","                os.remove(to_delete)\n","              except FileNotFoundError:\n","                print(f\"Wanted to delete old checkpoint {to_delete} but file does not exist.\")\n","            self.ckpt_best_queue.put(model_path)\n","\n","            best_path = \"{}/best.ckpt\".format(self.model_dir)\n","            torch.save(state, best_path)\n","\n","        # If this is just the checkpoint at every validation\n","        elif type == \"every\":\n","            if self.ckpt_queue.full():\n","              to_delete = self.ckpt_queue.get()  # delete oldest ckpt\n","              try:\n","                os.remove(to_delete)\n","              except FileNotFoundError:\n","                print(f\"Wanted to delete old checkpoint {to_delete} but file does not exist.\")\n","\n","            self.ckpt_queue.put(model_path)\n","            every_path = \"{}/every.ckpt\".format(self.model_dir)\n","            # overwrite every.ckpt\n","            torch.save(state, every_path)\n","\n","    # Initialise from a checkpoint\n","    def init_from_checkpoint(self, path: str) -> None:\n","        # Find last checkpoint\n","        model_checkpoint = load_checkpoint(path=path, use_cuda=self.use_cuda)\n","\n","        # restore model and optimizer parameters\n","        self.model.load_state_dict(model_checkpoint[\"model_state\"])\n","        self.optimizer.load_state_dict(model_checkpoint[\"optimizer_state\"])\n","\n","        if model_checkpoint[\"scheduler_state\"] is not None and \\\n","                self.scheduler is not None:\n","            # Load the scheduler state\n","            self.scheduler.load_state_dict(model_checkpoint[\"scheduler_state\"])\n","\n","        # restore counts\n","        self.steps = model_checkpoint[\"steps\"]\n","        self.total_tokens = model_checkpoint[\"total_tokens\"]\n","        self.best_ckpt_score = model_checkpoint[\"best_ckpt_score\"]\n","        self.best_ckpt_iteration = model_checkpoint[\"best_ckpt_iteration\"]\n","\n","        # move parameters to cuda\n","        if self.use_cuda:\n","            self.model.cuda()\n","\n","    # Train and validate function\n","    def train_and_validate(self, train_data: Dataset, valid_data: Dataset) \\\n","            -> None:\n","        # Make training iterator\n","        train_iter = make_data_iter(train_data,\n","                                    batch_size=self.batch_size,\n","                                    batch_type=self.batch_type,\n","                                    train=True, shuffle=self.shuffle)\n","\n","        val_step = 0\n","        if self.gaussian_noise:\n","            all_epoch_noise = []\n","        # Loop through epochs\n","        epoch_start_time = time.time()\n","        for epoch_no in range(self.epochs):\n","            if self.scheduler is not None and self.scheduler_step_at == \"epoch\":\n","                self.scheduler.step(epoch=epoch_no)\n","\n","            self.model.train()\n","\n","            # Reset statistics for each epoch.\n","            start = time.time()\n","            total_valid_duration = 0\n","            start_tokens = self.total_tokens\n","            count = self.batch_multiplier - 1\n","            epoch_loss = 0\n","            epoch_torso_loss = 0\n","            epoch_hand_loss = 0\n","            epoch_face_loss = 0\n","\n","            # If Gaussian Noise, extract STDs for each joint position\n","            if self.gaussian_noise:\n","                if len(all_epoch_noise) != 0:\n","                    self.model.out_stds = torch.mean(torch.stack(([noise.std(dim=[0]) for noise in all_epoch_noise])),dim=-2)\n","                else:\n","                    self.model.out_stds = None\n","                all_epoch_noise = []\n","\n","            for batch in iter(train_iter):\n","                # reactivate training\n","                self.model.train()\n","\n","                # create a Batch object from torchtext batch\n","                batch = Batch(torch_batch=batch,\n","                              pad_index=self.pad_index,\n","                              model=self.model)\n","\n","                update = count == 0\n","                # Train the model on a batch\n","                batch_loss, torso_loss, hand_loss, face_loss, noise = self._train_batch(batch, update=update)\n","                # If Gaussian Noise, collect the noise\n","                if self.gaussian_noise:\n","                    # If future Prediction, cut down the noise size to just one frame\n","                    if self.future_prediction != 0:\n","                        all_epoch_noise.append(noise.reshape(-1, self.model.out_trg_size // self.future_prediction))\n","                    else:\n","                        all_epoch_noise.append(noise.reshape(-1,self.model.out_trg_size))\n","\n","                count = self.batch_multiplier if update else count\n","                count -= 1\n","                epoch_loss += batch_loss.detach().cpu().numpy()\n","                epoch_torso_loss += torso_loss\n","                epoch_hand_loss += hand_loss\n","                epoch_face_loss += face_loss\n","\n","                if self.scheduler is not None and self.scheduler_step_at == \"step\" and update:\n","                    self.scheduler.step()\n","\n","                # log learning progress\n","                if self.steps % self.logging_freq == 0 and update:\n","                    elapsed = time.time() - start - total_valid_duration\n","                    elapsed_tokens = self.total_tokens - start_tokens\n","                    self.logger.info(\n","                        \"Epoch %3d Step: %8d Batch Loss: %12.6f [Torso : %12.6f, Hand : %12.6f, Face : %12.6f]\"\n","                        \"Tokens per Sec: %8.0f, Lr: %.6f\",\n","                        epoch_no + 1, self.steps, batch_loss, torso_loss, hand_loss, face_loss,\n","                        elapsed_tokens / elapsed,\n","                        self.optimizer.param_groups[0][\"lr\"])\n","                    start = time.time()\n","                    total_valid_duration = 0\n","                    start_tokens = self.total_tokens\n","\n","                # validate on the entire dev set\n","                if self.steps % self.validation_freq == 0 and update:\n","                    self.logger.info(\"Starting validation calculation.\")\n","                    valid_start_time = time.time()\n","\n","                    valid_score, valid_loss, valid_references, valid_hypotheses, \\\n","                        valid_inputs, all_dtw_scores, valid_file_paths = \\\n","                        validate_on_data(\n","                            batch_size=self.eval_batch_size,\n","                            data=valid_data,\n","                            eval_metric=self.eval_metric,\n","                            model=self.model,\n","                            max_output_length=self.max_output_length,\n","                            loss_function=self.loss,\n","                            batch_type=self.eval_batch_type,\n","                            type=\"val\",\n","                        )\n","\n","                    val_step += 1\n","\n","                    if self.early_stopping_metric == \"loss\":\n","                        ckpt_score = valid_loss\n","                    elif self.early_stopping_metric == \"dtw\":\n","                        ckpt_score = valid_score\n","                    else:\n","                        ckpt_score = valid_score\n","\n","                    new_best = False\n","                    self.best = False\n","                    if self.is_best(ckpt_score):\n","                        self.best = True\n","                        self.best_ckpt_score = ckpt_score\n","                        self.best_ckpt_iteration = self.steps\n","                        self.logger.info(\n","                            'Hooray! New best validation result [%s]!',\n","                            self.early_stopping_metric)\n","                        if self.ckpt_queue.maxsize > 0:\n","                            self.logger.info(\"Saving new checkpoint.\")\n","                            new_best = True\n","                            self._save_checkpoint(type=\"best\")\n","\n","                        # Display these sequences, in this index order\n","                        display = list(range(0, len(valid_hypotheses), int(np.ceil(len(valid_hypotheses) / 13.15))))\n","                        self.produce_validation_video(\n","                            output_joints=valid_hypotheses,\n","                            inputs=valid_inputs,\n","                            references=valid_references,\n","                            model_dir=self.model_dir,\n","                            steps=self.steps,\n","                            display=display,\n","                            type=\"val_inf\",\n","                            file_paths=valid_file_paths,\n","                        )\n","\n","                    self._save_checkpoint(type=\"every\")\n","\n","                    if self.scheduler is not None and self.scheduler_step_at == \"validation\":\n","                        self.scheduler.step(ckpt_score)\n","\n","                    # append to validation report\n","                    self._add_report(\n","                        valid_score=valid_score, valid_loss=valid_loss,\n","                        eval_metric=self.eval_metric,\n","                        new_best=new_best, report_type=\"val\",)\n","\n","                    valid_duration = time.time() - valid_start_time\n","                    total_valid_duration += valid_duration\n","                    self.logger.info(\n","                        'Validation result at epoch %3d, step %8d: Val DTW Score: %6.2f, '\n","                        'loss: %8.4f,  duration: %.4fs',\n","                            epoch_no+1, self.steps, valid_score,\n","                            valid_loss, valid_duration)\n","\n","                if self.stop:\n","                    break\n","            if self.stop:\n","                self.logger.info(\n","                    'Training ended since minimum lr %f was reached.',\n","                     self.learning_rate_min)\n","                break\n","\n","            self.logger.info('Epoch %3d: total training loss %.5f [torso: %.5f, hand: %.5f, face: %.5f', epoch_no+1,\n","                             epoch_loss, epoch_torso_loss, epoch_hand_loss, epoch_face_loss)\n","        else:\n","            self.logger.info('Training ended after %3d epochs.', epoch_no+1)\n","        self.logger.info('Best validation result at step %8d: %6.2f %s.',\n","                         self.best_ckpt_iteration, self.best_ckpt_score,\n","                         self.early_stopping_metric)\n","\n","\n","    # Train the batch\n","    def _train_batch(self, batch: Batch, update: bool = True):\n","\n","        # Get loss from this batch\n","        batch_loss, torso_loss, hand_loss, face_loss, noise = self.model.get_loss_for_batch(\n","            batch=batch, loss_function=self.loss)\n","\n","        # normalize batch loss\n","        if self.normalization == \"batch\":\n","            normalizer = batch.nseqs\n","        elif self.normalization == \"tokens\":\n","            normalizer = batch.ntokens\n","        else:\n","            raise NotImplementedError(\"Only normalize by 'batch' or 'tokens'\")\n","\n","        norm_batch_loss = batch_loss / normalizer\n","        norm_torso_loss = torso_loss / normalizer\n","        norm_hand_loss = hand_loss / normalizer\n","        norm_face_loss = face_loss /normalizer\n","        # division needed since loss.backward sums the gradients until updated\n","        norm_batch_multiply = norm_batch_loss / self.batch_multiplier\n","\n","        # compute gradients\n","        norm_batch_multiply.backward()\n","\n","        if self.clip_grad_fun is not None:\n","            # clip gradients (in-place)\n","            self.clip_grad_fun(params=self.model.parameters())\n","\n","        if update:\n","            # make gradient step\n","            self.optimizer.step()\n","            self.optimizer.zero_grad()\n","\n","            # increment step counter\n","            self.steps += 1\n","\n","        # increment token counter\n","        self.total_tokens += batch.ntokens\n","\n","        return norm_batch_loss, norm_torso_loss, norm_hand_loss, norm_face_loss, noise\n","\n","    def _add_report(self, valid_score: float, valid_loss: float, eval_metric: str,\n","                    new_best: bool = False, report_type: str = \"val\") -> None:\n","\n","        current_lr = -1\n","        # ignores other param groups for now\n","        for param_group in self.optimizer.param_groups:\n","            current_lr = param_group['lr']\n","\n","        if current_lr < self.learning_rate_min:\n","            self.stop = True\n","\n","        if report_type == \"val\":\n","            with open(self.valid_report_file, 'a') as opened_file:\n","                opened_file.write(\n","                    \"Steps: {} Loss: {:.5f}| DTW: {:.3f}|\"\n","                    \" LR: {:.6f} {}\\n\".format(\n","                        self.steps, valid_loss, valid_score,\n","                        current_lr, \"*\" if new_best else \"\"))\n","\n","    def _log_parameters_list(self) -> None:\n","        \"\"\"\n","        Write all model parameters (name, shape) to the log.\n","        \"\"\"\n","        model_parameters = filter(lambda p: p.requires_grad,\n","                                  self.model.parameters())\n","        n_params = sum([np.prod(p.size()) for p in model_parameters])\n","        self.logger.info(\"Total params: %d\", n_params)\n","        trainable_params = [n for (n, p) in self.model.named_parameters()\n","                            if p.requires_grad]\n","        self.logger.info(\"Trainable parameters: %s\", sorted(trainable_params))\n","        assert trainable_params\n","        \n","    # Produce the video of Phoenix MTC joints\n","    def produce_validation_video(self,output_joints, inputs, references, display, model_dir, type, steps=\"\", file_paths=None):\n","\n","        # If not at test\n","        if type != \"test\":\n","            dir_name = model_dir + \"/videos/Step_{}/\".format(steps)\n","            if not os.path.exists(model_dir + \"/videos/\"):\n","                os.mkdir(model_dir + \"/videos/\")\n","\n","        # If at test time\n","        elif type == \"test\":\n","            dir_name = model_dir + \"/test_videos/\"\n","\n","        # Create model video folder if not exist\n","        if not os.path.exists(dir_name):\n","            os.mkdir(dir_name)\n","        # For sequence to display\n","        for i in display:\n","\n","            seq = output_joints[i]\n","            ref_seq = references[i]\n","            input = inputs[i]\n","            # Write gloss label\n","            gloss_label = input[0] # [\"word\"]\n","\n","\n","            # Alter the dtw timing of the produced sequence, and collect the DTW score\n","            timing_hyp_seq, ref_seq_count, dtw_score = alter_DTW_timing(seq, ref_seq)\n","            video_ext = \"{}_{}.mp4\".format(gloss_label, \"{0:.2f}\".format(float(dtw_score)).replace(\".\", \"_\"))\n","\n","            try :\n","              if file_paths is not None:\n","                  sequence_ID = file_paths[i]\n","              else:\n","                  sequence_ID = None\n","            except:\n","              sequence_ID = None\n","\n","            # Plot this sequences video\n","            if \"<\" not in video_ext:\n","                plot_video(joints=timing_hyp_seq,\n","                            file_path=dir_name,\n","                            video_name=video_ext,\n","                            references=ref_seq_count,\n","                            skip_frames=self.skip_frames,\n","                            sequence_ID=gloss_label)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KMqh4f17vW5p"},"source":["#### Train Helper Methods"]},{"cell_type":"code","metadata":{"id":"OejOwbr8vYx-"},"source":["\n","                \n","def greedy(\n","        src_mask: Tensor,\n","        embed: Embeddings,\n","        decoder: Decoder,\n","        encoder_output: Tensor,\n","        trg_input: Tensor,\n","        model,\n","        ) -> (np.array, np.array):\n","    \"\"\"\n","    Special greedy function for transformer, since it works differently.\n","    The transformer remembers all previous states and attends to them.\n","\n","    :param src_mask: mask for source inputs, 0 for positions after </s>\n","    :param embed: target embedding\n","    :param bos_index: index of <s> in the vocabulary\n","    :param max_output_length: maximum length for the hypotheses\n","    :param decoder: decoder to use for greedy decoding\n","    :param encoder_output: encoder hidden states for attention\n","    :param encoder_hidden: encoder final state (unused in Transformer)\n","    :return:\n","        - stacked_output: output hypotheses (2d array of indices),\n","        - stacked_attention_scores: attention scores (3d array)\n","    \"\"\"\n","    # Initialise the input\n","    # Extract just the BOS first frame from the target\n","    ys = trg_input[:,:1,:].float()\n","\n","    # If the counter is coming into the decoder or not\n","    ys_out = ys\n","\n","    # Set the target mask, by finding the padded rows\n","    trg_mask = trg_input != 0.0\n","    trg_mask = trg_mask.unsqueeze(1)\n","\n","    # Find the maximum output length for this batch\n","    max_output_length = trg_input.shape[1]\n","\n","    # If just count in, input is just the counter\n","    if model.just_count_in:\n","        ys = ys[:,:,-1:]\n","\n","    for i in range(max_output_length):\n","\n","        # ys here is the input\n","        # Drive the timing by giving the GT timing - add in the counter to the last column\n","\n","        if model.just_count_in:\n","            # If just counter, drive the input using the GT counter\n","            ys[:,-1] = trg_input[:, i, -1:]\n","\n","        else:\n","            # Give the GT counter for timing, to drive the timing\n","            ys[:,-1,-1:] = trg_input[:, i, -1:]\n","\n","        # Embed the target input before passing to the decoder\n","        trg_embed = embed(ys)\n","\n","        # Cut padding mask to required size (of the size of the input)\n","        padding_mask = trg_mask[:, :, :i+1, :i+1]\n","        # Pad the mask (If required) (To make it square, and used later on correctly)\n","        pad_amount = padding_mask.shape[2] - padding_mask.shape[3]\n","        padding_mask = (F.pad(input=padding_mask.double(), pad=(pad_amount, 0, 0, 0), mode='replicate') == 1.0)\n","\n","        # Pass the embedded input and the encoder output into the decoder\n","        with torch.no_grad():\n","            out, _, _, _ = decoder(\n","                trg_embed=trg_embed,\n","                encoder_output=encoder_output,\n","                src_mask=src_mask,\n","                trg_mask=padding_mask,\n","            )\n","\n","            if model.future_prediction != 0:\n","                # Cut to only the first frame prediction\n","                out = torch.cat((out[:, :, :out.shape[2] // (model.future_prediction)],out[:,:,-1:]),dim=2)\n","\n","            if model.just_count_in:\n","                # If just counter in trg_input, concatenate counters of output\n","                ys = torch.cat([ys, out[:,-1:,-1:]], dim=1)\n","\n","            # Add this frame prediction to the overall prediction\n","            ys = torch.cat([ys, out[:,-1:,:]], dim=1)\n","\n","            # Add this next predicted frame to the full frame output\n","            ys_out = torch.cat([ys_out, out[:,-1:,:]], dim=1)\n","\n","    return ys_out, None\n","\n","\n","# Find the best timing match between a reference and a hypothesis, using DTW\n","def calculate_dtw(references, hypotheses):\n","    \"\"\"\n","    Calculate the DTW costs between a list of references and hypotheses\n","\n","    :param references: list of reference sequences to compare against\n","    :param hypotheses: list of hypothesis sequences to fit onto the reference\n","\n","    :return: dtw_scores: list of DTW costs\n","    \"\"\"\n","    # Euclidean norm is the cost function, difference of coordinates\n","    euclidean_norm = lambda x, y: np.sum(np.abs(x - y))\n","\n","    dtw_scores = []\n","\n","    # Remove the BOS frame from the hypothesis\n","    hypotheses = hypotheses[:, 1:]\n","\n","    # For each reference in the references list\n","    for i, ref in enumerate(references):\n","        # Cut the reference down to the max count value\n","        _ , ref_max_idx = torch.max(ref[:, -1], 0)\n","        if ref_max_idx == 0: ref_max_idx += 1\n","        # Cut down frames by to the max counter value, and chop off counter from joints\n","        ref_count = ref[:ref_max_idx,:-1].cpu().numpy()\n","\n","        # Cut the hypothesis down to the max count value\n","        hyp = hypotheses[i]\n","        _, hyp_max_idx = torch.max(hyp[:, -1], 0)\n","        if hyp_max_idx == 0: hyp_max_idx += 1\n","        # Cut down frames by to the max counter value, and chop off counter from joints\n","        hyp_count = hyp[:hyp_max_idx,:-1].cpu().numpy()\n","\n","        # Calculate DTW of the reference and hypothesis, using euclidean norm\n","        d, cost_matrix, acc_cost_matrix, path = dtw(ref_count, hyp_count, dist=euclidean_norm)\n","\n","        # Normalise the dtw cost by sequence length\n","        d = d/acc_cost_matrix.shape[0]\n","\n","        dtw_scores.append(d)\n","\n","    # Return dtw scores and the hypothesis with altered timing\n","    return dtw_scores\n","\n","# Validate epoch given a dataset\n","def validate_on_data(model: Model,\n","                     data: Dataset,\n","                     batch_size: int,\n","                     max_output_length: int,\n","                     eval_metric: str,\n","                     loss_function: torch.nn.Module = None,\n","                     batch_type: str = \"sentence\",\n","                     type = \"val\",\n","                     BT_model = None):\n","\n","    valid_iter = make_data_iter(\n","        dataset=data, batch_size=batch_size, batch_type=batch_type,\n","        shuffle=True, train=False)\n","\n","    pad_index = model.src_vocab.stoi[PAD_TOKEN]\n","    # disable dropout\n","    model.eval()\n","    # don't track gradients during validation\n","    with torch.no_grad():\n","        valid_hypotheses = []\n","        valid_references = []\n","        valid_inputs = []\n","        file_paths = []\n","        all_dtw_scores = []\n","\n","        valid_loss = 0\n","        total_ntokens = 0\n","        total_nseqs = 0\n","\n","        batches = 0\n","        for valid_batch in iter(valid_iter):\n","            # Extract batch\n","            batch = Batch(torch_batch=valid_batch,\n","                          pad_index = pad_index,\n","                          model = model)\n","            targets = batch.trg\n","\n","            # run as during training with teacher forcing\n","            if loss_function is not None and batch.trg is not None:\n","                # Get the loss for this batch\n","                batch_loss, _, _, _, _, = model.get_loss_for_batch(\n","                    batch, loss_function=loss_function)\n","\n","                valid_loss += batch_loss\n","                total_ntokens += batch.ntokens\n","                total_nseqs += batch.nseqs\n","\n","            # If not just count in, run inference to produce translation videos\n","            if not model.just_count_in:\n","                # Run batch through the model in an auto-regressive format\n","                output, attention_scores = model.run_batch(\n","                                            batch=batch,\n","                                            max_output_length=max_output_length)\n","\n","            # If future prediction\n","            if model.future_prediction != 0:\n","                # Cut to only the first frame prediction + add the counter\n","                # output = torch.cat((output[:, :, :output.shape[2] // (model.future_prediction)], output[:, :, -1:]),dim=2)\n","                # Cut to only the first frame prediction + add the counter\n","                targets = torch.cat((targets[:, :, :targets.shape[2] // (model.future_prediction)], targets[:, :, -1:]),dim=2)\n","\n","            # For just counter, the inference is the same as GTing\n","            if model.just_count_in:\n","                output = train_output\n","\n","            # Add references, hypotheses and file paths to list\n","            valid_references.extend(targets)\n","            valid_hypotheses.extend(output)\n","            #file_paths.extend(batch.file_paths)\n","            # Add the source sentences to list, by using the model source vocab and batch indices\n","            valid_inputs.extend([[model.src_vocab.itos[batch.src[i][j]] for j in range(len(batch.src[i]))] for i in\n","                                 range(len(batch.src))])\n","\n","            # Calculate the full Dynamic Time Warping score - for evaluation\n","            dtw_score = calculate_dtw(targets, output)\n","            all_dtw_scores.extend(dtw_score)\n","\n","            # Can set to only run a few batches\n","            # if batches == math.ceil(100/batch_size):\n","            #     break\n","            batches += 1\n","\n","        # Dynamic Time Warping scores\n","        current_valid_score = np.mean(all_dtw_scores)\n","\n","    return current_valid_score, valid_loss, valid_references, valid_hypotheses, \\\n","           valid_inputs, all_dtw_scores, file_paths"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HFFCa2koFv26"},"source":["### Plotting Videos"]},{"cell_type":"code","metadata":{"id":"4OEWsHWPFuVk"},"source":["import sys\n","import math\n","import numpy as np\n","import cv2\n","import torch\n","from numpy import array, zeros, full, argmin, inf, ndim\n","from scipy.spatial.distance import cdist\n","from math import isinf\n","\n","PAD_TOKEN = '<pad>'\n","\n","def dtw(x, y, dist, warp=1, w=inf, s=1.0):\n","    \"\"\"\n","    Computes Dynamic Time Warping (DTW) of two sequences.\n","\n","    :param array x: N1*M array\n","    :param array y: N2*M array\n","    :param func dist: distance used as cost measure\n","    :param int warp: how many shifts are computed.\n","    :param int w: window size limiting the maximal distance between indices of matched entries |i,j|.\n","    :param float s: weight applied on off-diagonal moves of the path. As s gets larger, the warping path is increasingly biased towards the diagonal\n","    Returns the minimum distance, the cost matrix, the accumulated cost matrix, and the wrap path.\n","    \"\"\"\n","    assert len(x)\n","    assert len(y)\n","    assert isinf(w) or (w >= abs(len(x) - len(y)))\n","    assert s > 0\n","    r, c = len(x), len(y)\n","    if not isinf(w):\n","        D0 = full((r + 1, c + 1), inf)\n","        for i in range(1, r + 1):\n","            D0[i, max(1, i - w):min(c + 1, i + w + 1)] = 0\n","        D0[0, 0] = 0\n","    else:\n","        D0 = zeros((r + 1, c + 1))\n","        D0[0, 1:] = inf\n","        D0[1:, 0] = inf\n","    D1 = D0[1:, 1:]  # view\n","    for i in range(r):\n","        for j in range(c):\n","            if (isinf(w) or (max(0, i - w) <= j <= min(c, i + w))):\n","                D1[i, j] = dist(x[i], y[j])\n","    C = D1.copy()\n","    jrange = range(c)\n","    for i in range(r):\n","        if not isinf(w):\n","            jrange = range(max(0, i - w), min(c, i + w + 1))\n","        for j in jrange:\n","            min_list = [D0[i, j]]\n","            for k in range(1, warp + 1):\n","                i_k = min(i + k, r)\n","                j_k = min(j + k, c)\n","                min_list += [D0[i_k, j] * s, D0[i, j_k] * s]\n","            D1[i, j] += min(min_list)\n","    if len(x) == 1:\n","        path = zeros(len(y)), range(len(y))\n","    elif len(y) == 1:\n","        path = range(len(x)), zeros(len(x))\n","    else:\n","        path = _traceback(D0)\n","    return D1[-1, -1], C, D1, path\n","\n","def _traceback(D):\n","    i, j = array(D.shape) - 2\n","    p, q = [i], [j]\n","    while (i > 0) or (j > 0):\n","        tb = argmin((D[i, j], D[i, j + 1], D[i + 1, j]))\n","        if tb == 0:\n","            i -= 1\n","            j -= 1\n","        elif tb == 1:\n","            i -= 1\n","        else:  # (tb == 2):\n","            j -= 1\n","        p.insert(0, i)\n","        q.insert(0, j)\n","    return array(p), array(q)\n","\n","\n","# Plot a video given a tensor of joints, a file path, video name and references/sequence ID\n","def plot_video(joints,\n","               file_path,\n","               video_name,\n","               references=None,\n","               skip_frames=1,\n","               sequence_ID=None):\n","    # Create video template\n","    FPS = (25 // skip_frames)\n","    video_file = file_path + \"/{}.mp4\".format(video_name.split(\".\")[0])\n","    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","\n","    if references is None:\n","        video = cv2.VideoWriter(video_file, fourcc, float(FPS), (650, 650), True)\n","    elif references is not None:\n","        video = cv2.VideoWriter(video_file, fourcc, float(FPS), (1300, 650), True)  # Long\n","\n","    num_frames = 0\n","\n","    for (j, frame_joints) in enumerate(joints):\n","\n","        # Reached padding\n","        if PAD_TOKEN in frame_joints:\n","            continue\n","\n","        # Initialise frame of white\n","        frame = np.ones((650, 650, 3), np.uint8) * 255\n","\n","        # Cut off the percent_tok, multiply by 3 to restore joint size\n","        # TODO - Remove the *3 if the joints weren't divided by 3 in data creation\n","        \n","        frame_joints = frame_joints[:-1]\n","        # Reduce the frame joints down to 2D for visualisation - Frame joints 2d shape is (48,2)\n","        frame_joints_2d = np.reshape(frame_joints, (-1, 2))\n","        \n","        # Draw the frame given 2D joints\n","        draw_frame_2D(frame, frame_joints_2d)\n","\n","        cv2.putText(frame, \"Predicted Sign Pose\", (180, 600), cv2.FONT_HERSHEY_SIMPLEX, 1,\n","                    (0, 0, 255), 2)\n","\n","        # If reference is provided, create and concatenate on the end\n","        if references is not None:\n","            # Extract the reference joints\n","            ref_joints = references[j]\n","            # Initialise frame of white\n","            ref_frame = np.ones((650, 650, 3), np.uint8) * 255\n","\n","            # Cut off the percent_tok and multiply each joint by 3 (as was reduced in training files)\n","            #ref_joints = ref_joints[:-1] * 3\n","            ref_joints = ref_joints[:-1]\n","            \n","            # Reduce the frame joints down to 2D- Frame joints 2d shape is (48,2)\n","            # ref_joints_2d = np.reshape(ref_joints, (50, 3))[:, :2]\n","            ref_joints_2d = np.reshape(ref_joints, (-1, 2))\n","\n","            # Draw these joints on the frame\n","            draw_frame_2D(ref_frame, ref_joints_2d)\n","\n","            cv2.putText(ref_frame, \"Ground Truth Pose\", (190, 600), cv2.FONT_HERSHEY_SIMPLEX, 1,\n","                        (0, 0, 0), 2)\n","\n","            frame = np.concatenate((frame, ref_frame), axis=1)\n","\n","            sequence_ID_write = \"Sequence ID: \" + sequence_ID\n","            cv2.putText(frame, sequence_ID_write, (700, 635), cv2.FONT_HERSHEY_SIMPLEX, 0.6,\n","                        (0, 0, 0), 2)\n","        # Write the video frame\n","        video.write(frame)\n","        num_frames += 1\n","    # Release the video\n","    video.release()\n","\n","# This is the format of the 3D data, outputted from the Inverse Kinematics model\n","def getSkeletalModelStructure():\n","    # Definition of skeleton model structure:\n","    #   The structure is an n-tuple of:\n","    #\n","    #   (index of a start point, index of an end point, index of a bone)\n","    #\n","    #   E.g., this simple skeletal model\n","    #\n","    #             (0)\n","    #              |\n","    #              |\n","    #              0\n","    #              |\n","    #              |\n","    #     (2)--1--(1)--1--(3)\n","    #      |               |\n","    #      |               |\n","    #      2               2\n","    #      |               |\n","    #      |               |\n","    #     (4)             (5)\n","    #\n","    #   has this structure:\n","    #\n","    #   (\n","    #     (0, 1, 0),\n","    #     (1, 2, 1),\n","    #     (1, 3, 1),\n","    #     (2, 4, 2),\n","    #     (3, 5, 2),\n","    #   )\n","    #\n","    #  Warning 1: The structure has to be a tree.\n","    #  Warning 2: The order isn't random. The order is from a root to lists.\n","    #\n","\n","    return (\n","        # head\n","        (0, 1, 0),\n","\n","        # left shoulder\n","        (1, 2, 1),\n","\n","        # left arm\n","        (2, 3, 2),\n","        # (3, 4, 3),\n","        # Changed to avoid wrist, go straight to hands\n","        (3, 29, 3),\n","\n","        # right shoulder\n","        (1, 5, 1),\n","\n","        # right arm\n","        (5, 6, 2),\n","        # (6, 7, 3),\n","        # Changed to avoid wrist, go straight to hands\n","        (6, 8, 3),\n","\n","        # left hand - wrist\n","        # (7, 8, 4),\n","\n","        # left hand - palm\n","        (8, 9, 5),\n","        (8, 13, 9),\n","        (8, 17, 13),\n","        (8, 21, 17),\n","        (8, 25, 21),\n","\n","        # left hand - 1st finger\n","        (9, 10, 6),\n","        (10, 11, 7),\n","        (11, 12, 8),\n","\n","        # left hand - 2nd finger\n","        (13, 14, 10),\n","        (14, 15, 11),\n","        (15, 16, 12),\n","\n","        # left hand - 3rd finger\n","        (17, 18, 14),\n","        (18, 19, 15),\n","        (19, 20, 16),\n","\n","        # left hand - 4th finger\n","        (21, 22, 18),\n","        (22, 23, 19),\n","        (23, 24, 20),\n","\n","        # left hand - 5th finger\n","        (25, 26, 22),\n","        (26, 27, 23),\n","        (27, 28, 24),\n","\n","        # right hand - wrist\n","        # (4, 29, 4),\n","\n","        # right hand - palm\n","        (29, 30, 5),\n","        (29, 34, 9),\n","        (29, 38, 13),\n","        (29, 42, 17),\n","        (29, 46, 21),\n","\n","        # right hand - 1st finger\n","        (30, 31, 6),\n","        (31, 32, 7),\n","        (32, 33, 8),\n","\n","        # right hand - 2nd finger\n","        (34, 35, 10),\n","        (35, 36, 11),\n","        (36, 37, 12),\n","\n","        # right hand - 3rd finger\n","        (38, 39, 14),\n","        (39, 40, 15),\n","        (40, 41, 16),\n","\n","        # right hand - 4th finger\n","        (42, 43, 18),\n","        (43, 44, 19),\n","        (44, 45, 20),\n","\n","        # right hand - 5th finger\n","        (46, 47, 22),\n","        (47, 48, 23),\n","        (48, 49, 24),\n","    )\n","\n","# Draw a line between two points, if they are positive points\n","def draw_line(im, joint1, joint2, c=(0, 0, 255),t=1, width=3):\n","    thresh = -100\n","    if joint1[0] > thresh and  joint1[1] > thresh and joint2[0] > thresh and joint2[1] > thresh:\n","\n","        center = (int((joint1[0] + joint2[0]) / 2), int((joint1[1] + joint2[1]) / 2))\n","\n","        length = int(math.sqrt(((joint1[0] - joint2[0]) ** 2) + ((joint1[1] - joint2[1]) ** 2))/2)\n","\n","        angle = math.degrees(math.atan2((joint1[0] - joint2[0]),(joint1[1] - joint2[1])))\n","\n","        cv2.ellipse(im, center, (width,length), -angle,0.0,360.0, c, -1)\n","\n","# Draw the frame given 2D joints that are in the Inverse Kinematics format\n","def draw_frame_2D(frame, joints):\n","    # Line to be between the stacked\n","    draw_line(frame, [1, 650], [1, 1], c=(0,0,0), t=1, width=1)\n","    # Give an offset to center the skeleton around\n","    offset = [350, 250]\n","\n","    # Get the skeleton structure details of each bone, and size\n","    skeleton = getSkeletalModelStructure()\n","    skeleton = np.array(skeleton)\n","\n","    number = skeleton.shape[0]\n","\n","    # Increase the size and position of the joints\n","    joints = joints * 10 * 12 * 2\n","    joints = joints + np.ones((joints.shape[0], 2)) * offset\n","\n","    # Loop through each of the bone structures, and plot the bone\n","    for j in range(number):\n","\n","        c = get_bone_colour(skeleton,j)\n","\n","        draw_line(frame, [joints[skeleton[j, 0]][0], joints[skeleton[j, 0]][1]],\n","                  [joints[skeleton[j, 1]][0], joints[skeleton[j, 1]][1]], c=c, t=1, width=1)\n","        \n","\n","# get bone colour given index\n","def get_bone_colour(skeleton,j):\n","    bone = skeleton[j, 2]\n","\n","    if bone == 0:  # head\n","        c = (0, 153, 0)\n","    elif bone == 1:  # Shoulder\n","        c = (0, 0, 255)\n","\n","    elif bone == 2 and skeleton[j, 1] == 3:  # left arm\n","        c = (0, 102, 204)\n","    elif bone == 3 and skeleton[j, 0] == 3:  # left lower arm\n","        c = (0, 204, 204)\n","\n","    elif bone == 2 and skeleton[j, 1] == 6:  # right arm\n","        c = (0, 153, 0)\n","    elif bone == 3 and skeleton[j, 0] == 6:  # right lower arm\n","        c = (0, 204, 0)\n","\n","    # Hands\n","    elif bone in [5, 6, 7, 8]:\n","        c = (0, 0, 255)\n","    elif bone in [9, 10, 11, 12]:\n","        c = (51, 255, 51)\n","    elif bone in [13, 14, 15, 16]:\n","        c = (255, 0, 0)\n","    elif bone in [17, 18, 19, 20]:\n","        c = (204, 153, 255)\n","    elif bone in [21, 22, 23, 24]:\n","        c = (51, 255, 255)\n","\n","    return c\n","\n","# Apply DTW to the produced sequence, so it can be visually compared to the reference sequence\n","def alter_DTW_timing(pred_seq,ref_seq):\n","\n","    # Define a cost function\n","    euclidean_norm = lambda x, y: np.sum(np.abs(x - y))\n","\n","    # Cut the reference down to the max count value\n","    _ , ref_max_idx = torch.max(ref_seq[:, -1], 0)\n","    if ref_max_idx == 0: ref_max_idx += 1\n","    # Cut down frames by counter\n","    ref_seq = ref_seq[:ref_max_idx,:].cpu().numpy()\n","\n","    # Cut the hypothesis down to the max count value\n","    _, hyp_max_idx = torch.max(pred_seq[:, -1], 0)\n","    if hyp_max_idx == 0: hyp_max_idx += 1\n","    # Cut down frames by counter\n","    pred_seq = pred_seq[:hyp_max_idx,:].cpu().numpy()\n","\n","    # Run DTW on the reference and predicted sequence\n","    d, cost_matrix, acc_cost_matrix, path = dtw(ref_seq[:,:-1], pred_seq[:,:-1], dist=euclidean_norm)\n","\n","    # Normalise the dtw cost by sequence length\n","    d = d / acc_cost_matrix.shape[0]\n","\n","    # Initialise new sequence\n","    new_pred_seq = np.zeros_like(ref_seq)\n","    # j tracks the position in the reference sequence\n","    j = 0\n","    skips = 0\n","    squeeze_frames = []\n","    for (i, pred_num) in enumerate(path[0]):\n","\n","        if i == len(path[0]) - 1:\n","            break\n","\n","        if path[1][i] == path[1][i + 1]:\n","            skips += 1\n","\n","        # If a double coming up\n","        if path[0][i] == path[0][i + 1]:\n","            squeeze_frames.append(pred_seq[i - skips])\n","            j += 1\n","        # Just finished a double\n","        elif path[0][i] == path[0][i - 1]:\n","            new_pred_seq[pred_num] = avg_frames(squeeze_frames)\n","            squeeze_frames = []\n","        else:\n","            new_pred_seq[pred_num] = pred_seq[i - skips]\n","\n","    return new_pred_seq, ref_seq, d\n","\n","# Find the average of the given frames\n","def avg_frames(frames):\n","    frames_sum = np.zeros_like(frames[0])\n","    for frame in frames:\n","        frames_sum += frame\n","\n","    avg_frame = frames_sum / len(frames)\n","    return avg_frame"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZEiw7aolTrBf"},"source":["### Run "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ARey4ccUH_D","executionInfo":{"elapsed":44741343,"status":"ok","timestamp":1606573587968,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"},"user_tz":480},"outputId":"ff999d4a-d5f3-4280-b83f-ba3582331815"},"source":["version = \"v2\"\n","\n","if not os.path.isdir(os.path.join(MODEL_DIR, version)):\n","  os.mkdir(os.path.join(MODEL_DIR, version))\n","\n","cfg = load_config(os.path.join(CONF_DIR, 'Base.yaml'))\n","\n","cfg[\"training\"][\"use_cuda\"] = True\n","cfg[\"data\"][\"max_sent_length\"] = 1\n","cfg[\"data\"][\"skip_frames\"] = 2\n","cfg[\"model\"][\"trg_size\"] = 240 # size of skeleton (xy of face included)\n","cfg[\"training\"][\"logging_freq\"] = 40\n","cfg[\"training\"][\"validation_freq\"] = 300\n","cfg['training'][\"max_output_length\"] = 20\n","cfg[\"training\"][\"batch_size\"] = 32\n","cfg[\"model\"][\"encoder\"][\"num_layers\"] = 1\n","cfg[\"training\"][\"epochs\"] = 1000\n","cfg[\"model\"][\"gaussian_noise\"] = True\n","cfg[\"model\"][\"future_prediction\"] = 5\n","\n","set_seed(seed=cfg[\"training\"].get(\"random_seed\", 42))\n","train_data, dev_data, src_vocab, trg_vocab = load_data(cfg)\n","\n","model = build_model(cfg, src_vocab=src_vocab, trg_vocab=trg_vocab)\n","trainer = TrainManager(model=model, config=cfg)\n","trainer.logger.info(model)\n","trainer.train_and_validate(train_data=train_data, valid_data=train_data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-11-28 02:00:50,911 - __main__ - INFO - Total params: 3624448\n","2020-11-28 02:00:50,913 - __main__ - INFO - Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.bias', 'trg_embed.weight']\n","2020-11-28 02:00:51,004 - __main__ - INFO - Can't find checkpoint in directory None\n","2020-11-28 02:00:51,005 - __main__ - INFO - Model(\n","\tencoder=TransformerEncoder(num_layers=1, num_heads=8),\n","\tdecoder=TransformerDecoder(num_layers=2, num_heads=8),\n","\tsrc_embed=Embeddings(embedding_dim=256, vocab_size=1396),\n","\ttrg_embed=Linear(in_features=241, out_features=256, bias=True))\n"],"name":"stderr"},{"output_type":"stream","text":["removing <StreamHandler stderr (NOTSET)>\n","removing <FileHandler /content/drive/My Drive/Colab Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer/model/v1/train.log (NOTSET)>\n","Future prediction. Frames predicted: [0, 1, 2, 3, 4]\n"],"name":"stdout"},{"output_type":"stream","text":["2020-11-28 02:01:03,739 - __main__ - INFO - Epoch   1 Step:       40 Batch Loss:     0.001991 [Torso :     0.001374, Hand :     0.002528, Face :     0.001777]Tokens per Sec:  6563071, Lr: 0.001000\n","2020-11-28 02:01:17,396 - __main__ - INFO - Epoch   1 Step:       80 Batch Loss:     0.000989 [Torso :     0.001030, Hand :     0.000977, Face :     0.000881]Tokens per Sec:  6377225, Lr: 0.001000\n","2020-11-28 02:01:30,172 - __main__ - INFO - Epoch   1 Step:      120 Batch Loss:     0.000598 [Torso :     0.000475, Hand :     0.000691, Face :     0.000622]Tokens per Sec:  6528784, Lr: 0.001000\n","2020-11-28 02:01:43,842 - __main__ - INFO - Epoch   1 Step:      160 Batch Loss:     0.000508 [Torso :     0.000431, Hand :     0.000568, Face :     0.000516]Tokens per Sec:  6385506, Lr: 0.001000\n","2020-11-28 02:01:57,617 - __main__ - INFO - Epoch   1 Step:      200 Batch Loss:     0.000550 [Torso :     0.000427, Hand :     0.000646, Face :     0.000566]Tokens per Sec:  6301058, Lr: 0.001000\n","2020-11-28 02:02:11,401 - __main__ - INFO - Epoch   1 Step:      240 Batch Loss:     0.000422 [Torso :     0.000288, Hand :     0.000522, Face :     0.000463]Tokens per Sec:  6290682, Lr: 0.001000\n","2020-11-28 02:02:25,222 - __main__ - INFO - Epoch   1 Step:      280 Batch Loss:     0.000413 [Torso :     0.000260, Hand :     0.000524, Face :     0.000473]Tokens per Sec:  6321515, Lr: 0.001000\n","2020-11-28 02:02:32,184 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 02:07:58,299 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 02:07:58,301 - __main__ - INFO - Saving new checkpoint.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","2020-11-28 02:08:12,706 - __main__ - INFO - Validation result at epoch   1, step      300: Val DTW Score: 136.83, loss:   3.9782,  duration: 340.5210s\n","2020-11-28 02:08:21,548 - __main__ - INFO - Epoch   1: total training loss 0.36493 [torso: 0.28112, hand: 0.43885, face: 0.33055\n","2020-11-28 02:08:23,165 - __main__ - INFO - Epoch   2 Step:      320 Batch Loss:     0.001836 [Torso :     0.001697, Hand :     0.002054, Face :     0.001302]Tokens per Sec:  3714747, Lr: 0.001000\n","2020-11-28 02:08:37,381 - __main__ - INFO - Epoch   2 Step:      360 Batch Loss:     0.001015 [Torso :     0.000894, Hand :     0.001167, Face :     0.000742]Tokens per Sec:  5999914, Lr: 0.001000\n","2020-11-28 02:08:50,712 - __main__ - INFO - Epoch   2 Step:      400 Batch Loss:     0.000948 [Torso :     0.000807, Hand :     0.001126, Face :     0.000622]Tokens per Sec:  6337864, Lr: 0.001000\n","2020-11-28 02:09:03,890 - __main__ - INFO - Epoch   2 Step:      440 Batch Loss:     0.000926 [Torso :     0.000714, Hand :     0.001146, Face :     0.000674]Tokens per Sec:  6472079, Lr: 0.001000\n","2020-11-28 02:09:17,911 - __main__ - INFO - Epoch   2 Step:      480 Batch Loss:     0.000831 [Torso :     0.000633, Hand :     0.001028, Face :     0.000640]Tokens per Sec:  6294470, Lr: 0.001000\n","2020-11-28 02:09:32,129 - __main__ - INFO - Epoch   2 Step:      520 Batch Loss:     0.000841 [Torso :     0.000684, Hand :     0.001024, Face :     0.000551]Tokens per Sec:  6190656, Lr: 0.001000\n","2020-11-28 02:09:45,643 - __main__ - INFO - Epoch   2 Step:      560 Batch Loss:     0.000899 [Torso :     0.000722, Hand :     0.001095, Face :     0.000626]Tokens per Sec:  6345548, Lr: 0.001000\n","2020-11-28 02:09:58,950 - __main__ - INFO - Epoch   2 Step:      600 Batch Loss:     0.000887 [Torso :     0.000689, Hand :     0.001091, Face :     0.000656]Tokens per Sec:  6348915, Lr: 0.001000\n","2020-11-28 02:09:58,952 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 02:15:24,602 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 02:15:24,603 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 02:15:40,466 - __main__ - INFO - Validation result at epoch   2, step      600: Val DTW Score: 119.64, loss:   8.3431,  duration: 341.5127s\n","2020-11-28 02:15:56,151 - __main__ - INFO - Epoch   2: total training loss 0.30926 [torso: 0.24932, hand: 0.37577, face: 0.21645\n","2020-11-28 02:15:58,676 - __main__ - INFO - Epoch   3 Step:      640 Batch Loss:     0.000808 [Torso :     0.000652, Hand :     0.000967, Face :     0.000637]Tokens per Sec:  5575851, Lr: 0.001000\n","2020-11-28 02:16:12,023 - __main__ - INFO - Epoch   3 Step:      680 Batch Loss:     0.000823 [Torso :     0.000705, Hand :     0.000980, Face :     0.000517]Tokens per Sec:  6333011, Lr: 0.001000\n","2020-11-28 02:16:25,839 - __main__ - INFO - Epoch   3 Step:      720 Batch Loss:     0.000905 [Torso :     0.000703, Hand :     0.001120, Face :     0.000639]Tokens per Sec:  6270709, Lr: 0.001000\n","2020-11-28 02:16:39,108 - __main__ - INFO - Epoch   3 Step:      760 Batch Loss:     0.000887 [Torso :     0.000630, Hand :     0.001141, Face :     0.000645]Tokens per Sec:  6323696, Lr: 0.001000\n","2020-11-28 02:16:53,003 - __main__ - INFO - Epoch   3 Step:      800 Batch Loss:     0.001077 [Torso :     0.000756, Hand :     0.001389, Face :     0.000800]Tokens per Sec:  6309995, Lr: 0.001000\n","2020-11-28 02:17:06,688 - __main__ - INFO - Epoch   3 Step:      840 Batch Loss:     0.000897 [Torso :     0.000689, Hand :     0.001120, Face :     0.000614]Tokens per Sec:  6316553, Lr: 0.001000\n","2020-11-28 02:17:20,758 - __main__ - INFO - Epoch   3 Step:      880 Batch Loss:     0.000618 [Torso :     0.000426, Hand :     0.000813, Face :     0.000411]Tokens per Sec:  6231467, Lr: 0.001000\n","2020-11-28 02:17:27,689 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 02:22:53,194 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 02:22:53,197 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 02:23:06,599 - __main__ - INFO - Validation result at epoch   3, step      900: Val DTW Score: 119.26, loss:   9.2787,  duration: 338.9087s\n","2020-11-28 02:23:15,109 - __main__ - INFO - Epoch   3 Step:      920 Batch Loss:     0.000709 [Torso :     0.000532, Hand :     0.000892, Face :     0.000499]Tokens per Sec:  5620447, Lr: 0.001000\n","2020-11-28 02:23:28,426 - __main__ - INFO - Epoch   3: total training loss 0.26703 [torso: 0.20666, hand: 0.33171, face: 0.18510\n","2020-11-28 02:23:31,593 - __main__ - INFO - Epoch   4 Step:      960 Batch Loss:     0.000956 [Torso :     0.000858, Hand :     0.001093, Face :     0.000661]Tokens per Sec:  6169006, Lr: 0.001000\n","2020-11-28 02:23:45,958 - __main__ - INFO - Epoch   4 Step:     1000 Batch Loss:     0.000739 [Torso :     0.000598, Hand :     0.000904, Face :     0.000475]Tokens per Sec:  6177942, Lr: 0.001000\n","2020-11-28 02:24:00,300 - __main__ - INFO - Epoch   4 Step:     1040 Batch Loss:     0.000755 [Torso :     0.000536, Hand :     0.000970, Face :     0.000558]Tokens per Sec:  6105087, Lr: 0.001000\n","2020-11-28 02:24:14,553 - __main__ - INFO - Epoch   4 Step:     1080 Batch Loss:     0.000728 [Torso :     0.000621, Hand :     0.000861, Face :     0.000487]Tokens per Sec:  6232504, Lr: 0.001000\n","2020-11-28 02:24:28,431 - __main__ - INFO - Epoch   4 Step:     1120 Batch Loss:     0.000732 [Torso :     0.000563, Hand :     0.000912, Face :     0.000510]Tokens per Sec:  6259277, Lr: 0.001000\n","2020-11-28 02:24:41,816 - __main__ - INFO - Epoch   4 Step:     1160 Batch Loss:     0.000788 [Torso :     0.000650, Hand :     0.000950, Face :     0.000525]Tokens per Sec:  6311816, Lr: 0.001000\n","2020-11-28 02:24:55,110 - __main__ - INFO - Epoch   4 Step:     1200 Batch Loss:     0.000811 [Torso :     0.000613, Hand :     0.001014, Face :     0.000585]Tokens per Sec:  6320476, Lr: 0.001000\n","2020-11-28 02:24:55,112 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 02:30:29,240 - __main__ - INFO - Validation result at epoch   4, step     1200: Val DTW Score: 120.49, loss:   7.0198,  duration: 334.1266s\n","2020-11-28 02:30:45,329 - __main__ - INFO - Epoch   4 Step:     1240 Batch Loss:     0.000749 [Torso :     0.000586, Hand :     0.000923, Face :     0.000532]Tokens per Sec:  5560553, Lr: 0.001000\n","2020-11-28 02:30:54,675 - __main__ - INFO - Epoch   4: total training loss 0.24598 [torso: 0.18697, hand: 0.30818, face: 0.17104\n","2020-11-28 02:30:58,515 - __main__ - INFO - Epoch   5 Step:     1280 Batch Loss:     0.000852 [Torso :     0.000783, Hand :     0.000964, Face :     0.000568]Tokens per Sec:  6278386, Lr: 0.001000\n","2020-11-28 02:31:13,176 - __main__ - INFO - Epoch   5 Step:     1320 Batch Loss:     0.000792 [Torso :     0.000597, Hand :     0.000995, Face :     0.000555]Tokens per Sec:  6158536, Lr: 0.001000\n","2020-11-28 02:31:26,917 - __main__ - INFO - Epoch   5 Step:     1360 Batch Loss:     0.000683 [Torso :     0.000484, Hand :     0.000870, Face :     0.000540]Tokens per Sec:  6179135, Lr: 0.001000\n","2020-11-28 02:31:41,339 - __main__ - INFO - Epoch   5 Step:     1400 Batch Loss:     0.000685 [Torso :     0.000475, Hand :     0.000888, Face :     0.000512]Tokens per Sec:  6121946, Lr: 0.001000\n","2020-11-28 02:31:54,592 - __main__ - INFO - Epoch   5 Step:     1440 Batch Loss:     0.000689 [Torso :     0.000542, Hand :     0.000850, Face :     0.000473]Tokens per Sec:  6351715, Lr: 0.001000\n","2020-11-28 02:32:08,249 - __main__ - INFO - Epoch   5 Step:     1480 Batch Loss:     0.000811 [Torso :     0.000567, Hand :     0.001039, Face :     0.000647]Tokens per Sec:  6310188, Lr: 0.001000\n","2020-11-28 02:32:15,912 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 02:37:47,020 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 02:37:47,022 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 02:38:01,697 - __main__ - INFO - Validation result at epoch   5, step     1500: Val DTW Score: 116.04, loss:   7.3108,  duration: 345.7838s\n","2020-11-28 02:38:11,073 - __main__ - INFO - Epoch   5 Step:     1520 Batch Loss:     0.000620 [Torso :     0.000474, Hand :     0.000766, Face :     0.000469]Tokens per Sec:  5293799, Lr: 0.001000\n","2020-11-28 02:38:25,811 - __main__ - INFO - Epoch   5 Step:     1560 Batch Loss:     0.000680 [Torso :     0.000520, Hand :     0.000857, Face :     0.000440]Tokens per Sec:  5883919, Lr: 0.001000\n","2020-11-28 02:38:34,280 - __main__ - INFO - Epoch   5: total training loss 0.23503 [torso: 0.17707, hand: 0.29573, face: 0.16339\n","2020-11-28 02:38:39,033 - __main__ - INFO - Epoch   6 Step:     1600 Batch Loss:     0.000793 [Torso :     0.000560, Hand :     0.001020, Face :     0.000589]Tokens per Sec:  6431642, Lr: 0.001000\n","2020-11-28 02:38:53,080 - __main__ - INFO - Epoch   6 Step:     1640 Batch Loss:     0.000931 [Torso :     0.000686, Hand :     0.001190, Face :     0.000616]Tokens per Sec:  6301757, Lr: 0.001000\n","2020-11-28 02:39:06,934 - __main__ - INFO - Epoch   6 Step:     1680 Batch Loss:     0.000526 [Torso :     0.000380, Hand :     0.000681, Face :     0.000330]Tokens per Sec:  6270031, Lr: 0.001000\n","2020-11-28 02:39:20,683 - __main__ - INFO - Epoch   6 Step:     1720 Batch Loss:     0.000665 [Torso :     0.000435, Hand :     0.000880, Face :     0.000506]Tokens per Sec:  6323853, Lr: 0.001000\n","2020-11-28 02:39:34,212 - __main__ - INFO - Epoch   6 Step:     1760 Batch Loss:     0.000646 [Torso :     0.000481, Hand :     0.000816, Face :     0.000459]Tokens per Sec:  6352469, Lr: 0.001000\n","2020-11-28 02:39:48,005 - __main__ - INFO - Epoch   6 Step:     1800 Batch Loss:     0.000906 [Torso :     0.000649, Hand :     0.001166, Face :     0.000631]Tokens per Sec:  6337114, Lr: 0.001000\n","2020-11-28 02:39:48,007 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 02:45:22,286 - __main__ - INFO - Validation result at epoch   6, step     1800: Val DTW Score: 122.75, loss:   6.8895,  duration: 334.2767s\n","2020-11-28 02:45:37,956 - __main__ - INFO - Epoch   6 Step:     1840 Batch Loss:     0.000702 [Torso :     0.000527, Hand :     0.000888, Face :     0.000468]Tokens per Sec:  5411994, Lr: 0.001000\n","2020-11-28 02:45:51,375 - __main__ - INFO - Epoch   6 Step:     1880 Batch Loss:     0.000664 [Torso :     0.000493, Hand :     0.000847, Face :     0.000435]Tokens per Sec:  6353509, Lr: 0.001000\n","2020-11-28 02:45:58,982 - __main__ - INFO - Epoch   6: total training loss 0.23502 [torso: 0.17276, hand: 0.29953, face: 0.16147\n","2020-11-28 02:46:04,843 - __main__ - INFO - Epoch   7 Step:     1920 Batch Loss:     0.000726 [Torso :     0.000566, Hand :     0.000909, Face :     0.000455]Tokens per Sec:  6349198, Lr: 0.001000\n","2020-11-28 02:46:18,572 - __main__ - INFO - Epoch   7 Step:     1960 Batch Loss:     0.000673 [Torso :     0.000484, Hand :     0.000873, Face :     0.000432]Tokens per Sec:  6206949, Lr: 0.001000\n","2020-11-28 02:46:32,315 - __main__ - INFO - Epoch   7 Step:     2000 Batch Loss:     0.000640 [Torso :     0.000452, Hand :     0.000836, Face :     0.000410]Tokens per Sec:  6239786, Lr: 0.001000\n","2020-11-28 02:46:46,378 - __main__ - INFO - Epoch   7 Step:     2040 Batch Loss:     0.000841 [Torso :     0.000642, Hand :     0.001055, Face :     0.000566]Tokens per Sec:  6248137, Lr: 0.001000\n","2020-11-28 02:47:01,175 - __main__ - INFO - Epoch   7 Step:     2080 Batch Loss:     0.000909 [Torso :     0.000699, Hand :     0.001145, Face :     0.000572]Tokens per Sec:  6065226, Lr: 0.001000\n","2020-11-28 02:47:08,281 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 02:52:47,182 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 02:52:47,184 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 02:53:03,110 - __main__ - INFO - Validation result at epoch   7, step     2100: Val DTW Score: 103.37, loss:   5.3450,  duration: 354.8271s\n","2020-11-28 02:53:13,691 - __main__ - INFO - Epoch   7 Step:     2120 Batch Loss:     0.000734 [Torso :     0.000540, Hand :     0.000932, Face :     0.000517]Tokens per Sec:  4997747, Lr: 0.001000\n","2020-11-28 02:53:29,421 - __main__ - INFO - Epoch   7 Step:     2160 Batch Loss:     0.000637 [Torso :     0.000562, Hand :     0.000746, Face :     0.000389]Tokens per Sec:  5671432, Lr: 0.001000\n","2020-11-28 02:53:43,385 - __main__ - INFO - Epoch   7 Step:     2200 Batch Loss:     0.000679 [Torso :     0.000488, Hand :     0.000879, Face :     0.000445]Tokens per Sec:  6165667, Lr: 0.001000\n","2020-11-28 02:53:49,527 - __main__ - INFO - Epoch   7: total training loss 0.23543 [torso: 0.16977, hand: 0.30330, face: 0.15870\n","2020-11-28 02:53:56,811 - __main__ - INFO - Epoch   8 Step:     2240 Batch Loss:     0.000938 [Torso :     0.000604, Hand :     0.001273, Face :     0.000591]Tokens per Sec:  6180732, Lr: 0.001000\n","2020-11-28 02:54:11,735 - __main__ - INFO - Epoch   8 Step:     2280 Batch Loss:     0.000828 [Torso :     0.000561, Hand :     0.001096, Face :     0.000558]Tokens per Sec:  6080720, Lr: 0.001000\n","2020-11-28 02:54:24,666 - __main__ - INFO - Epoch   8 Step:     2320 Batch Loss:     0.000711 [Torso :     0.000537, Hand :     0.000903, Face :     0.000451]Tokens per Sec:  6331416, Lr: 0.001000\n","2020-11-28 02:54:38,917 - __main__ - INFO - Epoch   8 Step:     2360 Batch Loss:     0.000663 [Torso :     0.000469, Hand :     0.000856, Face :     0.000475]Tokens per Sec:  6112198, Lr: 0.001000\n","2020-11-28 02:54:53,373 - __main__ - INFO - Epoch   8 Step:     2400 Batch Loss:     0.000596 [Torso :     0.000446, Hand :     0.000756, Face :     0.000390]Tokens per Sec:  6096848, Lr: 0.001000\n","2020-11-28 02:54:53,375 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 03:00:35,451 - __main__ - INFO - Validation result at epoch   8, step     2400: Val DTW Score: 115.09, loss:   5.7049,  duration: 342.0750s\n","2020-11-28 03:00:50,767 - __main__ - INFO - Epoch   8 Step:     2440 Batch Loss:     0.000764 [Torso :     0.000496, Hand :     0.001033, Face :     0.000489]Tokens per Sec:  5800989, Lr: 0.001000\n","2020-11-28 03:01:04,959 - __main__ - INFO - Epoch   8 Step:     2480 Batch Loss:     0.000759 [Torso :     0.000543, Hand :     0.000986, Face :     0.000488]Tokens per Sec:  5947713, Lr: 0.001000\n","2020-11-28 03:01:18,208 - __main__ - INFO - Epoch   8 Step:     2520 Batch Loss:     0.000791 [Torso :     0.000595, Hand :     0.001005, Face :     0.000511]Tokens per Sec:  6286864, Lr: 0.001000\n","2020-11-28 03:01:23,663 - __main__ - INFO - Epoch   8: total training loss 0.24146 [torso: 0.17236, hand: 0.31297, face: 0.16034\n","2020-11-28 03:01:32,300 - __main__ - INFO - Epoch   9 Step:     2560 Batch Loss:     0.000745 [Torso :     0.000508, Hand :     0.000988, Face :     0.000483]Tokens per Sec:  6128773, Lr: 0.001000\n","2020-11-28 03:01:47,038 - __main__ - INFO - Epoch   9 Step:     2600 Batch Loss:     0.000629 [Torso :     0.000490, Hand :     0.000792, Face :     0.000370]Tokens per Sec:  6092170, Lr: 0.001000\n","2020-11-28 03:02:01,518 - __main__ - INFO - Epoch   9 Step:     2640 Batch Loss:     0.000651 [Torso :     0.000495, Hand :     0.000827, Face :     0.000394]Tokens per Sec:  6076121, Lr: 0.001000\n","2020-11-28 03:02:15,132 - __main__ - INFO - Epoch   9 Step:     2680 Batch Loss:     0.000916 [Torso :     0.000637, Hand :     0.001200, Face :     0.000609]Tokens per Sec:  6249232, Lr: 0.001000\n","2020-11-28 03:02:22,071 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 03:08:04,635 - __main__ - INFO - Validation result at epoch   9, step     2700: Val DTW Score: 133.59, loss:   6.4944,  duration: 342.5620s\n","2020-11-28 03:08:13,155 - __main__ - INFO - Epoch   9 Step:     2720 Batch Loss:     0.000935 [Torso :     0.000542, Hand :     0.001307, Face :     0.000652]Tokens per Sec:  5712845, Lr: 0.001000\n","2020-11-28 03:08:27,841 - __main__ - INFO - Epoch   9 Step:     2760 Batch Loss:     0.000932 [Torso :     0.000637, Hand :     0.001243, Face :     0.000556]Tokens per Sec:  5830937, Lr: 0.001000\n","2020-11-28 03:08:41,393 - __main__ - INFO - Epoch   9 Step:     2800 Batch Loss:     0.000529 [Torso :     0.000337, Hand :     0.000717, Face :     0.000354]Tokens per Sec:  6242715, Lr: 0.001000\n","2020-11-28 03:08:54,747 - __main__ - INFO - Epoch   9 Step:     2840 Batch Loss:     0.000899 [Torso :     0.000673, Hand :     0.001148, Face :     0.000557]Tokens per Sec:  6340794, Lr: 0.001000\n","2020-11-28 03:08:58,936 - __main__ - INFO - Epoch   9: total training loss 0.24574 [torso: 0.17268, hand: 0.32121, face: 0.16058\n","2020-11-28 03:09:08,808 - __main__ - INFO - Epoch  10 Step:     2880 Batch Loss:     0.000616 [Torso :     0.000366, Hand :     0.000859, Face :     0.000396]Tokens per Sec:  6051169, Lr: 0.001000\n","2020-11-28 03:09:22,442 - __main__ - INFO - Epoch  10 Step:     2920 Batch Loss:     0.000674 [Torso :     0.000431, Hand :     0.000915, Face :     0.000439]Tokens per Sec:  6207881, Lr: 0.001000\n","2020-11-28 03:09:36,784 - __main__ - INFO - Epoch  10 Step:     2960 Batch Loss:     0.000600 [Torso :     0.000445, Hand :     0.000770, Face :     0.000367]Tokens per Sec:  6209646, Lr: 0.001000\n","2020-11-28 03:09:52,010 - __main__ - INFO - Epoch  10 Step:     3000 Batch Loss:     0.000685 [Torso :     0.000469, Hand :     0.000906, Face :     0.000438]Tokens per Sec:  6078778, Lr: 0.001000\n","2020-11-28 03:09:52,012 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 03:15:37,447 - __main__ - INFO - Validation result at epoch  10, step     3000: Val DTW Score: 131.07, loss:   6.7945,  duration: 345.4339s\n","2020-11-28 03:15:52,654 - __main__ - INFO - Epoch  10 Step:     3040 Batch Loss:     0.000798 [Torso :     0.000563, Hand :     0.001040, Face :     0.000532]Tokens per Sec:  5599749, Lr: 0.001000\n","2020-11-28 03:16:06,422 - __main__ - INFO - Epoch  10 Step:     3080 Batch Loss:     0.000754 [Torso :     0.000596, Hand :     0.000939, Face :     0.000460]Tokens per Sec:  6039192, Lr: 0.001000\n","2020-11-28 03:16:20,032 - __main__ - INFO - Epoch  10 Step:     3120 Batch Loss:     0.000876 [Torso :     0.000612, Hand :     0.001147, Face :     0.000577]Tokens per Sec:  6272330, Lr: 0.001000\n","2020-11-28 03:16:34,405 - __main__ - INFO - Epoch  10 Step:     3160 Batch Loss:     0.000900 [Torso :     0.000608, Hand :     0.001201, Face :     0.000558]Tokens per Sec:  6129590, Lr: 0.001000\n","2020-11-28 03:16:37,613 - __main__ - INFO - Epoch  10: total training loss 0.24587 [torso: 0.17187, hand: 0.32254, face: 0.15847\n","2020-11-28 03:16:49,019 - __main__ - INFO - Epoch  11 Step:     3200 Batch Loss:     0.000811 [Torso :     0.000492, Hand :     0.001124, Face :     0.000520]Tokens per Sec:  6079557, Lr: 0.001000\n","2020-11-28 03:17:03,538 - __main__ - INFO - Epoch  11 Step:     3240 Batch Loss:     0.000651 [Torso :     0.000412, Hand :     0.000890, Face :     0.000415]Tokens per Sec:  6120724, Lr: 0.001000\n","2020-11-28 03:17:17,070 - __main__ - INFO - Epoch  11 Step:     3280 Batch Loss:     0.000606 [Torso :     0.000412, Hand :     0.000811, Face :     0.000355]Tokens per Sec:  6269154, Lr: 0.001000\n","2020-11-28 03:17:24,142 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 03:23:11,442 - __main__ - INFO - Validation result at epoch  11, step     3300: Val DTW Score: 112.32, loss:   5.7185,  duration: 347.2983s\n","2020-11-28 03:23:19,805 - __main__ - INFO - Epoch  11 Step:     3320 Batch Loss:     0.001060 [Torso :     0.001137, Hand :     0.001098, Face :     0.000565]Tokens per Sec:  5716974, Lr: 0.001000\n","2020-11-28 03:23:33,792 - __main__ - INFO - Epoch  11 Step:     3360 Batch Loss:     0.000794 [Torso :     0.000578, Hand :     0.001019, Face :     0.000534]Tokens per Sec:  5902567, Lr: 0.001000\n","2020-11-28 03:23:48,109 - __main__ - INFO - Epoch  11 Step:     3400 Batch Loss:     0.000623 [Torso :     0.000441, Hand :     0.000819, Face :     0.000378]Tokens per Sec:  6094497, Lr: 0.001000\n","2020-11-28 03:24:02,265 - __main__ - INFO - Epoch  11 Step:     3440 Batch Loss:     0.000594 [Torso :     0.000475, Hand :     0.000740, Face :     0.000345]Tokens per Sec:  6128420, Lr: 0.001000\n","2020-11-28 03:24:16,498 - __main__ - INFO - Epoch  11 Step:     3480 Batch Loss:     0.000884 [Torso :     0.000613, Hand :     0.001158, Face :     0.000603]Tokens per Sec:  6136152, Lr: 0.001000\n","2020-11-28 03:24:18,793 - __main__ - INFO - Epoch  11: total training loss 0.24579 [torso: 0.16970, hand: 0.32443, face: 0.15701\n","2020-11-28 03:24:29,935 - __main__ - INFO - Epoch  12 Step:     3520 Batch Loss:     0.000840 [Torso :     0.000549, Hand :     0.001133, Face :     0.000543]Tokens per Sec:  6213129, Lr: 0.001000\n","2020-11-28 03:24:44,036 - __main__ - INFO - Epoch  12 Step:     3560 Batch Loss:     0.000514 [Torso :     0.000352, Hand :     0.000683, Face :     0.000317]Tokens per Sec:  6158061, Lr: 0.001000\n","2020-11-28 03:24:58,573 - __main__ - INFO - Epoch  12 Step:     3600 Batch Loss:     0.000638 [Torso :     0.000414, Hand :     0.000851, Face :     0.000464]Tokens per Sec:  6142145, Lr: 0.001000\n","2020-11-28 03:24:58,575 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 03:30:44,361 - __main__ - INFO - Validation result at epoch  12, step     3600: Val DTW Score: 108.60, loss:   5.6262,  duration: 345.7844s\n","2020-11-28 03:31:00,799 - __main__ - INFO - Epoch  12 Step:     3640 Batch Loss:     0.000534 [Torso :     0.000368, Hand :     0.000704, Face :     0.000352]Tokens per Sec:  5381678, Lr: 0.001000\n","2020-11-28 03:31:14,440 - __main__ - INFO - Epoch  12 Step:     3680 Batch Loss:     0.000662 [Torso :     0.000507, Hand :     0.000839, Face :     0.000399]Tokens per Sec:  6103367, Lr: 0.001000\n","2020-11-28 03:31:27,427 - __main__ - INFO - Epoch  12 Step:     3720 Batch Loss:     0.000901 [Torso :     0.000593, Hand :     0.001206, Face :     0.000603]Tokens per Sec:  6333679, Lr: 0.001000\n","2020-11-28 03:31:42,436 - __main__ - INFO - Epoch  12 Step:     3760 Batch Loss:     0.000753 [Torso :     0.000509, Hand :     0.000993, Face :     0.000530]Tokens per Sec:  6043723, Lr: 0.001000\n","2020-11-28 03:31:56,305 - __main__ - INFO - Epoch  12 Step:     3800 Batch Loss:     0.000957 [Torso :     0.000644, Hand :     0.001270, Face :     0.000640]Tokens per Sec:  6229767, Lr: 0.001000\n","2020-11-28 03:31:57,448 - __main__ - INFO - Epoch  12: total training loss 0.24850 [torso: 0.16924, hand: 0.33007, face: 0.15769\n","2020-11-28 03:32:10,051 - __main__ - INFO - Epoch  13 Step:     3840 Batch Loss:     0.000869 [Torso :     0.000605, Hand :     0.001138, Face :     0.000576]Tokens per Sec:  6115296, Lr: 0.001000\n","2020-11-28 03:32:24,607 - __main__ - INFO - Epoch  13 Step:     3880 Batch Loss:     0.000554 [Torso :     0.000350, Hand :     0.000757, Face :     0.000352]Tokens per Sec:  6083767, Lr: 0.001000\n","2020-11-28 03:32:31,588 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 03:38:16,893 - __main__ - INFO - Validation result at epoch  13, step     3900: Val DTW Score: 128.37, loss:   6.5543,  duration: 345.3027s\n","2020-11-28 03:38:24,311 - __main__ - INFO - Epoch  13 Step:     3920 Batch Loss:     0.000659 [Torso :     0.000448, Hand :     0.000884, Face :     0.000383]Tokens per Sec:  5973415, Lr: 0.001000\n","2020-11-28 03:38:39,481 - __main__ - INFO - Epoch  13 Step:     3960 Batch Loss:     0.000899 [Torso :     0.000577, Hand :     0.001217, Face :     0.000597]Tokens per Sec:  5693688, Lr: 0.001000\n","2020-11-28 03:38:52,960 - __main__ - INFO - Epoch  13 Step:     4000 Batch Loss:     0.000757 [Torso :     0.000551, Hand :     0.000981, Face :     0.000458]Tokens per Sec:  6242162, Lr: 0.001000\n","2020-11-28 03:39:06,540 - __main__ - INFO - Epoch  13 Step:     4040 Batch Loss:     0.000772 [Torso :     0.000477, Hand :     0.001055, Face :     0.000535]Tokens per Sec:  6224143, Lr: 0.001000\n","2020-11-28 03:39:20,180 - __main__ - INFO - Epoch  13 Step:     4080 Batch Loss:     0.001103 [Torso :     0.000691, Hand :     0.001509, Face :     0.000722]Tokens per Sec:  6230611, Lr: 0.001000\n","2020-11-28 03:39:33,432 - __main__ - INFO - Epoch  13 Step:     4120 Batch Loss:     0.001148 [Torso :     0.000712, Hand :     0.001578, Face :     0.000747]Tokens per Sec:  6328063, Lr: 0.001000\n","2020-11-28 03:39:33,934 - __main__ - INFO - Epoch  13: total training loss 0.24611 [torso: 0.16691, hand: 0.32752, face: 0.15586\n","2020-11-28 03:39:47,947 - __main__ - INFO - Epoch  14 Step:     4160 Batch Loss:     0.000745 [Torso :     0.000467, Hand :     0.001029, Face :     0.000444]Tokens per Sec:  6105941, Lr: 0.001000\n","2020-11-28 03:40:01,244 - __main__ - INFO - Epoch  14 Step:     4200 Batch Loss:     0.001017 [Torso :     0.000619, Hand :     0.001402, Face :     0.000685]Tokens per Sec:  6258380, Lr: 0.001000\n","2020-11-28 03:40:01,246 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 03:45:47,933 - __main__ - INFO - Validation result at epoch  14, step     4200: Val DTW Score: 127.30, loss:   6.5179,  duration: 346.6856s\n","2020-11-28 03:46:03,775 - __main__ - INFO - Epoch  14 Step:     4240 Batch Loss:     0.000954 [Torso :     0.000639, Hand :     0.001276, Face :     0.000598]Tokens per Sec:  5557475, Lr: 0.001000\n","2020-11-28 03:46:18,105 - __main__ - INFO - Epoch  14 Step:     4280 Batch Loss:     0.000796 [Torso :     0.000572, Hand :     0.001032, Face :     0.000506]Tokens per Sec:  6075474, Lr: 0.001000\n","2020-11-28 03:46:31,978 - __main__ - INFO - Epoch  14 Step:     4320 Batch Loss:     0.000896 [Torso :     0.000543, Hand :     0.001236, Face :     0.000606]Tokens per Sec:  6184215, Lr: 0.001000\n","2020-11-28 03:46:46,058 - __main__ - INFO - Epoch  14 Step:     4360 Batch Loss:     0.000895 [Torso :     0.000608, Hand :     0.001189, Face :     0.000572]Tokens per Sec:  6177803, Lr: 0.001000\n","2020-11-28 03:46:59,478 - __main__ - INFO - Epoch  14 Step:     4400 Batch Loss:     0.000830 [Torso :     0.000515, Hand :     0.001145, Face :     0.000517]Tokens per Sec:  6295516, Lr: 0.001000\n","2020-11-28 03:47:12,641 - __main__ - INFO - Epoch  14: total training loss 0.24720 [torso: 0.16689, hand: 0.32990, face: 0.15495\n","2020-11-28 03:47:13,321 - __main__ - INFO - Epoch  15 Step:     4440 Batch Loss:     0.000824 [Torso :     0.000586, Hand :     0.001084, Face :     0.000473]Tokens per Sec:  6067363, Lr: 0.001000\n","2020-11-28 03:47:26,868 - __main__ - INFO - Epoch  15 Step:     4480 Batch Loss:     0.000614 [Torso :     0.000411, Hand :     0.000825, Face :     0.000374]Tokens per Sec:  6242088, Lr: 0.001000\n","2020-11-28 03:47:33,892 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 03:53:22,277 - __main__ - INFO - Validation result at epoch  15, step     4500: Val DTW Score: 118.61, loss:   5.8393,  duration: 348.3831s\n","2020-11-28 03:53:28,898 - __main__ - INFO - Epoch  15 Step:     4520 Batch Loss:     0.001107 [Torso :     0.000737, Hand :     0.001489, Face :     0.000678]Tokens per Sec:  6201900, Lr: 0.000700\n","2020-11-28 03:53:44,416 - __main__ - INFO - Epoch  15 Step:     4560 Batch Loss:     0.000782 [Torso :     0.000491, Hand :     0.001061, Face :     0.000548]Tokens per Sec:  5546035, Lr: 0.000700\n","2020-11-28 03:53:58,595 - __main__ - INFO - Epoch  15 Step:     4600 Batch Loss:     0.000827 [Torso :     0.000606, Hand :     0.001070, Face :     0.000494]Tokens per Sec:  6153695, Lr: 0.000700\n","2020-11-28 03:54:11,442 - __main__ - INFO - Epoch  15 Step:     4640 Batch Loss:     0.000762 [Torso :     0.000548, Hand :     0.000991, Face :     0.000478]Tokens per Sec:  6381719, Lr: 0.000700\n","2020-11-28 03:54:26,475 - __main__ - INFO - Epoch  15 Step:     4680 Batch Loss:     0.000547 [Torso :     0.000338, Hand :     0.000756, Face :     0.000333]Tokens per Sec:  6000873, Lr: 0.000700\n","2020-11-28 03:54:40,823 - __main__ - INFO - Epoch  15 Step:     4720 Batch Loss:     0.000707 [Torso :     0.000458, Hand :     0.000962, Face :     0.000432]Tokens per Sec:  6129180, Lr: 0.000700\n","2020-11-28 03:54:52,283 - __main__ - INFO - Epoch  15: total training loss 0.24459 [torso: 0.16417, hand: 0.32722, face: 0.15315\n","2020-11-28 03:54:54,008 - __main__ - INFO - Epoch  16 Step:     4760 Batch Loss:     0.000688 [Torso :     0.000460, Hand :     0.000924, Face :     0.000416]Tokens per Sec:  6092733, Lr: 0.000700\n","2020-11-28 03:55:08,115 - __main__ - INFO - Epoch  16 Step:     4800 Batch Loss:     0.000698 [Torso :     0.000466, Hand :     0.000938, Face :     0.000421]Tokens per Sec:  6092167, Lr: 0.000700\n","2020-11-28 03:55:08,117 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 04:00:51,074 - __main__ - INFO - Validation result at epoch  16, step     4800: Val DTW Score: 112.62, loss:   5.9554,  duration: 342.9557s\n","2020-11-28 04:01:06,331 - __main__ - INFO - Epoch  16 Step:     4840 Batch Loss:     0.000583 [Torso :     0.000362, Hand :     0.000802, Face :     0.000372]Tokens per Sec:  5694783, Lr: 0.000700\n","2020-11-28 04:01:20,369 - __main__ - INFO - Epoch  16 Step:     4880 Batch Loss:     0.000767 [Torso :     0.000454, Hand :     0.001065, Face :     0.000526]Tokens per Sec:  5974728, Lr: 0.000700\n","2020-11-28 04:01:34,016 - __main__ - INFO - Epoch  16 Step:     4920 Batch Loss:     0.000842 [Torso :     0.000587, Hand :     0.001108, Face :     0.000533]Tokens per Sec:  6258470, Lr: 0.000700\n","2020-11-28 04:01:48,267 - __main__ - INFO - Epoch  16 Step:     4960 Batch Loss:     0.000612 [Torso :     0.000433, Hand :     0.000798, Face :     0.000391]Tokens per Sec:  6235684, Lr: 0.000700\n","2020-11-28 04:02:01,851 - __main__ - INFO - Epoch  16 Step:     5000 Batch Loss:     0.000714 [Torso :     0.000498, Hand :     0.000944, Face :     0.000424]Tokens per Sec:  6312638, Lr: 0.000700\n","2020-11-28 04:02:16,087 - __main__ - INFO - Epoch  16 Step:     5040 Batch Loss:     0.000837 [Torso :     0.000603, Hand :     0.001091, Face :     0.000507]Tokens per Sec:  6177669, Lr: 0.000700\n","2020-11-28 04:02:27,670 - __main__ - INFO - Epoch  16: total training loss 0.23367 [torso: 0.15651, hand: 0.31276, face: 0.14683\n","2020-11-28 04:02:30,184 - __main__ - INFO - Epoch  17 Step:     5080 Batch Loss:     0.000816 [Torso :     0.000618, Hand :     0.001034, Face :     0.000512]Tokens per Sec:  6393044, Lr: 0.000700\n","2020-11-28 04:02:37,273 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 04:08:18,438 - __main__ - INFO - Validation result at epoch  17, step     5100: Val DTW Score: 106.25, loss:   5.4727,  duration: 341.1635s\n","2020-11-28 04:08:25,964 - __main__ - INFO - Epoch  17 Step:     5120 Batch Loss:     0.000864 [Torso :     0.000531, Hand :     0.001187, Face :     0.000579]Tokens per Sec:  6048595, Lr: 0.000700\n","2020-11-28 04:08:40,707 - __main__ - INFO - Epoch  17 Step:     5160 Batch Loss:     0.001012 [Torso :     0.000758, Hand :     0.001297, Face :     0.000605]Tokens per Sec:  5602872, Lr: 0.000700\n","2020-11-28 04:08:54,752 - __main__ - INFO - Epoch  17 Step:     5200 Batch Loss:     0.000720 [Torso :     0.000400, Hand :     0.001018, Face :     0.000513]Tokens per Sec:  6256007, Lr: 0.000700\n","2020-11-28 04:09:09,386 - __main__ - INFO - Epoch  17 Step:     5240 Batch Loss:     0.000921 [Torso :     0.000663, Hand :     0.001200, Face :     0.000554]Tokens per Sec:  6140995, Lr: 0.000700\n","2020-11-28 04:09:22,459 - __main__ - INFO - Epoch  17 Step:     5280 Batch Loss:     0.000646 [Torso :     0.000405, Hand :     0.000887, Face :     0.000400]Tokens per Sec:  6382878, Lr: 0.000700\n","2020-11-28 04:09:36,835 - __main__ - INFO - Epoch  17 Step:     5320 Batch Loss:     0.000829 [Torso :     0.000490, Hand :     0.001156, Face :     0.000550]Tokens per Sec:  6186857, Lr: 0.000700\n","2020-11-28 04:09:50,717 - __main__ - INFO - Epoch  17 Step:     5360 Batch Loss:     0.000570 [Torso :     0.000353, Hand :     0.000785, Face :     0.000365]Tokens per Sec:  6193902, Lr: 0.000700\n","2020-11-28 04:10:00,381 - __main__ - INFO - Epoch  17: total training loss 0.23336 [torso: 0.15622, hand: 0.31252, face: 0.14614\n","2020-11-28 04:10:04,348 - __main__ - INFO - Epoch  18 Step:     5400 Batch Loss:     0.000662 [Torso :     0.000426, Hand :     0.000906, Face :     0.000391]Tokens per Sec:  5980574, Lr: 0.000700\n","2020-11-28 04:10:04,350 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 04:15:46,856 - __main__ - INFO - Validation result at epoch  18, step     5400: Val DTW Score: 110.86, loss:   5.9024,  duration: 342.5049s\n","2020-11-28 04:16:01,845 - __main__ - INFO - Epoch  18 Step:     5440 Batch Loss:     0.000639 [Torso :     0.000442, Hand :     0.000843, Face :     0.000408]Tokens per Sec:  5686499, Lr: 0.000700\n","2020-11-28 04:16:16,606 - __main__ - INFO - Epoch  18 Step:     5480 Batch Loss:     0.000730 [Torso :     0.000560, Hand :     0.000928, Face :     0.000419]Tokens per Sec:  5827740, Lr: 0.000700\n","2020-11-28 04:16:29,673 - __main__ - INFO - Epoch  18 Step:     5520 Batch Loss:     0.000898 [Torso :     0.000632, Hand :     0.001179, Face :     0.000556]Tokens per Sec:  6344532, Lr: 0.000700\n","2020-11-28 04:16:43,759 - __main__ - INFO - Epoch  18 Step:     5560 Batch Loss:     0.000729 [Torso :     0.000511, Hand :     0.000965, Face :     0.000424]Tokens per Sec:  6216429, Lr: 0.000700\n","2020-11-28 04:16:57,658 - __main__ - INFO - Epoch  18 Step:     5600 Batch Loss:     0.000728 [Torso :     0.000434, Hand :     0.001010, Face :     0.000496]Tokens per Sec:  6268933, Lr: 0.000700\n","2020-11-28 04:17:11,923 - __main__ - INFO - Epoch  18 Step:     5640 Batch Loss:     0.000708 [Torso :     0.000441, Hand :     0.000977, Face :     0.000432]Tokens per Sec:  6197413, Lr: 0.000700\n","2020-11-28 04:17:25,740 - __main__ - INFO - Epoch  18 Step:     5680 Batch Loss:     0.001086 [Torso :     0.000736, Hand :     0.001448, Face :     0.000679]Tokens per Sec:  6276000, Lr: 0.000700\n","2020-11-28 04:17:32,457 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 04:23:13,320 - __main__ - INFO - Validation result at epoch  18, step     5700: Val DTW Score: 110.58, loss:   5.8889,  duration: 340.8613s\n","2020-11-28 04:23:15,247 - __main__ - INFO - Epoch  18: total training loss 0.23425 [torso: 0.15669, hand: 0.31391, face: 0.14622\n","2020-11-28 04:23:20,243 - __main__ - INFO - Epoch  19 Step:     5720 Batch Loss:     0.000773 [Torso :     0.000525, Hand :     0.001026, Face :     0.000496]Tokens per Sec:  6056441, Lr: 0.000700\n","2020-11-28 04:23:36,303 - __main__ - INFO - Epoch  19 Step:     5760 Batch Loss:     0.000825 [Torso :     0.000533, Hand :     0.001117, Face :     0.000533]Tokens per Sec:  5373211, Lr: 0.000700\n","2020-11-28 04:23:50,421 - __main__ - INFO - Epoch  19 Step:     5800 Batch Loss:     0.000694 [Torso :     0.000408, Hand :     0.000973, Face :     0.000444]Tokens per Sec:  6215582, Lr: 0.000700\n","2020-11-28 04:24:03,376 - __main__ - INFO - Epoch  19 Step:     5840 Batch Loss:     0.000777 [Torso :     0.000495, Hand :     0.001060, Face :     0.000493]Tokens per Sec:  6349173, Lr: 0.000700\n","2020-11-28 04:24:16,914 - __main__ - INFO - Epoch  19 Step:     5880 Batch Loss:     0.000631 [Torso :     0.000466, Hand :     0.000808, Face :     0.000410]Tokens per Sec:  6254807, Lr: 0.000700\n","2020-11-28 04:24:30,542 - __main__ - INFO - Epoch  19 Step:     5920 Batch Loss:     0.000767 [Torso :     0.000510, Hand :     0.001031, Face :     0.000478]Tokens per Sec:  6290014, Lr: 0.000700\n","2020-11-28 04:24:44,719 - __main__ - INFO - Epoch  19 Step:     5960 Batch Loss:     0.000665 [Torso :     0.000423, Hand :     0.000905, Face :     0.000429]Tokens per Sec:  6118806, Lr: 0.000700\n","2020-11-28 04:24:58,811 - __main__ - INFO - Epoch  19 Step:     6000 Batch Loss:     0.000883 [Torso :     0.000500, Hand :     0.001254, Face :     0.000556]Tokens per Sec:  6169959, Lr: 0.000700\n","2020-11-28 04:24:58,812 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 04:30:42,033 - __main__ - INFO - Validation result at epoch  19, step     6000: Val DTW Score: 105.87, loss:   5.3130,  duration: 343.2198s\n","2020-11-28 04:30:51,714 - __main__ - INFO - Epoch  19: total training loss 0.23539 [torso: 0.15713, hand: 0.31585, face: 0.14617\n","2020-11-28 04:30:58,603 - __main__ - INFO - Epoch  20 Step:     6040 Batch Loss:     0.000715 [Torso :     0.000501, Hand :     0.000941, Face :     0.000439]Tokens per Sec:  5162902, Lr: 0.000700\n","2020-11-28 04:31:12,181 - __main__ - INFO - Epoch  20 Step:     6080 Batch Loss:     0.000913 [Torso :     0.000556, Hand :     0.001251, Face :     0.000652]Tokens per Sec:  6235879, Lr: 0.000700\n","2020-11-28 04:31:26,283 - __main__ - INFO - Epoch  20 Step:     6120 Batch Loss:     0.000626 [Torso :     0.000405, Hand :     0.000850, Face :     0.000393]Tokens per Sec:  6209220, Lr: 0.000700\n","2020-11-28 04:31:40,080 - __main__ - INFO - Epoch  20 Step:     6160 Batch Loss:     0.000663 [Torso :     0.000470, Hand :     0.000867, Face :     0.000411]Tokens per Sec:  6243339, Lr: 0.000700\n","2020-11-28 04:31:54,155 - __main__ - INFO - Epoch  20 Step:     6200 Batch Loss:     0.000623 [Torso :     0.000467, Hand :     0.000801, Face :     0.000350]Tokens per Sec:  6223485, Lr: 0.000700\n","2020-11-28 04:32:07,781 - __main__ - INFO - Epoch  20 Step:     6240 Batch Loss:     0.000710 [Torso :     0.000545, Hand :     0.000902, Face :     0.000417]Tokens per Sec:  6185871, Lr: 0.000700\n","2020-11-28 04:32:21,936 - __main__ - INFO - Epoch  20 Step:     6280 Batch Loss:     0.000722 [Torso :     0.000544, Hand :     0.000924, Face :     0.000421]Tokens per Sec:  6186024, Lr: 0.000700\n","2020-11-28 04:32:28,953 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 04:38:08,548 - __main__ - INFO - Validation result at epoch  20, step     6300: Val DTW Score: 104.53, loss:   5.2751,  duration: 339.5935s\n","2020-11-28 04:38:16,270 - __main__ - INFO - Epoch  20 Step:     6320 Batch Loss:     0.000671 [Torso :     0.000458, Hand :     0.000895, Face :     0.000409]Tokens per Sec:  5908590, Lr: 0.000700\n","2020-11-28 04:38:25,040 - __main__ - INFO - Epoch  20: total training loss 0.23147 [torso: 0.15532, hand: 0.30992, face: 0.14381\n","2020-11-28 04:38:32,621 - __main__ - INFO - Epoch  21 Step:     6360 Batch Loss:     0.000911 [Torso :     0.000553, Hand :     0.001248, Face :     0.000652]Tokens per Sec:  6065412, Lr: 0.000700\n","2020-11-28 04:38:47,265 - __main__ - INFO - Epoch  21 Step:     6400 Batch Loss:     0.000682 [Torso :     0.000413, Hand :     0.000947, Face :     0.000429]Tokens per Sec:  6036709, Lr: 0.000700\n","2020-11-28 04:39:01,336 - __main__ - INFO - Epoch  21 Step:     6440 Batch Loss:     0.000734 [Torso :     0.000458, Hand :     0.001001, Face :     0.000499]Tokens per Sec:  6138082, Lr: 0.000700\n","2020-11-28 04:39:15,332 - __main__ - INFO - Epoch  21 Step:     6480 Batch Loss:     0.000860 [Torso :     0.000473, Hand :     0.001233, Face :     0.000535]Tokens per Sec:  6168473, Lr: 0.000700\n","2020-11-28 04:39:29,232 - __main__ - INFO - Epoch  21 Step:     6520 Batch Loss:     0.000674 [Torso :     0.000490, Hand :     0.000877, Face :     0.000399]Tokens per Sec:  6229770, Lr: 0.000700\n","2020-11-28 04:39:43,106 - __main__ - INFO - Epoch  21 Step:     6560 Batch Loss:     0.000790 [Torso :     0.000516, Hand :     0.001058, Face :     0.000543]Tokens per Sec:  6200480, Lr: 0.000700\n","2020-11-28 04:39:57,738 - __main__ - INFO - Epoch  21 Step:     6600 Batch Loss:     0.000769 [Torso :     0.000502, Hand :     0.001039, Face :     0.000489]Tokens per Sec:  6096900, Lr: 0.000700\n","2020-11-28 04:39:57,740 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 04:45:40,051 - __main__ - INFO - Validation result at epoch  21, step     6600: Val DTW Score: 104.83, loss:   5.0541,  duration: 342.3105s\n","2020-11-28 04:45:54,907 - __main__ - INFO - Epoch  21 Step:     6640 Batch Loss:     0.000618 [Torso :     0.000389, Hand :     0.000844, Face :     0.000405]Tokens per Sec:  5745351, Lr: 0.000700\n","2020-11-28 04:46:01,235 - __main__ - INFO - Epoch  21: total training loss 0.22980 [torso: 0.15332, hand: 0.30846, face: 0.14247\n","2020-11-28 04:46:09,128 - __main__ - INFO - Epoch  22 Step:     6680 Batch Loss:     0.000918 [Torso :     0.000576, Hand :     0.001255, Face :     0.000597]Tokens per Sec:  6224584, Lr: 0.000700\n","2020-11-28 04:46:22,547 - __main__ - INFO - Epoch  22 Step:     6720 Batch Loss:     0.000663 [Torso :     0.000494, Hand :     0.000850, Face :     0.000399]Tokens per Sec:  6278508, Lr: 0.000700\n","2020-11-28 04:46:37,509 - __main__ - INFO - Epoch  22 Step:     6760 Batch Loss:     0.000740 [Torso :     0.000503, Hand :     0.000986, Face :     0.000460]Tokens per Sec:  6101460, Lr: 0.000700\n","2020-11-28 04:46:51,235 - __main__ - INFO - Epoch  22 Step:     6800 Batch Loss:     0.000754 [Torso :     0.000488, Hand :     0.001023, Face :     0.000475]Tokens per Sec:  6205365, Lr: 0.000700\n","2020-11-28 04:47:04,986 - __main__ - INFO - Epoch  22 Step:     6840 Batch Loss:     0.000594 [Torso :     0.000405, Hand :     0.000793, Face :     0.000357]Tokens per Sec:  6218978, Lr: 0.000700\n","2020-11-28 04:47:19,401 - __main__ - INFO - Epoch  22 Step:     6880 Batch Loss:     0.000919 [Torso :     0.000598, Hand :     0.001242, Face :     0.000582]Tokens per Sec:  6106751, Lr: 0.000700\n","2020-11-28 04:47:26,811 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 04:53:09,337 - __main__ - INFO - Validation result at epoch  22, step     6900: Val DTW Score: 119.17, loss:   6.3158,  duration: 342.5247s\n","2020-11-28 04:53:16,938 - __main__ - INFO - Epoch  22 Step:     6920 Batch Loss:     0.000672 [Torso :     0.000459, Hand :     0.000902, Face :     0.000375]Tokens per Sec:  5955672, Lr: 0.000490\n","2020-11-28 04:53:31,558 - __main__ - INFO - Epoch  22 Step:     6960 Batch Loss:     0.000864 [Torso :     0.000585, Hand :     0.001159, Face :     0.000509]Tokens per Sec:  5723798, Lr: 0.000490\n","2020-11-28 04:53:36,524 - __main__ - INFO - Epoch  22: total training loss 0.22853 [torso: 0.15188, hand: 0.30726, face: 0.14154\n","2020-11-28 04:53:45,557 - __main__ - INFO - Epoch  23 Step:     7000 Batch Loss:     0.000853 [Torso :     0.000564, Hand :     0.001155, Face :     0.000503]Tokens per Sec:  6192477, Lr: 0.000490\n","2020-11-28 04:53:59,362 - __main__ - INFO - Epoch  23 Step:     7040 Batch Loss:     0.000562 [Torso :     0.000416, Hand :     0.000721, Face :     0.000356]Tokens per Sec:  6203246, Lr: 0.000490\n","2020-11-28 04:54:13,664 - __main__ - INFO - Epoch  23 Step:     7080 Batch Loss:     0.000868 [Torso :     0.000585, Hand :     0.001154, Face :     0.000568]Tokens per Sec:  6092572, Lr: 0.000490\n","2020-11-28 04:54:27,196 - __main__ - INFO - Epoch  23 Step:     7120 Batch Loss:     0.000584 [Torso :     0.000370, Hand :     0.000801, Face :     0.000362]Tokens per Sec:  6266311, Lr: 0.000490\n","2020-11-28 04:54:41,251 - __main__ - INFO - Epoch  23 Step:     7160 Batch Loss:     0.000644 [Torso :     0.000425, Hand :     0.000866, Face :     0.000412]Tokens per Sec:  6122877, Lr: 0.000490\n","2020-11-28 04:54:54,945 - __main__ - INFO - Epoch  23 Step:     7200 Batch Loss:     0.000842 [Torso :     0.000546, Hand :     0.001137, Face :     0.000545]Tokens per Sec:  6234104, Lr: 0.000490\n","2020-11-28 04:54:54,947 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 05:00:35,617 - __main__ - INFO - Validation result at epoch  23, step     7200: Val DTW Score: 108.30, loss:   5.3800,  duration: 340.6685s\n","2020-11-28 05:00:51,585 - __main__ - INFO - Epoch  23 Step:     7240 Batch Loss:     0.000608 [Torso :     0.000355, Hand :     0.000849, Face :     0.000410]Tokens per Sec:  5443711, Lr: 0.000490\n","2020-11-28 05:01:06,205 - __main__ - INFO - Epoch  23 Step:     7280 Batch Loss:     0.000899 [Torso :     0.000636, Hand :     0.001187, Face :     0.000505]Tokens per Sec:  5983693, Lr: 0.000490\n","2020-11-28 05:01:10,318 - __main__ - INFO - Epoch  23: total training loss 0.22432 [torso: 0.14812, hand: 0.30231, face: 0.13910\n","2020-11-28 05:01:20,480 - __main__ - INFO - Epoch  24 Step:     7320 Batch Loss:     0.000686 [Torso :     0.000425, Hand :     0.000943, Face :     0.000444]Tokens per Sec:  6143518, Lr: 0.000490\n","2020-11-28 05:01:34,473 - __main__ - INFO - Epoch  24 Step:     7360 Batch Loss:     0.000512 [Torso :     0.000348, Hand :     0.000686, Face :     0.000296]Tokens per Sec:  6155436, Lr: 0.000490\n","2020-11-28 05:01:48,278 - __main__ - INFO - Epoch  24 Step:     7400 Batch Loss:     0.000854 [Torso :     0.000551, Hand :     0.001162, Face :     0.000523]Tokens per Sec:  6095068, Lr: 0.000490\n","2020-11-28 05:02:02,324 - __main__ - INFO - Epoch  24 Step:     7440 Batch Loss:     0.000539 [Torso :     0.000421, Hand :     0.000675, Face :     0.000324]Tokens per Sec:  6135297, Lr: 0.000490\n","2020-11-28 05:02:16,826 - __main__ - INFO - Epoch  24 Step:     7480 Batch Loss:     0.000661 [Torso :     0.000395, Hand :     0.000922, Face :     0.000421]Tokens per Sec:  6124952, Lr: 0.000490\n","2020-11-28 05:02:24,915 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 05:08:04,099 - __main__ - INFO - Validation result at epoch  24, step     7500: Val DTW Score: 103.55, loss:   5.0501,  duration: 339.1825s\n","2020-11-28 05:08:10,722 - __main__ - INFO - Epoch  24 Step:     7520 Batch Loss:     0.000779 [Torso :     0.000464, Hand :     0.001088, Face :     0.000498]Tokens per Sec:  6055516, Lr: 0.000490\n","2020-11-28 05:08:26,909 - __main__ - INFO - Epoch  24 Step:     7560 Batch Loss:     0.000838 [Torso :     0.000547, Hand :     0.001130, Face :     0.000544]Tokens per Sec:  5364329, Lr: 0.000490\n","2020-11-28 05:08:40,445 - __main__ - INFO - Epoch  24 Step:     7600 Batch Loss:     0.000822 [Torso :     0.000563, Hand :     0.001098, Face :     0.000478]Tokens per Sec:  6186152, Lr: 0.000490\n","2020-11-28 05:08:43,818 - __main__ - INFO - Epoch  24: total training loss 0.22049 [torso: 0.14513, hand: 0.29755, face: 0.13667\n","2020-11-28 05:08:54,868 - __main__ - INFO - Epoch  25 Step:     7640 Batch Loss:     0.000601 [Torso :     0.000392, Hand :     0.000815, Face :     0.000369]Tokens per Sec:  6153921, Lr: 0.000490\n","2020-11-28 05:09:08,674 - __main__ - INFO - Epoch  25 Step:     7680 Batch Loss:     0.000499 [Torso :     0.000304, Hand :     0.000684, Face :     0.000350]Tokens per Sec:  6222227, Lr: 0.000490\n","2020-11-28 05:09:23,451 - __main__ - INFO - Epoch  25 Step:     7720 Batch Loss:     0.000634 [Torso :     0.000485, Hand :     0.000808, Face :     0.000364]Tokens per Sec:  6066051, Lr: 0.000490\n","2020-11-28 05:09:37,384 - __main__ - INFO - Epoch  25 Step:     7760 Batch Loss:     0.000680 [Torso :     0.000433, Hand :     0.000930, Face :     0.000415]Tokens per Sec:  6182195, Lr: 0.000490\n","2020-11-28 05:09:51,509 - __main__ - INFO - Epoch  25 Step:     7800 Batch Loss:     0.000630 [Torso :     0.000539, Hand :     0.000758, Face :     0.000356]Tokens per Sec:  6041008, Lr: 0.000490\n","2020-11-28 05:09:51,511 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 05:15:29,402 - __main__ - INFO - Validation result at epoch  25, step     7800: Val DTW Score: 111.08, loss:   5.4106,  duration: 337.8895s\n","2020-11-28 05:15:44,282 - __main__ - INFO - Epoch  25 Step:     7840 Batch Loss:     0.000667 [Torso :     0.000416, Hand :     0.000915, Face :     0.000435]Tokens per Sec:  5846739, Lr: 0.000490\n","2020-11-28 05:15:59,264 - __main__ - INFO - Epoch  25 Step:     7880 Batch Loss:     0.000624 [Torso :     0.000409, Hand :     0.000837, Face :     0.000419]Tokens per Sec:  5849724, Lr: 0.000490\n","2020-11-28 05:16:12,427 - __main__ - INFO - Epoch  25 Step:     7920 Batch Loss:     0.000745 [Torso :     0.000479, Hand :     0.001006, Face :     0.000507]Tokens per Sec:  6324852, Lr: 0.000490\n","2020-11-28 05:16:14,373 - __main__ - INFO - Epoch  25: total training loss 0.22217 [torso: 0.14689, hand: 0.29928, face: 0.13770\n","2020-11-28 05:16:27,118 - __main__ - INFO - Epoch  26 Step:     7960 Batch Loss:     0.000492 [Torso :     0.000338, Hand :     0.000651, Face :     0.000312]Tokens per Sec:  6131109, Lr: 0.000490\n","2020-11-28 05:16:40,828 - __main__ - INFO - Epoch  26 Step:     8000 Batch Loss:     0.000711 [Torso :     0.000447, Hand :     0.000976, Face :     0.000442]Tokens per Sec:  6232513, Lr: 0.000490\n","2020-11-28 05:16:53,920 - __main__ - INFO - Epoch  26 Step:     8040 Batch Loss:     0.000807 [Torso :     0.000514, Hand :     0.001102, Face :     0.000501]Tokens per Sec:  6233008, Lr: 0.000490\n","2020-11-28 05:17:07,931 - __main__ - INFO - Epoch  26 Step:     8080 Batch Loss:     0.000744 [Torso :     0.000502, Hand :     0.000997, Face :     0.000449]Tokens per Sec:  6150641, Lr: 0.000490\n","2020-11-28 05:17:15,087 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 05:22:53,119 - __main__ - INFO - Validation result at epoch  26, step     8100: Val DTW Score: 110.37, loss:   5.9919,  duration: 338.0312s\n","2020-11-28 05:23:01,037 - __main__ - INFO - Epoch  26 Step:     8120 Batch Loss:     0.000793 [Torso :     0.000565, Hand :     0.001039, Face :     0.000473]Tokens per Sec:  5866872, Lr: 0.000490\n","2020-11-28 05:23:16,090 - __main__ - INFO - Epoch  26 Step:     8160 Batch Loss:     0.000676 [Torso :     0.000410, Hand :     0.000939, Face :     0.000422]Tokens per Sec:  5676784, Lr: 0.000490\n","2020-11-28 05:23:30,249 - __main__ - INFO - Epoch  26 Step:     8200 Batch Loss:     0.000813 [Torso :     0.000580, Hand :     0.001061, Face :     0.000501]Tokens per Sec:  6170347, Lr: 0.000490\n","2020-11-28 05:23:45,005 - __main__ - INFO - Epoch  26 Step:     8240 Batch Loss:     0.000533 [Torso :     0.000348, Hand :     0.000719, Face :     0.000344]Tokens per Sec:  6075087, Lr: 0.000490\n","2020-11-28 05:23:45,656 - __main__ - INFO - Epoch  26: total training loss 0.22102 [torso: 0.14594, hand: 0.29803, face: 0.13637\n","2020-11-28 05:23:59,776 - __main__ - INFO - Epoch  27 Step:     8280 Batch Loss:     0.000752 [Torso :     0.000545, Hand :     0.000981, Face :     0.000434]Tokens per Sec:  6070643, Lr: 0.000490\n","2020-11-28 05:24:13,800 - __main__ - INFO - Epoch  27 Step:     8320 Batch Loss:     0.000696 [Torso :     0.000436, Hand :     0.000952, Face :     0.000454]Tokens per Sec:  6229826, Lr: 0.000490\n","2020-11-28 05:24:27,306 - __main__ - INFO - Epoch  27 Step:     8360 Batch Loss:     0.000575 [Torso :     0.000360, Hand :     0.000790, Face :     0.000357]Tokens per Sec:  6221217, Lr: 0.000490\n","2020-11-28 05:24:41,046 - __main__ - INFO - Epoch  27 Step:     8400 Batch Loss:     0.000397 [Torso :     0.000260, Hand :     0.000538, Face :     0.000238]Tokens per Sec:  6173740, Lr: 0.000490\n","2020-11-28 05:24:41,048 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 05:30:20,301 - __main__ - INFO - Validation result at epoch  27, step     8400: Val DTW Score: 110.97, loss:   5.3504,  duration: 339.2515s\n","2020-11-28 05:30:35,175 - __main__ - INFO - Epoch  27 Step:     8440 Batch Loss:     0.000618 [Torso :     0.000430, Hand :     0.000820, Face :     0.000362]Tokens per Sec:  5781936, Lr: 0.000490\n","2020-11-28 05:30:49,945 - __main__ - INFO - Epoch  27 Step:     8480 Batch Loss:     0.000515 [Torso :     0.000338, Hand :     0.000695, Face :     0.000324]Tokens per Sec:  5881981, Lr: 0.000490\n","2020-11-28 05:31:02,689 - __main__ - INFO - Epoch  27 Step:     8520 Batch Loss:     0.000867 [Torso :     0.000500, Hand :     0.001215, Face :     0.000595]Tokens per Sec:  6451767, Lr: 0.000490\n","2020-11-28 05:31:16,594 - __main__ - INFO - Epoch  27: total training loss 0.22190 [torso: 0.14594, hand: 0.29971, face: 0.13668\n","2020-11-28 05:31:17,097 - __main__ - INFO - Epoch  28 Step:     8560 Batch Loss:     0.000605 [Torso :     0.000417, Hand :     0.000806, Face :     0.000354]Tokens per Sec:  5074536, Lr: 0.000490\n","2020-11-28 05:31:31,718 - __main__ - INFO - Epoch  28 Step:     8600 Batch Loss:     0.000583 [Torso :     0.000352, Hand :     0.000812, Face :     0.000361]Tokens per Sec:  6167648, Lr: 0.000490\n","2020-11-28 05:31:45,876 - __main__ - INFO - Epoch  28 Step:     8640 Batch Loss:     0.000665 [Torso :     0.000441, Hand :     0.000900, Face :     0.000387]Tokens per Sec:  6159936, Lr: 0.000490\n","2020-11-28 05:31:58,773 - __main__ - INFO - Epoch  28 Step:     8680 Batch Loss:     0.000774 [Torso :     0.000496, Hand :     0.001056, Face :     0.000480]Tokens per Sec:  6341928, Lr: 0.000490\n","2020-11-28 05:32:05,549 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 05:37:37,957 - __main__ - INFO - Validation result at epoch  28, step     8700: Val DTW Score: 104.49, loss:   5.1770,  duration: 332.4063s\n","2020-11-28 05:37:45,597 - __main__ - INFO - Epoch  28 Step:     8720 Batch Loss:     0.000793 [Torso :     0.000480, Hand :     0.001099, Face :     0.000513]Tokens per Sec:  6129292, Lr: 0.000490\n","2020-11-28 05:38:01,820 - __main__ - INFO - Epoch  28 Step:     8760 Batch Loss:     0.000549 [Torso :     0.000325, Hand :     0.000768, Face :     0.000351]Tokens per Sec:  5489267, Lr: 0.000490\n","2020-11-28 05:38:16,357 - __main__ - INFO - Epoch  28 Step:     8800 Batch Loss:     0.000758 [Torso :     0.000506, Hand :     0.001021, Face :     0.000452]Tokens per Sec:  6189886, Lr: 0.000490\n","2020-11-28 05:38:29,467 - __main__ - INFO - Epoch  28 Step:     8840 Batch Loss:     0.000621 [Torso :     0.000459, Hand :     0.000800, Face :     0.000366]Tokens per Sec:  6353256, Lr: 0.000490\n","2020-11-28 05:38:41,209 - __main__ - INFO - Epoch  28: total training loss 0.21936 [torso: 0.14499, hand: 0.29571, face: 0.13508\n","2020-11-28 05:38:42,756 - __main__ - INFO - Epoch  29 Step:     8880 Batch Loss:     0.000597 [Torso :     0.000440, Hand :     0.000775, Face :     0.000336]Tokens per Sec:  5872841, Lr: 0.000490\n","2020-11-28 05:38:56,118 - __main__ - INFO - Epoch  29 Step:     8920 Batch Loss:     0.000800 [Torso :     0.000569, Hand :     0.001045, Face :     0.000496]Tokens per Sec:  6319929, Lr: 0.000490\n","2020-11-28 05:39:10,163 - __main__ - INFO - Epoch  29 Step:     8960 Batch Loss:     0.000647 [Torso :     0.000368, Hand :     0.000915, Face :     0.000419]Tokens per Sec:  6228801, Lr: 0.000490\n","2020-11-28 05:39:24,085 - __main__ - INFO - Epoch  29 Step:     9000 Batch Loss:     0.000842 [Torso :     0.000528, Hand :     0.001146, Face :     0.000578]Tokens per Sec:  6187158, Lr: 0.000490\n","2020-11-28 05:39:24,087 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 05:44:56,650 - __main__ - INFO - Validation result at epoch  29, step     9000: Val DTW Score: 107.20, loss:   5.1793,  duration: 332.5620s\n","2020-11-28 05:45:11,176 - __main__ - INFO - Epoch  29 Step:     9040 Batch Loss:     0.000757 [Torso :     0.000441, Hand :     0.001066, Face :     0.000478]Tokens per Sec:  5849296, Lr: 0.000490\n","2020-11-28 05:45:25,985 - __main__ - INFO - Epoch  29 Step:     9080 Batch Loss:     0.000733 [Torso :     0.000474, Hand :     0.000991, Face :     0.000471]Tokens per Sec:  5792877, Lr: 0.000490\n","2020-11-28 05:45:40,133 - __main__ - INFO - Epoch  29 Step:     9120 Batch Loss:     0.000719 [Torso :     0.000433, Hand :     0.000998, Face :     0.000471]Tokens per Sec:  6207957, Lr: 0.000490\n","2020-11-28 05:45:53,714 - __main__ - INFO - Epoch  29 Step:     9160 Batch Loss:     0.000706 [Torso :     0.000565, Hand :     0.000875, Face :     0.000426]Tokens per Sec:  6158403, Lr: 0.000490\n","2020-11-28 05:46:05,246 - __main__ - INFO - Epoch  29: total training loss 0.22253 [torso: 0.14620, hand: 0.30067, face: 0.13711\n","2020-11-28 05:46:07,596 - __main__ - INFO - Epoch  30 Step:     9200 Batch Loss:     0.000581 [Torso :     0.000346, Hand :     0.000809, Face :     0.000381]Tokens per Sec:  6303362, Lr: 0.000490\n","2020-11-28 05:46:22,147 - __main__ - INFO - Epoch  30 Step:     9240 Batch Loss:     0.000694 [Torso :     0.000435, Hand :     0.000957, Face :     0.000420]Tokens per Sec:  6060005, Lr: 0.000490\n","2020-11-28 05:46:36,852 - __main__ - INFO - Epoch  30 Step:     9280 Batch Loss:     0.000790 [Torso :     0.000508, Hand :     0.001075, Face :     0.000489]Tokens per Sec:  6058841, Lr: 0.000490\n","2020-11-28 05:46:43,824 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 05:52:12,165 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 05:52:12,166 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 05:52:28,381 - __main__ - INFO - Validation result at epoch  30, step     9300: Val DTW Score: 100.45, loss:   5.5305,  duration: 344.5550s\n","2020-11-28 05:52:36,968 - __main__ - INFO - Epoch  30 Step:     9320 Batch Loss:     0.000635 [Torso :     0.000376, Hand :     0.000888, Face :     0.000404]Tokens per Sec:  5540356, Lr: 0.000490\n","2020-11-28 05:52:52,222 - __main__ - INFO - Epoch  30 Step:     9360 Batch Loss:     0.000520 [Torso :     0.000333, Hand :     0.000711, Face :     0.000317]Tokens per Sec:  5659975, Lr: 0.000490\n","2020-11-28 05:53:06,571 - __main__ - INFO - Epoch  30 Step:     9400 Batch Loss:     0.000530 [Torso :     0.000366, Hand :     0.000709, Face :     0.000296]Tokens per Sec:  6080829, Lr: 0.000490\n","2020-11-28 05:53:20,243 - __main__ - INFO - Epoch  30 Step:     9440 Batch Loss:     0.000539 [Torso :     0.000356, Hand :     0.000723, Face :     0.000352]Tokens per Sec:  6229770, Lr: 0.000490\n","2020-11-28 05:53:33,571 - __main__ - INFO - Epoch  30 Step:     9480 Batch Loss:     0.000728 [Torso :     0.000435, Hand :     0.001012, Face :     0.000487]Tokens per Sec:  6321924, Lr: 0.000490\n","2020-11-28 05:53:43,840 - __main__ - INFO - Epoch  30: total training loss 0.21937 [torso: 0.14443, hand: 0.29618, face: 0.13510\n","2020-11-28 05:53:47,328 - __main__ - INFO - Epoch  31 Step:     9520 Batch Loss:     0.000614 [Torso :     0.000437, Hand :     0.000807, Face :     0.000359]Tokens per Sec:  6096837, Lr: 0.000490\n","2020-11-28 05:54:01,318 - __main__ - INFO - Epoch  31 Step:     9560 Batch Loss:     0.000685 [Torso :     0.000462, Hand :     0.000918, Face :     0.000410]Tokens per Sec:  6190234, Lr: 0.000490\n","2020-11-28 05:54:16,943 - __main__ - INFO - Epoch  31 Step:     9600 Batch Loss:     0.000525 [Torso :     0.000316, Hand :     0.000730, Face :     0.000335]Tokens per Sec:  6021945, Lr: 0.000490\n","2020-11-28 05:54:16,945 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 05:59:42,913 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 05:59:42,916 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 05:59:57,866 - __main__ - INFO - Validation result at epoch  31, step     9600: Val DTW Score:  83.41, loss:   4.8050,  duration: 340.9203s\n","2020-11-28 06:00:14,620 - __main__ - INFO - Epoch  31 Step:     9640 Batch Loss:     0.000531 [Torso :     0.000355, Hand :     0.000719, Face :     0.000299]Tokens per Sec:  5066798, Lr: 0.000490\n","2020-11-28 06:00:28,821 - __main__ - INFO - Epoch  31 Step:     9680 Batch Loss:     0.000509 [Torso :     0.000368, Hand :     0.000661, Face :     0.000316]Tokens per Sec:  6152126, Lr: 0.000490\n","2020-11-28 06:00:42,554 - __main__ - INFO - Epoch  31 Step:     9720 Batch Loss:     0.000764 [Torso :     0.000484, Hand :     0.001050, Face :     0.000459]Tokens per Sec:  6191118, Lr: 0.000490\n","2020-11-28 06:00:56,963 - __main__ - INFO - Epoch  31 Step:     9760 Batch Loss:     0.000466 [Torso :     0.000284, Hand :     0.000647, Face :     0.000288]Tokens per Sec:  6092717, Lr: 0.000490\n","2020-11-28 06:01:09,965 - __main__ - INFO - Epoch  31 Step:     9800 Batch Loss:     0.000632 [Torso :     0.000455, Hand :     0.000822, Face :     0.000395]Tokens per Sec:  6323477, Lr: 0.000490\n","2020-11-28 06:01:18,905 - __main__ - INFO - Epoch  31: total training loss 0.21855 [torso: 0.14343, hand: 0.29556, face: 0.13398\n","2020-11-28 06:01:23,044 - __main__ - INFO - Epoch  32 Step:     9840 Batch Loss:     0.000683 [Torso :     0.000513, Hand :     0.000875, Face :     0.000398]Tokens per Sec:  6420239, Lr: 0.000490\n","2020-11-28 06:01:37,481 - __main__ - INFO - Epoch  32 Step:     9880 Batch Loss:     0.000755 [Torso :     0.000467, Hand :     0.001045, Face :     0.000461]Tokens per Sec:  6019716, Lr: 0.000490\n","2020-11-28 06:01:43,845 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 06:07:15,150 - __main__ - INFO - Validation result at epoch  32, step     9900: Val DTW Score:  95.49, loss:   5.2930,  duration: 331.3017s\n","2020-11-28 06:07:22,266 - __main__ - INFO - Epoch  32 Step:     9920 Batch Loss:     0.000762 [Torso :     0.000428, Hand :     0.001090, Face :     0.000461]Tokens per Sec:  6294803, Lr: 0.000490\n","2020-11-28 06:07:38,257 - __main__ - INFO - Epoch  32 Step:     9960 Batch Loss:     0.000563 [Torso :     0.000417, Hand :     0.000730, Face :     0.000309]Tokens per Sec:  5475494, Lr: 0.000490\n","2020-11-28 06:07:51,944 - __main__ - INFO - Epoch  32 Step:    10000 Batch Loss:     0.000700 [Torso :     0.000385, Hand :     0.001005, Face :     0.000433]Tokens per Sec:  6243812, Lr: 0.000490\n","2020-11-28 06:08:05,405 - __main__ - INFO - Epoch  32 Step:    10040 Batch Loss:     0.000558 [Torso :     0.000363, Hand :     0.000760, Face :     0.000330]Tokens per Sec:  6235954, Lr: 0.000490\n","2020-11-28 06:08:20,081 - __main__ - INFO - Epoch  32 Step:    10080 Batch Loss:     0.000562 [Torso :     0.000389, Hand :     0.000747, Face :     0.000327]Tokens per Sec:  6146997, Lr: 0.000490\n","2020-11-28 06:08:33,922 - __main__ - INFO - Epoch  32 Step:    10120 Batch Loss:     0.000510 [Torso :     0.000363, Hand :     0.000667, Face :     0.000308]Tokens per Sec:  6245470, Lr: 0.000490\n","2020-11-28 06:08:42,110 - __main__ - INFO - Epoch  32: total training loss 0.21796 [torso: 0.14309, hand: 0.29472, face: 0.13368\n","2020-11-28 06:08:47,198 - __main__ - INFO - Epoch  33 Step:    10160 Batch Loss:     0.000937 [Torso :     0.000553, Hand :     0.001308, Face :     0.000615]Tokens per Sec:  6341208, Lr: 0.000490\n","2020-11-28 06:09:00,751 - __main__ - INFO - Epoch  33 Step:    10200 Batch Loss:     0.000815 [Torso :     0.000535, Hand :     0.001098, Face :     0.000523]Tokens per Sec:  6446249, Lr: 0.000490\n","2020-11-28 06:09:00,752 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 06:14:17,535 - __main__ - INFO - Validation result at epoch  33, step    10200: Val DTW Score:  92.65, loss:   5.2707,  duration: 316.7810s\n","2020-11-28 06:14:31,979 - __main__ - INFO - Epoch  33 Step:    10240 Batch Loss:     0.000715 [Torso :     0.000525, Hand :     0.000924, Face :     0.000430]Tokens per Sec:  5898286, Lr: 0.000490\n","2020-11-28 06:14:45,689 - __main__ - INFO - Epoch  33 Step:    10280 Batch Loss:     0.000697 [Torso :     0.000434, Hand :     0.000958, Face :     0.000449]Tokens per Sec:  6277500, Lr: 0.000490\n","2020-11-28 06:14:58,431 - __main__ - INFO - Epoch  33 Step:    10320 Batch Loss:     0.000692 [Torso :     0.000428, Hand :     0.000958, Face :     0.000422]Tokens per Sec:  6606173, Lr: 0.000490\n","2020-11-28 06:15:12,290 - __main__ - INFO - Epoch  33 Step:    10360 Batch Loss:     0.000644 [Torso :     0.000382, Hand :     0.000899, Face :     0.000414]Tokens per Sec:  6434524, Lr: 0.000490\n","2020-11-28 06:15:25,620 - __main__ - INFO - Epoch  33 Step:    10400 Batch Loss:     0.000630 [Torso :     0.000354, Hand :     0.000897, Face :     0.000399]Tokens per Sec:  6467857, Lr: 0.000490\n","2020-11-28 06:15:39,363 - __main__ - INFO - Epoch  33 Step:    10440 Batch Loss:     0.000937 [Torso :     0.000546, Hand :     0.001320, Face :     0.000584]Tokens per Sec:  6477517, Lr: 0.000490\n","2020-11-28 06:15:46,076 - __main__ - INFO - Epoch  33: total training loss 0.21601 [torso: 0.14185, hand: 0.29199, face: 0.13272\n","2020-11-28 06:15:51,872 - __main__ - INFO - Epoch  34 Step:    10480 Batch Loss:     0.000788 [Torso :     0.000487, Hand :     0.001092, Face :     0.000469]Tokens per Sec:  6733096, Lr: 0.000490\n","2020-11-28 06:15:59,047 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 06:21:04,744 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 06:21:04,746 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 06:21:19,426 - __main__ - INFO - Validation result at epoch  34, step    10500: Val DTW Score:  71.96, loss:   4.9930,  duration: 320.3773s\n","2020-11-28 06:21:29,728 - __main__ - INFO - Epoch  34 Step:    10520 Batch Loss:     0.000536 [Torso :     0.000375, Hand :     0.000707, Face :     0.000319]Tokens per Sec:  5409427, Lr: 0.000490\n","2020-11-28 06:21:43,643 - __main__ - INFO - Epoch  34 Step:    10560 Batch Loss:     0.000820 [Torso :     0.000542, Hand :     0.001096, Face :     0.000558]Tokens per Sec:  6107687, Lr: 0.000490\n","2020-11-28 06:21:56,679 - __main__ - INFO - Epoch  34 Step:    10600 Batch Loss:     0.000582 [Torso :     0.000395, Hand :     0.000774, Face :     0.000371]Tokens per Sec:  6599135, Lr: 0.000490\n","2020-11-28 06:22:09,573 - __main__ - INFO - Epoch  34 Step:    10640 Batch Loss:     0.000539 [Torso :     0.000384, Hand :     0.000703, Face :     0.000334]Tokens per Sec:  6582546, Lr: 0.000490\n","2020-11-28 06:22:23,603 - __main__ - INFO - Epoch  34 Step:    10680 Batch Loss:     0.000506 [Torso :     0.000315, Hand :     0.000698, Face :     0.000315]Tokens per Sec:  6377583, Lr: 0.000490\n","2020-11-28 06:22:35,611 - __main__ - INFO - Epoch  34 Step:    10720 Batch Loss:     0.000790 [Torso :     0.000535, Hand :     0.001052, Face :     0.000494]Tokens per Sec:  6680848, Lr: 0.000490\n","2020-11-28 06:22:48,494 - __main__ - INFO - Epoch  34 Step:    10760 Batch Loss:     0.000732 [Torso :     0.000442, Hand :     0.001019, Face :     0.000454]Tokens per Sec:  6623255, Lr: 0.000490\n","2020-11-28 06:22:53,909 - __main__ - INFO - Epoch  34: total training loss 0.21680 [torso: 0.14251, hand: 0.29298, face: 0.13306\n","2020-11-28 06:23:00,947 - __main__ - INFO - Epoch  35 Step:    10800 Batch Loss:     0.000627 [Torso :     0.000434, Hand :     0.000830, Face :     0.000382]Tokens per Sec:  6598175, Lr: 0.000490\n","2020-11-28 06:23:00,948 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 06:28:09,398 - __main__ - INFO - Validation result at epoch  35, step    10800: Val DTW Score:  81.78, loss:   5.0935,  duration: 308.4487s\n","2020-11-28 06:28:23,340 - __main__ - INFO - Epoch  35 Step:    10840 Batch Loss:     0.000834 [Torso :     0.000513, Hand :     0.001154, Face :     0.000519]Tokens per Sec:  5983952, Lr: 0.000490\n","2020-11-28 06:28:37,852 - __main__ - INFO - Epoch  35 Step:    10880 Batch Loss:     0.000511 [Torso :     0.000422, Hand :     0.000624, Face :     0.000298]Tokens per Sec:  6110363, Lr: 0.000490\n","2020-11-28 06:28:50,461 - __main__ - INFO - Epoch  35 Step:    10920 Batch Loss:     0.000690 [Torso :     0.000412, Hand :     0.000962, Face :     0.000440]Tokens per Sec:  6658365, Lr: 0.000490\n","2020-11-28 06:29:04,252 - __main__ - INFO - Epoch  35 Step:    10960 Batch Loss:     0.000547 [Torso :     0.000352, Hand :     0.000747, Face :     0.000322]Tokens per Sec:  6479675, Lr: 0.000490\n","2020-11-28 06:29:17,568 - __main__ - INFO - Epoch  35 Step:    11000 Batch Loss:     0.000473 [Torso :     0.000330, Hand :     0.000629, Face :     0.000265]Tokens per Sec:  6532475, Lr: 0.000490\n","2020-11-28 06:29:31,015 - __main__ - INFO - Epoch  35 Step:    11040 Batch Loss:     0.000599 [Torso :     0.000303, Hand :     0.000877, Face :     0.000394]Tokens per Sec:  6591428, Lr: 0.000490\n","2020-11-28 06:29:44,642 - __main__ - INFO - Epoch  35 Step:    11080 Batch Loss:     0.000650 [Torso :     0.000459, Hand :     0.000859, Face :     0.000374]Tokens per Sec:  6543643, Lr: 0.000490\n","2020-11-28 06:29:49,144 - __main__ - INFO - Epoch  35: total training loss 0.21408 [torso: 0.13930, hand: 0.29051, face: 0.13102\n","2020-11-28 06:29:50,747 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 06:35:01,561 - __main__ - INFO - Validation result at epoch  36, step    11100: Val DTW Score:  85.46, loss:   5.1478,  duration: 310.8122s\n","2020-11-28 06:35:08,098 - __main__ - INFO - Epoch  36 Step:    11120 Batch Loss:     0.000784 [Torso :     0.000526, Hand :     0.001049, Face :     0.000486]Tokens per Sec:  6606349, Lr: 0.000490\n","2020-11-28 06:35:24,186 - __main__ - INFO - Epoch  36 Step:    11160 Batch Loss:     0.000682 [Torso :     0.000439, Hand :     0.000925, Face :     0.000435]Tokens per Sec:  5585594, Lr: 0.000490\n","2020-11-28 06:35:36,934 - __main__ - INFO - Epoch  36 Step:    11200 Batch Loss:     0.000708 [Torso :     0.000462, Hand :     0.000957, Face :     0.000439]Tokens per Sec:  6600184, Lr: 0.000490\n","2020-11-28 06:35:50,017 - __main__ - INFO - Epoch  36 Step:    11240 Batch Loss:     0.000618 [Torso :     0.000307, Hand :     0.000911, Face :     0.000397]Tokens per Sec:  6622012, Lr: 0.000490\n","2020-11-28 06:36:02,307 - __main__ - INFO - Epoch  36 Step:    11280 Batch Loss:     0.000703 [Torso :     0.000428, Hand :     0.000983, Face :     0.000406]Tokens per Sec:  6783831, Lr: 0.000490\n","2020-11-28 06:36:14,803 - __main__ - INFO - Epoch  36 Step:    11320 Batch Loss:     0.000711 [Torso :     0.000507, Hand :     0.000935, Face :     0.000408]Tokens per Sec:  6708389, Lr: 0.000490\n","2020-11-28 06:36:27,748 - __main__ - INFO - Epoch  36 Step:    11360 Batch Loss:     0.000709 [Torso :     0.000456, Hand :     0.000962, Face :     0.000457]Tokens per Sec:  6672312, Lr: 0.000490\n","2020-11-28 06:36:41,685 - __main__ - INFO - Epoch  36 Step:    11400 Batch Loss:     0.000688 [Torso :     0.000424, Hand :     0.000958, Face :     0.000397]Tokens per Sec:  6508529, Lr: 0.000490\n","2020-11-28 06:36:41,687 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 06:41:49,000 - __main__ - INFO - Validation result at epoch  36, step    11400: Val DTW Score:  73.19, loss:   5.0375,  duration: 307.3112s\n","2020-11-28 06:41:52,851 - __main__ - INFO - Epoch  36: total training loss 0.21448 [torso: 0.13985, hand: 0.29084, face: 0.13127\n","2020-11-28 06:42:03,039 - __main__ - INFO - Epoch  37 Step:    11440 Batch Loss:     0.000647 [Torso :     0.000434, Hand :     0.000857, Face :     0.000445]Tokens per Sec:  5957543, Lr: 0.000490\n","2020-11-28 06:42:17,203 - __main__ - INFO - Epoch  37 Step:    11480 Batch Loss:     0.000503 [Torso :     0.000359, Hand :     0.000663, Face :     0.000280]Tokens per Sec:  6054267, Lr: 0.000490\n","2020-11-28 06:42:30,853 - __main__ - INFO - Epoch  37 Step:    11520 Batch Loss:     0.000536 [Torso :     0.000342, Hand :     0.000737, Face :     0.000311]Tokens per Sec:  6542028, Lr: 0.000490\n","2020-11-28 06:42:44,098 - __main__ - INFO - Epoch  37 Step:    11560 Batch Loss:     0.000629 [Torso :     0.000436, Hand :     0.000831, Face :     0.000388]Tokens per Sec:  6521193, Lr: 0.000490\n","2020-11-28 06:42:57,754 - __main__ - INFO - Epoch  37 Step:    11600 Batch Loss:     0.000614 [Torso :     0.000371, Hand :     0.000853, Face :     0.000393]Tokens per Sec:  6391980, Lr: 0.000490\n","2020-11-28 06:43:10,161 - __main__ - INFO - Epoch  37 Step:    11640 Batch Loss:     0.000501 [Torso :     0.000365, Hand :     0.000651, Face :     0.000297]Tokens per Sec:  6688864, Lr: 0.000490\n","2020-11-28 06:43:23,313 - __main__ - INFO - Epoch  37 Step:    11680 Batch Loss:     0.000703 [Torso :     0.000450, Hand :     0.000958, Face :     0.000438]Tokens per Sec:  6581237, Lr: 0.000490\n","2020-11-28 06:43:30,071 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 06:48:38,181 - __main__ - INFO - Validation result at epoch  37, step    11700: Val DTW Score:  77.81, loss:   5.0865,  duration: 308.1089s\n","2020-11-28 06:48:45,591 - __main__ - INFO - Epoch  37 Step:    11720 Batch Loss:     0.000794 [Torso :     0.000500, Hand :     0.001088, Face :     0.000505]Tokens per Sec:  6147514, Lr: 0.000490\n","2020-11-28 06:48:48,996 - __main__ - INFO - Epoch  37: total training loss 0.21262 [torso: 0.13866, hand: 0.28826, face: 0.13021\n","2020-11-28 06:48:59,966 - __main__ - INFO - Epoch  38 Step:    11760 Batch Loss:     0.000830 [Torso :     0.000550, Hand :     0.001113, Face :     0.000531]Tokens per Sec:  6157837, Lr: 0.000490\n","2020-11-28 06:49:13,103 - __main__ - INFO - Epoch  38 Step:    11800 Batch Loss:     0.000629 [Torso :     0.000489, Hand :     0.000790, Face :     0.000386]Tokens per Sec:  6594928, Lr: 0.000490\n","2020-11-28 06:49:26,670 - __main__ - INFO - Epoch  38 Step:    11840 Batch Loss:     0.000631 [Torso :     0.000421, Hand :     0.000849, Face :     0.000384]Tokens per Sec:  6629558, Lr: 0.000490\n","2020-11-28 06:49:39,526 - __main__ - INFO - Epoch  38 Step:    11880 Batch Loss:     0.000530 [Torso :     0.000344, Hand :     0.000721, Face :     0.000318]Tokens per Sec:  6649604, Lr: 0.000490\n","2020-11-28 06:49:53,246 - __main__ - INFO - Epoch  38 Step:    11920 Batch Loss:     0.000617 [Torso :     0.000405, Hand :     0.000839, Face :     0.000354]Tokens per Sec:  6527673, Lr: 0.000490\n","2020-11-28 06:50:05,643 - __main__ - INFO - Epoch  38 Step:    11960 Batch Loss:     0.000690 [Torso :     0.000463, Hand :     0.000928, Face :     0.000407]Tokens per Sec:  6641284, Lr: 0.000490\n","2020-11-28 06:50:18,720 - __main__ - INFO - Epoch  38 Step:    12000 Batch Loss:     0.000654 [Torso :     0.000406, Hand :     0.000904, Face :     0.000397]Tokens per Sec:  6563817, Lr: 0.000490\n","2020-11-28 06:50:18,722 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 06:55:25,194 - __main__ - INFO - Validation result at epoch  38, step    12000: Val DTW Score:  73.35, loss:   5.2008,  duration: 306.4710s\n","2020-11-28 06:55:40,347 - __main__ - INFO - Epoch  38 Step:    12040 Batch Loss:     0.000517 [Torso :     0.000316, Hand :     0.000718, Face :     0.000315]Tokens per Sec:  5759451, Lr: 0.000490\n","2020-11-28 06:55:42,671 - __main__ - INFO - Epoch  38: total training loss 0.21239 [torso: 0.13933, hand: 0.28738, face: 0.12968\n","2020-11-28 06:55:54,270 - __main__ - INFO - Epoch  39 Step:    12080 Batch Loss:     0.000649 [Torso :     0.000387, Hand :     0.000914, Face :     0.000370]Tokens per Sec:  6468699, Lr: 0.000490\n","2020-11-28 06:56:06,951 - __main__ - INFO - Epoch  39 Step:    12120 Batch Loss:     0.000823 [Torso :     0.000641, Hand :     0.001038, Face :     0.000480]Tokens per Sec:  6565288, Lr: 0.000490\n","2020-11-28 06:56:20,501 - __main__ - INFO - Epoch  39 Step:    12160 Batch Loss:     0.000725 [Torso :     0.000518, Hand :     0.000948, Face :     0.000440]Tokens per Sec:  6450735, Lr: 0.000490\n","2020-11-28 06:56:34,007 - __main__ - INFO - Epoch  39 Step:    12200 Batch Loss:     0.000695 [Torso :     0.000437, Hand :     0.000950, Face :     0.000454]Tokens per Sec:  6494256, Lr: 0.000490\n","2020-11-28 06:56:47,286 - __main__ - INFO - Epoch  39 Step:    12240 Batch Loss:     0.000655 [Torso :     0.000366, Hand :     0.000936, Face :     0.000400]Tokens per Sec:  6466300, Lr: 0.000490\n","2020-11-28 06:57:00,417 - __main__ - INFO - Epoch  39 Step:    12280 Batch Loss:     0.000563 [Torso :     0.000368, Hand :     0.000766, Face :     0.000332]Tokens per Sec:  6539527, Lr: 0.000490\n","2020-11-28 06:57:07,017 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 07:02:14,749 - __main__ - INFO - Validation result at epoch  39, step    12300: Val DTW Score:  75.37, loss:   5.5244,  duration: 307.7303s\n","2020-11-28 07:02:21,742 - __main__ - INFO - Epoch  39 Step:    12320 Batch Loss:     0.000524 [Torso :     0.000328, Hand :     0.000719, Face :     0.000329]Tokens per Sec:  6367205, Lr: 0.000490\n","2020-11-28 07:02:35,887 - __main__ - INFO - Epoch  39 Step:    12360 Batch Loss:     0.000685 [Torso :     0.000423, Hand :     0.000945, Face :     0.000433]Tokens per Sec:  6094661, Lr: 0.000490\n","2020-11-28 07:02:36,863 - __main__ - INFO - Epoch  39: total training loss 0.21198 [torso: 0.13789, hand: 0.28776, face: 0.12942\n","2020-11-28 07:02:48,731 - __main__ - INFO - Epoch  40 Step:    12400 Batch Loss:     0.000572 [Torso :     0.000355, Hand :     0.000791, Face :     0.000347]Tokens per Sec:  6620170, Lr: 0.000490\n","2020-11-28 07:03:02,269 - __main__ - INFO - Epoch  40 Step:    12440 Batch Loss:     0.000647 [Torso :     0.000395, Hand :     0.000895, Face :     0.000417]Tokens per Sec:  6589572, Lr: 0.000490\n","2020-11-28 07:03:15,828 - __main__ - INFO - Epoch  40 Step:    12480 Batch Loss:     0.000663 [Torso :     0.000417, Hand :     0.000914, Face :     0.000393]Tokens per Sec:  6548302, Lr: 0.000490\n","2020-11-28 07:03:28,924 - __main__ - INFO - Epoch  40 Step:    12520 Batch Loss:     0.000902 [Torso :     0.000601, Hand :     0.001201, Face :     0.000610]Tokens per Sec:  6636425, Lr: 0.000490\n","2020-11-28 07:03:42,092 - __main__ - INFO - Epoch  40 Step:    12560 Batch Loss:     0.000785 [Torso :     0.000470, Hand :     0.001096, Face :     0.000489]Tokens per Sec:  6605411, Lr: 0.000490\n","2020-11-28 07:03:54,859 - __main__ - INFO - Epoch  40 Step:    12600 Batch Loss:     0.000719 [Torso :     0.000473, Hand :     0.000971, Face :     0.000439]Tokens per Sec:  6684025, Lr: 0.000490\n","2020-11-28 07:03:54,860 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 07:08:57,206 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 07:08:57,208 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 07:09:09,611 - __main__ - INFO - Validation result at epoch  40, step    12600: Val DTW Score:  67.49, loss:   4.8191,  duration: 314.7499s\n","2020-11-28 07:09:26,244 - __main__ - INFO - Epoch  40 Step:    12640 Batch Loss:     0.000650 [Torso :     0.000417, Hand :     0.000882, Face :     0.000422]Tokens per Sec:  5298048, Lr: 0.000490\n","2020-11-28 07:09:39,675 - __main__ - INFO - Epoch  40 Step:    12680 Batch Loss:     0.000600 [Torso :     0.000439, Hand :     0.000784, Face :     0.000329]Tokens per Sec:  6274695, Lr: 0.000490\n","2020-11-28 07:09:39,677 - __main__ - INFO - Epoch  40: total training loss 0.21061 [torso: 0.13744, hand: 0.28557, face: 0.12849\n","2020-11-28 07:09:52,625 - __main__ - INFO - Epoch  41 Step:    12720 Batch Loss:     0.000684 [Torso :     0.000457, Hand :     0.000914, Face :     0.000443]Tokens per Sec:  6578567, Lr: 0.000490\n","2020-11-28 07:10:05,483 - __main__ - INFO - Epoch  41 Step:    12760 Batch Loss:     0.001007 [Torso :     0.000681, Hand :     0.001354, Face :     0.000581]Tokens per Sec:  6606476, Lr: 0.000490\n","2020-11-28 07:10:18,947 - __main__ - INFO - Epoch  41 Step:    12800 Batch Loss:     0.000477 [Torso :     0.000345, Hand :     0.000623, Face :     0.000277]Tokens per Sec:  6514552, Lr: 0.000490\n","2020-11-28 07:10:31,917 - __main__ - INFO - Epoch  41 Step:    12840 Batch Loss:     0.000616 [Torso :     0.000421, Hand :     0.000827, Face :     0.000340]Tokens per Sec:  6632509, Lr: 0.000490\n","2020-11-28 07:10:44,947 - __main__ - INFO - Epoch  41 Step:    12880 Batch Loss:     0.000724 [Torso :     0.000446, Hand :     0.000998, Face :     0.000465]Tokens per Sec:  6625235, Lr: 0.000490\n","2020-11-28 07:10:51,848 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 07:15:59,958 - __main__ - INFO - Validation result at epoch  41, step    12900: Val DTW Score:  72.90, loss:   5.0230,  duration: 308.1083s\n","2020-11-28 07:16:07,421 - __main__ - INFO - Epoch  41 Step:    12920 Batch Loss:     0.000761 [Torso :     0.000501, Hand :     0.001026, Face :     0.000472]Tokens per Sec:  6218304, Lr: 0.000490\n","2020-11-28 07:16:22,309 - __main__ - INFO - Epoch  41 Step:    12960 Batch Loss:     0.000665 [Torso :     0.000452, Hand :     0.000887, Face :     0.000403]Tokens per Sec:  5922523, Lr: 0.000490\n","2020-11-28 07:16:34,913 - __main__ - INFO - Epoch  41: total training loss 0.20829 [torso: 0.13649, hand: 0.28201, face: 0.12686\n","2020-11-28 07:16:35,989 - __main__ - INFO - Epoch  42 Step:    13000 Batch Loss:     0.000402 [Torso :     0.000259, Hand :     0.000550, Face :     0.000235]Tokens per Sec:  6156561, Lr: 0.000490\n","2020-11-28 07:16:48,615 - __main__ - INFO - Epoch  42 Step:    13040 Batch Loss:     0.000723 [Torso :     0.000459, Hand :     0.000989, Face :     0.000448]Tokens per Sec:  6694151, Lr: 0.000490\n","2020-11-28 07:17:02,407 - __main__ - INFO - Epoch  42 Step:    13080 Batch Loss:     0.000610 [Torso :     0.000385, Hand :     0.000839, Face :     0.000371]Tokens per Sec:  6443683, Lr: 0.000490\n","2020-11-28 07:17:15,567 - __main__ - INFO - Epoch  42 Step:    13120 Batch Loss:     0.000692 [Torso :     0.000484, Hand :     0.000914, Face :     0.000416]Tokens per Sec:  6615001, Lr: 0.000490\n","2020-11-28 07:17:28,400 - __main__ - INFO - Epoch  42 Step:    13160 Batch Loss:     0.000844 [Torso :     0.000569, Hand :     0.001135, Face :     0.000490]Tokens per Sec:  6610570, Lr: 0.000490\n","2020-11-28 07:17:41,625 - __main__ - INFO - Epoch  42 Step:    13200 Batch Loss:     0.000704 [Torso :     0.000467, Hand :     0.000950, Face :     0.000417]Tokens per Sec:  6565778, Lr: 0.000490\n","2020-11-28 07:17:41,626 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 07:22:47,514 - __main__ - INFO - Validation result at epoch  42, step    13200: Val DTW Score:  69.70, loss:   4.8490,  duration: 305.8863s\n","2020-11-28 07:23:01,776 - __main__ - INFO - Epoch  42 Step:    13240 Batch Loss:     0.000862 [Torso :     0.000565, Hand :     0.001165, Face :     0.000541]Tokens per Sec:  6105719, Lr: 0.000490\n","2020-11-28 07:23:16,042 - __main__ - INFO - Epoch  42 Step:    13280 Batch Loss:     0.000723 [Torso :     0.000528, Hand :     0.000941, Face :     0.000414]Tokens per Sec:  6169686, Lr: 0.000490\n","2020-11-28 07:23:27,155 - __main__ - INFO - Epoch  42: total training loss 0.20871 [torso: 0.13591, hand: 0.28321, face: 0.12738\n","2020-11-28 07:23:29,351 - __main__ - INFO - Epoch  43 Step:    13320 Batch Loss:     0.000706 [Torso :     0.000427, Hand :     0.000986, Face :     0.000427]Tokens per Sec:  6113578, Lr: 0.000490\n","2020-11-28 07:23:43,148 - __main__ - INFO - Epoch  43 Step:    13360 Batch Loss:     0.000541 [Torso :     0.000341, Hand :     0.000739, Face :     0.000352]Tokens per Sec:  6563523, Lr: 0.000490\n","2020-11-28 07:23:56,309 - __main__ - INFO - Epoch  43 Step:    13400 Batch Loss:     0.000671 [Torso :     0.000413, Hand :     0.000932, Face :     0.000399]Tokens per Sec:  6533556, Lr: 0.000490\n","2020-11-28 07:24:09,428 - __main__ - INFO - Epoch  43 Step:    13440 Batch Loss:     0.000705 [Torso :     0.000426, Hand :     0.000977, Face :     0.000461]Tokens per Sec:  6539223, Lr: 0.000490\n","2020-11-28 07:24:21,901 - __main__ - INFO - Epoch  43 Step:    13480 Batch Loss:     0.000675 [Torso :     0.000423, Hand :     0.000929, Face :     0.000408]Tokens per Sec:  6631623, Lr: 0.000490\n","2020-11-28 07:24:28,257 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 07:29:31,165 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 07:29:31,167 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 07:29:45,838 - __main__ - INFO - Validation result at epoch  43, step    13500: Val DTW Score:  63.22, loss:   4.8272,  duration: 317.5786s\n","2020-11-28 07:29:54,480 - __main__ - INFO - Epoch  43 Step:    13520 Batch Loss:     0.000570 [Torso :     0.000405, Hand :     0.000749, Face :     0.000333]Tokens per Sec:  5670747, Lr: 0.000490\n","2020-11-28 07:30:08,772 - __main__ - INFO - Epoch  43 Step:    13560 Batch Loss:     0.000767 [Torso :     0.000502, Hand :     0.001040, Face :     0.000456]Tokens per Sec:  5941007, Lr: 0.000490\n","2020-11-28 07:30:22,290 - __main__ - INFO - Epoch  43 Step:    13600 Batch Loss:     0.000788 [Torso :     0.000555, Hand :     0.001041, Face :     0.000457]Tokens per Sec:  6545508, Lr: 0.000490\n","2020-11-28 07:30:32,197 - __main__ - INFO - Epoch  43: total training loss 0.20890 [torso: 0.13582, hand: 0.28365, face: 0.12748\n","2020-11-28 07:30:35,043 - __main__ - INFO - Epoch  44 Step:    13640 Batch Loss:     0.000778 [Torso :     0.000535, Hand :     0.001035, Face :     0.000463]Tokens per Sec:  6688429, Lr: 0.000490\n","2020-11-28 07:30:47,981 - __main__ - INFO - Epoch  44 Step:    13680 Batch Loss:     0.000548 [Torso :     0.000390, Hand :     0.000721, Face :     0.000320]Tokens per Sec:  6541990, Lr: 0.000490\n","2020-11-28 07:31:01,239 - __main__ - INFO - Epoch  44 Step:    13720 Batch Loss:     0.000705 [Torso :     0.000557, Hand :     0.000880, Face :     0.000418]Tokens per Sec:  6528789, Lr: 0.000490\n","2020-11-28 07:31:15,113 - __main__ - INFO - Epoch  44 Step:    13760 Batch Loss:     0.000566 [Torso :     0.000358, Hand :     0.000772, Face :     0.000363]Tokens per Sec:  6455082, Lr: 0.000490\n","2020-11-28 07:31:28,231 - __main__ - INFO - Epoch  44 Step:    13800 Batch Loss:     0.000716 [Torso :     0.000442, Hand :     0.000989, Face :     0.000445]Tokens per Sec:  6563811, Lr: 0.000490\n","2020-11-28 07:31:28,233 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 07:36:34,267 - __main__ - INFO - Validation result at epoch  44, step    13800: Val DTW Score:  69.69, loss:   4.9421,  duration: 306.0322s\n","2020-11-28 07:36:48,075 - __main__ - INFO - Epoch  44 Step:    13840 Batch Loss:     0.000669 [Torso :     0.000420, Hand :     0.000922, Face :     0.000399]Tokens per Sec:  6099972, Lr: 0.000490\n","2020-11-28 07:37:02,061 - __main__ - INFO - Epoch  44 Step:    13880 Batch Loss:     0.000514 [Torso :     0.000401, Hand :     0.000651, Face :     0.000283]Tokens per Sec:  6285850, Lr: 0.000490\n","2020-11-28 07:37:15,558 - __main__ - INFO - Epoch  44 Step:    13920 Batch Loss:     0.000524 [Torso :     0.000347, Hand :     0.000709, Face :     0.000307]Tokens per Sec:  6532814, Lr: 0.000490\n","2020-11-28 07:37:24,722 - __main__ - INFO - Epoch  44: total training loss 0.20663 [torso: 0.13526, hand: 0.27988, face: 0.12583\n","2020-11-28 07:37:28,216 - __main__ - INFO - Epoch  45 Step:    13960 Batch Loss:     0.000607 [Torso :     0.000420, Hand :     0.000804, Face :     0.000367]Tokens per Sec:  6901355, Lr: 0.000490\n","2020-11-28 07:37:40,872 - __main__ - INFO - Epoch  45 Step:    14000 Batch Loss:     0.000464 [Torso :     0.000316, Hand :     0.000615, Face :     0.000296]Tokens per Sec:  6751150, Lr: 0.000490\n","2020-11-28 07:37:54,082 - __main__ - INFO - Epoch  45 Step:    14040 Batch Loss:     0.000574 [Torso :     0.000362, Hand :     0.000786, Face :     0.000358]Tokens per Sec:  6567323, Lr: 0.000490\n","2020-11-28 07:38:07,939 - __main__ - INFO - Epoch  45 Step:    14080 Batch Loss:     0.000594 [Torso :     0.000313, Hand :     0.000859, Face :     0.000397]Tokens per Sec:  6504696, Lr: 0.000490\n","2020-11-28 07:38:14,349 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 07:43:31,387 - __main__ - INFO - Validation result at epoch  45, step    14100: Val DTW Score:  67.12, loss:   4.8290,  duration: 317.0365s\n","2020-11-28 07:43:39,356 - __main__ - INFO - Epoch  45 Step:    14120 Batch Loss:     0.000541 [Torso :     0.000326, Hand :     0.000757, Face :     0.000324]Tokens per Sec:  6067092, Lr: 0.000490\n","2020-11-28 07:43:54,412 - __main__ - INFO - Epoch  45 Step:    14160 Batch Loss:     0.000589 [Torso :     0.000416, Hand :     0.000773, Face :     0.000363]Tokens per Sec:  5677630, Lr: 0.000490\n","2020-11-28 07:44:07,523 - __main__ - INFO - Epoch  45 Step:    14200 Batch Loss:     0.000553 [Torso :     0.000410, Hand :     0.000712, Face :     0.000327]Tokens per Sec:  6300255, Lr: 0.000490\n","2020-11-28 07:44:21,443 - __main__ - INFO - Epoch  45 Step:    14240 Batch Loss:     0.000630 [Torso :     0.000432, Hand :     0.000842, Face :     0.000362]Tokens per Sec:  6240587, Lr: 0.000490\n","2020-11-28 07:44:30,689 - __main__ - INFO - Epoch  45: total training loss 0.20641 [torso: 0.13494, hand: 0.27969, face: 0.12593\n","2020-11-28 07:44:36,166 - __main__ - INFO - Epoch  46 Step:    14280 Batch Loss:     0.000622 [Torso :     0.000386, Hand :     0.000854, Face :     0.000408]Tokens per Sec:  6022947, Lr: 0.000490\n","2020-11-28 07:44:49,902 - __main__ - INFO - Epoch  46 Step:    14320 Batch Loss:     0.000832 [Torso :     0.000478, Hand :     0.001175, Face :     0.000526]Tokens per Sec:  6251590, Lr: 0.000490\n","2020-11-28 07:45:04,315 - __main__ - INFO - Epoch  46 Step:    14360 Batch Loss:     0.000718 [Torso :     0.000482, Hand :     0.000960, Face :     0.000451]Tokens per Sec:  6090734, Lr: 0.000490\n","2020-11-28 07:45:17,688 - __main__ - INFO - Epoch  46 Step:    14400 Batch Loss:     0.000668 [Torso :     0.000453, Hand :     0.000894, Face :     0.000400]Tokens per Sec:  6266177, Lr: 0.000490\n","2020-11-28 07:45:17,689 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 07:50:34,372 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 07:50:34,375 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 07:50:50,524 - __main__ - INFO - Validation result at epoch  46, step    14400: Val DTW Score:  62.73, loss:   4.8419,  duration: 332.8340s\n","2020-11-28 07:51:06,430 - __main__ - INFO - Epoch  46 Step:    14440 Batch Loss:     0.000754 [Torso :     0.000495, Hand :     0.001026, Face :     0.000428]Tokens per Sec:  5264663, Lr: 0.000490\n","2020-11-28 07:51:21,474 - __main__ - INFO - Epoch  46 Step:    14480 Batch Loss:     0.000770 [Torso :     0.000534, Hand :     0.001013, Face :     0.000499]Tokens per Sec:  6050261, Lr: 0.000490\n","2020-11-28 07:51:35,276 - __main__ - INFO - Epoch  46 Step:    14520 Batch Loss:     0.000713 [Torso :     0.000434, Hand :     0.000990, Face :     0.000441]Tokens per Sec:  6254811, Lr: 0.000490\n","2020-11-28 07:51:49,409 - __main__ - INFO - Epoch  46 Step:    14560 Batch Loss:     0.000637 [Torso :     0.000426, Hand :     0.000859, Face :     0.000371]Tokens per Sec:  6209192, Lr: 0.000490\n","2020-11-28 07:51:56,649 - __main__ - INFO - Epoch  46: total training loss 0.20462 [torso: 0.13314, hand: 0.27777, face: 0.12474\n","2020-11-28 07:52:03,116 - __main__ - INFO - Epoch  47 Step:    14600 Batch Loss:     0.000612 [Torso :     0.000411, Hand :     0.000826, Face :     0.000349]Tokens per Sec:  6154791, Lr: 0.000490\n","2020-11-28 07:52:16,998 - __main__ - INFO - Epoch  47 Step:    14640 Batch Loss:     0.000510 [Torso :     0.000354, Hand :     0.000677, Face :     0.000300]Tokens per Sec:  6221502, Lr: 0.000490\n","2020-11-28 07:52:31,216 - __main__ - INFO - Epoch  47 Step:    14680 Batch Loss:     0.000569 [Torso :     0.000339, Hand :     0.000793, Face :     0.000370]Tokens per Sec:  6233829, Lr: 0.000490\n","2020-11-28 07:52:37,678 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 07:57:56,178 - __main__ - INFO - Validation result at epoch  47, step    14700: Val DTW Score:  64.86, loss:   4.8998,  duration: 318.4986s\n","2020-11-28 07:58:02,847 - __main__ - INFO - Epoch  47 Step:    14720 Batch Loss:     0.000485 [Torso :     0.000304, Hand :     0.000668, Face :     0.000293]Tokens per Sec:  6369617, Lr: 0.000490\n","2020-11-28 07:58:18,240 - __main__ - INFO - Epoch  47 Step:    14760 Batch Loss:     0.000798 [Torso :     0.000510, Hand :     0.001094, Face :     0.000470]Tokens per Sec:  5543390, Lr: 0.000490\n","2020-11-28 07:58:31,911 - __main__ - INFO - Epoch  47 Step:    14800 Batch Loss:     0.000714 [Torso :     0.000432, Hand :     0.000995, Face :     0.000441]Tokens per Sec:  6224892, Lr: 0.000490\n","2020-11-28 07:58:46,115 - __main__ - INFO - Epoch  47 Step:    14840 Batch Loss:     0.000644 [Torso :     0.000416, Hand :     0.000877, Face :     0.000394]Tokens per Sec:  6161581, Lr: 0.000490\n","2020-11-28 07:59:00,832 - __main__ - INFO - Epoch  47 Step:    14880 Batch Loss:     0.000688 [Torso :     0.000441, Hand :     0.000938, Face :     0.000430]Tokens per Sec:  6101138, Lr: 0.000490\n","2020-11-28 07:59:07,696 - __main__ - INFO - Epoch  47: total training loss 0.20240 [torso: 0.13235, hand: 0.27416, face: 0.12378\n","2020-11-28 07:59:15,043 - __main__ - INFO - Epoch  48 Step:    14920 Batch Loss:     0.000784 [Torso :     0.000495, Hand :     0.001073, Face :     0.000500]Tokens per Sec:  6164554, Lr: 0.000490\n","2020-11-28 07:59:29,377 - __main__ - INFO - Epoch  48 Step:    14960 Batch Loss:     0.000645 [Torso :     0.000420, Hand :     0.000871, Face :     0.000416]Tokens per Sec:  6129762, Lr: 0.000490\n","2020-11-28 07:59:43,728 - __main__ - INFO - Epoch  48 Step:    15000 Batch Loss:     0.000645 [Torso :     0.000438, Hand :     0.000866, Face :     0.000368]Tokens per Sec:  6162706, Lr: 0.000490\n","2020-11-28 07:59:43,730 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 08:05:02,460 - __main__ - INFO - Validation result at epoch  48, step    15000: Val DTW Score:  65.12, loss:   4.9521,  duration: 318.7294s\n","2020-11-28 08:05:16,377 - __main__ - INFO - Epoch  48 Step:    15040 Batch Loss:     0.000584 [Torso :     0.000361, Hand :     0.000804, Face :     0.000381]Tokens per Sec:  5840165, Lr: 0.000490\n","2020-11-28 08:05:30,282 - __main__ - INFO - Epoch  48 Step:    15080 Batch Loss:     0.000913 [Torso :     0.000521, Hand :     0.001299, Face :     0.000556]Tokens per Sec:  5959992, Lr: 0.000490\n","2020-11-28 08:05:43,967 - __main__ - INFO - Epoch  48 Step:    15120 Batch Loss:     0.000593 [Torso :     0.000405, Hand :     0.000792, Face :     0.000348]Tokens per Sec:  6279978, Lr: 0.000490\n","2020-11-28 08:05:57,455 - __main__ - INFO - Epoch  48 Step:    15160 Batch Loss:     0.000836 [Torso :     0.000583, Hand :     0.001105, Face :     0.000497]Tokens per Sec:  6277928, Lr: 0.000490\n","2020-11-28 08:06:11,447 - __main__ - INFO - Epoch  48 Step:    15200 Batch Loss:     0.000517 [Torso :     0.000341, Hand :     0.000697, Face :     0.000316]Tokens per Sec:  6318305, Lr: 0.000490\n","2020-11-28 08:06:17,060 - __main__ - INFO - Epoch  48: total training loss 0.20521 [torso: 0.13347, hand: 0.27861, face: 0.12524\n","2020-11-28 08:06:25,369 - __main__ - INFO - Epoch  49 Step:    15240 Batch Loss:     0.000573 [Torso :     0.000380, Hand :     0.000776, Face :     0.000336]Tokens per Sec:  6204759, Lr: 0.000490\n","2020-11-28 08:06:38,719 - __main__ - INFO - Epoch  49 Step:    15280 Batch Loss:     0.000639 [Torso :     0.000394, Hand :     0.000888, Face :     0.000375]Tokens per Sec:  6265088, Lr: 0.000490\n","2020-11-28 08:06:45,094 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 08:12:05,521 - __main__ - INFO - Validation result at epoch  49, step    15300: Val DTW Score:  66.90, loss:   5.1657,  duration: 320.4246s\n","2020-11-28 08:12:12,517 - __main__ - INFO - Epoch  49 Step:    15320 Batch Loss:     0.000646 [Torso :     0.000464, Hand :     0.000842, Face :     0.000398]Tokens per Sec:  6173235, Lr: 0.000490\n","2020-11-28 08:12:26,902 - __main__ - INFO - Epoch  49 Step:    15360 Batch Loss:     0.000511 [Torso :     0.000337, Hand :     0.000689, Face :     0.000319]Tokens per Sec:  5734207, Lr: 0.000490\n","2020-11-28 08:12:40,799 - __main__ - INFO - Epoch  49 Step:    15400 Batch Loss:     0.000786 [Torso :     0.000471, Hand :     0.001102, Face :     0.000467]Tokens per Sec:  6245165, Lr: 0.000490\n","2020-11-28 08:12:55,186 - __main__ - INFO - Epoch  49 Step:    15440 Batch Loss:     0.000655 [Torso :     0.000459, Hand :     0.000867, Face :     0.000382]Tokens per Sec:  6195581, Lr: 0.000490\n","2020-11-28 08:13:09,563 - __main__ - INFO - Epoch  49 Step:    15480 Batch Loss:     0.000885 [Torso :     0.000662, Hand :     0.001126, Face :     0.000576]Tokens per Sec:  6221323, Lr: 0.000490\n","2020-11-28 08:13:24,208 - __main__ - INFO - Epoch  49 Step:    15520 Batch Loss:     0.000633 [Torso :     0.000375, Hand :     0.000890, Face :     0.000380]Tokens per Sec:  6167639, Lr: 0.000490\n","2020-11-28 08:13:28,862 - __main__ - INFO - Epoch  49: total training loss 0.20244 [torso: 0.13174, hand: 0.27482, face: 0.12331\n","2020-11-28 08:13:38,304 - __main__ - INFO - Epoch  50 Step:    15560 Batch Loss:     0.000486 [Torso :     0.000296, Hand :     0.000676, Face :     0.000298]Tokens per Sec:  6220835, Lr: 0.000490\n","2020-11-28 08:13:52,304 - __main__ - INFO - Epoch  50 Step:    15600 Batch Loss:     0.000596 [Torso :     0.000400, Hand :     0.000796, Face :     0.000379]Tokens per Sec:  6243171, Lr: 0.000490\n","2020-11-28 08:13:52,306 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 08:19:03,126 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 08:19:03,128 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 08:19:16,159 - __main__ - INFO - Validation result at epoch  50, step    15600: Val DTW Score:  59.70, loss:   4.8145,  duration: 323.8515s\n","2020-11-28 08:19:33,664 - __main__ - INFO - Epoch  50 Step:    15640 Batch Loss:     0.000624 [Torso :     0.000430, Hand :     0.000832, Face :     0.000363]Tokens per Sec:  4976605, Lr: 0.000490\n","2020-11-28 08:19:47,391 - __main__ - INFO - Epoch  50 Step:    15680 Batch Loss:     0.000619 [Torso :     0.000451, Hand :     0.000805, Face :     0.000362]Tokens per Sec:  6319944, Lr: 0.000490\n","2020-11-28 08:20:00,487 - __main__ - INFO - Epoch  50 Step:    15720 Batch Loss:     0.000663 [Torso :     0.000463, Hand :     0.000874, Face :     0.000409]Tokens per Sec:  6395097, Lr: 0.000490\n","2020-11-28 08:20:13,656 - __main__ - INFO - Epoch  50 Step:    15760 Batch Loss:     0.000699 [Torso :     0.000468, Hand :     0.000939, Face :     0.000420]Tokens per Sec:  6439212, Lr: 0.000490\n","2020-11-28 08:20:26,645 - __main__ - INFO - Epoch  50 Step:    15800 Batch Loss:     0.000951 [Torso :     0.000754, Hand :     0.001197, Face :     0.000505]Tokens per Sec:  6480357, Lr: 0.000490\n","2020-11-28 08:20:40,559 - __main__ - INFO - Epoch  50 Step:    15840 Batch Loss:     0.000492 [Torso :     0.000303, Hand :     0.000681, Face :     0.000298]Tokens per Sec:  6242931, Lr: 0.000490\n","2020-11-28 08:20:44,018 - __main__ - INFO - Epoch  50: total training loss 0.20175 [torso: 0.13180, hand: 0.27347, face: 0.12292\n","2020-11-28 08:20:54,891 - __main__ - INFO - Epoch  51 Step:    15880 Batch Loss:     0.000583 [Torso :     0.000452, Hand :     0.000743, Face :     0.000309]Tokens per Sec:  6236254, Lr: 0.000490\n","2020-11-28 08:21:02,453 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 08:26:16,845 - __main__ - INFO - Validation result at epoch  51, step    15900: Val DTW Score:  63.03, loss:   4.8050,  duration: 314.3909s\n","2020-11-28 08:26:23,987 - __main__ - INFO - Epoch  51 Step:    15920 Batch Loss:     0.000565 [Torso :     0.000367, Hand :     0.000766, Face :     0.000347]Tokens per Sec:  6093072, Lr: 0.000490\n","2020-11-28 08:26:39,781 - __main__ - INFO - Epoch  51 Step:    15960 Batch Loss:     0.000686 [Torso :     0.000400, Hand :     0.000960, Face :     0.000459]Tokens per Sec:  5402500, Lr: 0.000490\n","2020-11-28 08:26:53,484 - __main__ - INFO - Epoch  51 Step:    16000 Batch Loss:     0.000550 [Torso :     0.000369, Hand :     0.000737, Face :     0.000341]Tokens per Sec:  6317065, Lr: 0.000490\n","2020-11-28 08:27:07,412 - __main__ - INFO - Epoch  51 Step:    16040 Batch Loss:     0.000718 [Torso :     0.000465, Hand :     0.000977, Face :     0.000438]Tokens per Sec:  6283588, Lr: 0.000490\n","2020-11-28 08:27:20,609 - __main__ - INFO - Epoch  51 Step:    16080 Batch Loss:     0.000522 [Torso :     0.000320, Hand :     0.000729, Face :     0.000293]Tokens per Sec:  6413635, Lr: 0.000490\n","2020-11-28 08:27:33,516 - __main__ - INFO - Epoch  51 Step:    16120 Batch Loss:     0.000722 [Torso :     0.000523, Hand :     0.000947, Face :     0.000398]Tokens per Sec:  6450852, Lr: 0.000490\n","2020-11-28 08:27:46,834 - __main__ - INFO - Epoch  51 Step:    16160 Batch Loss:     0.001173 [Torso :     0.000994, Hand :     0.001430, Face :     0.000609]Tokens per Sec:  6382928, Lr: 0.000490\n","2020-11-28 08:27:48,900 - __main__ - INFO - Epoch  51: total training loss 0.20080 [torso: 0.13058, hand: 0.27263, face: 0.12249\n","2020-11-28 08:28:00,613 - __main__ - INFO - Epoch  52 Step:    16200 Batch Loss:     0.000600 [Torso :     0.000378, Hand :     0.000827, Face :     0.000354]Tokens per Sec:  6218612, Lr: 0.000490\n","2020-11-28 08:28:00,615 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 08:33:17,391 - __main__ - INFO - Validation result at epoch  52, step    16200: Val DTW Score:  60.77, loss:   4.8386,  duration: 316.7739s\n","2020-11-28 08:33:32,911 - __main__ - INFO - Epoch  52 Step:    16240 Batch Loss:     0.000527 [Torso :     0.000412, Hand :     0.000666, Face :     0.000298]Tokens per Sec:  5434787, Lr: 0.000490\n","2020-11-28 08:33:46,812 - __main__ - INFO - Epoch  52 Step:    16280 Batch Loss:     0.000690 [Torso :     0.000458, Hand :     0.000933, Face :     0.000401]Tokens per Sec:  6253434, Lr: 0.000490\n","2020-11-28 08:34:01,372 - __main__ - INFO - Epoch  52 Step:    16320 Batch Loss:     0.000565 [Torso :     0.000357, Hand :     0.000778, Face :     0.000329]Tokens per Sec:  6156382, Lr: 0.000490\n","2020-11-28 08:34:15,112 - __main__ - INFO - Epoch  52 Step:    16360 Batch Loss:     0.000589 [Torso :     0.000361, Hand :     0.000819, Face :     0.000353]Tokens per Sec:  6218414, Lr: 0.000490\n","2020-11-28 08:34:27,965 - __main__ - INFO - Epoch  52 Step:    16400 Batch Loss:     0.000763 [Torso :     0.000407, Hand :     0.001102, Face :     0.000491]Tokens per Sec:  6453768, Lr: 0.000490\n","2020-11-28 08:34:42,109 - __main__ - INFO - Epoch  52 Step:    16440 Batch Loss:     0.000616 [Torso :     0.000405, Hand :     0.000833, Face :     0.000373]Tokens per Sec:  6252991, Lr: 0.000490\n","2020-11-28 08:34:55,567 - __main__ - INFO - Epoch  52 Step:    16480 Batch Loss:     0.000864 [Torso :     0.000555, Hand :     0.001185, Face :     0.000496]Tokens per Sec:  6348118, Lr: 0.000490\n","2020-11-28 08:34:57,087 - __main__ - INFO - Epoch  52: total training loss 0.19928 [torso: 0.12957, hand: 0.27060, face: 0.12150\n","2020-11-28 08:35:02,726 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 08:40:19,404 - __main__ - INFO - Validation result at epoch  53, step    16500: Val DTW Score:  61.50, loss:   4.6714,  duration: 316.6761s\n","2020-11-28 08:40:26,605 - __main__ - INFO - Epoch  53 Step:    16520 Batch Loss:     0.000827 [Torso :     0.000583, Hand :     0.001089, Face :     0.000499]Tokens per Sec:  6204423, Lr: 0.000490\n","2020-11-28 08:40:42,662 - __main__ - INFO - Epoch  53 Step:    16560 Batch Loss:     0.000656 [Torso :     0.000495, Hand :     0.000834, Face :     0.000406]Tokens per Sec:  5488894, Lr: 0.000490\n","2020-11-28 08:40:56,585 - __main__ - INFO - Epoch  53 Step:    16600 Batch Loss:     0.000562 [Torso :     0.000381, Hand :     0.000752, Face :     0.000339]Tokens per Sec:  6255543, Lr: 0.000490\n","2020-11-28 08:41:09,707 - __main__ - INFO - Epoch  53 Step:    16640 Batch Loss:     0.000640 [Torso :     0.000447, Hand :     0.000850, Face :     0.000364]Tokens per Sec:  6368265, Lr: 0.000490\n","2020-11-28 08:41:24,005 - __main__ - INFO - Epoch  53 Step:    16680 Batch Loss:     0.000743 [Torso :     0.000446, Hand :     0.001025, Face :     0.000521]Tokens per Sec:  6209681, Lr: 0.000490\n","2020-11-28 08:41:37,951 - __main__ - INFO - Epoch  53 Step:    16720 Batch Loss:     0.000563 [Torso :     0.000342, Hand :     0.000781, Face :     0.000353]Tokens per Sec:  6259186, Lr: 0.000490\n","2020-11-28 08:41:51,273 - __main__ - INFO - Epoch  53 Step:    16760 Batch Loss:     0.000724 [Torso :     0.000483, Hand :     0.000971, Face :     0.000452]Tokens per Sec:  6327448, Lr: 0.000490\n","2020-11-28 08:42:04,921 - __main__ - INFO - Epoch  53 Step:    16800 Batch Loss:     0.000685 [Torso :     0.000484, Hand :     0.000906, Face :     0.000390]Tokens per Sec:  6288858, Lr: 0.000490\n","2020-11-28 08:42:04,923 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 08:47:16,202 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 08:47:16,204 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 08:47:31,467 - __main__ - INFO - Validation result at epoch  53, step    16800: Val DTW Score:  59.56, loss:   4.7402,  duration: 326.5421s\n","2020-11-28 08:47:31,959 - __main__ - INFO - Epoch  53: total training loss 0.19809 [torso: 0.12854, hand: 0.26926, face: 0.12047\n","2020-11-28 08:47:48,848 - __main__ - INFO - Epoch  54 Step:    16840 Batch Loss:     0.000682 [Torso :     0.000451, Hand :     0.000915, Face :     0.000436]Tokens per Sec:  4781668, Lr: 0.000490\n","2020-11-28 08:48:02,574 - __main__ - INFO - Epoch  54 Step:    16880 Batch Loss:     0.000484 [Torso :     0.000324, Hand :     0.000650, Face :     0.000297]Tokens per Sec:  6312102, Lr: 0.000490\n","2020-11-28 08:48:15,566 - __main__ - INFO - Epoch  54 Step:    16920 Batch Loss:     0.000743 [Torso :     0.000451, Hand :     0.001030, Face :     0.000479]Tokens per Sec:  6342675, Lr: 0.000490\n","2020-11-28 08:48:28,957 - __main__ - INFO - Epoch  54 Step:    16960 Batch Loss:     0.000570 [Torso :     0.000341, Hand :     0.000797, Face :     0.000350]Tokens per Sec:  6306391, Lr: 0.000490\n","2020-11-28 08:48:44,150 - __main__ - INFO - Epoch  54 Step:    17000 Batch Loss:     0.000609 [Torso :     0.000381, Hand :     0.000841, Face :     0.000362]Tokens per Sec:  6091868, Lr: 0.000490\n","2020-11-28 08:48:58,644 - __main__ - INFO - Epoch  54 Step:    17040 Batch Loss:     0.000710 [Torso :     0.000446, Hand :     0.000980, Face :     0.000415]Tokens per Sec:  6120543, Lr: 0.000490\n","2020-11-28 08:49:12,912 - __main__ - INFO - Epoch  54 Step:    17080 Batch Loss:     0.000470 [Torso :     0.000322, Hand :     0.000622, Face :     0.000301]Tokens per Sec:  6201309, Lr: 0.000490\n","2020-11-28 08:49:20,158 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 08:54:37,668 - __main__ - INFO - Validation result at epoch  54, step    17100: Val DTW Score:  60.47, loss:   4.6935,  duration: 317.5083s\n","2020-11-28 08:54:43,229 - __main__ - INFO - Epoch  54: total training loss 0.20044 [torso: 0.13106, hand: 0.27169, face: 0.12175\n","2020-11-28 08:54:44,319 - __main__ - INFO - Epoch  55 Step:    17120 Batch Loss:     0.000687 [Torso :     0.000415, Hand :     0.000957, Face :     0.000427]Tokens per Sec:  4523073, Lr: 0.000490\n","2020-11-28 08:55:00,139 - __main__ - INFO - Epoch  55 Step:    17160 Batch Loss:     0.000580 [Torso :     0.000388, Hand :     0.000779, Face :     0.000356]Tokens per Sec:  5513280, Lr: 0.000490\n","2020-11-28 08:55:14,378 - __main__ - INFO - Epoch  55 Step:    17200 Batch Loss:     0.000808 [Torso :     0.000468, Hand :     0.001146, Face :     0.000481]Tokens per Sec:  6216715, Lr: 0.000490\n","2020-11-28 08:55:28,039 - __main__ - INFO - Epoch  55 Step:    17240 Batch Loss:     0.000766 [Torso :     0.000482, Hand :     0.001055, Face :     0.000458]Tokens per Sec:  6314047, Lr: 0.000490\n","2020-11-28 08:55:42,199 - __main__ - INFO - Epoch  55 Step:    17280 Batch Loss:     0.000549 [Torso :     0.000389, Hand :     0.000725, Face :     0.000307]Tokens per Sec:  6243015, Lr: 0.000490\n","2020-11-28 08:55:55,686 - __main__ - INFO - Epoch  55 Step:    17320 Batch Loss:     0.000684 [Torso :     0.000344, Hand :     0.001006, Face :     0.000434]Tokens per Sec:  6252635, Lr: 0.000490\n","2020-11-28 08:56:09,487 - __main__ - INFO - Epoch  55 Step:    17360 Batch Loss:     0.000600 [Torso :     0.000479, Hand :     0.000748, Face :     0.000343]Tokens per Sec:  6224863, Lr: 0.000490\n","2020-11-28 08:56:23,054 - __main__ - INFO - Epoch  55 Step:    17400 Batch Loss:     0.000791 [Torso :     0.000448, Hand :     0.001125, Face :     0.000488]Tokens per Sec:  6349067, Lr: 0.000490\n","2020-11-28 08:56:23,056 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 09:01:36,515 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 09:01:36,517 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 09:01:50,125 - __main__ - INFO - Validation result at epoch  55, step    17400: Val DTW Score:  56.23, loss:   4.8022,  duration: 327.0684s\n","2020-11-28 09:02:04,483 - __main__ - INFO - Epoch  55: total training loss 0.19763 [torso: 0.12846, hand: 0.26840, face: 0.12049\n","2020-11-28 09:02:06,509 - __main__ - INFO - Epoch  56 Step:    17440 Batch Loss:     0.000606 [Torso :     0.000412, Hand :     0.000808, Face :     0.000370]Tokens per Sec:  5316661, Lr: 0.000490\n","2020-11-28 09:02:20,346 - __main__ - INFO - Epoch  56 Step:    17480 Batch Loss:     0.000427 [Torso :     0.000312, Hand :     0.000550, Face :     0.000272]Tokens per Sec:  6200201, Lr: 0.000490\n","2020-11-28 09:02:34,646 - __main__ - INFO - Epoch  56 Step:    17520 Batch Loss:     0.000579 [Torso :     0.000380, Hand :     0.000781, Face :     0.000364]Tokens per Sec:  6123471, Lr: 0.000490\n","2020-11-28 09:02:48,087 - __main__ - INFO - Epoch  56 Step:    17560 Batch Loss:     0.000622 [Torso :     0.000449, Hand :     0.000809, Face :     0.000375]Tokens per Sec:  6259661, Lr: 0.000490\n","2020-11-28 09:03:01,780 - __main__ - INFO - Epoch  56 Step:    17600 Batch Loss:     0.000622 [Torso :     0.000451, Hand :     0.000809, Face :     0.000367]Tokens per Sec:  6310183, Lr: 0.000490\n","2020-11-28 09:03:16,396 - __main__ - INFO - Epoch  56 Step:    17640 Batch Loss:     0.000577 [Torso :     0.000378, Hand :     0.000785, Face :     0.000330]Tokens per Sec:  6117013, Lr: 0.000490\n","2020-11-28 09:03:30,095 - __main__ - INFO - Epoch  56 Step:    17680 Batch Loss:     0.000700 [Torso :     0.000452, Hand :     0.000955, Face :     0.000418]Tokens per Sec:  6240106, Lr: 0.000490\n","2020-11-28 09:03:36,440 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 09:08:55,629 - __main__ - INFO - Validation result at epoch  56, step    17700: Val DTW Score:  59.47, loss:   4.7038,  duration: 319.1874s\n","2020-11-28 09:09:03,244 - __main__ - INFO - Epoch  56 Step:    17720 Batch Loss:     0.000650 [Torso :     0.000458, Hand :     0.000859, Face :     0.000370]Tokens per Sec:  6092439, Lr: 0.000490\n","2020-11-28 09:09:15,526 - __main__ - INFO - Epoch  56: total training loss 0.19755 [torso: 0.12829, hand: 0.26840, face: 0.12030\n","2020-11-28 09:09:18,085 - __main__ - INFO - Epoch  57 Step:    17760 Batch Loss:     0.000635 [Torso :     0.000424, Hand :     0.000856, Face :     0.000371]Tokens per Sec:  6554978, Lr: 0.000490\n","2020-11-28 09:09:31,829 - __main__ - INFO - Epoch  57 Step:    17800 Batch Loss:     0.000684 [Torso :     0.000438, Hand :     0.000934, Face :     0.000422]Tokens per Sec:  6253533, Lr: 0.000490\n","2020-11-28 09:09:44,766 - __main__ - INFO - Epoch  57 Step:    17840 Batch Loss:     0.000553 [Torso :     0.000354, Hand :     0.000754, Face :     0.000348]Tokens per Sec:  6405386, Lr: 0.000490\n","2020-11-28 09:09:58,952 - __main__ - INFO - Epoch  57 Step:    17880 Batch Loss:     0.000667 [Torso :     0.000353, Hand :     0.000971, Face :     0.000405]Tokens per Sec:  6186721, Lr: 0.000490\n","2020-11-28 09:10:12,589 - __main__ - INFO - Epoch  57 Step:    17920 Batch Loss:     0.000537 [Torso :     0.000351, Hand :     0.000727, Face :     0.000336]Tokens per Sec:  6279657, Lr: 0.000490\n","2020-11-28 09:10:26,476 - __main__ - INFO - Epoch  57 Step:    17960 Batch Loss:     0.000439 [Torso :     0.000300, Hand :     0.000586, Face :     0.000261]Tokens per Sec:  6108583, Lr: 0.000490\n","2020-11-28 09:10:40,429 - __main__ - INFO - Epoch  57 Step:    18000 Batch Loss:     0.000459 [Torso :     0.000306, Hand :     0.000615, Face :     0.000291]Tokens per Sec:  6226199, Lr: 0.000490\n","2020-11-28 09:10:40,431 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 09:15:59,402 - __main__ - INFO - Validation result at epoch  57, step    18000: Val DTW Score:  59.18, loss:   4.7409,  duration: 318.9703s\n","2020-11-28 09:16:14,361 - __main__ - INFO - Epoch  57 Step:    18040 Batch Loss:     0.000761 [Torso :     0.000589, Hand :     0.000964, Face :     0.000428]Tokens per Sec:  5718370, Lr: 0.000490\n","2020-11-28 09:16:24,856 - __main__ - INFO - Epoch  57: total training loss 0.19925 [torso: 0.12958, hand: 0.27061, face: 0.12110\n","2020-11-28 09:16:29,211 - __main__ - INFO - Epoch  58 Step:    18080 Batch Loss:     0.000353 [Torso :     0.000231, Hand :     0.000477, Face :     0.000223]Tokens per Sec:  5923948, Lr: 0.000490\n","2020-11-28 09:16:43,845 - __main__ - INFO - Epoch  58 Step:    18120 Batch Loss:     0.000662 [Torso :     0.000346, Hand :     0.000967, Face :     0.000395]Tokens per Sec:  6112245, Lr: 0.000490\n","2020-11-28 09:16:57,225 - __main__ - INFO - Epoch  58 Step:    18160 Batch Loss:     0.000585 [Torso :     0.000369, Hand :     0.000805, Face :     0.000353]Tokens per Sec:  6270922, Lr: 0.000490\n","2020-11-28 09:17:10,647 - __main__ - INFO - Epoch  58 Step:    18200 Batch Loss:     0.000561 [Torso :     0.000361, Hand :     0.000767, Face :     0.000331]Tokens per Sec:  6271540, Lr: 0.000490\n","2020-11-28 09:17:24,642 - __main__ - INFO - Epoch  58 Step:    18240 Batch Loss:     0.000532 [Torso :     0.000304, Hand :     0.000752, Face :     0.000342]Tokens per Sec:  6229289, Lr: 0.000490\n","2020-11-28 09:17:39,148 - __main__ - INFO - Epoch  58 Step:    18280 Batch Loss:     0.000581 [Torso :     0.000348, Hand :     0.000814, Face :     0.000344]Tokens per Sec:  6102372, Lr: 0.000490\n","2020-11-28 09:17:46,865 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 09:23:07,456 - __main__ - INFO - Validation result at epoch  58, step    18300: Val DTW Score:  56.92, loss:   4.7000,  duration: 320.5894s\n","2020-11-28 09:23:15,690 - __main__ - INFO - Epoch  58 Step:    18320 Batch Loss:     0.000789 [Torso :     0.000512, Hand :     0.001074, Face :     0.000477]Tokens per Sec:  5683662, Lr: 0.000490\n","2020-11-28 09:23:30,335 - __main__ - INFO - Epoch  58 Step:    18360 Batch Loss:     0.000654 [Torso :     0.000383, Hand :     0.000909, Face :     0.000462]Tokens per Sec:  5808153, Lr: 0.000490\n","2020-11-28 09:23:39,270 - __main__ - INFO - Epoch  58: total training loss 0.19303 [torso: 0.12578, hand: 0.26192, face: 0.11762\n","2020-11-28 09:23:44,656 - __main__ - INFO - Epoch  59 Step:    18400 Batch Loss:     0.000648 [Torso :     0.000471, Hand :     0.000846, Face :     0.000368]Tokens per Sec:  6009928, Lr: 0.000490\n","2020-11-28 09:23:59,102 - __main__ - INFO - Epoch  59 Step:    18440 Batch Loss:     0.000528 [Torso :     0.000360, Hand :     0.000706, Face :     0.000311]Tokens per Sec:  6084995, Lr: 0.000490\n","2020-11-28 09:24:12,836 - __main__ - INFO - Epoch  59 Step:    18480 Batch Loss:     0.000643 [Torso :     0.000334, Hand :     0.000937, Face :     0.000412]Tokens per Sec:  6202164, Lr: 0.000490\n","2020-11-28 09:24:26,645 - __main__ - INFO - Epoch  59 Step:    18520 Batch Loss:     0.000623 [Torso :     0.000416, Hand :     0.000831, Face :     0.000408]Tokens per Sec:  6170676, Lr: 0.000490\n","2020-11-28 09:24:40,972 - __main__ - INFO - Epoch  59 Step:    18560 Batch Loss:     0.000491 [Torso :     0.000317, Hand :     0.000668, Face :     0.000301]Tokens per Sec:  6119756, Lr: 0.000490\n","2020-11-28 09:24:54,780 - __main__ - INFO - Epoch  59 Step:    18600 Batch Loss:     0.000558 [Torso :     0.000338, Hand :     0.000773, Face :     0.000360]Tokens per Sec:  6246541, Lr: 0.000490\n","2020-11-28 09:24:54,782 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 09:30:15,245 - __main__ - INFO - Validation result at epoch  59, step    18600: Val DTW Score:  62.46, loss:   4.7328,  duration: 320.4621s\n","2020-11-28 09:30:30,103 - __main__ - INFO - Epoch  59 Step:    18640 Batch Loss:     0.000524 [Torso :     0.000422, Hand :     0.000649, Face :     0.000308]Tokens per Sec:  5806397, Lr: 0.000490\n","2020-11-28 09:30:44,826 - __main__ - INFO - Epoch  59 Step:    18680 Batch Loss:     0.000559 [Torso :     0.000370, Hand :     0.000755, Face :     0.000334]Tokens per Sec:  5853216, Lr: 0.000490\n","2020-11-28 09:30:52,659 - __main__ - INFO - Epoch  59: total training loss 0.19452 [torso: 0.12678, hand: 0.26393, face: 0.11845\n","2020-11-28 09:30:58,610 - __main__ - INFO - Epoch  60 Step:    18720 Batch Loss:     0.000411 [Torso :     0.000249, Hand :     0.000571, Face :     0.000257]Tokens per Sec:  6099629, Lr: 0.000490\n","2020-11-28 09:31:12,680 - __main__ - INFO - Epoch  60 Step:    18760 Batch Loss:     0.000591 [Torso :     0.000419, Hand :     0.000773, Face :     0.000370]Tokens per Sec:  6220266, Lr: 0.000490\n","2020-11-28 09:31:26,744 - __main__ - INFO - Epoch  60 Step:    18800 Batch Loss:     0.000487 [Torso :     0.000305, Hand :     0.000673, Face :     0.000285]Tokens per Sec:  6176489, Lr: 0.000490\n","2020-11-28 09:31:40,322 - __main__ - INFO - Epoch  60 Step:    18840 Batch Loss:     0.000679 [Torso :     0.000413, Hand :     0.000933, Face :     0.000473]Tokens per Sec:  6236011, Lr: 0.000490\n","2020-11-28 09:31:55,155 - __main__ - INFO - Epoch  60 Step:    18880 Batch Loss:     0.000588 [Torso :     0.000374, Hand :     0.000808, Face :     0.000343]Tokens per Sec:  6089790, Lr: 0.000490\n","2020-11-28 09:32:02,525 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 09:37:23,821 - __main__ - INFO - Validation result at epoch  60, step    18900: Val DTW Score:  57.75, loss:   4.5924,  duration: 321.2938s\n","2020-11-28 09:37:31,667 - __main__ - INFO - Epoch  60 Step:    18920 Batch Loss:     0.000564 [Torso :     0.000385, Hand :     0.000750, Face :     0.000350]Tokens per Sec:  5849580, Lr: 0.000490\n","2020-11-28 09:37:46,653 - __main__ - INFO - Epoch  60 Step:    18960 Batch Loss:     0.000634 [Torso :     0.000441, Hand :     0.000835, Face :     0.000395]Tokens per Sec:  5727230, Lr: 0.000490\n","2020-11-28 09:38:00,412 - __main__ - INFO - Epoch  60 Step:    19000 Batch Loss:     0.000748 [Torso :     0.000500, Hand :     0.001001, Face :     0.000471]Tokens per Sec:  6179646, Lr: 0.000490\n","2020-11-28 09:38:07,058 - __main__ - INFO - Epoch  60: total training loss 0.19285 [torso: 0.12451, hand: 0.26262, face: 0.11739\n","2020-11-28 09:38:14,131 - __main__ - INFO - Epoch  61 Step:    19040 Batch Loss:     0.000588 [Torso :     0.000372, Hand :     0.000804, Face :     0.000370]Tokens per Sec:  6081921, Lr: 0.000490\n","2020-11-28 09:38:28,430 - __main__ - INFO - Epoch  61 Step:    19080 Batch Loss:     0.000593 [Torso :     0.000401, Hand :     0.000795, Face :     0.000351]Tokens per Sec:  6096274, Lr: 0.000490\n","2020-11-28 09:38:43,323 - __main__ - INFO - Epoch  61 Step:    19120 Batch Loss:     0.000441 [Torso :     0.000270, Hand :     0.000607, Face :     0.000293]Tokens per Sec:  6021123, Lr: 0.000490\n","2020-11-28 09:38:57,361 - __main__ - INFO - Epoch  61 Step:    19160 Batch Loss:     0.000538 [Torso :     0.000349, Hand :     0.000731, Face :     0.000330]Tokens per Sec:  6130376, Lr: 0.000490\n","2020-11-28 09:39:10,627 - __main__ - INFO - Epoch  61 Step:    19200 Batch Loss:     0.000719 [Torso :     0.000453, Hand :     0.000984, Face :     0.000455]Tokens per Sec:  6253062, Lr: 0.000490\n","2020-11-28 09:39:10,628 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 09:44:28,065 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 09:44:28,067 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 09:44:41,603 - __main__ - INFO - Validation result at epoch  61, step    19200: Val DTW Score:  54.13, loss:   4.5381,  duration: 330.9728s\n","2020-11-28 09:44:59,063 - __main__ - INFO - Epoch  61 Step:    19240 Batch Loss:     0.000540 [Torso :     0.000344, Hand :     0.000742, Face :     0.000318]Tokens per Sec:  4943384, Lr: 0.000490\n","2020-11-28 09:45:13,607 - __main__ - INFO - Epoch  61 Step:    19280 Batch Loss:     0.000556 [Torso :     0.000345, Hand :     0.000769, Face :     0.000341]Tokens per Sec:  6099534, Lr: 0.000490\n","2020-11-28 09:45:27,629 - __main__ - INFO - Epoch  61 Step:    19320 Batch Loss:     0.000674 [Torso :     0.000462, Hand :     0.000898, Face :     0.000402]Tokens per Sec:  6189417, Lr: 0.000490\n","2020-11-28 09:45:33,942 - __main__ - INFO - Epoch  61: total training loss 0.19257 [torso: 0.12547, hand: 0.26129, face: 0.11741\n","2020-11-28 09:45:42,513 - __main__ - INFO - Epoch  62 Step:    19360 Batch Loss:     0.000712 [Torso :     0.000386, Hand :     0.001015, Face :     0.000503]Tokens per Sec:  6041028, Lr: 0.000490\n","2020-11-28 09:45:56,597 - __main__ - INFO - Epoch  62 Step:    19400 Batch Loss:     0.000577 [Torso :     0.000408, Hand :     0.000764, Face :     0.000324]Tokens per Sec:  6162171, Lr: 0.000490\n","2020-11-28 09:46:10,672 - __main__ - INFO - Epoch  62 Step:    19440 Batch Loss:     0.000594 [Torso :     0.000390, Hand :     0.000805, Face :     0.000364]Tokens per Sec:  6093134, Lr: 0.000490\n","2020-11-28 09:46:25,386 - __main__ - INFO - Epoch  62 Step:    19480 Batch Loss:     0.000601 [Torso :     0.000405, Hand :     0.000810, Face :     0.000340]Tokens per Sec:  6039197, Lr: 0.000490\n","2020-11-28 09:46:32,576 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 09:51:54,947 - __main__ - INFO - Validation result at epoch  62, step    19500: Val DTW Score:  57.21, loss:   4.6259,  duration: 322.3690s\n","2020-11-28 09:52:02,431 - __main__ - INFO - Epoch  62 Step:    19520 Batch Loss:     0.000678 [Torso :     0.000439, Hand :     0.000922, Face :     0.000409]Tokens per Sec:  5892927, Lr: 0.000490\n","2020-11-28 09:52:17,130 - __main__ - INFO - Epoch  62 Step:    19560 Batch Loss:     0.000655 [Torso :     0.000436, Hand :     0.000889, Face :     0.000355]Tokens per Sec:  5758577, Lr: 0.000490\n","2020-11-28 09:52:30,156 - __main__ - INFO - Epoch  62 Step:    19600 Batch Loss:     0.000612 [Torso :     0.000477, Hand :     0.000768, Face :     0.000373]Tokens per Sec:  6462218, Lr: 0.000490\n","2020-11-28 09:52:44,504 - __main__ - INFO - Epoch  62 Step:    19640 Batch Loss:     0.000708 [Torso :     0.000393, Hand :     0.001009, Face :     0.000463]Tokens per Sec:  6220702, Lr: 0.000490\n","2020-11-28 09:52:48,889 - __main__ - INFO - Epoch  62: total training loss 0.19102 [torso: 0.12432, hand: 0.25928, face: 0.11655\n","2020-11-28 09:52:58,617 - __main__ - INFO - Epoch  63 Step:    19680 Batch Loss:     0.000357 [Torso :     0.000220, Hand :     0.000494, Face :     0.000220]Tokens per Sec:  6089100, Lr: 0.000490\n","2020-11-28 09:53:12,652 - __main__ - INFO - Epoch  63 Step:    19720 Batch Loss:     0.000700 [Torso :     0.000449, Hand :     0.000957, Face :     0.000412]Tokens per Sec:  6131703, Lr: 0.000490\n","2020-11-28 09:53:26,599 - __main__ - INFO - Epoch  63 Step:    19760 Batch Loss:     0.000401 [Torso :     0.000267, Hand :     0.000543, Face :     0.000227]Tokens per Sec:  6209273, Lr: 0.000490\n","2020-11-28 09:53:40,135 - __main__ - INFO - Epoch  63 Step:    19800 Batch Loss:     0.000375 [Torso :     0.000249, Hand :     0.000507, Face :     0.000219]Tokens per Sec:  6338056, Lr: 0.000490\n","2020-11-28 09:53:40,137 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 09:58:57,580 - __main__ - INFO - Validation result at epoch  63, step    19800: Val DTW Score:  58.58, loss:   4.6262,  duration: 317.4421s\n","2020-11-28 09:59:12,877 - __main__ - INFO - Epoch  63 Step:    19840 Batch Loss:     0.000637 [Torso :     0.000439, Hand :     0.000850, Face :     0.000364]Tokens per Sec:  5813276, Lr: 0.000490\n","2020-11-28 09:59:26,804 - __main__ - INFO - Epoch  63 Step:    19880 Batch Loss:     0.000717 [Torso :     0.000503, Hand :     0.000952, Face :     0.000401]Tokens per Sec:  6077300, Lr: 0.000490\n","2020-11-28 09:59:40,789 - __main__ - INFO - Epoch  63 Step:    19920 Batch Loss:     0.000543 [Torso :     0.000347, Hand :     0.000745, Face :     0.000323]Tokens per Sec:  6365199, Lr: 0.000490\n","2020-11-28 09:59:53,714 - __main__ - INFO - Epoch  63 Step:    19960 Batch Loss:     0.000518 [Torso :     0.000336, Hand :     0.000701, Face :     0.000326]Tokens per Sec:  6435416, Lr: 0.000490\n","2020-11-28 09:59:57,531 - __main__ - INFO - Epoch  63: total training loss 0.19108 [torso: 0.12428, hand: 0.25951, face: 0.11619\n","2020-11-28 10:00:07,534 - __main__ - INFO - Epoch  64 Step:    20000 Batch Loss:     0.000459 [Torso :     0.000279, Hand :     0.000641, Face :     0.000271]Tokens per Sec:  6294801, Lr: 0.000490\n","2020-11-28 10:00:21,535 - __main__ - INFO - Epoch  64 Step:    20040 Batch Loss:     0.000537 [Torso :     0.000349, Hand :     0.000731, Face :     0.000320]Tokens per Sec:  6234378, Lr: 0.000490\n","2020-11-28 10:00:34,991 - __main__ - INFO - Epoch  64 Step:    20080 Batch Loss:     0.000706 [Torso :     0.000427, Hand :     0.000975, Face :     0.000475]Tokens per Sec:  6364542, Lr: 0.000490\n","2020-11-28 10:00:41,778 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 10:05:58,514 - __main__ - INFO - Validation result at epoch  64, step    20100: Val DTW Score:  57.20, loss:   4.6739,  duration: 316.7348s\n","2020-11-28 10:06:04,646 - __main__ - INFO - Epoch  64 Step:    20120 Batch Loss:     0.000611 [Torso :     0.000380, Hand :     0.000845, Face :     0.000362]Tokens per Sec:  6428819, Lr: 0.000490\n","2020-11-28 10:06:20,245 - __main__ - INFO - Epoch  64 Step:    20160 Batch Loss:     0.000534 [Torso :     0.000341, Hand :     0.000729, Face :     0.000327]Tokens per Sec:  5376641, Lr: 0.000490\n","2020-11-28 10:06:35,040 - __main__ - INFO - Epoch  64 Step:    20200 Batch Loss:     0.000656 [Torso :     0.000422, Hand :     0.000889, Face :     0.000423]Tokens per Sec:  6084061, Lr: 0.000490\n","2020-11-28 10:06:48,833 - __main__ - INFO - Epoch  64 Step:    20240 Batch Loss:     0.000713 [Torso :     0.000422, Hand :     0.000997, Face :     0.000455]Tokens per Sec:  6270482, Lr: 0.000490\n","2020-11-28 10:07:02,269 - __main__ - INFO - Epoch  64 Step:    20280 Batch Loss:     0.000820 [Torso :     0.000552, Hand :     0.001099, Face :     0.000494]Tokens per Sec:  6330312, Lr: 0.000490\n","2020-11-28 10:07:04,848 - __main__ - INFO - Epoch  64: total training loss 0.19234 [torso: 0.12450, hand: 0.26164, face: 0.11718\n","2020-11-28 10:07:15,789 - __main__ - INFO - Epoch  65 Step:    20320 Batch Loss:     0.000512 [Torso :     0.000309, Hand :     0.000709, Face :     0.000336]Tokens per Sec:  6246691, Lr: 0.000490\n","2020-11-28 10:07:29,978 - __main__ - INFO - Epoch  65 Step:    20360 Batch Loss:     0.000459 [Torso :     0.000324, Hand :     0.000602, Face :     0.000285]Tokens per Sec:  6252297, Lr: 0.000490\n","2020-11-28 10:07:44,028 - __main__ - INFO - Epoch  65 Step:    20400 Batch Loss:     0.000467 [Torso :     0.000285, Hand :     0.000648, Face :     0.000288]Tokens per Sec:  6264890, Lr: 0.000490\n","2020-11-28 10:07:44,030 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 10:13:01,771 - __main__ - INFO - Validation result at epoch  65, step    20400: Val DTW Score:  55.74, loss:   4.6453,  duration: 317.7395s\n","2020-11-28 10:13:17,415 - __main__ - INFO - Epoch  65 Step:    20440 Batch Loss:     0.000572 [Torso :     0.000381, Hand :     0.000769, Face :     0.000358]Tokens per Sec:  5534471, Lr: 0.000490\n","2020-11-28 10:13:31,104 - __main__ - INFO - Epoch  65 Step:    20480 Batch Loss:     0.000468 [Torso :     0.000287, Hand :     0.000651, Face :     0.000279]Tokens per Sec:  6303743, Lr: 0.000490\n","2020-11-28 10:13:44,366 - __main__ - INFO - Epoch  65 Step:    20520 Batch Loss:     0.000588 [Torso :     0.000323, Hand :     0.000851, Face :     0.000335]Tokens per Sec:  6393469, Lr: 0.000490\n","2020-11-28 10:13:58,122 - __main__ - INFO - Epoch  65 Step:    20560 Batch Loss:     0.000562 [Torso :     0.000347, Hand :     0.000777, Face :     0.000347]Tokens per Sec:  6301074, Lr: 0.000490\n","2020-11-28 10:14:11,351 - __main__ - INFO - Epoch  65 Step:    20600 Batch Loss:     0.000791 [Torso :     0.000511, Hand :     0.001079, Face :     0.000472]Tokens per Sec:  6338348, Lr: 0.000490\n","2020-11-28 10:14:13,274 - __main__ - INFO - Epoch  65: total training loss 0.19064 [torso: 0.12377, hand: 0.25899, face: 0.11633\n","2020-11-28 10:14:25,733 - __main__ - INFO - Epoch  66 Step:    20640 Batch Loss:     0.000540 [Torso :     0.000330, Hand :     0.000748, Face :     0.000337]Tokens per Sec:  6259899, Lr: 0.000490\n","2020-11-28 10:14:39,459 - __main__ - INFO - Epoch  66 Step:    20680 Batch Loss:     0.000635 [Torso :     0.000360, Hand :     0.000906, Face :     0.000381]Tokens per Sec:  6264654, Lr: 0.000490\n","2020-11-28 10:14:45,847 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 10:19:57,752 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 10:19:57,754 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 10:20:10,953 - __main__ - INFO - Validation result at epoch  66, step    20700: Val DTW Score:  53.96, loss:   4.4040,  duration: 325.1042s\n","2020-11-28 10:20:19,888 - __main__ - INFO - Epoch  66 Step:    20720 Batch Loss:     0.000453 [Torso :     0.000278, Hand :     0.000630, Face :     0.000271]Tokens per Sec:  5517913, Lr: 0.000490\n","2020-11-28 10:20:36,585 - __main__ - INFO - Epoch  66 Step:    20760 Batch Loss:     0.000629 [Torso :     0.000391, Hand :     0.000873, Face :     0.000361]Tokens per Sec:  5297005, Lr: 0.000490\n","2020-11-28 10:20:49,681 - __main__ - INFO - Epoch  66 Step:    20800 Batch Loss:     0.000732 [Torso :     0.000456, Hand :     0.001004, Face :     0.000476]Tokens per Sec:  6462693, Lr: 0.000490\n","2020-11-28 10:21:03,362 - __main__ - INFO - Epoch  66 Step:    20840 Batch Loss:     0.000622 [Torso :     0.000373, Hand :     0.000869, Face :     0.000385]Tokens per Sec:  6257192, Lr: 0.000490\n","2020-11-28 10:21:17,625 - __main__ - INFO - Epoch  66 Step:    20880 Batch Loss:     0.000644 [Torso :     0.000453, Hand :     0.000841, Face :     0.000424]Tokens per Sec:  6163326, Lr: 0.000490\n","2020-11-28 10:21:31,128 - __main__ - INFO - Epoch  66 Step:    20920 Batch Loss:     0.000505 [Torso :     0.000329, Hand :     0.000684, Face :     0.000312]Tokens per Sec:  6344937, Lr: 0.000490\n","2020-11-28 10:21:31,632 - __main__ - INFO - Epoch  66: total training loss 0.19130 [torso: 0.12309, hand: 0.26088, face: 0.11630\n","2020-11-28 10:21:44,361 - __main__ - INFO - Epoch  67 Step:    20960 Batch Loss:     0.000714 [Torso :     0.000467, Hand :     0.000971, Face :     0.000415]Tokens per Sec:  6374798, Lr: 0.000490\n","2020-11-28 10:21:57,336 - __main__ - INFO - Epoch  67 Step:    21000 Batch Loss:     0.000584 [Torso :     0.000412, Hand :     0.000772, Face :     0.000328]Tokens per Sec:  6481271, Lr: 0.000490\n","2020-11-28 10:21:57,338 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 10:27:06,536 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 10:27:06,538 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 10:27:19,279 - __main__ - INFO - Validation result at epoch  67, step    21000: Val DTW Score:  52.25, loss:   4.3372,  duration: 321.9400s\n","2020-11-28 10:27:36,617 - __main__ - INFO - Epoch  67 Step:    21040 Batch Loss:     0.000589 [Torso :     0.000404, Hand :     0.000784, Face :     0.000357]Tokens per Sec:  5257677, Lr: 0.000490\n","2020-11-28 10:27:51,015 - __main__ - INFO - Epoch  67 Step:    21080 Batch Loss:     0.000534 [Torso :     0.000337, Hand :     0.000736, Face :     0.000312]Tokens per Sec:  5982348, Lr: 0.000490\n","2020-11-28 10:28:05,657 - __main__ - INFO - Epoch  67 Step:    21120 Batch Loss:     0.000527 [Torso :     0.000326, Hand :     0.000729, Face :     0.000318]Tokens per Sec:  6224134, Lr: 0.000490\n","2020-11-28 10:28:18,674 - __main__ - INFO - Epoch  67 Step:    21160 Batch Loss:     0.000714 [Torso :     0.000405, Hand :     0.001018, Face :     0.000434]Tokens per Sec:  6460884, Lr: 0.000490\n","2020-11-28 10:28:32,721 - __main__ - INFO - Epoch  67 Step:    21200 Batch Loss:     0.000575 [Torso :     0.000381, Hand :     0.000777, Face :     0.000345]Tokens per Sec:  6342537, Lr: 0.000490\n","2020-11-28 10:28:45,860 - __main__ - INFO - Epoch  67: total training loss 0.18713 [torso: 0.12125, hand: 0.25448, face: 0.11395\n","2020-11-28 10:28:46,183 - __main__ - INFO - Epoch  68 Step:    21240 Batch Loss:     0.000685 [Torso :     0.000424, Hand :     0.000949, Face :     0.000408]Tokens per Sec:  6384571, Lr: 0.000490\n","2020-11-28 10:29:00,665 - __main__ - INFO - Epoch  68 Step:    21280 Batch Loss:     0.000515 [Torso :     0.000345, Hand :     0.000692, Face :     0.000314]Tokens per Sec:  6263390, Lr: 0.000490\n","2020-11-28 10:29:07,685 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 10:34:16,990 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 10:34:16,992 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 10:34:31,116 - __main__ - INFO - Validation result at epoch  68, step    21300: Val DTW Score:  51.22, loss:   4.3896,  duration: 323.4288s\n","2020-11-28 10:34:39,074 - __main__ - INFO - Epoch  68 Step:    21320 Batch Loss:     0.000452 [Torso :     0.000315, Hand :     0.000599, Face :     0.000265]Tokens per Sec:  5657502, Lr: 0.000490\n","2020-11-28 10:34:53,737 - __main__ - INFO - Epoch  68 Step:    21360 Batch Loss:     0.000535 [Torso :     0.000338, Hand :     0.000736, Face :     0.000323]Tokens per Sec:  5832595, Lr: 0.000490\n","2020-11-28 10:35:07,777 - __main__ - INFO - Epoch  68 Step:    21400 Batch Loss:     0.000550 [Torso :     0.000330, Hand :     0.000768, Face :     0.000341]Tokens per Sec:  6310126, Lr: 0.000490\n","2020-11-28 10:35:21,215 - __main__ - INFO - Epoch  68 Step:    21440 Batch Loss:     0.000554 [Torso :     0.000372, Hand :     0.000746, Face :     0.000318]Tokens per Sec:  6404611, Lr: 0.000490\n","2020-11-28 10:35:34,227 - __main__ - INFO - Epoch  68 Step:    21480 Batch Loss:     0.000750 [Torso :     0.000512, Hand :     0.000999, Face :     0.000455]Tokens per Sec:  6468972, Lr: 0.000490\n","2020-11-28 10:35:48,210 - __main__ - INFO - Epoch  68 Step:    21520 Batch Loss:     0.000418 [Torso :     0.000312, Hand :     0.000536, Face :     0.000251]Tokens per Sec:  6336359, Lr: 0.000490\n","2020-11-28 10:35:59,955 - __main__ - INFO - Epoch  68: total training loss 0.18840 [torso: 0.12157, hand: 0.25659, face: 0.11472\n","2020-11-28 10:36:01,297 - __main__ - INFO - Epoch  69 Step:    21560 Batch Loss:     0.000680 [Torso :     0.000492, Hand :     0.000883, Face :     0.000415]Tokens per Sec:  6025340, Lr: 0.000490\n","2020-11-28 10:36:14,800 - __main__ - INFO - Epoch  69 Step:    21600 Batch Loss:     0.000567 [Torso :     0.000355, Hand :     0.000773, Face :     0.000383]Tokens per Sec:  6316547, Lr: 0.000490\n","2020-11-28 10:36:14,801 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 10:41:27,722 - __main__ - INFO - Validation result at epoch  69, step    21600: Val DTW Score:  55.15, loss:   4.5140,  duration: 312.9198s\n","2020-11-28 10:41:42,545 - __main__ - INFO - Epoch  69 Step:    21640 Batch Loss:     0.000636 [Torso :     0.000439, Hand :     0.000840, Face :     0.000400]Tokens per Sec:  5937134, Lr: 0.000490\n","2020-11-28 10:41:56,768 - __main__ - INFO - Epoch  69 Step:    21680 Batch Loss:     0.000646 [Torso :     0.000397, Hand :     0.000894, Face :     0.000401]Tokens per Sec:  6039975, Lr: 0.000490\n","2020-11-28 10:42:10,279 - __main__ - INFO - Epoch  69 Step:    21720 Batch Loss:     0.000704 [Torso :     0.000500, Hand :     0.000931, Face :     0.000382]Tokens per Sec:  6361313, Lr: 0.000490\n","2020-11-28 10:42:23,371 - __main__ - INFO - Epoch  69 Step:    21760 Batch Loss:     0.000456 [Torso :     0.000264, Hand :     0.000636, Face :     0.000321]Tokens per Sec:  6453049, Lr: 0.000490\n","2020-11-28 10:42:37,494 - __main__ - INFO - Epoch  69 Step:    21800 Batch Loss:     0.000679 [Torso :     0.000350, Hand :     0.000993, Face :     0.000425]Tokens per Sec:  6311449, Lr: 0.000490\n","2020-11-28 10:42:50,788 - __main__ - INFO - Epoch  69 Step:    21840 Batch Loss:     0.000477 [Torso :     0.000303, Hand :     0.000653, Face :     0.000298]Tokens per Sec:  6450714, Lr: 0.000490\n","2020-11-28 10:43:01,711 - __main__ - INFO - Epoch  69: total training loss 0.18896 [torso: 0.12192, hand: 0.25741, face: 0.11492\n","2020-11-28 10:43:04,222 - __main__ - INFO - Epoch  70 Step:    21880 Batch Loss:     0.000443 [Torso :     0.000290, Hand :     0.000597, Face :     0.000283]Tokens per Sec:  6127917, Lr: 0.000490\n","2020-11-28 10:43:11,346 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 10:48:25,235 - __main__ - INFO - Validation result at epoch  70, step    21900: Val DTW Score:  55.92, loss:   4.6395,  duration: 313.8873s\n","2020-11-28 10:48:32,575 - __main__ - INFO - Epoch  70 Step:    21920 Batch Loss:     0.000664 [Torso :     0.000365, Hand :     0.000955, Face :     0.000408]Tokens per Sec:  6089916, Lr: 0.000490\n","2020-11-28 10:48:46,919 - __main__ - INFO - Epoch  70 Step:    21960 Batch Loss:     0.000703 [Torso :     0.000473, Hand :     0.000930, Face :     0.000486]Tokens per Sec:  5887542, Lr: 0.000490\n","2020-11-28 10:49:00,134 - __main__ - INFO - Epoch  70 Step:    22000 Batch Loss:     0.000742 [Torso :     0.000508, Hand :     0.000988, Face :     0.000451]Tokens per Sec:  6361198, Lr: 0.000490\n","2020-11-28 10:49:13,569 - __main__ - INFO - Epoch  70 Step:    22040 Batch Loss:     0.000600 [Torso :     0.000361, Hand :     0.000841, Face :     0.000352]Tokens per Sec:  6382826, Lr: 0.000490\n","2020-11-28 10:49:27,037 - __main__ - INFO - Epoch  70 Step:    22080 Batch Loss:     0.000595 [Torso :     0.000387, Hand :     0.000804, Face :     0.000376]Tokens per Sec:  6415884, Lr: 0.000490\n","2020-11-28 10:49:41,165 - __main__ - INFO - Epoch  70 Step:    22120 Batch Loss:     0.000682 [Torso :     0.000419, Hand :     0.000947, Face :     0.000415]Tokens per Sec:  6230038, Lr: 0.000490\n","2020-11-28 10:49:54,004 - __main__ - INFO - Epoch  70 Step:    22160 Batch Loss:     0.000468 [Torso :     0.000308, Hand :     0.000634, Face :     0.000277]Tokens per Sec:  6499428, Lr: 0.000490\n","2020-11-28 10:50:04,144 - __main__ - INFO - Epoch  70: total training loss 0.18954 [torso: 0.12280, hand: 0.25777, face: 0.11538\n","2020-11-28 10:50:07,389 - __main__ - INFO - Epoch  71 Step:    22200 Batch Loss:     0.000416 [Torso :     0.000292, Hand :     0.000550, Face :     0.000245]Tokens per Sec:  6316567, Lr: 0.000490\n","2020-11-28 10:50:07,390 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 10:55:22,318 - __main__ - INFO - Validation result at epoch  71, step    22200: Val DTW Score:  53.50, loss:   4.6084,  duration: 314.9255s\n","2020-11-28 10:55:37,814 - __main__ - INFO - Epoch  71 Step:    22240 Batch Loss:     0.000424 [Torso :     0.000267, Hand :     0.000584, Face :     0.000251]Tokens per Sec:  5544806, Lr: 0.000490\n","2020-11-28 10:55:52,417 - __main__ - INFO - Epoch  71 Step:    22280 Batch Loss:     0.000609 [Torso :     0.000349, Hand :     0.000861, Face :     0.000383]Tokens per Sec:  6272549, Lr: 0.000490\n","2020-11-28 10:56:05,226 - __main__ - INFO - Epoch  71 Step:    22320 Batch Loss:     0.000386 [Torso :     0.000251, Hand :     0.000523, Face :     0.000240]Tokens per Sec:  6481963, Lr: 0.000490\n","2020-11-28 10:56:18,583 - __main__ - INFO - Epoch  71 Step:    22360 Batch Loss:     0.000556 [Torso :     0.000398, Hand :     0.000727, Face :     0.000329]Tokens per Sec:  6393771, Lr: 0.000490\n","2020-11-28 10:56:32,835 - __main__ - INFO - Epoch  71 Step:    22400 Batch Loss:     0.000521 [Torso :     0.000313, Hand :     0.000725, Face :     0.000337]Tokens per Sec:  6316225, Lr: 0.000490\n","2020-11-28 10:56:46,075 - __main__ - INFO - Epoch  71 Step:    22440 Batch Loss:     0.000698 [Torso :     0.000433, Hand :     0.000957, Face :     0.000458]Tokens per Sec:  6453904, Lr: 0.000490\n","2020-11-28 10:56:59,461 - __main__ - INFO - Epoch  71 Step:    22480 Batch Loss:     0.000742 [Torso :     0.000458, Hand :     0.001033, Face :     0.000422]Tokens per Sec:  6440746, Lr: 0.000490\n","2020-11-28 10:57:05,473 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 11:02:14,722 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 11:02:14,724 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 11:02:29,113 - __main__ - INFO - Validation result at epoch  71, step    22500: Val DTW Score:  49.53, loss:   4.2069,  duration: 323.6385s\n","2020-11-28 11:02:32,486 - __main__ - INFO - Epoch  71: total training loss 0.18577 [torso: 0.12033, hand: 0.25268, face: 0.11297\n","2020-11-28 11:02:38,575 - __main__ - INFO - Epoch  72 Step:    22520 Batch Loss:     0.000476 [Torso :     0.000320, Hand :     0.000639, Face :     0.000280]Tokens per Sec:  5037728, Lr: 0.000490\n","2020-11-28 11:02:53,058 - __main__ - INFO - Epoch  72 Step:    22560 Batch Loss:     0.000584 [Torso :     0.000411, Hand :     0.000767, Face :     0.000354]Tokens per Sec:  5734036, Lr: 0.000490\n","2020-11-28 11:03:06,675 - __main__ - INFO - Epoch  72 Step:    22600 Batch Loss:     0.000395 [Torso :     0.000233, Hand :     0.000557, Face :     0.000235]Tokens per Sec:  6373530, Lr: 0.000490\n","2020-11-28 11:03:20,002 - __main__ - INFO - Epoch  72 Step:    22640 Batch Loss:     0.000659 [Torso :     0.000410, Hand :     0.000908, Face :     0.000409]Tokens per Sec:  6382842, Lr: 0.000490\n","2020-11-28 11:03:33,822 - __main__ - INFO - Epoch  72 Step:    22680 Batch Loss:     0.000744 [Torso :     0.000440, Hand :     0.001043, Face :     0.000465]Tokens per Sec:  6296753, Lr: 0.000490\n","2020-11-28 11:03:48,074 - __main__ - INFO - Epoch  72 Step:    22720 Batch Loss:     0.000455 [Torso :     0.000348, Hand :     0.000577, Face :     0.000270]Tokens per Sec:  6221906, Lr: 0.000490\n","2020-11-28 11:04:01,702 - __main__ - INFO - Epoch  72 Step:    22760 Batch Loss:     0.000568 [Torso :     0.000383, Hand :     0.000764, Face :     0.000328]Tokens per Sec:  6391097, Lr: 0.000490\n","2020-11-28 11:04:15,319 - __main__ - INFO - Epoch  72 Step:    22800 Batch Loss:     0.000477 [Torso :     0.000288, Hand :     0.000666, Face :     0.000287]Tokens per Sec:  6353932, Lr: 0.000490\n","2020-11-28 11:04:15,321 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 11:09:30,021 - __main__ - INFO - Validation result at epoch  72, step    22800: Val DTW Score:  55.29, loss:   4.6118,  duration: 314.6986s\n","2020-11-28 11:09:38,792 - __main__ - INFO - Epoch  72: total training loss 0.18331 [torso: 0.11849, hand: 0.24948, face: 0.11173\n","2020-11-28 11:09:45,329 - __main__ - INFO - Epoch  73 Step:    22840 Batch Loss:     0.000752 [Torso :     0.000586, Hand :     0.000948, Face :     0.000438]Tokens per Sec:  5204966, Lr: 0.000490\n","2020-11-28 11:09:59,358 - __main__ - INFO - Epoch  73 Step:    22880 Batch Loss:     0.000667 [Torso :     0.000392, Hand :     0.000931, Face :     0.000450]Tokens per Sec:  6129046, Lr: 0.000490\n","2020-11-28 11:10:13,250 - __main__ - INFO - Epoch  73 Step:    22920 Batch Loss:     0.000555 [Torso :     0.000372, Hand :     0.000745, Face :     0.000334]Tokens per Sec:  6219988, Lr: 0.000490\n","2020-11-28 11:10:25,995 - __main__ - INFO - Epoch  73 Step:    22960 Batch Loss:     0.000513 [Torso :     0.000385, Hand :     0.000657, Face :     0.000304]Tokens per Sec:  6450872, Lr: 0.000490\n","2020-11-28 11:10:40,149 - __main__ - INFO - Epoch  73 Step:    23000 Batch Loss:     0.000648 [Torso :     0.000431, Hand :     0.000871, Face :     0.000405]Tokens per Sec:  6278742, Lr: 0.000490\n","2020-11-28 11:10:53,555 - __main__ - INFO - Epoch  73 Step:    23040 Batch Loss:     0.000596 [Torso :     0.000339, Hand :     0.000845, Face :     0.000376]Tokens per Sec:  6468149, Lr: 0.000490\n","2020-11-28 11:11:07,951 - __main__ - INFO - Epoch  73 Step:    23080 Batch Loss:     0.000460 [Torso :     0.000312, Hand :     0.000618, Face :     0.000266]Tokens per Sec:  6234420, Lr: 0.000490\n","2020-11-28 11:11:14,445 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 11:16:30,526 - __main__ - INFO - Validation result at epoch  73, step    23100: Val DTW Score:  53.57, loss:   4.4436,  duration: 316.0794s\n","2020-11-28 11:16:37,130 - __main__ - INFO - Epoch  73 Step:    23120 Batch Loss:     0.000529 [Torso :     0.000365, Hand :     0.000704, Face :     0.000316]Tokens per Sec:  6425831, Lr: 0.000490\n","2020-11-28 11:16:45,371 - __main__ - INFO - Epoch  73: total training loss 0.18496 [torso: 0.11969, hand: 0.25164, face: 0.11269\n","2020-11-28 11:16:52,581 - __main__ - INFO - Epoch  74 Step:    23160 Batch Loss:     0.000592 [Torso :     0.000431, Hand :     0.000771, Face :     0.000337]Tokens per Sec:  5683753, Lr: 0.000490\n","2020-11-28 11:17:06,848 - __main__ - INFO - Epoch  74 Step:    23200 Batch Loss:     0.000567 [Torso :     0.000356, Hand :     0.000779, Face :     0.000353]Tokens per Sec:  6171956, Lr: 0.000490\n","2020-11-28 11:17:20,564 - __main__ - INFO - Epoch  74 Step:    23240 Batch Loss:     0.000592 [Torso :     0.000389, Hand :     0.000801, Face :     0.000358]Tokens per Sec:  6300093, Lr: 0.000490\n","2020-11-28 11:17:34,018 - __main__ - INFO - Epoch  74 Step:    23280 Batch Loss:     0.000578 [Torso :     0.000367, Hand :     0.000791, Face :     0.000355]Tokens per Sec:  6308141, Lr: 0.000490\n","2020-11-28 11:17:47,899 - __main__ - INFO - Epoch  74 Step:    23320 Batch Loss:     0.000522 [Torso :     0.000372, Hand :     0.000682, Face :     0.000322]Tokens per Sec:  6241511, Lr: 0.000490\n","2020-11-28 11:18:01,428 - __main__ - INFO - Epoch  74 Step:    23360 Batch Loss:     0.000614 [Torso :     0.000352, Hand :     0.000866, Face :     0.000405]Tokens per Sec:  6301846, Lr: 0.000490\n","2020-11-28 11:18:14,941 - __main__ - INFO - Epoch  74 Step:    23400 Batch Loss:     0.000697 [Torso :     0.000489, Hand :     0.000920, Face :     0.000409]Tokens per Sec:  6379997, Lr: 0.000490\n","2020-11-28 11:18:14,943 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 11:23:21,218 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 11:23:21,219 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 11:23:35,334 - __main__ - INFO - Validation result at epoch  74, step    23400: Val DTW Score:  47.99, loss:   4.3247,  duration: 320.3895s\n","2020-11-28 11:23:51,273 - __main__ - INFO - Epoch  74 Step:    23440 Batch Loss:     0.000585 [Torso :     0.000356, Hand :     0.000804, Face :     0.000402]Tokens per Sec:  5328225, Lr: 0.000490\n","2020-11-28 11:23:57,266 - __main__ - INFO - Epoch  74: total training loss 0.18457 [torso: 0.11951, hand: 0.25108, face: 0.11229\n","2020-11-28 11:24:04,566 - __main__ - INFO - Epoch  75 Step:    23480 Batch Loss:     0.000470 [Torso :     0.000333, Hand :     0.000619, Face :     0.000267]Tokens per Sec:  6518985, Lr: 0.000490\n","2020-11-28 11:24:18,047 - __main__ - INFO - Epoch  75 Step:    23520 Batch Loss:     0.000644 [Torso :     0.000408, Hand :     0.000882, Face :     0.000402]Tokens per Sec:  6472086, Lr: 0.000490\n","2020-11-28 11:24:31,648 - __main__ - INFO - Epoch  75 Step:    23560 Batch Loss:     0.000389 [Torso :     0.000283, Hand :     0.000504, Face :     0.000237]Tokens per Sec:  6449155, Lr: 0.000490\n","2020-11-28 11:24:44,913 - __main__ - INFO - Epoch  75 Step:    23600 Batch Loss:     0.000611 [Torso :     0.000352, Hand :     0.000862, Face :     0.000394]Tokens per Sec:  6412663, Lr: 0.000490\n","2020-11-28 11:24:58,217 - __main__ - INFO - Epoch  75 Step:    23640 Batch Loss:     0.000680 [Torso :     0.000426, Hand :     0.000934, Face :     0.000426]Tokens per Sec:  6492102, Lr: 0.000490\n","2020-11-28 11:25:11,298 - __main__ - INFO - Epoch  75 Step:    23680 Batch Loss:     0.000665 [Torso :     0.000433, Hand :     0.000905, Face :     0.000395]Tokens per Sec:  6523194, Lr: 0.000490\n","2020-11-28 11:25:18,066 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 11:30:27,711 - __main__ - INFO - Validation result at epoch  75, step    23700: Val DTW Score:  54.19, loss:   4.4302,  duration: 309.6431s\n","2020-11-28 11:30:34,285 - __main__ - INFO - Epoch  75 Step:    23720 Batch Loss:     0.000594 [Torso :     0.000408, Hand :     0.000790, Face :     0.000355]Tokens per Sec:  6486907, Lr: 0.000490\n","2020-11-28 11:30:49,422 - __main__ - INFO - Epoch  75 Step:    23760 Batch Loss:     0.000626 [Torso :     0.000370, Hand :     0.000874, Face :     0.000406]Tokens per Sec:  5596380, Lr: 0.000490\n","2020-11-28 11:30:54,242 - __main__ - INFO - Epoch  75: total training loss 0.18417 [torso: 0.11951, hand: 0.25030, face: 0.11216\n","2020-11-28 11:31:02,193 - __main__ - INFO - Epoch  76 Step:    23800 Batch Loss:     0.000544 [Torso :     0.000401, Hand :     0.000700, Face :     0.000330]Tokens per Sec:  6541544, Lr: 0.000490\n","2020-11-28 11:31:15,603 - __main__ - INFO - Epoch  76 Step:    23840 Batch Loss:     0.000548 [Torso :     0.000330, Hand :     0.000765, Face :     0.000335]Tokens per Sec:  6412232, Lr: 0.000490\n","2020-11-28 11:31:29,172 - __main__ - INFO - Epoch  76 Step:    23880 Batch Loss:     0.000695 [Torso :     0.000423, Hand :     0.000954, Face :     0.000492]Tokens per Sec:  6435661, Lr: 0.000490\n","2020-11-28 11:31:43,243 - __main__ - INFO - Epoch  76 Step:    23920 Batch Loss:     0.000450 [Torso :     0.000267, Hand :     0.000632, Face :     0.000267]Tokens per Sec:  6331880, Lr: 0.000490\n","2020-11-28 11:31:56,127 - __main__ - INFO - Epoch  76 Step:    23960 Batch Loss:     0.000556 [Torso :     0.000402, Hand :     0.000727, Face :     0.000322]Tokens per Sec:  6545102, Lr: 0.000490\n","2020-11-28 11:32:09,793 - __main__ - INFO - Epoch  76 Step:    24000 Batch Loss:     0.000604 [Torso :     0.000403, Hand :     0.000811, Face :     0.000370]Tokens per Sec:  6350815, Lr: 0.000490\n","2020-11-28 11:32:09,795 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 11:37:18,924 - __main__ - INFO - Validation result at epoch  76, step    24000: Val DTW Score:  49.80, loss:   4.4197,  duration: 309.1284s\n","2020-11-28 11:37:32,977 - __main__ - INFO - Epoch  76 Step:    24040 Batch Loss:     0.000534 [Torso :     0.000313, Hand :     0.000755, Face :     0.000311]Tokens per Sec:  6016176, Lr: 0.000490\n","2020-11-28 11:37:47,242 - __main__ - INFO - Epoch  76 Step:    24080 Batch Loss:     0.000455 [Torso :     0.000291, Hand :     0.000628, Face :     0.000243]Tokens per Sec:  6160076, Lr: 0.000490\n","2020-11-28 11:37:50,987 - __main__ - INFO - Epoch  76: total training loss 0.18361 [torso: 0.11917, hand: 0.24955, face: 0.11169\n","2020-11-28 11:38:00,587 - __main__ - INFO - Epoch  77 Step:    24120 Batch Loss:     0.000564 [Torso :     0.000388, Hand :     0.000753, Face :     0.000327]Tokens per Sec:  6406728, Lr: 0.000490\n","2020-11-28 11:38:13,810 - __main__ - INFO - Epoch  77 Step:    24160 Batch Loss:     0.000475 [Torso :     0.000319, Hand :     0.000638, Face :     0.000289]Tokens per Sec:  6465116, Lr: 0.000490\n","2020-11-28 11:38:27,553 - __main__ - INFO - Epoch  77 Step:    24200 Batch Loss:     0.000507 [Torso :     0.000376, Hand :     0.000652, Face :     0.000302]Tokens per Sec:  6424187, Lr: 0.000490\n","2020-11-28 11:38:39,780 - __main__ - INFO - Epoch  77 Step:    24240 Batch Loss:     0.000704 [Torso :     0.000399, Hand :     0.001001, Face :     0.000434]Tokens per Sec:  6673784, Lr: 0.000490\n","2020-11-28 11:38:53,975 - __main__ - INFO - Epoch  77 Step:    24280 Batch Loss:     0.000501 [Torso :     0.000293, Hand :     0.000705, Face :     0.000312]Tokens per Sec:  6463729, Lr: 0.000490\n","2020-11-28 11:39:00,074 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 11:44:06,050 - __main__ - INFO - Validation result at epoch  77, step    24300: Val DTW Score:  53.44, loss:   4.2708,  duration: 305.9736s\n","2020-11-28 11:44:13,200 - __main__ - INFO - Epoch  77 Step:    24320 Batch Loss:     0.000497 [Torso :     0.000330, Hand :     0.000669, Face :     0.000305]Tokens per Sec:  6393125, Lr: 0.000490\n","2020-11-28 11:44:26,989 - __main__ - INFO - Epoch  77 Step:    24360 Batch Loss:     0.000724 [Torso :     0.000417, Hand :     0.001025, Face :     0.000446]Tokens per Sec:  6004131, Lr: 0.000490\n","2020-11-28 11:44:40,171 - __main__ - INFO - Epoch  77 Step:    24400 Batch Loss:     0.000761 [Torso :     0.000438, Hand :     0.001077, Face :     0.000476]Tokens per Sec:  6581240, Lr: 0.000490\n","2020-11-28 11:44:42,724 - __main__ - INFO - Epoch  77: total training loss 0.18245 [torso: 0.11753, hand: 0.24859, face: 0.11137\n","2020-11-28 11:44:51,825 - __main__ - INFO - Epoch  78 Step:    24440 Batch Loss:     0.000686 [Torso :     0.000377, Hand :     0.000980, Face :     0.000450]Tokens per Sec:  6838599, Lr: 0.000490\n","2020-11-28 11:45:04,453 - __main__ - INFO - Epoch  78 Step:    24480 Batch Loss:     0.000552 [Torso :     0.000346, Hand :     0.000761, Face :     0.000331]Tokens per Sec:  6720970, Lr: 0.000490\n","2020-11-28 11:45:17,969 - __main__ - INFO - Epoch  78 Step:    24520 Batch Loss:     0.000509 [Torso :     0.000364, Hand :     0.000663, Face :     0.000316]Tokens per Sec:  6637668, Lr: 0.000490\n","2020-11-28 11:45:30,567 - __main__ - INFO - Epoch  78 Step:    24560 Batch Loss:     0.000613 [Torso :     0.000416, Hand :     0.000823, Face :     0.000347]Tokens per Sec:  6678459, Lr: 0.000490\n","2020-11-28 11:45:44,042 - __main__ - INFO - Epoch  78 Step:    24600 Batch Loss:     0.000386 [Torso :     0.000264, Hand :     0.000514, Face :     0.000237]Tokens per Sec:  6483455, Lr: 0.000490\n","2020-11-28 11:45:44,044 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 11:50:51,272 - __main__ - INFO - Validation result at epoch  78, step    24600: Val DTW Score:  49.72, loss:   4.3335,  duration: 307.2266s\n","2020-11-28 11:51:06,966 - __main__ - INFO - Epoch  78 Step:    24640 Batch Loss:     0.000470 [Torso :     0.000315, Hand :     0.000630, Face :     0.000285]Tokens per Sec:  5587947, Lr: 0.000490\n","2020-11-28 11:51:20,272 - __main__ - INFO - Epoch  78 Step:    24680 Batch Loss:     0.000738 [Torso :     0.000436, Hand :     0.001038, Face :     0.000454]Tokens per Sec:  6479473, Lr: 0.000490\n","2020-11-28 11:51:33,663 - __main__ - INFO - Epoch  78 Step:    24720 Batch Loss:     0.000421 [Torso :     0.000294, Hand :     0.000560, Face :     0.000240]Tokens per Sec:  6472314, Lr: 0.000490\n","2020-11-28 11:51:35,645 - __main__ - INFO - Epoch  78: total training loss 0.18280 [torso: 0.11787, hand: 0.24904, face: 0.11128\n","2020-11-28 11:51:46,649 - __main__ - INFO - Epoch  79 Step:    24760 Batch Loss:     0.000453 [Torso :     0.000305, Hand :     0.000606, Face :     0.000275]Tokens per Sec:  6544368, Lr: 0.000490\n","2020-11-28 11:52:00,538 - __main__ - INFO - Epoch  79 Step:    24800 Batch Loss:     0.000394 [Torso :     0.000259, Hand :     0.000533, Face :     0.000231]Tokens per Sec:  6403787, Lr: 0.000490\n","2020-11-28 11:52:14,119 - __main__ - INFO - Epoch  79 Step:    24840 Batch Loss:     0.000668 [Torso :     0.000461, Hand :     0.000884, Face :     0.000418]Tokens per Sec:  6373403, Lr: 0.000490\n","2020-11-28 11:52:27,728 - __main__ - INFO - Epoch  79 Step:    24880 Batch Loss:     0.000504 [Torso :     0.000285, Hand :     0.000718, Face :     0.000307]Tokens per Sec:  6484879, Lr: 0.000490\n","2020-11-28 11:52:33,997 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 11:57:43,240 - __main__ - INFO - Validation result at epoch  79, step    24900: Val DTW Score:  49.14, loss:   4.1693,  duration: 309.2412s\n","2020-11-28 11:57:50,417 - __main__ - INFO - Epoch  79 Step:    24920 Batch Loss:     0.000537 [Torso :     0.000317, Hand :     0.000754, Face :     0.000332]Tokens per Sec:  6325017, Lr: 0.000490\n","2020-11-28 11:58:04,474 - __main__ - INFO - Epoch  79 Step:    24960 Batch Loss:     0.000631 [Torso :     0.000528, Hand :     0.000773, Face :     0.000333]Tokens per Sec:  5950098, Lr: 0.000490\n","2020-11-28 11:58:18,077 - __main__ - INFO - Epoch  79 Step:    25000 Batch Loss:     0.000523 [Torso :     0.000284, Hand :     0.000754, Face :     0.000324]Tokens per Sec:  6510023, Lr: 0.000490\n","2020-11-28 11:58:31,333 - __main__ - INFO - Epoch  79 Step:    25040 Batch Loss:     0.001110 [Torso :     0.000699, Hand :     0.001520, Face :     0.000703]Tokens per Sec:  6450090, Lr: 0.000490\n","2020-11-28 11:58:32,292 - __main__ - INFO - Epoch  79: total training loss 0.18057 [torso: 0.11670, hand: 0.24573, face: 0.11019\n","2020-11-28 11:58:44,590 - __main__ - INFO - Epoch  80 Step:    25080 Batch Loss:     0.000713 [Torso :     0.000444, Hand :     0.000984, Face :     0.000434]Tokens per Sec:  6497881, Lr: 0.000490\n","2020-11-28 11:58:57,519 - __main__ - INFO - Epoch  80 Step:    25120 Batch Loss:     0.000452 [Torso :     0.000277, Hand :     0.000626, Face :     0.000280]Tokens per Sec:  6573354, Lr: 0.000490\n","2020-11-28 11:59:11,352 - __main__ - INFO - Epoch  80 Step:    25160 Batch Loss:     0.000574 [Torso :     0.000331, Hand :     0.000820, Face :     0.000317]Tokens per Sec:  6504901, Lr: 0.000490\n","2020-11-28 11:59:24,529 - __main__ - INFO - Epoch  80 Step:    25200 Batch Loss:     0.000435 [Torso :     0.000282, Hand :     0.000591, Face :     0.000268]Tokens per Sec:  6583924, Lr: 0.000490\n","2020-11-28 11:59:24,530 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 12:04:31,819 - __main__ - INFO - Validation result at epoch  80, step    25200: Val DTW Score:  52.39, loss:   4.3457,  duration: 307.2865s\n","2020-11-28 12:04:46,718 - __main__ - INFO - Epoch  80 Step:    25240 Batch Loss:     0.000592 [Torso :     0.000334, Hand :     0.000843, Face :     0.000366]Tokens per Sec:  5754007, Lr: 0.000490\n","2020-11-28 12:05:00,819 - __main__ - INFO - Epoch  80 Step:    25280 Batch Loss:     0.000445 [Torso :     0.000316, Hand :     0.000580, Face :     0.000284]Tokens per Sec:  6296724, Lr: 0.000490\n","2020-11-28 12:05:13,586 - __main__ - INFO - Epoch  80 Step:    25320 Batch Loss:     0.000737 [Torso :     0.000484, Hand :     0.001000, Face :     0.000438]Tokens per Sec:  6608853, Lr: 0.000490\n","2020-11-28 12:05:26,754 - __main__ - INFO - Epoch  80 Step:    25360 Batch Loss:     0.000322 [Torso :     0.000213, Hand :     0.000436, Face :     0.000184]Tokens per Sec:  6511726, Lr: 0.000490\n","2020-11-28 12:05:26,756 - __main__ - INFO - Epoch  80: total training loss 0.17854 [torso: 0.11475, hand: 0.24347, face: 0.10900\n","2020-11-28 12:05:40,727 - __main__ - INFO - Epoch  81 Step:    25400 Batch Loss:     0.000442 [Torso :     0.000268, Hand :     0.000616, Face :     0.000265]Tokens per Sec:  6432317, Lr: 0.000490\n","2020-11-28 12:05:53,669 - __main__ - INFO - Epoch  81 Step:    25440 Batch Loss:     0.000587 [Torso :     0.000377, Hand :     0.000809, Face :     0.000320]Tokens per Sec:  6531130, Lr: 0.000490\n","2020-11-28 12:06:07,429 - __main__ - INFO - Epoch  81 Step:    25480 Batch Loss:     0.000488 [Torso :     0.000319, Hand :     0.000662, Face :     0.000293]Tokens per Sec:  6547469, Lr: 0.000490\n","2020-11-28 12:06:14,067 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 12:11:22,688 - __main__ - INFO - Validation result at epoch  81, step    25500: Val DTW Score:  49.72, loss:   4.1834,  duration: 308.6198s\n","2020-11-28 12:11:29,436 - __main__ - INFO - Epoch  81 Step:    25520 Batch Loss:     0.000504 [Torso :     0.000365, Hand :     0.000661, Face :     0.000272]Tokens per Sec:  6394127, Lr: 0.000490\n","2020-11-28 12:11:44,226 - __main__ - INFO - Epoch  81 Step:    25560 Batch Loss:     0.000422 [Torso :     0.000303, Hand :     0.000550, Face :     0.000259]Tokens per Sec:  5855262, Lr: 0.000490\n","2020-11-28 12:11:57,401 - __main__ - INFO - Epoch  81 Step:    25600 Batch Loss:     0.000497 [Torso :     0.000325, Hand :     0.000671, Face :     0.000319]Tokens per Sec:  6514546, Lr: 0.000490\n","2020-11-28 12:12:10,908 - __main__ - INFO - Epoch  81 Step:    25640 Batch Loss:     0.000564 [Torso :     0.000349, Hand :     0.000781, Face :     0.000335]Tokens per Sec:  6505392, Lr: 0.000490\n","2020-11-28 12:12:22,458 - __main__ - INFO - Epoch  81: total training loss 0.17983 [torso: 0.11569, hand: 0.24518, face: 0.10960\n","2020-11-28 12:12:23,725 - __main__ - INFO - Epoch  82 Step:    25680 Batch Loss:     0.000415 [Torso :     0.000261, Hand :     0.000571, Face :     0.000254]Tokens per Sec:  5920847, Lr: 0.000490\n","2020-11-28 12:12:36,719 - __main__ - INFO - Epoch  82 Step:    25720 Batch Loss:     0.000522 [Torso :     0.000378, Hand :     0.000685, Face :     0.000286]Tokens per Sec:  6570023, Lr: 0.000490\n","2020-11-28 12:12:50,219 - __main__ - INFO - Epoch  82 Step:    25760 Batch Loss:     0.000517 [Torso :     0.000359, Hand :     0.000683, Face :     0.000320]Tokens per Sec:  6508355, Lr: 0.000490\n","2020-11-28 12:13:02,955 - __main__ - INFO - Epoch  82 Step:    25800 Batch Loss:     0.000694 [Torso :     0.000469, Hand :     0.000932, Face :     0.000399]Tokens per Sec:  6642751, Lr: 0.000490\n","2020-11-28 12:13:02,957 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 12:18:10,177 - __main__ - INFO - Validation result at epoch  82, step    25800: Val DTW Score:  54.12, loss:   4.4604,  duration: 307.2178s\n","2020-11-28 12:18:25,798 - __main__ - INFO - Epoch  82 Step:    25840 Batch Loss:     0.000519 [Torso :     0.000350, Hand :     0.000701, Face :     0.000288]Tokens per Sec:  5608665, Lr: 0.000343\n","2020-11-28 12:18:39,689 - __main__ - INFO - Epoch  82 Step:    25880 Batch Loss:     0.000566 [Torso :     0.000348, Hand :     0.000774, Face :     0.000395]Tokens per Sec:  6436757, Lr: 0.000343\n","2020-11-28 12:18:52,353 - __main__ - INFO - Epoch  82 Step:    25920 Batch Loss:     0.000479 [Torso :     0.000302, Hand :     0.000657, Face :     0.000302]Tokens per Sec:  6592691, Lr: 0.000343\n","2020-11-28 12:19:05,394 - __main__ - INFO - Epoch  82 Step:    25960 Batch Loss:     0.000595 [Torso :     0.000373, Hand :     0.000822, Face :     0.000350]Tokens per Sec:  6660994, Lr: 0.000343\n","2020-11-28 12:19:16,267 - __main__ - INFO - Epoch  82: total training loss 0.17639 [torso: 0.11293, hand: 0.24092, face: 0.10760\n","2020-11-28 12:19:18,323 - __main__ - INFO - Epoch  83 Step:    26000 Batch Loss:     0.000404 [Torso :     0.000260, Hand :     0.000552, Face :     0.000241]Tokens per Sec:  6361760, Lr: 0.000343\n","2020-11-28 12:19:32,330 - __main__ - INFO - Epoch  83 Step:    26040 Batch Loss:     0.000503 [Torso :     0.000311, Hand :     0.000698, Face :     0.000298]Tokens per Sec:  6481543, Lr: 0.000343\n","2020-11-28 12:19:44,824 - __main__ - INFO - Epoch  83 Step:    26080 Batch Loss:     0.000655 [Torso :     0.000360, Hand :     0.000942, Face :     0.000405]Tokens per Sec:  6500459, Lr: 0.000343\n","2020-11-28 12:19:51,586 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 12:25:00,792 - __main__ - INFO - Validation result at epoch  83, step    26100: Val DTW Score:  50.99, loss:   4.0530,  duration: 309.2044s\n","2020-11-28 12:25:07,438 - __main__ - INFO - Epoch  83 Step:    26120 Batch Loss:     0.000543 [Torso :     0.000319, Hand :     0.000763, Face :     0.000336]Tokens per Sec:  6288866, Lr: 0.000343\n","2020-11-28 12:25:22,878 - __main__ - INFO - Epoch  83 Step:    26160 Batch Loss:     0.000421 [Torso :     0.000341, Hand :     0.000518, Face :     0.000254]Tokens per Sec:  5768100, Lr: 0.000343\n","2020-11-28 12:25:35,852 - __main__ - INFO - Epoch  83 Step:    26200 Batch Loss:     0.000563 [Torso :     0.000428, Hand :     0.000717, Face :     0.000333]Tokens per Sec:  6452251, Lr: 0.000343\n","2020-11-28 12:25:49,533 - __main__ - INFO - Epoch  83 Step:    26240 Batch Loss:     0.000413 [Torso :     0.000276, Hand :     0.000558, Face :     0.000236]Tokens per Sec:  6377564, Lr: 0.000343\n","2020-11-28 12:26:02,807 - __main__ - INFO - Epoch  83 Step:    26280 Batch Loss:     0.000494 [Torso :     0.000305, Hand :     0.000688, Face :     0.000278]Tokens per Sec:  6515130, Lr: 0.000343\n","2020-11-28 12:26:14,406 - __main__ - INFO - Epoch  83: total training loss 0.17208 [torso: 0.11042, hand: 0.23478, face: 0.10523\n","2020-11-28 12:26:17,475 - __main__ - INFO - Epoch  84 Step:    26320 Batch Loss:     0.000485 [Torso :     0.000269, Hand :     0.000689, Face :     0.000328]Tokens per Sec:  6202350, Lr: 0.000343\n","2020-11-28 12:26:31,770 - __main__ - INFO - Epoch  84 Step:    26360 Batch Loss:     0.000587 [Torso :     0.000319, Hand :     0.000847, Face :     0.000358]Tokens per Sec:  6335118, Lr: 0.000343\n","2020-11-28 12:26:45,330 - __main__ - INFO - Epoch  84 Step:    26400 Batch Loss:     0.000579 [Torso :     0.000342, Hand :     0.000807, Face :     0.000385]Tokens per Sec:  6428791, Lr: 0.000343\n","2020-11-28 12:26:45,332 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 12:31:51,533 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-28 12:31:51,536 - __main__ - INFO - Saving new checkpoint.\n","2020-11-28 12:32:04,383 - __main__ - INFO - Validation result at epoch  84, step    26400: Val DTW Score:  47.79, loss:   4.0138,  duration: 319.0495s\n","2020-11-28 12:32:20,228 - __main__ - INFO - Epoch  84 Step:    26440 Batch Loss:     0.000537 [Torso :     0.000329, Hand :     0.000743, Face :     0.000339]Tokens per Sec:  5330909, Lr: 0.000343\n","2020-11-28 12:32:34,087 - __main__ - INFO - Epoch  84 Step:    26480 Batch Loss:     0.000547 [Torso :     0.000310, Hand :     0.000777, Face :     0.000352]Tokens per Sec:  6292527, Lr: 0.000343\n","2020-11-28 12:32:47,307 - __main__ - INFO - Epoch  84 Step:    26520 Batch Loss:     0.000556 [Torso :     0.000326, Hand :     0.000783, Face :     0.000338]Tokens per Sec:  6524643, Lr: 0.000343\n","2020-11-28 12:33:00,938 - __main__ - INFO - Epoch  84 Step:    26560 Batch Loss:     0.000597 [Torso :     0.000384, Hand :     0.000813, Face :     0.000373]Tokens per Sec:  6378573, Lr: 0.000343\n","2020-11-28 12:33:14,092 - __main__ - INFO - Epoch  84 Step:    26600 Batch Loss:     0.000478 [Torso :     0.000266, Hand :     0.000689, Face :     0.000272]Tokens per Sec:  6475326, Lr: 0.000343\n","2020-11-28 12:33:23,365 - __main__ - INFO - Epoch  84: total training loss 0.17058 [torso: 0.10916, hand: 0.23299, face: 0.10427\n","2020-11-28 12:33:27,777 - __main__ - INFO - Epoch  85 Step:    26640 Batch Loss:     0.000594 [Torso :     0.000339, Hand :     0.000839, Face :     0.000391]Tokens per Sec:  6212438, Lr: 0.000343\n","2020-11-28 12:33:41,813 - __main__ - INFO - Epoch  85 Step:    26680 Batch Loss:     0.000365 [Torso :     0.000246, Hand :     0.000489, Face :     0.000218]Tokens per Sec:  6303818, Lr: 0.000343\n","2020-11-28 12:33:48,554 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 12:39:00,981 - __main__ - INFO - Validation result at epoch  85, step    26700: Val DTW Score:  50.71, loss:   4.2709,  duration: 312.4253s\n","2020-11-28 12:39:07,999 - __main__ - INFO - Epoch  85 Step:    26720 Batch Loss:     0.000640 [Torso :     0.000412, Hand :     0.000871, Face :     0.000393]Tokens per Sec:  6296168, Lr: 0.000343\n","2020-11-28 12:39:23,108 - __main__ - INFO - Epoch  85 Step:    26760 Batch Loss:     0.000622 [Torso :     0.000376, Hand :     0.000862, Face :     0.000400]Tokens per Sec:  5665468, Lr: 0.000343\n","2020-11-28 12:39:37,472 - __main__ - INFO - Epoch  85 Step:    26800 Batch Loss:     0.000496 [Torso :     0.000282, Hand :     0.000706, Face :     0.000301]Tokens per Sec:  6264437, Lr: 0.000343\n","2020-11-28 12:39:49,668 - __main__ - INFO - Epoch  85 Step:    26840 Batch Loss:     0.000547 [Torso :     0.000370, Hand :     0.000734, Face :     0.000321]Tokens per Sec:  6580386, Lr: 0.000343\n","2020-11-28 12:40:03,163 - __main__ - INFO - Epoch  85 Step:    26880 Batch Loss:     0.000527 [Torso :     0.000339, Hand :     0.000719, Face :     0.000316]Tokens per Sec:  6377540, Lr: 0.000343\n","2020-11-28 12:40:16,356 - __main__ - INFO - Epoch  85 Step:    26920 Batch Loss:     0.000358 [Torso :     0.000224, Hand :     0.000492, Face :     0.000221]Tokens per Sec:  6438901, Lr: 0.000343\n","2020-11-28 12:40:24,802 - __main__ - INFO - Epoch  85: total training loss 0.17213 [torso: 0.11043, hand: 0.23483, face: 0.10536\n","2020-11-28 12:40:29,876 - __main__ - INFO - Epoch  86 Step:    26960 Batch Loss:     0.000651 [Torso :     0.000356, Hand :     0.000941, Face :     0.000379]Tokens per Sec:  6319587, Lr: 0.000343\n","2020-11-28 12:40:43,156 - __main__ - INFO - Epoch  86 Step:    27000 Batch Loss:     0.000501 [Torso :     0.000347, Hand :     0.000658, Face :     0.000329]Tokens per Sec:  6393761, Lr: 0.000343\n","2020-11-28 12:40:43,157 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 12:45:56,076 - __main__ - INFO - Validation result at epoch  86, step    27000: Val DTW Score:  49.76, loss:   4.1986,  duration: 312.9163s\n","2020-11-28 12:46:10,936 - __main__ - INFO - Epoch  86 Step:    27040 Batch Loss:     0.000673 [Torso :     0.000526, Hand :     0.000843, Face :     0.000409]Tokens per Sec:  5991336, Lr: 0.000343\n","2020-11-28 12:46:24,760 - __main__ - INFO - Epoch  86 Step:    27080 Batch Loss:     0.000594 [Torso :     0.000388, Hand :     0.000800, Face :     0.000390]Tokens per Sec:  6039163, Lr: 0.000343\n","2020-11-28 12:46:38,131 - __main__ - INFO - Epoch  86 Step:    27120 Batch Loss:     0.000639 [Torso :     0.000361, Hand :     0.000906, Face :     0.000410]Tokens per Sec:  6465283, Lr: 0.000343\n","2020-11-28 12:46:52,085 - __main__ - INFO - Epoch  86 Step:    27160 Batch Loss:     0.000457 [Torso :     0.000302, Hand :     0.000617, Face :     0.000278]Tokens per Sec:  6423362, Lr: 0.000343\n","2020-11-28 12:47:06,348 - __main__ - INFO - Epoch  86 Step:    27200 Batch Loss:     0.000334 [Torso :     0.000200, Hand :     0.000466, Face :     0.000215]Tokens per Sec:  6313929, Lr: 0.000343\n","2020-11-28 12:47:19,523 - __main__ - INFO - Epoch  86 Step:    27240 Batch Loss:     0.000673 [Torso :     0.000387, Hand :     0.000942, Face :     0.000472]Tokens per Sec:  6517798, Lr: 0.000343\n","2020-11-28 12:47:26,059 - __main__ - INFO - Epoch  86: total training loss 0.17122 [torso: 0.10887, hand: 0.23440, face: 0.10470\n","2020-11-28 12:47:31,994 - __main__ - INFO - Epoch  87 Step:    27280 Batch Loss:     0.000663 [Torso :     0.000355, Hand :     0.000959, Face :     0.000416]Tokens per Sec:  6386459, Lr: 0.000343\n","2020-11-28 12:47:39,025 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 12:52:50,981 - __main__ - INFO - Validation result at epoch  87, step    27300: Val DTW Score:  48.90, loss:   4.1528,  duration: 311.9553s\n","2020-11-28 12:52:58,094 - __main__ - INFO - Epoch  87 Step:    27320 Batch Loss:     0.000668 [Torso :     0.000385, Hand :     0.000940, Face :     0.000434]Tokens per Sec:  6255556, Lr: 0.000343\n","2020-11-28 12:53:12,894 - __main__ - INFO - Epoch  87 Step:    27360 Batch Loss:     0.000426 [Torso :     0.000253, Hand :     0.000594, Face :     0.000275]Tokens per Sec:  5597470, Lr: 0.000343\n","2020-11-28 12:53:26,288 - __main__ - INFO - Epoch  87 Step:    27400 Batch Loss:     0.000590 [Torso :     0.000379, Hand :     0.000802, Face :     0.000371]Tokens per Sec:  6433805, Lr: 0.000343\n","2020-11-28 12:53:39,688 - __main__ - INFO - Epoch  87 Step:    27440 Batch Loss:     0.000604 [Torso :     0.000377, Hand :     0.000833, Face :     0.000369]Tokens per Sec:  6457127, Lr: 0.000343\n","2020-11-28 12:53:53,045 - __main__ - INFO - Epoch  87 Step:    27480 Batch Loss:     0.000518 [Torso :     0.000310, Hand :     0.000725, Face :     0.000317]Tokens per Sec:  6394008, Lr: 0.000343\n","2020-11-28 12:54:06,366 - __main__ - INFO - Epoch  87 Step:    27520 Batch Loss:     0.000567 [Torso :     0.000347, Hand :     0.000783, Face :     0.000371]Tokens per Sec:  6555766, Lr: 0.000343\n","2020-11-28 12:54:19,999 - __main__ - INFO - Epoch  87 Step:    27560 Batch Loss:     0.000417 [Torso :     0.000267, Hand :     0.000570, Face :     0.000252]Tokens per Sec:  6484567, Lr: 0.000343\n","2020-11-28 12:54:26,397 - __main__ - INFO - Epoch  87: total training loss 0.17083 [torso: 0.10939, hand: 0.23330, face: 0.10426\n","2020-11-28 12:54:34,221 - __main__ - INFO - Epoch  88 Step:    27600 Batch Loss:     0.000467 [Torso :     0.000316, Hand :     0.000623, Face :     0.000293]Tokens per Sec:  6112279, Lr: 0.000343\n","2020-11-28 12:54:34,223 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 12:59:47,416 - __main__ - INFO - Validation result at epoch  88, step    27600: Val DTW Score:  49.22, loss:   4.0610,  duration: 313.1914s\n","2020-11-28 13:00:02,927 - __main__ - INFO - Epoch  88 Step:    27640 Batch Loss:     0.000581 [Torso :     0.000338, Hand :     0.000815, Face :     0.000380]Tokens per Sec:  5564171, Lr: 0.000343\n","2020-11-28 13:00:17,692 - __main__ - INFO - Epoch  88 Step:    27680 Batch Loss:     0.000551 [Torso :     0.000354, Hand :     0.000749, Face :     0.000346]Tokens per Sec:  6123261, Lr: 0.000343\n","2020-11-28 13:00:31,098 - __main__ - INFO - Epoch  88 Step:    27720 Batch Loss:     0.000505 [Torso :     0.000305, Hand :     0.000707, Face :     0.000297]Tokens per Sec:  6407877, Lr: 0.000343\n","2020-11-28 13:00:44,727 - __main__ - INFO - Epoch  88 Step:    27760 Batch Loss:     0.000536 [Torso :     0.000292, Hand :     0.000774, Face :     0.000319]Tokens per Sec:  6430261, Lr: 0.000343\n","2020-11-28 13:00:58,173 - __main__ - INFO - Epoch  88 Step:    27800 Batch Loss:     0.000522 [Torso :     0.000320, Hand :     0.000721, Face :     0.000339]Tokens per Sec:  6386368, Lr: 0.000343\n","2020-11-28 13:01:11,033 - __main__ - INFO - Epoch  88 Step:    27840 Batch Loss:     0.000518 [Torso :     0.000345, Hand :     0.000698, Face :     0.000310]Tokens per Sec:  6432345, Lr: 0.000343\n","2020-11-28 13:01:24,491 - __main__ - INFO - Epoch  88 Step:    27880 Batch Loss:     0.000626 [Torso :     0.000378, Hand :     0.000866, Face :     0.000417]Tokens per Sec:  6334975, Lr: 0.000343\n","2020-11-28 13:01:30,263 - __main__ - INFO - Epoch  88: total training loss 0.16973 [torso: 0.10822, hand: 0.23213, face: 0.10374\n","2020-11-28 13:01:31,700 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 13:06:44,331 - __main__ - INFO - Validation result at epoch  89, step    27900: Val DTW Score:  54.21, loss:   4.1235,  duration: 312.6290s\n","2020-11-28 13:06:51,516 - __main__ - INFO - Epoch  89 Step:    27920 Batch Loss:     0.000527 [Torso :     0.000338, Hand :     0.000724, Face :     0.000295]Tokens per Sec:  6013896, Lr: 0.000343\n","2020-11-28 13:07:06,162 - __main__ - INFO - Epoch  89 Step:    27960 Batch Loss:     0.000676 [Torso :     0.000380, Hand :     0.000960, Face :     0.000438]Tokens per Sec:  5789360, Lr: 0.000343\n","2020-11-28 13:07:19,282 - __main__ - INFO - Epoch  89 Step:    28000 Batch Loss:     0.000427 [Torso :     0.000291, Hand :     0.000570, Face :     0.000258]Tokens per Sec:  6445284, Lr: 0.000343\n","2020-11-28 13:07:33,049 - __main__ - INFO - Epoch  89 Step:    28040 Batch Loss:     0.000567 [Torso :     0.000390, Hand :     0.000758, Face :     0.000315]Tokens per Sec:  6334931, Lr: 0.000343\n","2020-11-28 13:07:46,677 - __main__ - INFO - Epoch  89 Step:    28080 Batch Loss:     0.000633 [Torso :     0.000411, Hand :     0.000857, Face :     0.000399]Tokens per Sec:  6366315, Lr: 0.000343\n","2020-11-28 13:08:00,486 - __main__ - INFO - Epoch  89 Step:    28120 Batch Loss:     0.000506 [Torso :     0.000307, Hand :     0.000708, Face :     0.000296]Tokens per Sec:  6338138, Lr: 0.000343\n","2020-11-28 13:08:14,222 - __main__ - INFO - Epoch  89 Step:    28160 Batch Loss:     0.000702 [Torso :     0.000449, Hand :     0.000951, Face :     0.000470]Tokens per Sec:  6321043, Lr: 0.000343\n","2020-11-28 13:08:28,354 - __main__ - INFO - Epoch  89 Step:    28200 Batch Loss:     0.000638 [Torso :     0.000368, Hand :     0.000895, Face :     0.000432]Tokens per Sec:  6302127, Lr: 0.000343\n","2020-11-28 13:08:28,355 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 13:13:40,890 - __main__ - INFO - Validation result at epoch  89, step    28200: Val DTW Score:  50.97, loss:   4.1416,  duration: 312.5330s\n","2020-11-28 13:13:45,287 - __main__ - INFO - Epoch  89: total training loss 0.16996 [torso: 0.10831, hand: 0.23255, face: 0.10359\n","2020-11-28 13:13:56,223 - __main__ - INFO - Epoch  90 Step:    28240 Batch Loss:     0.000487 [Torso :     0.000343, Hand :     0.000642, Face :     0.000294]Tokens per Sec:  5153191, Lr: 0.000343\n","2020-11-28 13:14:09,242 - __main__ - INFO - Epoch  90 Step:    28280 Batch Loss:     0.000390 [Torso :     0.000299, Hand :     0.000494, Face :     0.000233]Tokens per Sec:  6442394, Lr: 0.000343\n","2020-11-28 13:14:22,573 - __main__ - INFO - Epoch  90 Step:    28320 Batch Loss:     0.000416 [Torso :     0.000251, Hand :     0.000577, Face :     0.000269]Tokens per Sec:  6412365, Lr: 0.000343\n","2020-11-28 13:14:36,315 - __main__ - INFO - Epoch  90 Step:    28360 Batch Loss:     0.000418 [Torso :     0.000240, Hand :     0.000589, Face :     0.000278]Tokens per Sec:  6396419, Lr: 0.000343\n","2020-11-28 13:14:51,630 - __main__ - INFO - Epoch  90 Step:    28400 Batch Loss:     0.000385 [Torso :     0.000239, Hand :     0.000530, Face :     0.000245]Tokens per Sec:  6186737, Lr: 0.000343\n","2020-11-28 13:15:04,863 - __main__ - INFO - Epoch  90 Step:    28440 Batch Loss:     0.000528 [Torso :     0.000314, Hand :     0.000739, Face :     0.000333]Tokens per Sec:  6396354, Lr: 0.000343\n","2020-11-28 13:15:18,368 - __main__ - INFO - Epoch  90 Step:    28480 Batch Loss:     0.000647 [Torso :     0.000363, Hand :     0.000921, Face :     0.000412]Tokens per Sec:  6466285, Lr: 0.000343\n","2020-11-28 13:15:24,921 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 13:20:39,318 - __main__ - INFO - Validation result at epoch  90, step    28500: Val DTW Score:  48.08, loss:   4.0041,  duration: 314.3953s\n","2020-11-28 13:20:46,058 - __main__ - INFO - Epoch  90 Step:    28520 Batch Loss:     0.000404 [Torso :     0.000267, Hand :     0.000545, Face :     0.000248]Tokens per Sec:  6349690, Lr: 0.000343\n","2020-11-28 13:20:50,654 - __main__ - INFO - Epoch  90: total training loss 0.16799 [torso: 0.10767, hand: 0.22930, face: 0.10267\n","2020-11-28 13:21:02,235 - __main__ - INFO - Epoch  91 Step:    28560 Batch Loss:     0.000517 [Torso :     0.000312, Hand :     0.000718, Face :     0.000332]Tokens per Sec:  5662332, Lr: 0.000343\n","2020-11-28 13:21:15,753 - __main__ - INFO - Epoch  91 Step:    28600 Batch Loss:     0.000631 [Torso :     0.000385, Hand :     0.000879, Face :     0.000376]Tokens per Sec:  6332172, Lr: 0.000343\n","2020-11-28 13:21:29,011 - __main__ - INFO - Epoch  91 Step:    28640 Batch Loss:     0.000503 [Torso :     0.000305, Hand :     0.000705, Face :     0.000284]Tokens per Sec:  6392597, Lr: 0.000343\n","2020-11-28 13:21:43,344 - __main__ - INFO - Epoch  91 Step:    28680 Batch Loss:     0.000580 [Torso :     0.000367, Hand :     0.000796, Face :     0.000350]Tokens per Sec:  6316362, Lr: 0.000343\n","2020-11-28 13:21:57,045 - __main__ - INFO - Epoch  91 Step:    28720 Batch Loss:     0.000664 [Torso :     0.000412, Hand :     0.000920, Face :     0.000387]Tokens per Sec:  6323472, Lr: 0.000343\n","2020-11-28 13:22:10,230 - __main__ - INFO - Epoch  91 Step:    28760 Batch Loss:     0.000545 [Torso :     0.000340, Hand :     0.000747, Face :     0.000351]Tokens per Sec:  6445353, Lr: 0.000343\n","2020-11-28 13:22:23,632 - __main__ - INFO - Epoch  91 Step:    28800 Batch Loss:     0.000375 [Torso :     0.000257, Hand :     0.000501, Face :     0.000217]Tokens per Sec:  6384140, Lr: 0.000343\n","2020-11-28 13:22:23,635 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 13:27:37,302 - __main__ - INFO - Validation result at epoch  91, step    28800: Val DTW Score:  52.65, loss:   4.0593,  duration: 313.6655s\n","2020-11-28 13:27:52,834 - __main__ - INFO - Epoch  91 Step:    28840 Batch Loss:     0.000894 [Torso :     0.000659, Hand :     0.001150, Face :     0.000552]Tokens per Sec:  5471089, Lr: 0.000240\n","2020-11-28 13:27:55,458 - __main__ - INFO - Epoch  91: total training loss 0.16887 [torso: 0.10755, hand: 0.23108, face: 0.10312\n","2020-11-28 13:28:08,026 - __main__ - INFO - Epoch  92 Step:    28880 Batch Loss:     0.000544 [Torso :     0.000382, Hand :     0.000719, Face :     0.000318]Tokens per Sec:  6092184, Lr: 0.000240\n","2020-11-28 13:28:23,385 - __main__ - INFO - Epoch  92 Step:    28920 Batch Loss:     0.000448 [Torso :     0.000353, Hand :     0.000560, Face :     0.000267]Tokens per Sec:  5913487, Lr: 0.000240\n","2020-11-28 13:28:37,801 - __main__ - INFO - Epoch  92 Step:    28960 Batch Loss:     0.000457 [Torso :     0.000296, Hand :     0.000625, Face :     0.000260]Tokens per Sec:  6031785, Lr: 0.000240\n","2020-11-28 13:28:51,386 - __main__ - INFO - Epoch  92 Step:    29000 Batch Loss:     0.000451 [Torso :     0.000313, Hand :     0.000596, Face :     0.000281]Tokens per Sec:  6140009, Lr: 0.000240\n","2020-11-28 13:29:04,404 - __main__ - INFO - Epoch  92 Step:    29040 Batch Loss:     0.000620 [Torso :     0.000444, Hand :     0.000818, Face :     0.000332]Tokens per Sec:  6277336, Lr: 0.000240\n","2020-11-28 13:29:18,062 - __main__ - INFO - Epoch  92 Step:    29080 Batch Loss:     0.000490 [Torso :     0.000342, Hand :     0.000647, Face :     0.000295]Tokens per Sec:  6140400, Lr: 0.000240\n","2020-11-28 13:29:24,973 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 13:34:54,013 - __main__ - INFO - Validation result at epoch  92, step    29100: Val DTW Score:  47.80, loss:   3.9688,  duration: 329.0374s\n","2020-11-28 13:35:01,075 - __main__ - INFO - Epoch  92 Step:    29120 Batch Loss:     0.000534 [Torso :     0.000293, Hand :     0.000766, Face :     0.000338]Tokens per Sec:  6091952, Lr: 0.000240\n","2020-11-28 13:35:17,456 - __main__ - INFO - Epoch  92 Step:    29160 Batch Loss:     0.000366 [Torso :     0.000277, Hand :     0.000470, Face :     0.000201]Tokens per Sec:  5305807, Lr: 0.000240\n","2020-11-28 13:35:18,845 - __main__ - INFO - Epoch  92: total training loss 0.16547 [torso: 0.10568, hand: 0.22617, face: 0.10114\n","2020-11-28 13:35:30,984 - __main__ - INFO - Epoch  93 Step:    29200 Batch Loss:     0.000543 [Torso :     0.000317, Hand :     0.000757, Face :     0.000377]Tokens per Sec:  6219025, Lr: 0.000240\n","2020-11-28 13:35:45,138 - __main__ - INFO - Epoch  93 Step:    29240 Batch Loss:     0.000500 [Torso :     0.000331, Hand :     0.000672, Face :     0.000311]Tokens per Sec:  6083011, Lr: 0.000240\n","2020-11-28 13:35:59,010 - __main__ - INFO - Epoch  93 Step:    29280 Batch Loss:     0.000486 [Torso :     0.000314, Hand :     0.000665, Face :     0.000286]Tokens per Sec:  6156878, Lr: 0.000240\n","2020-11-28 13:36:12,874 - __main__ - INFO - Epoch  93 Step:    29320 Batch Loss:     0.000455 [Torso :     0.000261, Hand :     0.000637, Face :     0.000321]Tokens per Sec:  6124223, Lr: 0.000240\n","2020-11-28 13:36:27,902 - __main__ - INFO - Epoch  93 Step:    29360 Batch Loss:     0.000631 [Torso :     0.000371, Hand :     0.000884, Face :     0.000407]Tokens per Sec:  5974777, Lr: 0.000240\n","2020-11-28 13:36:42,329 - __main__ - INFO - Epoch  93 Step:    29400 Batch Loss:     0.000542 [Torso :     0.000372, Hand :     0.000721, Face :     0.000325]Tokens per Sec:  6068952, Lr: 0.000240\n","2020-11-28 13:36:42,331 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 13:42:13,470 - __main__ - INFO - Validation result at epoch  93, step    29400: Val DTW Score:  48.74, loss:   3.8943,  duration: 331.1376s\n","2020-11-28 13:42:29,373 - __main__ - INFO - Epoch  93 Step:    29440 Batch Loss:     0.000558 [Torso :     0.000342, Hand :     0.000771, Face :     0.000356]Tokens per Sec:  5376615, Lr: 0.000240\n","2020-11-28 13:42:43,712 - __main__ - INFO - Epoch  93 Step:    29480 Batch Loss:     0.000700 [Torso :     0.000423, Hand :     0.000974, Face :     0.000435]Tokens per Sec:  5793463, Lr: 0.000240\n","2020-11-28 13:42:44,114 - __main__ - INFO - Epoch  93: total training loss 0.16472 [torso: 0.10417, hand: 0.22588, face: 0.10116\n","2020-11-28 13:42:58,026 - __main__ - INFO - Epoch  94 Step:    29520 Batch Loss:     0.000586 [Torso :     0.000384, Hand :     0.000789, Face :     0.000379]Tokens per Sec:  6048188, Lr: 0.000240\n","2020-11-28 13:43:12,503 - __main__ - INFO - Epoch  94 Step:    29560 Batch Loss:     0.000433 [Torso :     0.000267, Hand :     0.000598, Face :     0.000269]Tokens per Sec:  6016500, Lr: 0.000240\n","2020-11-28 13:43:26,831 - __main__ - INFO - Epoch  94 Step:    29600 Batch Loss:     0.000567 [Torso :     0.000395, Hand :     0.000748, Face :     0.000353]Tokens per Sec:  5966161, Lr: 0.000240\n","2020-11-28 13:43:42,106 - __main__ - INFO - Epoch  94 Step:    29640 Batch Loss:     0.000539 [Torso :     0.000362, Hand :     0.000721, Face :     0.000342]Tokens per Sec:  5913414, Lr: 0.000240\n","2020-11-28 13:43:56,916 - __main__ - INFO - Epoch  94 Step:    29680 Batch Loss:     0.000422 [Torso :     0.000277, Hand :     0.000574, Face :     0.000244]Tokens per Sec:  5904460, Lr: 0.000240\n","2020-11-28 13:44:04,385 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 13:49:37,115 - __main__ - INFO - Validation result at epoch  94, step    29700: Val DTW Score:  48.55, loss:   3.9824,  duration: 332.7284s\n","2020-11-28 13:49:44,665 - __main__ - INFO - Epoch  94 Step:    29720 Batch Loss:     0.000484 [Torso :     0.000303, Hand :     0.000657, Face :     0.000342]Tokens per Sec:  5854805, Lr: 0.000240\n","2020-11-28 13:49:59,902 - __main__ - INFO - Epoch  94 Step:    29760 Batch Loss:     0.000700 [Torso :     0.000368, Hand :     0.001015, Face :     0.000456]Tokens per Sec:  5507280, Lr: 0.000240\n","2020-11-28 13:50:13,402 - __main__ - INFO - Epoch  94: total training loss 0.16315 [torso: 0.10361, hand: 0.22343, face: 0.09990\n","2020-11-28 13:50:14,331 - __main__ - INFO - Epoch  95 Step:    29800 Batch Loss:     0.000412 [Torso :     0.000220, Hand :     0.000596, Face :     0.000263]Tokens per Sec:  5558346, Lr: 0.000240\n","2020-11-28 13:50:28,565 - __main__ - INFO - Epoch  95 Step:    29840 Batch Loss:     0.000528 [Torso :     0.000345, Hand :     0.000718, Face :     0.000316]Tokens per Sec:  6019120, Lr: 0.000240\n","2020-11-28 13:50:41,942 - __main__ - INFO - Epoch  95 Step:    29880 Batch Loss:     0.000466 [Torso :     0.000358, Hand :     0.000590, Face :     0.000281]Tokens per Sec:  6249925, Lr: 0.000240\n","2020-11-28 13:50:56,793 - __main__ - INFO - Epoch  95 Step:    29920 Batch Loss:     0.000563 [Torso :     0.000356, Hand :     0.000773, Face :     0.000341]Tokens per Sec:  6001889, Lr: 0.000240\n","2020-11-28 13:51:11,500 - __main__ - INFO - Epoch  95 Step:    29960 Batch Loss:     0.000390 [Torso :     0.000253, Hand :     0.000530, Face :     0.000236]Tokens per Sec:  6053239, Lr: 0.000240\n","2020-11-28 13:51:25,869 - __main__ - INFO - Epoch  95 Step:    30000 Batch Loss:     0.000616 [Torso :     0.000382, Hand :     0.000847, Face :     0.000393]Tokens per Sec:  6066615, Lr: 0.000240\n","2020-11-28 13:51:25,871 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 13:56:56,365 - __main__ - INFO - Validation result at epoch  95, step    30000: Val DTW Score:  50.11, loss:   3.9435,  duration: 330.4925s\n","2020-11-28 13:57:10,490 - __main__ - INFO - Epoch  95 Step:    30040 Batch Loss:     0.000463 [Torso :     0.000299, Hand :     0.000630, Face :     0.000285]Tokens per Sec:  5819386, Lr: 0.000240\n","2020-11-28 13:57:26,344 - __main__ - INFO - Epoch  95 Step:    30080 Batch Loss:     0.000612 [Torso :     0.000357, Hand :     0.000867, Face :     0.000359]Tokens per Sec:  5632123, Lr: 0.000240\n","2020-11-28 13:57:37,849 - __main__ - INFO - Epoch  95: total training loss 0.16476 [torso: 0.10444, hand: 0.22577, face: 0.10098\n","2020-11-28 13:57:40,092 - __main__ - INFO - Epoch  96 Step:    30120 Batch Loss:     0.000413 [Torso :     0.000274, Hand :     0.000558, Face :     0.000247]Tokens per Sec:  5591785, Lr: 0.000240\n","2020-11-28 13:57:54,180 - __main__ - INFO - Epoch  96 Step:    30160 Batch Loss:     0.000516 [Torso :     0.000331, Hand :     0.000707, Face :     0.000301]Tokens per Sec:  6051864, Lr: 0.000240\n","2020-11-28 13:58:08,369 - __main__ - INFO - Epoch  96 Step:    30200 Batch Loss:     0.000606 [Torso :     0.000408, Hand :     0.000816, Face :     0.000349]Tokens per Sec:  6057252, Lr: 0.000240\n","2020-11-28 13:58:22,593 - __main__ - INFO - Epoch  96 Step:    30240 Batch Loss:     0.000610 [Torso :     0.000377, Hand :     0.000845, Face :     0.000362]Tokens per Sec:  5982904, Lr: 0.000240\n","2020-11-28 13:58:36,766 - __main__ - INFO - Epoch  96 Step:    30280 Batch Loss:     0.000424 [Torso :     0.000298, Hand :     0.000558, Face :     0.000262]Tokens per Sec:  5977306, Lr: 0.000240\n","2020-11-28 13:58:44,060 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 14:04:17,282 - __main__ - INFO - Validation result at epoch  96, step    30300: Val DTW Score:  48.64, loss:   3.9595,  duration: 333.2187s\n","2020-11-28 14:04:24,529 - __main__ - INFO - Epoch  96 Step:    30320 Batch Loss:     0.000517 [Torso :     0.000296, Hand :     0.000727, Face :     0.000355]Tokens per Sec:  5991250, Lr: 0.000240\n","2020-11-28 14:04:41,718 - __main__ - INFO - Epoch  96 Step:    30360 Batch Loss:     0.000461 [Torso :     0.000264, Hand :     0.000654, Face :     0.000278]Tokens per Sec:  5221179, Lr: 0.000240\n","2020-11-28 14:04:55,832 - __main__ - INFO - Epoch  96 Step:    30400 Batch Loss:     0.000606 [Torso :     0.000411, Hand :     0.000809, Face :     0.000373]Tokens per Sec:  6018601, Lr: 0.000240\n","2020-11-28 14:05:06,673 - __main__ - INFO - Epoch  96: total training loss 0.16392 [torso: 0.10370, hand: 0.22482, face: 0.10030\n","2020-11-28 14:05:09,248 - __main__ - INFO - Epoch  97 Step:    30440 Batch Loss:     0.000558 [Torso :     0.000350, Hand :     0.000766, Face :     0.000348]Tokens per Sec:  6183899, Lr: 0.000240\n","2020-11-28 14:05:23,950 - __main__ - INFO - Epoch  97 Step:    30480 Batch Loss:     0.000459 [Torso :     0.000296, Hand :     0.000625, Face :     0.000283]Tokens per Sec:  5997606, Lr: 0.000240\n","2020-11-28 14:05:37,415 - __main__ - INFO - Epoch  97 Step:    30520 Batch Loss:     0.000534 [Torso :     0.000343, Hand :     0.000727, Face :     0.000331]Tokens per Sec:  6091915, Lr: 0.000240\n","2020-11-28 14:05:51,683 - __main__ - INFO - Epoch  97 Step:    30560 Batch Loss:     0.000649 [Torso :     0.000435, Hand :     0.000862, Face :     0.000436]Tokens per Sec:  5977547, Lr: 0.000240\n","2020-11-28 14:06:06,381 - __main__ - INFO - Epoch  97 Step:    30600 Batch Loss:     0.000550 [Torso :     0.000382, Hand :     0.000728, Face :     0.000326]Tokens per Sec:  5860540, Lr: 0.000240\n","2020-11-28 14:06:06,383 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 14:11:40,206 - __main__ - INFO - Validation result at epoch  97, step    30600: Val DTW Score:  50.07, loss:   3.9191,  duration: 333.8212s\n","2020-11-28 14:11:56,630 - __main__ - INFO - Epoch  97 Step:    30640 Batch Loss:     0.000634 [Torso :     0.000419, Hand :     0.000851, Face :     0.000410]Tokens per Sec:  5386067, Lr: 0.000240\n","2020-11-28 14:12:11,133 - __main__ - INFO - Epoch  97 Step:    30680 Batch Loss:     0.000545 [Torso :     0.000371, Hand :     0.000730, Face :     0.000318]Tokens per Sec:  5931915, Lr: 0.000240\n","2020-11-28 14:12:25,834 - __main__ - INFO - Epoch  97 Step:    30720 Batch Loss:     0.000465 [Torso :     0.000361, Hand :     0.000590, Face :     0.000251]Tokens per Sec:  6013417, Lr: 0.000240\n","2020-11-28 14:12:36,244 - __main__ - INFO - Epoch  97: total training loss 0.16381 [torso: 0.10419, hand: 0.22421, face: 0.10034\n","2020-11-28 14:12:40,036 - __main__ - INFO - Epoch  98 Step:    30760 Batch Loss:     0.000479 [Torso :     0.000334, Hand :     0.000635, Face :     0.000279]Tokens per Sec:  6065240, Lr: 0.000240\n","2020-11-28 14:12:54,197 - __main__ - INFO - Epoch  98 Step:    30800 Batch Loss:     0.000526 [Torso :     0.000328, Hand :     0.000726, Face :     0.000320]Tokens per Sec:  6014741, Lr: 0.000240\n","2020-11-28 14:13:08,387 - __main__ - INFO - Epoch  98 Step:    30840 Batch Loss:     0.000557 [Torso :     0.000367, Hand :     0.000750, Face :     0.000347]Tokens per Sec:  6045575, Lr: 0.000240\n","2020-11-28 14:13:22,932 - __main__ - INFO - Epoch  98 Step:    30880 Batch Loss:     0.000423 [Torso :     0.000229, Hand :     0.000609, Face :     0.000269]Tokens per Sec:  6070310, Lr: 0.000240\n","2020-11-28 14:13:30,238 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 14:19:02,482 - __main__ - INFO - Validation result at epoch  98, step    30900: Val DTW Score:  50.32, loss:   3.9782,  duration: 332.2423s\n","2020-11-28 14:19:10,749 - __main__ - INFO - Epoch  98 Step:    30920 Batch Loss:     0.000492 [Torso :     0.000333, Hand :     0.000660, Face :     0.000291]Tokens per Sec:  5616877, Lr: 0.000240\n","2020-11-28 14:19:26,036 - __main__ - INFO - Epoch  98 Step:    30960 Batch Loss:     0.000606 [Torso :     0.000409, Hand :     0.000813, Face :     0.000362]Tokens per Sec:  5624460, Lr: 0.000240\n","2020-11-28 14:19:40,965 - __main__ - INFO - Epoch  98 Step:    31000 Batch Loss:     0.000639 [Torso :     0.000361, Hand :     0.000910, Face :     0.000394]Tokens per Sec:  5911606, Lr: 0.000240\n","2020-11-28 14:19:55,840 - __main__ - INFO - Epoch  98 Step:    31040 Batch Loss:     0.000499 [Torso :     0.000290, Hand :     0.000701, Face :     0.000328]Tokens per Sec:  5912178, Lr: 0.000240\n","2020-11-28 14:20:05,027 - __main__ - INFO - Epoch  98: total training loss 0.16133 [torso: 0.10209, hand: 0.22123, face: 0.09875\n","2020-11-28 14:20:10,761 - __main__ - INFO - Epoch  99 Step:    31080 Batch Loss:     0.000545 [Torso :     0.000348, Hand :     0.000746, Face :     0.000328]Tokens per Sec:  5793650, Lr: 0.000240\n","2020-11-28 14:20:24,250 - __main__ - INFO - Epoch  99 Step:    31120 Batch Loss:     0.000511 [Torso :     0.000359, Hand :     0.000674, Face :     0.000300]Tokens per Sec:  6223369, Lr: 0.000240\n","2020-11-28 14:20:38,437 - __main__ - INFO - Epoch  99 Step:    31160 Batch Loss:     0.000605 [Torso :     0.000383, Hand :     0.000829, Face :     0.000368]Tokens per Sec:  5928072, Lr: 0.000240\n","2020-11-28 14:20:52,947 - __main__ - INFO - Epoch  99 Step:    31200 Batch Loss:     0.000672 [Torso :     0.000359, Hand :     0.000975, Face :     0.000409]Tokens per Sec:  5968389, Lr: 0.000240\n","2020-11-28 14:20:52,949 - __main__ - INFO - Starting validation calculation.\n","2020-11-28 14:26:27,635 - __main__ - INFO - Validation result at epoch  99, step    31200: Val DTW Score:  48.92, loss:   3.9412,  duration: 334.6843s\n","2020-11-28 14:26:27,637 - __main__ - INFO - Training ended since minimum lr 0.000200 was reached.\n","2020-11-28 14:26:27,638 - __main__ - INFO - Best validation result at step    26400:  47.79 dtw.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"y3goUK5zTusO"},"source":["### Evaluation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"id":"eojcZw-a40t9","executionInfo":{"elapsed":171322,"status":"error","timestamp":1605997907047,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"},"user_tz":480},"outputId":"61ad3f41-f13d-4604-dca6-0ea1ad8e7c4c"},"source":["cfg = load_config('model.yaml')\n","ckpt = 'best.ckpt'\n","train_data, src_vocab, trg_vocab = load_data()\n","\n","model_checkpoint = load_checkpoint(os.path.join(MODEL_DIR, ckpt), use_cuda=True)\n","model = build_model(cfg, src_vocab=src_vocab, trg_vocab=trg_vocab)\n","model.load_state_dict(model_checkpoint[\"model_state\"])\n","model.cuda()\n","\n","valid_iter = make_data_iter(\n","    dataset=train_data, batch_size=1, batch_type='sentence',\n","    shuffle=True, train=False)\n","\n","pad_index = model.src_vocab.stoi[PAD_TOKEN]\n","# disable dropout\n","model.eval()\n","\n","all_outputs = []\n","with torch.no_grad():\n","   for valid_batch in iter(valid_iter):\n","        batch = Batch(torch_batch=valid_batch, pad_index = pad_index, model = model)\n","        output, attention_scores = model.run_batch(\n","                            batch=batch,\n","                            max_output_length=300)\n","        all_outputs.append(output.to('cpu').numpy())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Data's max frame cnt is 254\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-87-a2fa9138ea01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         output, attention_scores = model.run_batch(\n\u001b[1;32m     23\u001b[0m                             \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                             max_output_length=300)\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mall_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-57706d7060d2>\u001b[0m in \u001b[0;36mrun_batch\u001b[0;34m(self, batch, max_output_length)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mdecoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0mtrg_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 model=self)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstacked_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacked_attention_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-d8cdacebd948>\u001b[0m in \u001b[0;36mgreedy\u001b[0;34m(src_mask, embed, decoder, encoder_output, trg_input, model)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mencoder_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mtrg_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             )\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-3a4de572b419>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, trg_embed, encoder_output, src_mask, trg_mask, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             x = layer(x=x, memory=encoder_output,\n\u001b[0;32m--> 155\u001b[0;31m                       src_mask=src_mask, trg_mask=sub_mask, padding_mask=padding_mask)\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# Apply a layer normalisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/transformer_layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, memory, src_mask, trg_mask, padding_mask)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;31m# final position-wise feed-forward layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/transformer_layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mx_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpwff_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_norm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         return F.layer_norm(\n\u001b[0;32m--> 170\u001b[0;31m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2093\u001b[0m                 layer_norm, (input,), input, normalized_shape, weight=weight, bias=bias, eps=eps)\n\u001b[1;32m   2094\u001b[0m     return torch.layer_norm(input, normalized_shape, weight, bias, eps,\n\u001b[0;32m-> 2095\u001b[0;31m                             torch.backends.cudnn.enabled)\n\u001b[0m\u001b[1;32m   2096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264},"id":"u5OAkGHL4_FJ","executionInfo":{"elapsed":1512,"status":"ok","timestamp":1605998047210,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"},"user_tz":480},"outputId":"8334307b-e89d-4496-ab80-76d3cde0b9e0"},"source":["output = all_outputs[50]\n","x_output = output[0,21,::3][0:50]\n","y_output = output[0,21,1::3]\n","for s in getSkeletalModelStructure():\n","    sns.lineplot(x=[x_output[s[0]], x_output[s[1]]],\n","                 y=[y_output[s[0]]*-1, y_output[s[1]]*-1], color='blue')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"e87__Tze44k9"},"source":[""],"execution_count":null,"outputs":[]}]}