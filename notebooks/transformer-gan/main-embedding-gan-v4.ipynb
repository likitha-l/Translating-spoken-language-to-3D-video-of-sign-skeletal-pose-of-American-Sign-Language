{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main-embedding-gan-v4.ipynb","provenance":[],"collapsed_sections":["j3yqvRko3s8c","rCrvrN30tHa3","IUgSFmiTrwU8","GgvIk4H6F-W6","A6F9FE6tTVig","a-aRdpmlTanv","HFFCa2koFv26"],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7AMKmmdQpI16","executionInfo":{"status":"ok","timestamp":1606763020655,"user_tz":480,"elapsed":39586,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"}},"outputId":"d882f40c-44b8-4c5c-cdac-9565886da163"},"source":["import os \n","from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j3yqvRko3s8c"},"source":["### Basic Imports"]},{"cell_type":"code","metadata":{"id":"wX4s0cGrpiCb","executionInfo":{"status":"ok","timestamp":1606763041380,"user_tz":480,"elapsed":32082,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"}}},"source":["MAIN_DIR = '/content/drive/My Drive/Colab Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer'\n","DATA_DIR = '/content/drive/My Drive/Colab Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/backtranslation/data'\n","MODEL_DIR = os.path.join(MAIN_DIR, 'model')\n","CONF_DIR = os.path.join(MAIN_DIR, 'conf')\n","\n","UNK_TOKEN = '<unk>'\n","PAD_TOKEN = '<pad>'\n","EOS_TOKEN = '</s>'\n","BOS_TOKEN = '<s>'\n","\n","TARGET_PAD = 0.0\n","\n","DEFAULT_UNK_ID = lambda: 0\n","\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer/vocabulary.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer/initialization.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer/transformer_layers.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer/batch.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer/loss.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer/builders.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer/dtw.py .\n","!cp /content/drive/My\\ Drive/Colab\\ Notebooks/openpose/DLF2020/dlf2020/src/AmyExperiments/papertransformer/plot_videos.py .\n","\n","\n","import yaml\n","import numpy as np\n","import random\n","import pickle\n","import sys\n","from typing import Optional\n","import queue\n","import glob\n","import time\n","from logging import Logger\n","import logging\n","\n","import torch\n","from torch import nn, Tensor\n","import torch.nn.functional as F\n","from torchtext.data import Dataset, Example, Field, BucketIterator, Iterator\n","\n","from collections import defaultdict, Counter\n","from vocabulary import build_vocab\n","from initialization import initialize_model\n","from transformer_layers import TransformerEncoderLayer, PositionalEncoding, TransformerDecoderLayer\n","from vocabulary import Vocabulary\n","from batch import Batch\n","from loss import RegLoss\n","from builders import build_optimizer, build_scheduler, build_gradient_clipper\n","from dtw import dtw\n","from plot_videos import plot_video, alter_DTW_timing"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rCrvrN30tHa3"},"source":["### Helper functions"]},{"cell_type":"code","metadata":{"id":"WEZP6CDXtJnM","executionInfo":{"status":"ok","timestamp":1606763041385,"user_tz":480,"elapsed":29327,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"}}},"source":["def load_config(path=\"model.yaml\") -> dict:\n","    \"\"\"\n","    Loads and parses a YAML configuration file.\n","\n","    :param path: path to YAML configuration file\n","    :return: configuration dictionary\n","    \"\"\"\n","    with open(os.path.join(CONF_DIR, path), 'r') as ymlfile:\n","        cfg = yaml.safe_load(ymlfile)\n","    return cfg\n","\n","def set_seed(seed: int) -> None:\n","    \"\"\"\n","    Set the random seed for modules torch, numpy and random.\n","\n","    :param seed: random seed\n","    \"\"\"\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","def freeze_params(module: nn.Module) -> None:\n","    \"\"\"\n","    Freeze the parameters of this module,\n","    i.e. do not update them during training\n","\n","    :param module: freeze parameters of this module\n","    \"\"\"\n","    for _, p in module.named_parameters():\n","        p.requires_grad = False\n","\n","def subsequent_mask(size: int) -> Tensor:\n","    \"\"\"\n","    Mask out subsequent positions (to prevent attending to future positions)\n","    Transformer helper function.\n","\n","    :param size: size of mask (2nd and 3rd dim)\n","    :return: Tensor with 0s and 1s of shape (1, size, size)\n","    \"\"\"\n","    mask = np.triu(np.ones((1, size, size)), k=1).astype('uint8')\n","\n","    return torch.from_numpy(mask) == 0 # Turns it into True and False's\n","\n","def symlink_update(target, link_name):\n","    try:\n","        os.symlink(target, link_name)\n","    except FileExistsError as e:\n","        if e.errno == errno.EEXIST:\n","            os.remove(link_name)\n","            os.symlink(target, link_name)\n","        else:\n","            raise e\n","\n","def load_checkpoint(path: str, use_cuda: bool = True) -> dict:\n","    \"\"\"\n","    Load model from saved checkpoint.\n","\n","    :param path: path to checkpoint\n","    :param use_cuda: using cuda or not\n","    :return: checkpoint (dict)\n","    \"\"\"\n","    assert os.path.isfile(path), \"Checkpoint %s not found\" % path\n","    checkpoint = torch.load(path, map_location='cuda' if use_cuda else 'cpu')\n","    return checkpoint\n","\n","class ConfigurationError(Exception):\n","    \"\"\" Custom exception for misspecifications of configuration \"\"\"\n","\n","\n","def get_latest_checkpoint(ckpt_dir, post_fix=\"every\", model_type='_tf') -> Optional[str]:\n","    \"\"\"\n","    Returns the latest checkpoint (by time) from the given directory, of either every validation step or best\n","    If there is no checkpoint in this directory, returns None\n","\n","    :param ckpt_dir: directory of checkpoint\n","    :param post_fixe: type of checkpoint, either \"_every\" or \"_best\"\n","\n","    :return: latest checkpoint file\n","    \"\"\"\n","    # Find all the every validation checkpoints\n","    list_of_files = glob.glob(\"{}/*{}{}.ckpt\".format(ckpt_dir, post_fix, model_type))\n","    latest_checkpoint = None\n","    if list_of_files:\n","        latest_checkpoint = max(list_of_files, key=os.path.getctime)\n","    return latest_checkpoint\n","\n","def log_cfg(cfg: dict, logger: Logger, prefix: str = \"cfg\"):\n","    \"\"\"\n","    Write configuration to log.\n","\n","    :param cfg: configuration to log\n","    :param logger: logger that defines where log is written to\n","    :param prefix: prefix for logging\n","    \"\"\"\n","    for k, v in cfg.items():\n","        if isinstance(v, dict):\n","            p = \".\".join([prefix, k])\n","            log_cfg(v, logger, prefix=p)\n","        else:\n","            p = \".\".join([prefix, k])\n","            logger.info(\"{:34s} : {}\".format(p, v))\n","\n","def make_logger(model_dir: str, log_file: str = \"train.log\") -> Logger:\n","    \"\"\"\n","    Create a logger for logging the training process.\n","\n","    :param model_dir: path to logging directory\n","    :param log_file: path to logging file\n","    :return: logger object\n","    \"\"\"\n","    #if not logger.handlers:\n","    logger = logging.getLogger(__name__)\n","    while len(logger.handlers) > 0:\n","        h = logger.handlers[0]\n","        print('removing {}'.format(h))\n","        logger.removeHandler(h)\n","    logger.propagate = False\n","    logger.setLevel(logging.INFO)\n","    # Create handlers\n","    c_handler = logging.StreamHandler()\n","    f_handler = logging.FileHandler(os.path.join(model_dir, log_file), mode='w')\n","\n","    # Create formatters and add it to handlers\n","    c_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n","    f_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n","    c_handler.setFormatter(c_format)\n","    f_handler.setFormatter(f_format)\n","\n","    # Add handlers to the logger\n","    logger.addHandler(c_handler)\n","    logger.addHandler(f_handler)\n","\n","    return logger"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IUgSFmiTrwU8"},"source":["### Data Loading"]},{"cell_type":"code","metadata":{"id":"O-i9NBfQruOe","executionInfo":{"status":"ok","timestamp":1606763056785,"user_tz":480,"elapsed":15377,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"}}},"source":["def build_vocab(field: str, max_size: int, min_freq: int, dataset: Dataset,\n","                vocab_file: str = None) -> Vocabulary:\n","    \"\"\"\n","    Builds vocabulary for a torchtext `field` from given`dataset` or\n","    `vocab_file`.\n","\n","    :param field: attribute e.g. \"src\"\n","    :param max_size: maximum size of vocabulary\n","    :param min_freq: minimum frequency for an item to be included\n","    :param dataset: dataset to load data for field from\n","    :param vocab_file: file to store the vocabulary,\n","        if not None, load vocabulary from here\n","    :return: Vocabulary created from either `dataset` or `vocab_file`\n","    \"\"\"\n","\n","    if vocab_file is not None:\n","        # load it from file\n","        vocab = Vocabulary(file=vocab_file)\n","    else:\n","        # create newly\n","        def filter_min(counter: Counter, min_freq: int):\n","            \"\"\" Filter counter by min frequency \"\"\"\n","            filtered_counter = Counter({t: c for t, c in counter.items()\n","                                        if c >= min_freq})\n","            return filtered_counter\n","\n","        def sort_and_cut(counter: Counter, limit: int):\n","            \"\"\" Cut counter to most frequent,\n","            sorted numerically and alphabetically\"\"\"\n","            # sort by frequency, then alphabetically\n","            tokens_and_frequencies = sorted(counter.items(),\n","                                            key=lambda tup: tup[0])\n","            tokens_and_frequencies.sort(key=lambda tup: tup[1], reverse=True)\n","            vocab_tokens = [i[0] for i in tokens_and_frequencies[:limit]]\n","            return vocab_tokens\n","\n","        tokens = []\n","        for i in dataset.examples:\n","            if field == \"src\":\n","                tokens.extend(i.src)\n","            elif field == \"trg\":\n","                tokens.extend(i.trg)\n","            elif field == 'emb':\n","                tokens.extend(i.emb)\n","\n","        counter = Counter(tokens)\n","        if min_freq > -1:\n","            counter = filter_min(counter, min_freq)\n","        vocab_tokens = sort_and_cut(counter, max_size)\n","        assert len(vocab_tokens) <= max_size\n","\n","        vocab = Vocabulary(tokens=vocab_tokens)\n","        assert len(vocab) <= max_size + len(vocab.specials)\n","        assert vocab.itos[DEFAULT_UNK_ID()] == UNK_TOKEN\n","\n","    # check for all except for UNK token whether they are OOVs\n","    for s in vocab.specials[1:]:\n","        assert not vocab.is_unk(s)\n","\n","    return vocab\n","\n","def load_data(cfg: dict):\n","    \n","    # read parsed data\n","    # list of ['video_id', 'skeletons', 'frame_cnt', 'word', 'embedding']\n","    # skeleton shape [frame #, skeleton + counter = 151]\n","\n","    train_path = os.path.join(DATA_DIR, 'train.pkl')\n","    val_path = os.path.join(DATA_DIR, 'val.pkl')\n","    level = \"word\"\n","    data_cfg = cfg[\"data\"]\n","    src_lang = data_cfg[\"src\"] #gloss\n","    trg_lang = data_cfg[\"trg\"] #skels\n","    lowercase = False\n","    max_sent_length = data_cfg[\"max_sent_length\"] # 1\n","    trg_size = cfg[\"model\"][\"trg_size\"] + 1 # to account for counter\n","    skip_frames = data_cfg.get(\"skip_frames\", 1)\n","\n","    EOS_TOKEN = '</s>'\n","    tok_fun = lambda s: list(s) if level == \"char\" else s.split()\n","    \n","    src_field = Field(init_token=None,\n","                      pad_token=PAD_TOKEN, tokenize=tok_fun,\n","                      batch_first=True, lower=lowercase,\n","                      unk_token=UNK_TOKEN,\n","                      include_lengths=True)\n","        \n","\n","    reg_trg_field = Field(sequential=True,\n","                          use_vocab=False,\n","                          dtype=torch.float32,\n","                          batch_first=True,\n","                          include_lengths=False,\n","                          pad_token=torch.ones((trg_size))*TARGET_PAD)\n","    \n","    embedding_field = Field(sequential=True,\n","                            use_vocab=False,\n","                            dtype=torch.float32,\n","                            batch_first=True,\n","                            include_lengths=True)\n","\n","\n","    train_data = SignProdDataset(fields=(embedding_field, reg_trg_field, src_field),\n","                                 path=train_path,\n","                                 trg_size=trg_size,\n","                                 skip_frames=skip_frames)\n","    \n","    src_vocab = build_vocab(field=\"emb\", min_freq=1,\n","                            max_size=sys.maxsize,\n","                            dataset=train_data, vocab_file=None)\n","    \n","    src_field.vocab = src_vocab\n","    trg_vocab = [None]*(trg_size)\n","\n","      # Create the Validation Data\n","    dev_data = SignProdDataset(fields=(embedding_field, reg_trg_field, src_field),\n","                               path=val_path,\n","                               trg_size=trg_size,\n","                               skip_frames=skip_frames)\n","    \n","    \n","    return train_data, dev_data, src_vocab, trg_vocab\n","\n","global max_src_in_batch, max_tgt_in_batch\n","\n","\n","# pylint: disable=unused-argument,global-variable-undefined\n","def token_batch_size_fn(new, count, sofar):\n","    \"\"\"Compute batch size based on number of tokens (+padding).\"\"\"\n","    global max_src_in_batch, max_tgt_in_batch\n","    if count == 1:\n","        max_src_in_batch = 0\n","        max_tgt_in_batch = 0\n","    max_src_in_batch = max(max_src_in_batch, len(new.src))\n","    src_elements = count * max_src_in_batch\n","    if hasattr(new, 'trg'):  # for monolingual data sets (\"translate\" mode)\n","        max_tgt_in_batch = max(max_tgt_in_batch, len(new.trg) + 2)\n","        tgt_elements = count * max_tgt_in_batch\n","    else:\n","        tgt_elements = 0\n","    return max(src_elements, tgt_elements)\n","\n","class SignProdDataset(Dataset):\n","    def __init__(self, \n","                 fields,\n","                 path,\n","                 trg_size,\n","                 skip_frames=1,\n","                 **kwargs):\n","        if not isinstance(fields[0], (tuple, list)):\n","            fields = [('src', fields[0]), ('trg', fields[1]), ('emb', fields[2])]\n","        \n","        examples = []\n","        with open(path, 'rb') as data_file:\n","            dataset = pickle.load(data_file)\n","        with open(os.path.join(DATA_DIR, 'embedding.200.pkl') ,'rb') as embed_file:\n","            embed_dict= pickle.load(embed_file)\n","\n","        for i, skeleton in enumerate(dataset[\"skeleton\"]):\n","            src_line = dataset[\"gloss\"][i].replace(' ', '')\n","            # add start frame (zeros)\n","            start_frame = np.zeros((1, skeleton.shape[-1]))\n","            with_start_frame = np.concatenate((start_frame, skeleton))\n","            normalized = with_start_frame + 1e-8\n","\n","            if skip_frames > 1:\n","              normalized = normalized[0::skip_frames]\n","\n","            # add counter here\n","            counters = np.arange(0,len(normalized),1)/len(normalized)\n","            with_counter = np.concatenate((normalized, counters[:, np.newaxis]), axis=1)\n","\n","            # set embedding\n","            embed_x = embed_dict[src_line][np.newaxis, :]\n","\n","            examples.append(Example.fromlist([embed_x, with_counter, src_line], fields))\n","            super(SignProdDataset, self).__init__(examples, fields, **kwargs)\n","         \n","            \n","def make_data_iter(dataset: Dataset,\n","                   batch_size: int,\n","                   batch_type: str = \"sentence\",\n","                   train: bool = False,\n","                   shuffle: bool = False) -> Iterator:\n","    \"\"\"\n","    Returns a torchtext iterator for a torchtext dataset.\n","\n","    :param dataset: torchtext dataset containing src and optionally trg\n","    :param batch_size: size of the batches the iterator prepares\n","    :param batch_type: measure batch size by sentence count or by token count\n","    :param train: whether it's training time, when turned off,\n","        bucketing, sorting within batches and shuffling is disabled\n","    :param shuffle: whether to shuffle the data before each epoch\n","        (no effect if set to True for testing)\n","    :return: torchtext iterator\n","    \"\"\"\n","\n","    batch_size_fn = token_batch_size_fn if batch_type == \"token\" else None\n","\n","    if train:\n","        # optionally shuffle and sort during training\n","        data_iter = BucketIterator(\n","            repeat=False, sort=False, dataset=dataset,\n","            batch_size=batch_size, batch_size_fn=batch_size_fn,\n","            train=True, sort_within_batch=True,\n","            sort_key=lambda x: len(x.src), shuffle=shuffle)\n","    else:\n","        # don't sort/shuffle for validation/inference\n","        data_iter = BucketIterator(\n","            repeat=False, dataset=dataset,\n","            batch_size=batch_size, batch_size_fn=batch_size_fn,\n","            train=False, sort=False)\n","\n","    return data_iter\n","\n","import torch\n","import torch.nn.functional as F\n","\n","\n","class Batch:\n","    \"\"\"Object for holding a batch of data with mask during training.\n","    Input is a batch from a torch text iterator.\n","    \"\"\"\n","\n","    def __init__(self, torch_batch, pad_index, model):\n","\n","        \"\"\"\n","        Create a new joey batch from a torch batch.\n","        This batch extends torch text's batch attributes with src and trg\n","        length, masks, number of non-padded tokens in trg.\n","        Furthermore, it can be sorted by src length.\n","\n","        :param torch_batch:\n","        :param pad_index:\n","        :param use_cuda:\n","        \"\"\"\n","        self.src, self.src_lengths = torch_batch.src\n","\n","        self.emb, _ = torch_batch.emb\n","        self.src_mask = (self.emb != pad_index).unsqueeze(1)\n","        self.nseqs = self.src.size(0)\n","        self.trg_input = None\n","        self.trg = None\n","        self.trg_mask = None\n","        self.trg_lengths = None\n","        self.ntokens = None\n","\n","        self.padded_src = torch.zeros(self.nseqs, self.src.shape[1], 240)\n","        self.padded_src[:, :, 0:200] = self.src\n","\n","\n","        self.use_cuda = model.use_cuda\n","        self.target_pad = TARGET_PAD\n","        # Just Count\n","        self.just_count_in = model.just_count_in\n","        # Future Prediction\n","        self.future_prediction = model.future_prediction\n","\n","        if hasattr(torch_batch, \"trg\"):\n","            trg = torch_batch.trg\n","            trg_lengths = torch_batch.trg.shape[1]\n","            # trg_input is used for teacher forcing, last one is cut off\n","            # Remove the last frame for target input, as inputs are only up to frame N-1\n","            self.trg_input = trg.clone()[:, :-1,:]\n","\n","            self.trg_lengths = trg_lengths\n","            # trg is used for loss computation, shifted by one since BOS\n","            self.trg = trg.clone()[:, 1:, :]\n","\n","            # Just Count\n","            if self.just_count_in:\n","                # If Just Count, cut off the first frame of trg_input\n","                self.trg_input = self.trg_input[:, :, -1:]\n","\n","            # Future Prediction\n","            if self.future_prediction != 0:\n","                # Loop through the future prediction, concatenating the frames shifted across once each time\n","                future_trg = torch.Tensor()\n","                # Concatenate each frame (Not counter)\n","                for i in range(0, self.future_prediction):\n","                    future_trg = torch.cat((future_trg, self.trg[:, i:-(self.future_prediction - i), :-1].clone()), dim=2)\n","                # Create the final target using the collected future_trg and original trg\n","                self.trg = torch.cat((future_trg, self.trg[:,:-self.future_prediction,-1:]), dim=2)\n","\n","                # Cut off the last N frames of the trg_input\n","                self.trg_input = self.trg_input[:, :-self.future_prediction, :]\n","\n","            # Target Pad is dynamic, so we exclude the padded areas from the loss computation\n","            trg_mask = (self.trg_input != self.target_pad).unsqueeze(1)\n","            # This increases the shape of the target mask to be even (16,1,120,120) -\n","            # adding padding that replicates - so just continues the False's or True's\n","            pad_amount = self.trg_input.shape[1] - self.trg_input.shape[2]\n","            # Create the target mask the same size as target input\n","            self.trg_mask = (F.pad(input=trg_mask.double(), pad=(pad_amount, 0, 0, 0), mode='replicate') == 1.0)\n","            self.ntokens = (self.trg != pad_index).data.sum().item()\n","\n","        if self.use_cuda:\n","            self._make_cuda()\n","\n","    # If using Cuda\n","    def _make_cuda(self):\n","        \"\"\"\n","        Move the batch to GPU\n","\n","        :return:\n","        \"\"\"\n","        self.src = self.src.cuda()\n","        self.src_mask = self.src_mask.cuda()\n","\n","        if self.trg_input is not None:\n","            self.trg_input = self.trg_input.cuda()\n","            self.trg = self.trg.cuda()\n","            self.trg_mask = self.trg_mask.cuda()\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GgvIk4H6F-W6"},"source":["### Initialization"]},{"cell_type":"code","metadata":{"id":"qaW65Z01GEWb","executionInfo":{"status":"ok","timestamp":1606763056789,"user_tz":480,"elapsed":15365,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"}}},"source":["from torch.nn.init import _calculate_fan_in_and_fan_out\n","\n","\n","def xavier_uniform_n_(w: Tensor, gain: float = 1., n: int = 4) -> None:\n","    \"\"\"\n","    Xavier initializer for parameters that combine multiple matrices in one\n","    parameter for efficiency. This is e.g. used for GRU and LSTM parameters,\n","    where e.g. all gates are computed at the same time by 1 big matrix.\n","\n","    :param w: parameter\n","    :param gain: default 1\n","    :param n: default 4\n","    \"\"\"\n","    with torch.no_grad():\n","        fan_in, fan_out = _calculate_fan_in_and_fan_out(w)\n","        assert fan_out % n == 0, \"fan_out should be divisible by n\"\n","        fan_out //= n\n","        std = gain * math.sqrt(2.0 / (fan_in + fan_out))\n","        a = math.sqrt(3.0) * std\n","        nn.init.uniform_(w, -a, a)\n","\n","# pylint: disable=too-many-branches\n","def intialize_discriminator(model: nn.Module, cfg: dict) -> None:\n","  \n","    # defaults: xavier, embeddings: normal 0.01, biases: zeros, no orthogonal\n","    gain = float(cfg.get(\"init_gain\", 1.0))  # for xavier\n","    init = cfg.get(\"initializer\", \"xavier\")\n","    init_weight = float(cfg.get(\"init_weight\", 0.01))\n","\n","    embed_init = cfg.get(\"embed_initializer\", \"normal\")\n","    embed_init_weight = float(cfg.get(\"embed_init_weight\", 0.01))\n","    embed_gain = float(cfg.get(\"embed_init_gain\", 1.0))  # for xavier\n","\n","    bias_init = cfg.get(\"bias_initializer\", \"zeros\")\n","    bias_init_weight = float(cfg.get(\"bias_init_weight\", 0.01))\n","\n","    # pylint: disable=unnecessary-lambda, no-else-return\n","    def _parse_init(s, scale, _gain):\n","        scale = float(scale)\n","        assert scale > 0., \"incorrect init_weight\"\n","        if s.lower() == \"xavier\":\n","            return lambda p: nn.init.xavier_uniform_(p, gain=_gain)\n","        elif s.lower() == \"uniform\":\n","            return lambda p: nn.init.uniform_(p, a=-scale, b=scale)\n","        elif s.lower() == \"normal\":\n","            return lambda p: nn.init.normal_(p, mean=0., std=scale)\n","        elif s.lower() == \"zeros\":\n","            return lambda p: nn.init.zeros_(p)\n","        else:\n","            raise ValueError(\"unknown initializer\")\n","\n","    init_fn_ = _parse_init(init, init_weight, gain)\n","    bias_init_fn_ = _parse_init(bias_init, bias_init_weight, gain)\n","    with torch.no_grad():\n","        for name, p in model.named_parameters():\n","          if \"bias\" in name:\n","            bias_init_fn_(p)\n","          else:\n","            init_fn_(p)\n"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A6F9FE6tTVig"},"source":["### Building blocks of the Model"]},{"cell_type":"code","metadata":{"id":"7VFATXOht3GB","executionInfo":{"status":"ok","timestamp":1606763059049,"user_tz":480,"elapsed":2238,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"}}},"source":["class Embeddings(nn.Module):\n","\n","    \"\"\"\n","    Updated Embedding Class\n","    \"\"\"\n","\n","    # pylint: disable=unused-argument\n","    def __init__(self,\n","                 embedding_dim: int = 64,\n","                 scale: bool = False,\n","                 vocab_size: int = 0,\n","                 padding_idx: int = 1,\n","                 freeze: bool = False,\n","                 **kwargs):\n","        \"\"\"\n","        Create new embeddings for the vocabulary.\n","        Use scaling for the Transformer.\n","\n","        :param embedding_dim:\n","        :param scale:\n","        :param vocab_size:\n","        :param padding_idx:\n","        :param freeze: freeze the embeddings during training\n","        \"\"\"\n","        super(Embeddings, self).__init__()\n","        self.embedding_dim = embedding_dim\n","        self.scale = scale\n","        self.vocab_size = vocab_size\n","        #self.lut = nn.Embedding(vocab_size, self.embedding_dim,\n","        #                        padding_idx=padding_idx)\n","        self.lut = nn.Linear(200, embedding_dim)\n","\n","        if freeze:\n","            freeze_params(self)\n","\n","    # pylint: disable=arguments-differ\n","    def forward(self, x: Tensor) -> Tensor:\n","        \"\"\"\n","        Perform lookup for input `x` in the embedding table.\n","\n","        :param x: index in the vocabulary\n","        :return: embedded representation for `x`\n","        \"\"\"\n","        if self.scale:\n","            return self.lut(x) * math.sqrt(self.embedding_dim)\n","        return self.lut(x)\n","\n","    def __repr__(self):\n","        return \"%s(embedding_dim=%d, vocab_size=%d)\" % (\n","            self.__class__.__name__, self.embedding_dim, self.vocab_size)\n","\n","        \n","class Decoder(nn.Module):\n","    \"\"\"\n","    Base decoder class\n","    \"\"\"\n","\n","    @property\n","    def output_size(self):\n","        \"\"\"\n","        Return the output size (size of the target vocabulary)\n","\n","        :return:\n","        \"\"\"\n","        return self._output_size\n","\n","class TransformerDecoder(Decoder):\n","    \"\"\"\n","    A transformer decoder with N masked layers.\n","    Decoder layers are masked so that an attention head cannot see the future.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 num_layers: int = 4,\n","                 num_heads: int = 8,\n","                 hidden_size: int = 512,\n","                 ff_size: int = 2048,\n","                 dropout: float = 0.1,\n","                 emb_dropout: float = 0.1,\n","                 vocab_size: int = 1,\n","                 freeze: bool = False,\n","                 trg_size: int = 97,\n","                 decoder_trg_trg_: bool = True,\n","                 **kwargs):\n","        \"\"\"\n","        Initialize a Transformer decoder.\n","\n","        :param num_layers: number of Transformer layers\n","        :param num_heads: number of heads for each layer\n","        :param hidden_size: hidden size\n","        :param ff_size: position-wise feed-forward size\n","        :param dropout: dropout probability (1-keep)\n","        :param emb_dropout: dropout probability for embeddings\n","        :param vocab_size: size of the output vocabulary\n","        :param freeze: set to True keep all decoder parameters fixed\n","        :param kwargs:\n","        \"\"\"\n","        super(TransformerDecoder, self).__init__()\n","\n","        self._hidden_size = hidden_size\n","\n","        # Dynamic output size depending on the target size\n","        self._output_size = trg_size\n","\n","        # create num_layers decoder layers and put them in a list\n","        self.layers = nn.ModuleList([TransformerDecoderLayer(\n","                size=hidden_size, ff_size=ff_size, num_heads=num_heads,\n","                dropout=dropout, decoder_trg_trg=decoder_trg_trg_) for _ in range(num_layers)])\n","\n","        self.pe = PositionalEncoding(hidden_size,mask_count=True)\n","        self.layer_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n","\n","        self.emb_dropout = nn.Dropout(p=emb_dropout)\n","\n","        # Output layer to be the size of joints vector + 1 for counter (total is trg_size)\n","        self.output_layer = nn.Linear(hidden_size, trg_size, bias=False)\n","\n","        if freeze:\n","            freeze_params(self)\n","\n","    def forward(self,\n","                trg_embed: Tensor = None,\n","                encoder_output: Tensor = None,\n","                src_mask: Tensor = None,\n","                trg_mask: Tensor = None,\n","                **kwargs):\n","        \"\"\"\n","        Transformer decoder forward pass.\n","\n","        :param trg_embed: embedded targets\n","        :param encoder_output: source representations\n","        :param encoder_hidden: unused\n","        :param src_mask:\n","        :param unroll_steps: unused\n","        :param hidden: unused\n","        :param trg_mask: to mask out target paddings\n","                         Note that a subsequent mask is applied here.\n","        :param kwargs:\n","        :return:\n","        \"\"\"\n","        assert trg_mask is not None, \"trg_mask required for Transformer\"\n","\n","        # add position encoding to word embedding\n","        x = self.pe(trg_embed)\n","        # Dropout if given\n","        x = self.emb_dropout(x)\n","\n","        padding_mask = trg_mask\n","        # Create subsequent mask for decoding\n","        sub_mask = subsequent_mask(\n","            trg_embed.size(1)).type_as(trg_mask)\n","\n","        # Apply each layer to the input\n","        for layer in self.layers:\n","            x = layer(x=x, memory=encoder_output,\n","                      src_mask=src_mask, trg_mask=sub_mask, padding_mask=padding_mask)\n","\n","        # Apply a layer normalisation\n","        x = self.layer_norm(x)\n","        # Output layer turns it back into vectors of size trg_size\n","        output = self.output_layer(x)\n","\n","        return output, x, None, None\n","\n","    def __repr__(self):\n","        return \"%s(num_layers=%r, num_heads=%r)\" % (\n","            self.__class__.__name__, len(self.layers),\n","            self.layers[0].trg_trg_att.num_heads)\n","\n","class Encoder(nn.Module):\n","    \"\"\"\n","    Base encoder class\n","    \"\"\"\n","    @property\n","    def output_size(self):\n","        \"\"\"\n","        Return the output size\n","\n","        :return:\n","        \"\"\"\n","        return self._output_size\n","\n","class TransformerEncoder(Encoder):\n","    \"\"\"\n","    Transformer Encoder\n","    \"\"\"\n","\n","    #pylint: disable=unused-argument\n","    def __init__(self,\n","                 hidden_size: int = 512,\n","                 ff_size: int = 2048,\n","                 num_layers: int = 8,\n","                 num_heads: int = 4,\n","                 dropout: float = 0.1,\n","                 emb_dropout: float = 0.1,\n","                 freeze: bool = False,\n","                 **kwargs):\n","        \"\"\"\n","        Initializes the Transformer.\n","        :param hidden_size: hidden size and size of embeddings\n","        :param ff_size: position-wise feed-forward layer size.\n","          (Typically this is 2*hidden_size.)\n","        :param num_layers: number of layers\n","        :param num_heads: number of heads for multi-headed attention\n","        :param dropout: dropout probability for Transformer layers\n","        :param emb_dropout: Is applied to the input (word embeddings).\n","        :param freeze: freeze the parameters of the encoder during training\n","        :param kwargs:\n","        \"\"\"\n","        super(TransformerEncoder, self).__init__()\n","\n","        # build all (num_layers) layers\n","        self.layers = nn.ModuleList([\n","            TransformerEncoderLayer(size=hidden_size, ff_size=ff_size,\n","                                    num_heads=num_heads, dropout=dropout)\n","            for _ in range(num_layers)])\n","\n","        self.layer_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n","        self.pe = PositionalEncoding(hidden_size)\n","        self.emb_dropout = nn.Dropout(p=emb_dropout)\n","        self._output_size = hidden_size\n","\n","        if freeze:\n","            freeze_params(self)\n","\n","    #pylint: disable=arguments-differ\n","    def forward(self,\n","                embed_src: Tensor,\n","                src_length: Tensor,\n","                mask: Tensor) -> (Tensor, Tensor):\n","        \"\"\"\n","        Pass the input (and mask) through each layer in turn.\n","        Applies a Transformer encoder to sequence of embeddings x.\n","        The input mini-batch x needs to be sorted by src length.\n","        x and mask should have the same dimensions [batch, time, dim].\n","\n","        :param embed_src: embedded src inputs,\n","            shape (batch_size, src_len, embed_size)\n","        :param src_length: length of src inputs\n","            (counting tokens before padding), shape (batch_size)\n","        :param mask: indicates padding areas (zeros where padding), shape\n","            (batch_size, src_len, embed_size)\n","        :return:\n","            - output: hidden states with\n","                shape (batch_size, max_length, directions*hidden),\n","            - hidden_concat: last hidden state with\n","                shape (batch_size, directions*hidden)\n","        \"\"\"\n","\n","        x = embed_src\n","        # Add position encoding to word embeddings\n","        x = self.pe(x)\n","        # Add Dropout\n","        x = self.emb_dropout(x)\n","\n","        # Apply each layer to the input\n","        for layer in self.layers:\n","            x = layer(x, mask)\n","\n","        return self.layer_norm(x), None\n","\n","    def __repr__(self):\n","        return \"%s(num_layers=%r, num_heads=%r)\" % (\n","            self.__class__.__name__, len(self.layers),\n","            self.layers[0].src_src_att.num_heads)\n","\n","\n","class RegLoss(nn.Module):\n","    \"\"\"\n","    Regression Loss\n","    \"\"\"\n","\n","    def __init__(self, cfg, target_pad=0.0):\n","        super(RegLoss, self).__init__()\n","\n","        self.loss = cfg[\"training\"][\"loss\"].lower()\n","\n","        if self.loss == \"l1\":\n","            self.criterion = nn.L1Loss()\n","        elif self.loss == \"mse\":\n","            self.criterion = nn.MSELoss()\n","\n","        else:\n","            print(\"Loss not found - revert to default L1 loss\")\n","            self.criterion = nn.L1Loss()\n","\n","        model_cfg = cfg[\"model\"]\n","\n","        self.target_pad = target_pad\n","        self.loss_scale = model_cfg.get(\"loss_scale\", 1.0)\n","\n","    # pylint: disable=arguments-differ\n","    def forward(self, preds, targets):\n","\n","        loss_mask = (targets != self.target_pad)\n","       \n","        # Find the masked predictions and targets using loss mask\n","        preds_masked = preds * loss_mask\n","        targets_masked = targets * loss_mask\n","\n","        # Calculate loss just over the masked predictions\n","        loss = self.criterion(preds_masked, targets_masked)\n","\n","        # Multiply loss by the loss scale\n","        if self.loss_scale != 1.0:\n","            loss = loss * self.loss_scale\n","\n","        return loss\n","\n","class Discriminator(nn.Module):\n","    \"\"\"\n","    Consists of 3 1D CONV with 64 features \n","    in between a RELU\n","    and final linear layer to sigmoid.\n","\n","    Wil concatennate the skeleton with word \n","    \"\"\"\n","    def __init__(self, max_frame=88, feature=64, filter=10, embedding_size=240):\n","        super(Discriminator, self).__init__()\n","        self.max_frame = max_frame\n","        self.discriminate = nn.Sequential(\n","            # plus 1 for the word \n","            nn.Conv1d(embedding_size, feature, filter),      \n","            nn.LeakyReLU(),\n","            nn.Conv1d(feature, feature, filter),\n","            nn.LeakyReLU(),\n","            nn.Conv1d(feature, 1, filter),\n","            nn.LeakyReLU(),\n","            nn.Linear(62, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input, word):\n","        # print(input.shape, word.shape)\n","        # padded input\n","        padded_input = torch.zeros(input.size(0), self.max_frame, 240)\n","        padded_input[:, 0:input.size(1), :] = input\n","        input = torch.cat((padded_input, word), 1).cuda()\n","        x = self.discriminate(input.permute(0, 2, 1))\n","        return x.squeeze()\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"VrJVbl9wC-lw","executionInfo":{"status":"ok","timestamp":1606763059050,"user_tz":480,"elapsed":2167,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"}},"outputId":"580209c5-67ef-46b8-feac-ec062f98d0ec"},"source":["\"\""],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["''"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"a-aRdpmlTanv"},"source":["### Main Model"]},{"cell_type":"code","metadata":{"id":"N32V5ozAtFQx","executionInfo":{"status":"ok","timestamp":1606763059052,"user_tz":480,"elapsed":1871,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"}}},"source":["class Model(nn.Module):\n","    \"\"\"\n","    Base Model class\n","    \"\"\"\n","\n","    def __init__(self,\n","                 encoder: Encoder,\n","                 decoder: Decoder,\n","                 src_embed: Embeddings,\n","                 trg_embed: Embeddings,\n","                 src_vocab: Vocabulary,\n","                 trg_vocab: Vocabulary,\n","                 cfg: dict,\n","                 in_trg_size: int,\n","                 out_trg_size: int,\n","                 ) -> None:\n","        \"\"\"\n","        Create a new encoder-decoder model\n","\n","        :param encoder: encoder\n","        :param decoder: decoder\n","        :param src_embed: source embedding\n","        :param trg_embed: target embedding\n","        :param src_vocab: source vocabulary\n","        :param trg_vocab: target vocabulary\n","        \"\"\"\n","        super(Model, self).__init__()\n","\n","        model_cfg = cfg[\"model\"]\n","\n","        self.src_embed = src_embed\n","        self.trg_embed = trg_embed\n","\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.src_vocab = src_vocab\n","        self.trg_vocab = trg_vocab\n","        self.bos_index = self.src_vocab.stoi[BOS_TOKEN]\n","        self.pad_index = self.src_vocab.stoi[PAD_TOKEN]\n","        self.eos_index = self.src_vocab.stoi[EOS_TOKEN]\n","        self.target_pad = TARGET_PAD\n","\n","        self.use_cuda = cfg[\"training\"][\"use_cuda\"]\n","\n","        self.in_trg_size = in_trg_size\n","        self.out_trg_size = out_trg_size\n","        self.count_in = model_cfg.get(\"count_in\",True)\n","        # Just Counter\n","        self.just_count_in = model_cfg.get(\"just_count_in\",False)\n","        # Gaussian Noise\n","        self.gaussian_noise = model_cfg.get(\"gaussian_noise\",False)\n","        # Gaussian Noise\n","        if self.gaussian_noise:\n","            self.noise_rate = model_cfg.get(\"noise_rate\", 1.0)\n","\n","        # Future Prediction - predict for this many frames in the future\n","        self.future_prediction = model_cfg.get(\"future_prediction\", 0)\n","\n","    # pylint: disable=arguments-differ\n","    def forward(self,\n","                src: Tensor,\n","                trg_input: Tensor,\n","                src_mask: Tensor,\n","                src_lengths: Tensor,\n","                trg_mask: Tensor = None) -> (\n","        Tensor, Tensor, Tensor, Tensor):\n","        \"\"\"\n","        First encodes the source sentence.\n","        Then produces the target one word at a time.\n","\n","        :param src: source input\n","        :param trg_input: target input\n","        :param src_mask: source mask\n","        :param src_lengths: length of source inputs\n","        :param trg_mask: target mask\n","        :return: decoder outputs\n","        \"\"\"\n","\n","        # Encode the source sequence\n","        encoder_output, encoder_hidden = self.encode(src=src,\n","                                                     src_length=src_lengths,\n","                                                     src_mask=src_mask)\n","        unroll_steps = trg_input.size(1)\n","\n","        # Add gaussian noise to the target inputs, if in training\n","        if (self.gaussian_noise) and (self.training) and (self.out_stds is not None):\n","\n","            # Create a normal distribution of random numbers between 0-1\n","            noise = trg_input.data.new(trg_input.size()).normal_(0, 1)\n","            # Zero out the noise over the counter\n","            noise[:,:,-1] = torch.zeros_like(noise[:, :, -1])\n","\n","            # Need to add a zero on the end of\n","            if self.future_prediction != 0:\n","                self.out_stds = torch.cat((self.out_stds,torch.zeros_like(self.out_stds)))[:trg_input.shape[-1]]\n","\n","            # Need to multiply by the standard deviations\n","            noise = noise * self.out_stds\n","\n","            # Add to trg_input multiplied by the noise rate\n","            trg_input = trg_input + self.noise_rate*noise\n","\n","        # Decode the target sequence\n","        skel_out, dec_hidden, _, _ = self.decode(encoder_output=encoder_output,\n","                                                 src_mask=src_mask, trg_input=trg_input,\n","                                                 trg_mask=trg_mask)\n","\n","        gloss_out = None\n","\n","        return skel_out, gloss_out\n","\n","    def encode(self, src: Tensor, src_length: Tensor, src_mask: Tensor) \\\n","        -> (Tensor, Tensor):\n","        \"\"\"\n","        Encodes the source sentence.\n","\n","        :param src:\n","        :param src_length:\n","        :param src_mask:\n","        :return: encoder outputs (output, hidden_concat)\n","        \"\"\"\n","        # Encode an embedded source\n","        encode_output = self.encoder(self.src_embed(src), src_length, src_mask)\n","\n","        return encode_output\n","\n","\n","    def decode(self, encoder_output: Tensor,\n","               src_mask: Tensor, trg_input: Tensor,\n","               trg_mask: Tensor = None) \\\n","        -> (Tensor, Tensor, Tensor, Tensor):\n","\n","        \"\"\"\n","        Decode, given an encoded source sentence.\n","\n","        :param encoder_output: encoder states for attention computation\n","        :param encoder_hidden: last encoder state for decoder initialization\n","        :param src_mask: source mask, 1 at valid tokens\n","        :param trg_input: target inputs\n","        :param unroll_steps: number of steps to unrol the decoder for\n","        :param decoder_hidden: decoder hidden state (optional)\n","        :param trg_mask: mask for target steps\n","        :return: decoder outputs (outputs, hidden, att_probs, att_vectors)\n","        \"\"\"\n","\n","        # Enbed the target using a linear layer\n","        trg_embed = self.trg_embed(trg_input)\n","        # Apply decoder to the embedded target\n","        decoder_output = self.decoder(trg_embed=trg_embed, encoder_output=encoder_output,\n","                               src_mask=src_mask,trg_mask=trg_mask)\n","\n","        return decoder_output\n","\n","    def calculate_generator_loss(self, skel_out, trg, loss_function: nn.Module):\n","        torso_loss = loss_function(skel_out[:, :, 0:16], trg[:, :, 0:16])\n","        hand_loss = loss_function(skel_out[:, :, 16:16+84], trg[:, :, 16:16+84])\n","        face_loss = loss_function(skel_out[:, :, 16+84:], trg[:, :, 16+84:])\n","        \n","        #batch_loss = loss_function(skel_out, batch.trg)\n","        batch_loss = torso_loss * 0.4 + hand_loss * 0.5 + face_loss * 0.1\n","\n","        # If gaussian noise, find the noise for the next epoch\n","        if self.gaussian_noise:\n","            # Calculate the difference between prediction and GT, to find STDs of error\n","            with torch.no_grad():\n","                noise = skel_out.detach() - trg.detach()\n","\n","            if self.future_prediction != 0:\n","                # Cut to only the first frame prediction + add the counter\n","                noise = noise[:, :, :noise.shape[2] // (self.future_prediction)]\n","\n","        else:\n","            noise = None\n","\n","        # return batch loss = sum over all elements in batch that are not pad\n","        return batch_loss, torso_loss.item(), hand_loss.item(), face_loss.item(), noise\n","\n","    def get_loss_for_batch(self, batch: Batch, loss_function: nn.Module):\n","        \"\"\"\n","        Compute non-normalized loss and number of tokens for a batch\n","\n","        :param batch: batch to compute loss for\n","        :param loss_function: loss function, computes for input and target\n","            a scalar loss for the complete batch\n","        :return: batch_loss: sum of losses over non-pad elements in the batch\n","        \"\"\"\n","        # Forward through the batch input\n","        skel_out, _ = self.forward(\n","            src=batch.src, trg_input=batch.trg_input,\n","            src_mask=batch.src_mask, src_lengths=batch.src_lengths,\n","            trg_mask=batch.trg_mask)\n","\n","        # compute batch loss using skel_out and the batch target\n","        # do it by weight\n","        torso_loss = loss_function(skel_out[:, :, 0:16], batch.trg[:, :, 0:16])\n","        hand_loss = loss_function(skel_out[:, :, 16:16+84], batch.trg[:, :, 16:16+84])\n","        face_loss = loss_function(skel_out[:, :, 16+84:], batch.trg[:, :, 16+84:])\n","        \n","        #batch_loss = loss_function(skel_out, batch.trg)\n","        batch_loss = torso_loss * 0.4 + hand_loss * 0.5 + face_loss * 0.1\n","\n","        # If gaussian noise, find the noise for the next epoch\n","        if self.gaussian_noise:\n","            # Calculate the difference between prediction and GT, to find STDs of error\n","            with torch.no_grad():\n","                noise = skel_out.detach() - batch.trg.detach()\n","\n","            if self.future_prediction != 0:\n","                # Cut to only the first frame prediction + add the counter\n","                noise = noise[:, :, :noise.shape[2] // (self.future_prediction)]\n","\n","        else:\n","            noise = None\n","\n","        dtw = 0 #calculate_dtw(batch.trg, skel_out)\n","        # return batch loss = sum over all elements in batch that are not pad\n","        return batch_loss, torso_loss.item(), hand_loss.item(), face_loss.item(), noise\n","\n","    def run_batch(self, batch: Batch, max_output_length: int,) -> (np.array, np.array):\n","        \"\"\"\n","        Get outputs and attentions scores for a given batch\n","\n","        :param batch: batch to generate hypotheses for\n","        :param max_output_length: maximum length of hypotheses\n","        :param beam_size: size of the beam for beam search, if 0 use greedy\n","        :param beam_alpha: alpha value for beam search\n","        :return: stacked_output: hypotheses for batch,\n","            stacked_attention_scores: attention scores for batch\n","        \"\"\"\n","        # First encode the batch, as this can be done in all one go\n","        encoder_output, encoder_hidden = self.encode(\n","            batch.src, batch.src_lengths,\n","            batch.src_mask)\n","\n","        # if maximum output length is not globally specified, adapt to src len\n","        if max_output_length is None:\n","            max_output_length = int(max(batch.src_lengths.cpu().numpy()) * 1.5)\n","\n","        # Then decode the batch separately, as needs to be done iteratively\n","        # greedy decoding\n","        stacked_output, stacked_attention_scores = greedy(\n","                encoder_output=encoder_output,\n","                src_mask=batch.src_mask,\n","                embed=self.trg_embed,\n","                decoder=self.decoder,\n","                trg_input=batch.trg_input,\n","                model=self)\n","\n","        return stacked_output, stacked_attention_scores\n","\n","    def __repr__(self) -> str:\n","        \"\"\"\n","        String representation: a description of encoder, decoder and embeddings\n","\n","        :return: string representation\n","        \"\"\"\n","        return \"%s(\\n\" \\\n","               \"\\tencoder=%s,\\n\" \\\n","               \"\\tdecoder=%s,\\n\" \\\n","               \"\\tsrc_embed=%s,\\n\" \\\n","               \"\\ttrg_embed=%s)\" % (self.__class__.__name__, self.encoder,\n","                   self.decoder, self.src_embed, self.trg_embed)\n","               \n","def build_model(cfg: dict = None,\n","                src_vocab = None,\n","                trg_vocab = None) -> Model:\n","    \"\"\"\n","    Build and initialize the model according to the configuration.\n","\n","    :param cfg: dictionary configuration containing model specifications\n","    :param src_vocab: source vocabulary\n","    :param trg_vocab: target vocabulary\n","    :return: built and initialized model\n","    \"\"\"\n","\n","    full_cfg = cfg\n","    cfg = cfg[\"model\"]\n","\n","    src_padding_idx = None\n","    trg_padding_idx = 0\n","\n","    # Input target size is the joint vector length plus one for counter\n","    in_trg_size = cfg[\"trg_size\"] + 1\n","    # Output target size is the joint vector length plus one for counter\n","    out_trg_size = cfg[\"trg_size\"] + 1\n","\n","    just_count_in = cfg.get(\"just_count_in\", False)\n","    future_prediction = cfg.get(\"future_prediction\", 0)\n","\n","    #  Just count in limits the in target size to 1\n","    if just_count_in:\n","        in_trg_size = 1\n","\n","    # Future Prediction increases the output target size\n","    if future_prediction != 0:\n","        # Times the trg_size (minus counter) by amount of predicted frames, and then add back counter\n","        out_trg_size = (out_trg_size - 1 ) * future_prediction + 1\n","\n","    # Define source embedding\n","\n","    with open(os.path.join(DATA_DIR, 'embedding.200.pkl') ,'rb') as f:\n","        embedding_dict = pickle.load(f)\n","    src_embed = Embeddings(\n","        embedding_dict=embedding_dict,\n","        **cfg[\"encoder\"][\"embeddings\"], vocab_size=len(src_vocab),\n","        padding_idx=src_padding_idx)\n","\n","    # Define target linear\n","    # Linear layer replaces an embedding layer - as this takes in the joints size as opposed to a token\n","    trg_linear = nn.Linear(in_trg_size, cfg[\"decoder\"][\"embeddings\"][\"embedding_dim\"])\n","\n","    ## Encoder -------\n","    enc_dropout = cfg[\"encoder\"].get(\"dropout\", 0.) # Dropout\n","    enc_emb_dropout = cfg[\"encoder\"][\"embeddings\"].get(\"dropout\", enc_dropout)\n","    assert cfg[\"encoder\"][\"embeddings\"][\"embedding_dim\"] == \\\n","           cfg[\"encoder\"][\"hidden_size\"], \\\n","           \"for transformer, emb_size must be hidden_size\"\n","\n","    # Transformer Encoder\n","    encoder = TransformerEncoder(**cfg[\"encoder\"],\n","                                 emb_size=src_embed.embedding_dim,\n","                                 emb_dropout=enc_emb_dropout)\n","\n","    ## Decoder -------\n","    dec_dropout = cfg[\"decoder\"].get(\"dropout\", 0.) # Dropout\n","    dec_emb_dropout = cfg[\"decoder\"][\"embeddings\"].get(\"dropout\", dec_dropout)\n","    decoder_trg_trg = cfg[\"decoder\"].get(\"decoder_trg_trg\", True)\n","    # Transformer Decoder\n","    decoder = TransformerDecoder(\n","        **cfg[\"decoder\"], encoder=encoder, vocab_size=len(trg_vocab),\n","        emb_size=trg_linear.out_features, emb_dropout=dec_emb_dropout,\n","        trg_size=out_trg_size, decoder_trg_trg_=decoder_trg_trg)\n","\n","    # Define the model\n","    model = Model(encoder=encoder,\n","                  decoder=decoder,\n","                  src_embed=src_embed,\n","                  trg_embed=trg_linear,\n","                  src_vocab=src_vocab,\n","                  trg_vocab=trg_vocab,\n","                  cfg=full_cfg,\n","                  in_trg_size=in_trg_size,\n","                  out_trg_size=out_trg_size)\n","\n","    # Custom initialization of model parameters\n","    initialize_model(model, cfg, src_padding_idx, trg_padding_idx)\n","\n","    return model\n"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6xnnemWTTdmc"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"wgalc53TTiWV"},"source":["### Main Train Call"]},{"cell_type":"code","metadata":{"id":"uPS0rTD2xRzq","executionInfo":{"status":"ok","timestamp":1606763089813,"user_tz":480,"elapsed":2255,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"}}},"source":["class TrainManager:\n","\n","    def __init__(self, model: Model, \n","                 discriminator: Discriminator,\n","                 config: dict, test=False) -> None:\n","\n","        train_config = config[\"training\"]\n","        model_dir = os.path.join(MODEL_DIR, version)\n","        # If model continue, continues model from the latest checkpoint\n","        model_continue = train_config.get(\"continue\", True)\n","        # If the directory has not been created, can't continue from anything\n","        if not os.path.isdir(model_dir):\n","            model_continue = False\n","        if test:\n","            model_continue = True\n","\n","        # files for logging and storing\n","        self.model_dir = model_dir\n","        \n","        # Build validation files\n","        self.valid_report_file = \"{}/validations.txt\".format(self.model_dir)\n","        self.logger = make_logger(model_dir=self.model_dir)\n","        self.logging_freq = train_config.get('logging_freq', 100)\n","\n","        # model\n","        self.model = model\n","        self.disc = discriminator\n","        self.pad_index = self.model.pad_index\n","        self.bos_index = self.model.bos_index\n","        self._log_parameters_list()\n","        self.target_pad = TARGET_PAD\n","\n","        # New Regression loss - depending on config\n","        self.loss = RegLoss(cfg = config,\n","                            target_pad=self.target_pad)\n","        self.adv_loss = nn.BCELoss()\n","\n","        self.normalization = \"batch\"\n","\n","        # optimization\n","        self.learning_rate_min = train_config.get(\"learning_rate_min\", 1.0e-8)\n","        self.clip_grad_fun = build_gradient_clipper(config=train_config)\n","        self.optimizer = build_optimizer(config=train_config, parameters=model.parameters())\n","        self.optimizerD = build_optimizer(config=train_config, parameters=discriminator.parameters())\n","\n","        # validation & early stopping\n","        self.validation_freq = train_config.get(\"validation_freq\", 1000)\n","        self.ckpt_best_queue = queue.Queue(maxsize=train_config.get(\"keep_last_ckpts\", 1))\n","        self.ckpt_queue = queue.Queue(maxsize=1)\n","\n","        self.val_on_train = config[\"data\"].get(\"val_on_train\", True)\n","\n","        # TODO - Include Back Translation\n","        self.eval_metric = train_config.get(\"eval_metric\", \"dtw\").lower()\n","        if self.eval_metric not in ['bleu', 'chrf', \"dtw\"]:\n","            raise ConfigurationError(\"Invalid setting for 'eval_metric', \"\n","                                     \"valid options: 'bleu', 'chrf', 'DTW'\")\n","        self.early_stopping_metric = train_config.get(\"early_stopping_metric\",\n","                                                       \"eval_metric\")\n","\n","        # if we schedule after BLEU/chrf, we want to maximize it, else minimize\n","        # early_stopping_metric decides on how to find the early stopping point:\n","        # ckpts are written when there's a new high/low score for this metric\n","        if self.early_stopping_metric in [\"loss\",\"dtw\"]:\n","            self.minimize_metric = True\n","        else:\n","            raise ConfigurationError(\"Invalid setting for 'early_stopping_metric', \"\n","                                    \"valid options: 'loss', 'dtw',.\")\n","\n","        # learning rate scheduling\n","        self.scheduler, self.scheduler_step_at = build_scheduler(\n","            config=train_config,\n","            scheduler_mode=\"min\" if self.minimize_metric else \"max\",\n","            optimizer=self.optimizer,\n","            hidden_size=config[\"model\"][\"encoder\"][\"hidden_size\"])\n","\n","        # data & batch handling\n","        self.level = \"word\"\n","        self.shuffle = train_config.get(\"shuffle\", True)\n","        self.epochs = train_config.get('epochs')\n","        self.batch_size = train_config[\"batch_size\"]\n","        self.batch_type = \"sentence\"\n","        self.eval_batch_size = train_config.get(\"eval_batch_size\",self.batch_size)\n","        self.eval_batch_type = train_config.get(\"eval_batch_type\",self.batch_type)\n","        self.batch_multiplier = train_config.get(\"batch_multiplier\", 1)\n","\n","        # generation\n","        self.max_output_length = train_config.get(\"max_output_length\", None)\n","\n","        # CPU / GPU\n","        self.use_cuda = train_config[\"use_cuda\"]\n","        if self.use_cuda:\n","            self.model.cuda()\n","            self.loss.cuda()\n","            self.disc.cuda()\n","            self.adv_loss.cuda()\n","\n","        # initialize training statistics\n","        self.steps = 0\n","        # stop training if this flag is True by reaching learning rate minimum\n","        self.stop = False\n","        self.total_tokens = 0\n","        self.best_ckpt_iteration = 0\n","        # initial values for best scores\n","        self.best_ckpt_score = np.inf if self.minimize_metric else -np.inf\n","        # comparison function for scores\n","        self.is_best = lambda score: score < self.best_ckpt_score \\\n","            if self.minimize_metric else score > self.best_ckpt_score\n","\n","        ## Checkpoint restart\n","        # If continuing\n","        if model_continue:\n","            # Get the latest checkpoint\n","            tf_ckpt = get_latest_checkpoint(model_dir, model_type='_tf')\n","            gan_ckpt = get_latest_checkpoint(model_dir, model_type='_gan')\n","            if tf_ckpt is None:\n","                self.logger.info(f\"Can't find checkpoint in directory {tf_ckpt}\")\n","            else:\n","                self.logger.info(f\"Continuing model from {tf_ckpt} and {gan_ckpt}\", )\n","                self.init_from_checkpoint(tf_ckpt, model_type='tf')\n","                self.init_from_checkpoint(gan_ckpt, model_type='gan')\n","\n","        # Skip frames\n","        self.skip_frames = config[\"data\"].get(\"skip_frames\", 1)\n","\n","        ## -- Data augmentation --\n","        # Just Counter\n","        self.just_count_in = config[\"model\"].get(\"just_count_in\",False)\n","        # Gaussian Noise\n","        self.gaussian_noise = config[\"model\"].get(\"gaussian_noise\", False)\n","        \n","        if self.gaussian_noise:\n","            # How much the noise is added in\n","            self.noise_rate = config[\"model\"].get(\"noise_rate\", 1.0)\n","\n","        if self.just_count_in and (self.gaussian_noise):\n","            raise ConfigurationError(\"Can't have both just_count_in and gaussian_noise as True\")\n","\n","        self.future_prediction = config[\"model\"].get(\"future_prediction\", 0)\n","        if self.future_prediction != 0:\n","            frames_predicted = [i for i in range(self.future_prediction)]\n","            print(f\"Future prediction. Frames predicted: {frames_predicted}\")\n","\n","    # Save a checkpoint\n","    def _save_checkpoint(self, type=\"every\", model_type=\"tf\") -> None:\n","        # Define model path\n","        model_path = \"{}/{}_{}_{}.ckpt\".format(self.model_dir, self.steps, type, model_type)\n","        # Define State\n","\n","        state = {\n","            \"steps\": self.steps,\n","            \"total_tokens\": self.total_tokens,\n","            \"best_ckpt_score\": self.best_ckpt_score,\n","            \"best_ckpt_iteration\": self.best_ckpt_iteration,\n","            \"model_state\": self.model.state_dict(),\n","            \"optimizer_state\": self.optimizer.state_dict(),\n","            \"scheduler_state\": self.scheduler.state_dict() if \\\n","            self.scheduler is not None else None,\n","        }\n","\n","        if model_type ==\"gan\":\n","            state[\"model_state\"] = self.disc.state_dict()\n","            state[\"optimizer_state\"] = self.optimizerD.state_dict()\n","\n","        torch.save(state, model_path)\n","\n","        # If this is the best checkpoint\n","        if type == \"best\":\n","            if self.ckpt_best_queue.full():\n","              to_delete = self.ckpt_best_queue.get()  # delete oldest ckpt\n","              try:\n","                os.remove(to_delete)\n","              except FileNotFoundError:\n","                print(f\"Wanted to delete old checkpoint {to_delete} but file does not exist.\")\n","            self.ckpt_best_queue.put(model_path)\n","\n","            best_path = \"{}/best_{}.ckpt\".format(self.model_dir, model_type)\n","            torch.save(state, best_path)\n","\n","        # If this is just the checkpoint at every validation\n","        elif type == \"every\":\n","            if self.ckpt_queue.full():\n","              to_delete = self.ckpt_queue.get()  # delete oldest ckpt\n","              try:\n","                os.remove(to_delete)\n","              except FileNotFoundError:\n","                print(f\"Wanted to delete old checkpoint {to_delete} but file does not exist.\")\n","\n","            self.ckpt_queue.put(model_path)\n","            every_path = \"{}/every_{}.ckpt\".format(self.model_dir, model_type)\n","            # overwrite every.ckpt\n","            torch.save(state, every_path)\n","\n","    # Initialise from a checkpoint\n","    def init_from_checkpoint(self, path: str, model_type: str = \"tf\") -> None:\n","        # Find last checkpoint\n","        model_checkpoint = load_checkpoint(path=path, use_cuda=self.use_cuda)\n","\n","        # restore model and optimizer parameters\n","        if model_type == \"tf\":\n","          self.model.load_state_dict(model_checkpoint[\"model_state\"])\n","          self.optimizer.load_state_dict(model_checkpoint[\"optimizer_state\"])\n","\n","          if model_checkpoint[\"scheduler_state\"] is not None and \\\n","                  self.scheduler is not None:\n","              # Load the scheduler state\n","              self.scheduler.load_state_dict(model_checkpoint[\"scheduler_state\"])\n","\n","          # restore counts\n","          self.steps = model_checkpoint[\"steps\"]\n","          self.total_tokens = model_checkpoint[\"total_tokens\"]\n","          self.best_ckpt_score = model_checkpoint[\"best_ckpt_score\"]\n","          self.best_ckpt_iteration = model_checkpoint[\"best_ckpt_iteration\"]\n","        else:\n","          self.optimizerD.load_state_dict(model_checkpoint[\"optimizer_state\"])\n","          self.disc.load_state_dict(model_checkpoint['model_state'])\n","\n","        # move parameters to cuda\n","        if self.use_cuda:\n","            self.model.cuda()\n","\n","    # Train and validate function\n","    def train_and_validate(self, train_data: Dataset, valid_data: Dataset) \\\n","            -> None:\n","        # Make training iterator\n","        train_iter = make_data_iter(train_data,\n","                                    batch_size=self.batch_size,\n","                                    batch_type=self.batch_type,\n","                                    train=True, shuffle=self.shuffle)\n","\n","        val_step = 0\n","        if self.gaussian_noise:\n","            all_epoch_noise = []\n","        # Loop through epochs\n","        epoch_start_time = time.time()\n","        for epoch_no in range(self.epochs):\n","            if self.scheduler is not None and self.scheduler_step_at == \"epoch\":\n","                self.scheduler.step(epoch=epoch_no)\n","\n","            self.model.train()\n","\n","            # Reset statistics for each epoch.\n","            start = time.time()\n","            total_valid_duration = 0\n","            start_tokens = self.total_tokens\n","            count = self.batch_multiplier - 1\n","            epoch_loss = 0\n","            epoch_torso_loss = 0\n","            epoch_hand_loss = 0\n","            epoch_face_loss = 0\n","            epoch_disc_real_loss= 0\n","            epoch_disc_fake_loss = 0\n","            epoch_total_generator_loss = 0\n","            epoch_generator_adv_loss = 0\n","\n","            # If Gaussian Noise, extract STDs for each joint position\n","            if self.gaussian_noise:\n","                if len(all_epoch_noise) != 0:\n","                    self.model.out_stds = torch.mean(torch.stack(([noise.std(dim=[0]) for noise in all_epoch_noise])),dim=-2)\n","                else:\n","                    self.model.out_stds = None\n","                all_epoch_noise = []\n","\n","            for batch in iter(train_iter):\n","                # reactivate training\n","                self.model.train()\n","\n","                # create a Batch object from torchtext batch\n","                batch = Batch(torch_batch=batch,\n","                              pad_index=self.pad_index,\n","                              model=self.model)\n","\n","                update = count == 0\n","                # Train the model on a batch\n","\n","                batch_loss, torso_loss, hand_loss, face_loss, disc_real_loss, disc_fake_loss, total_generator_loss, generator_adv_loss, noise = self._train_batch(batch, update=update)\n","                # If Gaussian Noise, collect the noise\n","                if self.gaussian_noise:\n","                    # If future Prediction, cut down the noise size to just one frame\n","                    if self.future_prediction != 0:\n","                        all_epoch_noise.append(noise.reshape(-1, self.model.out_trg_size // self.future_prediction))\n","                    else:\n","                        all_epoch_noise.append(noise.reshape(-1,self.model.out_trg_size))\n","\n","                count = self.batch_multiplier if update else count\n","                count -= 1\n","                epoch_loss += batch_loss.detach().cpu().numpy()\n","                epoch_torso_loss += torso_loss\n","                epoch_hand_loss += hand_loss\n","                epoch_face_loss += face_loss\n","                epoch_disc_real_loss += disc_real_loss\n","                epoch_disc_fake_loss += disc_fake_loss\n","                epoch_total_generator_loss += total_generator_loss\n","                epoch_generator_adv_loss += generator_adv_loss\n","\n","                if self.scheduler is not None and self.scheduler_step_at == \"step\" and update:\n","                    self.scheduler.step()\n","\n","                # log learning progress\n","                if self.steps % self.logging_freq == 0 and update:\n","                    elapsed = time.time() - start - total_valid_duration\n","                    elapsed_tokens = self.total_tokens - start_tokens\n","                    self.logger.info(\n","                        \"Epoch %3d Step: %8d Batch Loss: %12.6f [Torso : %12.6f, Hand : %12.6f, Face : %12.6f]\"\n","                        \"Tokens per Sec: %8.0f, Lr: %.6f\",\n","                        epoch_no + 1, self.steps, batch_loss, torso_loss, hand_loss, face_loss,\n","                        elapsed_tokens / elapsed,\n","                        self.optimizer.param_groups[0][\"lr\"])\n","                    start = time.time()\n","                    total_valid_duration = 0\n","                    start_tokens = self.total_tokens\n","\n","                # validate on the entire dev set\n","                if self.steps % self.validation_freq == 0 and update:\n","                    self.logger.info(\"Starting validation calculation.\")\n","                    valid_start_time = time.time()\n","\n","                    valid_score, valid_loss, valid_references, valid_hypotheses, \\\n","                        valid_inputs, all_dtw_scores, valid_file_paths = \\\n","                        validate_on_data(\n","                            batch_size=self.eval_batch_size,\n","                            data=valid_data,\n","                            eval_metric=self.eval_metric,\n","                            model=self.model,\n","                            max_output_length=self.max_output_length,\n","                            loss_function=self.loss,\n","                            batch_type=self.eval_batch_type,\n","                            type=\"val\",\n","                        )\n","\n","                    val_step += 1\n","\n","                    if self.early_stopping_metric == \"loss\":\n","                        ckpt_score = valid_loss\n","                    elif self.early_stopping_metric == \"dtw\":\n","                        ckpt_score = valid_score\n","                    else:\n","                        ckpt_score = valid_score\n","\n","                    new_best = False\n","                    self.best = False\n","                    if self.is_best(ckpt_score):\n","                        self.best = True\n","                        self.best_ckpt_score = ckpt_score\n","                        self.best_ckpt_iteration = self.steps\n","                        self.logger.info(\n","                            'Hooray! New best validation result [%s]!',\n","                            self.early_stopping_metric)\n","                        if self.ckpt_queue.maxsize > 0:\n","                            self.logger.info(\"Saving new checkpoint.\")\n","                            new_best = True\n","                            self._save_checkpoint(type=\"best\", model_type='tf')\n","                            self._save_checkpoint(type=\"best\", model_type=\"gan\")\n","\n","                        # Display these sequences, in this index order\n","                        display = list(range(0, len(valid_hypotheses), int(np.ceil(len(valid_hypotheses) / 13.15))))\n","                        self.produce_validation_video(\n","                            output_joints=valid_hypotheses,\n","                            inputs=valid_inputs,\n","                            references=valid_references,\n","                            model_dir=self.model_dir,\n","                            steps=self.steps,\n","                            display=display,\n","                            type=\"val_inf\",\n","                            file_paths=valid_file_paths,\n","                        )\n","\n","                    self._save_checkpoint(type=\"every\", model_type='tf')\n","                    self._save_checkpoint(type=\"every\", model_type=\"gan\")\n","\n","\n","                    if self.scheduler is not None and self.scheduler_step_at == \"validation\":\n","                        self.scheduler.step(ckpt_score)\n","\n","                    # append to validation report\n","                    self._add_report(\n","                        valid_score=valid_score, valid_loss=valid_loss,\n","                        eval_metric=self.eval_metric,\n","                        new_best=new_best, report_type=\"val\",)\n","\n","                    valid_duration = time.time() - valid_start_time\n","                    total_valid_duration += valid_duration\n","                    self.logger.info(\n","                        'Validation result at epoch %3d, step %8d: Val DTW Score: %6.2f, '\n","                        'loss: %8.4f,  duration: %.4fs',\n","                            epoch_no+1, self.steps, valid_score,\n","                            valid_loss, valid_duration)\n","\n","                if self.stop:\n","                    break\n","            if self.stop:\n","                self.logger.info(\n","                    'Training ended since minimum lr %f was reached.',\n","                     self.learning_rate_min)\n","                break\n","\n","            self.logger.info('Epoch %3d: total training loss %.5f [torso: %.5f, hand: %.5f, face: %.5f', epoch_no+1,\n","                             epoch_loss, epoch_torso_loss, epoch_hand_loss, epoch_face_loss)\n","            \n","            self.logger.info('Epoch %3d: disc loss [real: %.5f, fake: %.5f], generator [total: %.5f, adv: %.5f]', epoch_no+1,\n","                             epoch_disc_real_loss, epoch_disc_fake_loss, epoch_total_generator_loss, epoch_generator_adv_loss)\n","            \n","        else:\n","            self.logger.info('Training ended after %3d epochs.', epoch_no+1)\n","        self.logger.info('Best validation result at step %8d: %6.2f %s.',\n","                         self.best_ckpt_iteration, self.best_ckpt_score,\n","                         self.early_stopping_metric)\n","\n","\n","    # Train the batch\n","    def _train_batch(self, batch: Batch, update: bool = True):\n","        #TRAIN Discriminator\n","        self.optimizerD.zero_grad()\n","\n","        real_d = self.disc(batch.trg[:, :, 0:240], batch.padded_src)\n","        valid = torch.ones(len(batch.trg)).cuda()\n","        d_real_loss = self.adv_loss(real_d, valid)\n","\n","        # generated\n","        skel_out, _ = self.model.forward(\n","          src=batch.src, trg_input=batch.trg_input,\n","          src_mask=batch.src_mask, src_lengths=batch.src_lengths,\n","          trg_mask=batch.trg_mask)\n","        \n","      \n","        fake_d = self.disc(skel_out.detach()[:, :, 0:240], batch.padded_src)\n","        fake = torch.zeros(len(batch.trg)).cuda()\n","        d_fake_loss = self.adv_loss(fake_d, fake)\n","\n","        d_loss = (d_real_loss + d_fake_loss)\n","        d_loss.backward()\n","        self.optimizerD.step()\n","\n","        # TRAIN GENERATOR\n","        self.optimizer.zero_grad()\n","\n","        batch_loss, torso_loss, hand_loss, face_loss, noise = self.model.calculate_generator_loss(skel_out,\n","                                                                                                  batch.trg,\n","                                                                                                  loss_function=self.loss)\n","\n","        # normalize batch loss\n","        if self.normalization == \"batch\":\n","            normalizer = batch.nseqs\n","        elif self.normalization == \"tokens\":\n","            normalizer = batch.ntokens\n","        else:\n","            raise NotImplementedError(\"Only normalize by 'batch' or 'tokens'\")\n","\n","        norm_batch_loss = batch_loss / normalizer\n","        # division needed since loss.backward sums the gradients until updated\n","        norm_batch_multiply = norm_batch_loss / self.batch_multiplier\n","\n","        generator_regression_loss = 100 * norm_batch_multiply \n","        d = self.disc(skel_out[:, :, 0:240], batch.padded_src)\n","        generator_adv_loss = 0.0002 * self.adv_loss(d, valid) \n","        total_generator_loss = generator_regression_loss + generator_adv_loss\n","        total_generator_loss.backward()\n","        self.optimizer.step()\n","\n","\n","        norm_torso_loss = torso_loss / normalizer\n","        norm_hand_loss = hand_loss / normalizer\n","        norm_face_loss = face_loss /normalizer\n","\n","\n","        if self.clip_grad_fun is not None:\n","            # clip gradients (in-place)\n","            self.clip_grad_fun(params=self.model.parameters())\n","\n","        if update:\n","            # make gradient step\n","            self.optimizer.step()\n","            self.optimizer.zero_grad()\n","\n","            # increment step counter\n","            self.steps += 1\n","\n","        # increment token counter\n","        self.total_tokens += batch.ntokens\n","\n","        return norm_batch_loss, norm_torso_loss, norm_hand_loss, norm_face_loss, d_real_loss.item(), d_fake_loss.item(), total_generator_loss.item(), generator_adv_loss.item(), noise\n","\n","    def _add_report(self, valid_score: float, valid_loss: float, eval_metric: str,\n","                    new_best: bool = False, report_type: str = \"val\") -> None:\n","\n","        current_lr = -1\n","        # ignores other param groups for now\n","        for param_group in self.optimizer.param_groups:\n","            current_lr = param_group['lr']\n","\n","        if current_lr < self.learning_rate_min:\n","            self.stop = True\n","\n","        if report_type == \"val\":\n","            with open(self.valid_report_file, 'a') as opened_file:\n","                opened_file.write(\n","                    \"Steps: {} Loss: {:.5f}| DTW: {:.3f}|\"\n","                    \" LR: {:.6f} {}\\n\".format(\n","                        self.steps, valid_loss, valid_score,\n","                        current_lr, \"*\" if new_best else \"\"))\n","\n","    def _log_parameters_list(self) -> None:\n","        \"\"\"\n","        Write all model parameters (name, shape) to the log.\n","        \"\"\"\n","        model_parameters = filter(lambda p: p.requires_grad,\n","                                  self.model.parameters())\n","        n_params = sum([np.prod(p.size()) for p in model_parameters])\n","        self.logger.info(\"Total params: %d\", n_params)\n","        trainable_params = [n for (n, p) in self.model.named_parameters()\n","                            if p.requires_grad]\n","        self.logger.info(\"Trainable parameters: %s\", sorted(trainable_params))\n","        assert trainable_params\n","        \n","    # Produce the video of Phoenix MTC joints\n","    def produce_validation_video(self,output_joints, inputs, references, display, model_dir, type, steps=\"\", file_paths=None):\n","\n","        # If not at test\n","        if type != \"test\":\n","            dir_name = model_dir + \"/videos/Step_{}/\".format(steps)\n","            if not os.path.exists(model_dir + \"/videos/\"):\n","                os.mkdir(model_dir + \"/videos/\")\n","\n","        # If at test time\n","        elif type == \"test\":\n","            dir_name = model_dir + \"/test_videos/\"\n","\n","        # Create model video folder if not exist\n","        if not os.path.exists(dir_name):\n","            os.mkdir(dir_name)\n","        # For sequence to display\n","\n","        for i in display:\n","\n","            seq = output_joints[i]\n","            ref_seq = references[i]\n","            input = inputs[i]\n","            # Write gloss label\n","            gloss_label = input[0] # [\"word\"]\n","\n","\n","            # Alter the dtw timing of the produced sequence, and collect the DTW score\n","            timing_hyp_seq, ref_seq_count, dtw_score = alter_DTW_timing(seq, ref_seq)\n","            video_ext = \"{}_{}.mp4\".format(gloss_label, \"{0:.2f}\".format(float(dtw_score)).replace(\".\", \"_\"))\n","\n","            try :\n","              if file_paths is not None:\n","                  sequence_ID = file_paths[i]\n","              else:\n","                  sequence_ID = None\n","            except:\n","              sequence_ID = None\n","        \n","            # Plot this sequences video\n","            if \"<\" not in video_ext:\n","                plot_video(joints=timing_hyp_seq,\n","                            file_path=dir_name,\n","                            video_name=video_ext,\n","                            references=ref_seq_count,\n","                            skip_frames=self.skip_frames,\n","                            sequence_ID=gloss_label)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KMqh4f17vW5p"},"source":["#### Train Helper Methods"]},{"cell_type":"code","metadata":{"id":"OejOwbr8vYx-","executionInfo":{"status":"ok","timestamp":1606763089818,"user_tz":480,"elapsed":2235,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"}}},"source":["\n","                \n","def greedy(\n","        src_mask: Tensor,\n","        embed: Embeddings,\n","        decoder: Decoder,\n","        encoder_output: Tensor,\n","        trg_input: Tensor,\n","        model,\n","        ) -> (np.array, np.array):\n","    \"\"\"\n","    Special greedy function for transformer, since it works differently.\n","    The transformer remembers all previous states and attends to them.\n","\n","    :param src_mask: mask for source inputs, 0 for positions after </s>\n","    :param embed: target embedding\n","    :param bos_index: index of <s> in the vocabulary\n","    :param max_output_length: maximum length for the hypotheses\n","    :param decoder: decoder to use for greedy decoding\n","    :param encoder_output: encoder hidden states for attention\n","    :param encoder_hidden: encoder final state (unused in Transformer)\n","    :return:\n","        - stacked_output: output hypotheses (2d array of indices),\n","        - stacked_attention_scores: attention scores (3d array)\n","    \"\"\"\n","    # Initialise the input\n","    # Extract just the BOS first frame from the target\n","    ys = trg_input[:,:1,:].float()\n","\n","    # If the counter is coming into the decoder or not\n","    ys_out = ys\n","\n","    # Set the target mask, by finding the padded rows\n","    trg_mask = trg_input != 0.0\n","    trg_mask = trg_mask.unsqueeze(1)\n","\n","    # Find the maximum output length for this batch\n","    max_output_length = trg_input.shape[1]\n","\n","    # If just count in, input is just the counter\n","    if model.just_count_in:\n","        ys = ys[:,:,-1:]\n","\n","    for i in range(max_output_length):\n","\n","        # ys here is the input\n","        # Drive the timing by giving the GT timing - add in the counter to the last column\n","\n","        if model.just_count_in:\n","            # If just counter, drive the input using the GT counter\n","            ys[:,-1] = trg_input[:, i, -1:]\n","\n","        else:\n","            # Give the GT counter for timing, to drive the timing\n","            ys[:,-1,-1:] = trg_input[:, i, -1:]\n","\n","        # Embed the target input before passing to the decoder\n","        trg_embed = embed(ys)\n","\n","        # Cut padding mask to required size (of the size of the input)\n","        padding_mask = trg_mask[:, :, :i+1, :i+1]\n","        # Pad the mask (If required) (To make it square, and used later on correctly)\n","        pad_amount = padding_mask.shape[2] - padding_mask.shape[3]\n","        padding_mask = (F.pad(input=padding_mask.double(), pad=(pad_amount, 0, 0, 0), mode='replicate') == 1.0)\n","\n","        # Pass the embedded input and the encoder output into the decoder\n","        with torch.no_grad():\n","            out, _, _, _ = decoder(\n","                trg_embed=trg_embed,\n","                encoder_output=encoder_output,\n","                src_mask=src_mask,\n","                trg_mask=padding_mask,\n","            )\n","\n","            if model.future_prediction != 0:\n","                # Cut to only the first frame prediction\n","                out = torch.cat((out[:, :, :out.shape[2] // (model.future_prediction)],out[:,:,-1:]),dim=2)\n","\n","            if model.just_count_in:\n","                # If just counter in trg_input, concatenate counters of output\n","                ys = torch.cat([ys, out[:,-1:,-1:]], dim=1)\n","\n","            # Add this frame prediction to the overall prediction\n","            ys = torch.cat([ys, out[:,-1:,:]], dim=1)\n","\n","            # Add this next predicted frame to the full frame output\n","            ys_out = torch.cat([ys_out, out[:,-1:,:]], dim=1)\n","\n","    return ys_out, None\n","\n","\n","# Find the best timing match between a reference and a hypothesis, using DTW\n","def calculate_dtw(references, hypotheses):\n","    \"\"\"\n","    Calculate the DTW costs between a list of references and hypotheses\n","\n","    :param references: list of reference sequences to compare against\n","    :param hypotheses: list of hypothesis sequences to fit onto the reference\n","\n","    :return: dtw_scores: list of DTW costs\n","    \"\"\"\n","    # Euclidean norm is the cost function, difference of coordinates\n","    euclidean_norm = lambda x, y: np.sum(np.abs(x - y))\n","\n","    dtw_scores = []\n","\n","    # Remove the BOS frame from the hypothesis\n","    hypotheses = hypotheses[:, 1:]\n","\n","    # For each reference in the references list\n","    for i, ref in enumerate(references):\n","        # Cut the reference down to the max count value\n","        _ , ref_max_idx = torch.max(ref[:, -1], 0)\n","        if ref_max_idx == 0: ref_max_idx += 1\n","        # Cut down frames by to the max counter value, and chop off counter from joints\n","        ref_count = ref[:ref_max_idx,:-1].cpu().numpy()\n","\n","        # Cut the hypothesis down to the max count value\n","        hyp = hypotheses[i]\n","        _, hyp_max_idx = torch.max(hyp[:, -1], 0)\n","        if hyp_max_idx == 0: hyp_max_idx += 1\n","        # Cut down frames by to the max counter value, and chop off counter from joints\n","        hyp_count = hyp[:hyp_max_idx,:-1].cpu().numpy()\n","\n","        # Calculate DTW of the reference and hypothesis, using euclidean norm\n","        d, cost_matrix, acc_cost_matrix, path = dtw(ref_count, hyp_count, dist=euclidean_norm)\n","\n","        # Normalise the dtw cost by sequence length\n","        d = d/acc_cost_matrix.shape[0]\n","\n","        dtw_scores.append(d)\n","\n","    # Return dtw scores and the hypothesis with altered timing\n","    return dtw_scores\n","\n","# Validate epoch given a dataset\n","def validate_on_data(model: Model,\n","                     data: Dataset,\n","                     batch_size: int,\n","                     max_output_length: int,\n","                     eval_metric: str,\n","                     loss_function: torch.nn.Module = None,\n","                     batch_type: str = \"sentence\",\n","                     type = \"val\",\n","                     BT_model = None):\n","\n","    valid_iter = make_data_iter(\n","        dataset=data, batch_size=batch_size, batch_type=batch_type,\n","        shuffle=True, train=False)\n","\n","    pad_index = model.src_vocab.stoi[PAD_TOKEN]\n","    # disable dropout\n","    model.eval()\n","    # don't track gradients during validation\n","    with torch.no_grad():\n","        valid_hypotheses = []\n","        valid_references = []\n","        valid_inputs = []\n","        file_paths = []\n","        all_dtw_scores = []\n","\n","        valid_loss = 0\n","        total_ntokens = 0\n","        total_nseqs = 0\n","\n","        batches = 0\n","        for valid_batch in iter(valid_iter):\n","            # Extract batch\n","            batch = Batch(torch_batch=valid_batch,\n","                          pad_index = pad_index,\n","                          model = model)\n","            targets = batch.trg\n","\n","            # run as during training with teacher forcing\n","            if loss_function is not None and batch.trg is not None:\n","                # Get the loss for this batch\n","                batch_loss, _, _, _, _, = model.get_loss_for_batch(\n","                    batch, loss_function=loss_function)\n","\n","                valid_loss += batch_loss\n","                total_ntokens += batch.ntokens\n","                total_nseqs += batch.nseqs\n","\n","            # If not just count in, run inference to produce translation videos\n","            if not model.just_count_in:\n","                # Run batch through the model in an auto-regressive format\n","                output, attention_scores = model.run_batch(\n","                                            batch=batch,\n","                                            max_output_length=max_output_length)\n","\n","            # If future prediction\n","            if model.future_prediction != 0:\n","                # Cut to only the first frame prediction + add the counter\n","                # output = torch.cat((output[:, :, :output.shape[2] // (model.future_prediction)], output[:, :, -1:]),dim=2)\n","                # Cut to only the first frame prediction + add the counter\n","                targets = torch.cat((targets[:, :, :targets.shape[2] // (model.future_prediction)], targets[:, :, -1:]),dim=2)\n","\n","            # For just counter, the inference is the same as GTing\n","            if model.just_count_in:\n","                output = train_output\n","\n","            # Add references, hypotheses and file paths to list\n","            valid_references.extend(targets)\n","            valid_hypotheses.extend(output)\n","            #file_paths.extend(batch.file_paths)\n","            # Add the source sentences to list, by using the model source vocab and batch indices\n","            valid_inputs.extend([[model.src_vocab.itos[batch.emb[i][j]] for j in range(len(batch.emb[i]))] for i in\n","                                 range(len(batch.emb))])\n","\n","            # Calculate the full Dynamic Time Warping score - for evaluation\n","            dtw_score = calculate_dtw(targets, output)\n","            all_dtw_scores.extend(dtw_score)\n","\n","            # Can set to only run a few batches\n","            # if batches == math.ceil(100/batch_size):\n","            #     break\n","            batches += 1\n","\n","        # Dynamic Time Warping scores\n","        current_valid_score = np.mean(all_dtw_scores)\n","\n","    return current_valid_score, valid_loss, valid_references, valid_hypotheses, \\\n","           valid_inputs, all_dtw_scores, file_paths"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HFFCa2koFv26"},"source":["### Plotting Videos"]},{"cell_type":"code","metadata":{"id":"4OEWsHWPFuVk","executionInfo":{"status":"ok","timestamp":1606763091280,"user_tz":480,"elapsed":2720,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"}}},"source":["import sys\n","import math\n","import numpy as np\n","import cv2\n","import torch\n","from numpy import array, zeros, full, argmin, inf, ndim\n","from scipy.spatial.distance import cdist\n","from math import isinf\n","\n","PAD_TOKEN = '<pad>'\n","\n","def dtw(x, y, dist, warp=1, w=inf, s=1.0):\n","    \"\"\"\n","    Computes Dynamic Time Warping (DTW) of two sequences.\n","\n","    :param array x: N1*M array\n","    :param array y: N2*M array\n","    :param func dist: distance used as cost measure\n","    :param int warp: how many shifts are computed.\n","    :param int w: window size limiting the maximal distance between indices of matched entries |i,j|.\n","    :param float s: weight applied on off-diagonal moves of the path. As s gets larger, the warping path is increasingly biased towards the diagonal\n","    Returns the minimum distance, the cost matrix, the accumulated cost matrix, and the wrap path.\n","    \"\"\"\n","    assert len(x)\n","    assert len(y)\n","    assert isinf(w) or (w >= abs(len(x) - len(y)))\n","    assert s > 0\n","    r, c = len(x), len(y)\n","    if not isinf(w):\n","        D0 = full((r + 1, c + 1), inf)\n","        for i in range(1, r + 1):\n","            D0[i, max(1, i - w):min(c + 1, i + w + 1)] = 0\n","        D0[0, 0] = 0\n","    else:\n","        D0 = zeros((r + 1, c + 1))\n","        D0[0, 1:] = inf\n","        D0[1:, 0] = inf\n","    D1 = D0[1:, 1:]  # view\n","    for i in range(r):\n","        for j in range(c):\n","            if (isinf(w) or (max(0, i - w) <= j <= min(c, i + w))):\n","                D1[i, j] = dist(x[i], y[j])\n","    C = D1.copy()\n","    jrange = range(c)\n","    for i in range(r):\n","        if not isinf(w):\n","            jrange = range(max(0, i - w), min(c, i + w + 1))\n","        for j in jrange:\n","            min_list = [D0[i, j]]\n","            for k in range(1, warp + 1):\n","                i_k = min(i + k, r)\n","                j_k = min(j + k, c)\n","                min_list += [D0[i_k, j] * s, D0[i, j_k] * s]\n","            D1[i, j] += min(min_list)\n","    if len(x) == 1:\n","        path = zeros(len(y)), range(len(y))\n","    elif len(y) == 1:\n","        path = range(len(x)), zeros(len(x))\n","    else:\n","        path = _traceback(D0)\n","    return D1[-1, -1], C, D1, path\n","\n","def _traceback(D):\n","    i, j = array(D.shape) - 2\n","    p, q = [i], [j]\n","    while (i > 0) or (j > 0):\n","        tb = argmin((D[i, j], D[i, j + 1], D[i + 1, j]))\n","        if tb == 0:\n","            i -= 1\n","            j -= 1\n","        elif tb == 1:\n","            i -= 1\n","        else:  # (tb == 2):\n","            j -= 1\n","        p.insert(0, i)\n","        q.insert(0, j)\n","    return array(p), array(q)\n","\n","\n","# Plot a video given a tensor of joints, a file path, video name and references/sequence ID\n","def plot_video(joints,\n","               file_path,\n","               video_name,\n","               references=None,\n","               skip_frames=1,\n","               sequence_ID=None):\n","    # Create video template\n","    FPS = (25 // skip_frames)\n","    video_file = file_path + \"/{}.mp4\".format(video_name.split(\".\")[0])\n","    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","\n","    if references is None:\n","        video = cv2.VideoWriter(video_file, fourcc, float(FPS), (650, 650), True)\n","    elif references is not None:\n","        video = cv2.VideoWriter(video_file, fourcc, float(FPS), (1300, 650), True)  # Long\n","\n","    num_frames = 0\n","\n","    for (j, frame_joints) in enumerate(joints):\n","\n","        # Reached padding\n","        if PAD_TOKEN in frame_joints:\n","            continue\n","\n","        # Initialise frame of white\n","        frame = np.ones((650, 650, 3), np.uint8) * 255\n","\n","        # Cut off the percent_tok, multiply by 3 to restore joint size\n","        # TODO - Remove the *3 if the joints weren't divided by 3 in data creation\n","        \n","        frame_joints = frame_joints[:-1]\n","        # Reduce the frame joints down to 2D for visualisation - Frame joints 2d shape is (48,2)\n","        frame_joints_2d = np.reshape(frame_joints, (-1, 2))\n","        \n","        # Draw the frame given 2D joints\n","        draw_frame_2D(frame, frame_joints_2d)\n","\n","        cv2.putText(frame, \"Predicted Sign Pose\", (180, 600), cv2.FONT_HERSHEY_SIMPLEX, 1,\n","                    (0, 0, 255), 2)\n","\n","        # If reference is provided, create and concatenate on the end\n","        if references is not None:\n","            # Extract the reference joints\n","            ref_joints = references[j]\n","            # Initialise frame of white\n","            ref_frame = np.ones((650, 650, 3), np.uint8) * 255\n","\n","            # Cut off the percent_tok and multiply each joint by 3 (as was reduced in training files)\n","            #ref_joints = ref_joints[:-1] * 3\n","            ref_joints = ref_joints[:-1]\n","            \n","            # Reduce the frame joints down to 2D- Frame joints 2d shape is (48,2)\n","            # ref_joints_2d = np.reshape(ref_joints, (50, 3))[:, :2]\n","            ref_joints_2d = np.reshape(ref_joints, (-1, 2))\n","\n","            # Draw these joints on the frame\n","            draw_frame_2D(ref_frame, ref_joints_2d)\n","\n","            cv2.putText(ref_frame, \"Ground Truth Pose\", (190, 600), cv2.FONT_HERSHEY_SIMPLEX, 1,\n","                        (0, 0, 0), 2)\n","\n","            frame = np.concatenate((frame, ref_frame), axis=1)\n","\n","            sequence_ID_write = \"Sequence ID: \" + sequence_ID\n","            cv2.putText(frame, sequence_ID_write, (700, 635), cv2.FONT_HERSHEY_SIMPLEX, 0.6,\n","                        (0, 0, 0), 2)\n","        # Write the video frame\n","        video.write(frame)\n","        num_frames += 1\n","    # Release the video\n","    video.release()\n","\n","# This is the format of the 3D data, outputted from the Inverse Kinematics model\n","def getSkeletalModelStructure():\n","    # Definition of skeleton model structure:\n","    #   The structure is an n-tuple of:\n","    #\n","    #   (index of a start point, index of an end point, index of a bone)\n","    #\n","    #   E.g., this simple skeletal model\n","    #\n","    #             (0)\n","    #              |\n","    #              |\n","    #              0\n","    #              |\n","    #              |\n","    #     (2)--1--(1)--1--(3)\n","    #      |               |\n","    #      |               |\n","    #      2               2\n","    #      |               |\n","    #      |               |\n","    #     (4)             (5)\n","    #\n","    #   has this structure:\n","    #\n","    #   (\n","    #     (0, 1, 0),\n","    #     (1, 2, 1),\n","    #     (1, 3, 1),\n","    #     (2, 4, 2),\n","    #     (3, 5, 2),\n","    #   )\n","    #\n","    #  Warning 1: The structure has to be a tree.\n","    #  Warning 2: The order isn't random. The order is from a root to lists.\n","    #\n","\n","    return (\n","        # head\n","        (0, 1, 0),\n","\n","        # left shoulder\n","        (1, 2, 1),\n","\n","        # left arm\n","        (2, 3, 2),\n","        # (3, 4, 3),\n","        # Changed to avoid wrist, go straight to hands\n","        (3, 29, 3),\n","\n","        # right shoulder\n","        (1, 5, 1),\n","\n","        # right arm\n","        (5, 6, 2),\n","        # (6, 7, 3),\n","        # Changed to avoid wrist, go straight to hands\n","        (6, 8, 3),\n","\n","        # left hand - wrist\n","        # (7, 8, 4),\n","\n","        # left hand - palm\n","        (8, 9, 5),\n","        (8, 13, 9),\n","        (8, 17, 13),\n","        (8, 21, 17),\n","        (8, 25, 21),\n","\n","        # left hand - 1st finger\n","        (9, 10, 6),\n","        (10, 11, 7),\n","        (11, 12, 8),\n","\n","        # left hand - 2nd finger\n","        (13, 14, 10),\n","        (14, 15, 11),\n","        (15, 16, 12),\n","\n","        # left hand - 3rd finger\n","        (17, 18, 14),\n","        (18, 19, 15),\n","        (19, 20, 16),\n","\n","        # left hand - 4th finger\n","        (21, 22, 18),\n","        (22, 23, 19),\n","        (23, 24, 20),\n","\n","        # left hand - 5th finger\n","        (25, 26, 22),\n","        (26, 27, 23),\n","        (27, 28, 24),\n","\n","        # right hand - wrist\n","        # (4, 29, 4),\n","\n","        # right hand - palm\n","        (29, 30, 5),\n","        (29, 34, 9),\n","        (29, 38, 13),\n","        (29, 42, 17),\n","        (29, 46, 21),\n","\n","        # right hand - 1st finger\n","        (30, 31, 6),\n","        (31, 32, 7),\n","        (32, 33, 8),\n","\n","        # right hand - 2nd finger\n","        (34, 35, 10),\n","        (35, 36, 11),\n","        (36, 37, 12),\n","\n","        # right hand - 3rd finger\n","        (38, 39, 14),\n","        (39, 40, 15),\n","        (40, 41, 16),\n","\n","        # right hand - 4th finger\n","        (42, 43, 18),\n","        (43, 44, 19),\n","        (44, 45, 20),\n","\n","        # right hand - 5th finger\n","        (46, 47, 22),\n","        (47, 48, 23),\n","        (48, 49, 24),\n","    )\n","\n","# Draw a line between two points, if they are positive points\n","def draw_line(im, joint1, joint2, c=(0, 0, 255),t=1, width=3):\n","    thresh = -100\n","    if joint1[0] > thresh and  joint1[1] > thresh and joint2[0] > thresh and joint2[1] > thresh:\n","\n","        center = (int((joint1[0] + joint2[0]) / 2), int((joint1[1] + joint2[1]) / 2))\n","\n","        length = int(math.sqrt(((joint1[0] - joint2[0]) ** 2) + ((joint1[1] - joint2[1]) ** 2))/2)\n","\n","        angle = math.degrees(math.atan2((joint1[0] - joint2[0]),(joint1[1] - joint2[1])))\n","\n","        cv2.ellipse(im, center, (width,length), -angle,0.0,360.0, c, -1)\n","\n","# Draw the frame given 2D joints that are in the Inverse Kinematics format\n","def draw_frame_2D(frame, joints):\n","    # Line to be between the stacked\n","    draw_line(frame, [1, 650], [1, 1], c=(0,0,0), t=1, width=1)\n","    # Give an offset to center the skeleton around\n","    offset = [350, 250]\n","\n","    # Get the skeleton structure details of each bone, and size\n","    skeleton = getSkeletalModelStructure()\n","    skeleton = np.array(skeleton)\n","\n","    number = skeleton.shape[0]\n","\n","    # Increase the size and position of the joints\n","    joints = joints * 10 * 12 * 2\n","    joints = joints + np.ones((joints.shape[0], 2)) * offset\n","\n","    # Loop through each of the bone structures, and plot the bone\n","    for j in range(number):\n","\n","        c = get_bone_colour(skeleton,j)\n","\n","        draw_line(frame, [joints[skeleton[j, 0]][0], joints[skeleton[j, 0]][1]],\n","                  [joints[skeleton[j, 1]][0], joints[skeleton[j, 1]][1]], c=c, t=1, width=1)\n","        \n","\n","# get bone colour given index\n","def get_bone_colour(skeleton,j):\n","    bone = skeleton[j, 2]\n","\n","    if bone == 0:  # head\n","        c = (0, 153, 0)\n","    elif bone == 1:  # Shoulder\n","        c = (0, 0, 255)\n","\n","    elif bone == 2 and skeleton[j, 1] == 3:  # left arm\n","        c = (0, 102, 204)\n","    elif bone == 3 and skeleton[j, 0] == 3:  # left lower arm\n","        c = (0, 204, 204)\n","\n","    elif bone == 2 and skeleton[j, 1] == 6:  # right arm\n","        c = (0, 153, 0)\n","    elif bone == 3 and skeleton[j, 0] == 6:  # right lower arm\n","        c = (0, 204, 0)\n","\n","    # Hands\n","    elif bone in [5, 6, 7, 8]:\n","        c = (0, 0, 255)\n","    elif bone in [9, 10, 11, 12]:\n","        c = (51, 255, 51)\n","    elif bone in [13, 14, 15, 16]:\n","        c = (255, 0, 0)\n","    elif bone in [17, 18, 19, 20]:\n","        c = (204, 153, 255)\n","    elif bone in [21, 22, 23, 24]:\n","        c = (51, 255, 255)\n","\n","    return c\n","\n","# Apply DTW to the produced sequence, so it can be visually compared to the reference sequence\n","def alter_DTW_timing(pred_seq,ref_seq):\n","\n","    # Define a cost function\n","    euclidean_norm = lambda x, y: np.sum(np.abs(x - y))\n","\n","    # Cut the reference down to the max count value\n","    _ , ref_max_idx = torch.max(ref_seq[:, -1], 0)\n","    if ref_max_idx == 0: ref_max_idx += 1\n","    # Cut down frames by counter\n","    ref_seq = ref_seq[:ref_max_idx,:].cpu().numpy()\n","\n","    # Cut the hypothesis down to the max count value\n","    _, hyp_max_idx = torch.max(pred_seq[:, -1], 0)\n","    if hyp_max_idx == 0: hyp_max_idx += 1\n","    # Cut down frames by counter\n","    pred_seq = pred_seq[:hyp_max_idx,:].cpu().numpy()\n","\n","    # Run DTW on the reference and predicted sequence\n","    d, cost_matrix, acc_cost_matrix, path = dtw(ref_seq[:,:-1], pred_seq[:,:-1], dist=euclidean_norm)\n","\n","    # Normalise the dtw cost by sequence length\n","    d = d / acc_cost_matrix.shape[0]\n","\n","    # Initialise new sequence\n","    new_pred_seq = np.zeros_like(ref_seq)\n","    # j tracks the position in the reference sequence\n","    j = 0\n","    skips = 0\n","    squeeze_frames = []\n","    for (i, pred_num) in enumerate(path[0]):\n","\n","        if i == len(path[0]) - 1:\n","            break\n","\n","        if path[1][i] == path[1][i + 1]:\n","            skips += 1\n","\n","        # If a double coming up\n","        if path[0][i] == path[0][i + 1]:\n","            squeeze_frames.append(pred_seq[i - skips])\n","            j += 1\n","        # Just finished a double\n","        elif path[0][i] == path[0][i - 1]:\n","            new_pred_seq[pred_num] = avg_frames(squeeze_frames)\n","            squeeze_frames = []\n","        else:\n","            new_pred_seq[pred_num] = pred_seq[i - skips]\n","\n","    return new_pred_seq, ref_seq, d\n","\n","# Find the average of the given frames\n","def avg_frames(frames):\n","    frames_sum = np.zeros_like(frames[0])\n","    for frame in frames:\n","        frames_sum += frame\n","\n","    avg_frame = frames_sum / len(frames)\n","    return avg_frame"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZEiw7aolTrBf"},"source":["### Run "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ARey4ccUH_D","executionInfo":{"status":"ok","timestamp":1606770195300,"user_tz":480,"elapsed":7082265,"user":{"displayName":"Amy Lee","photoUrl":"","userId":"14323350772356815607"}},"outputId":"cecb4214-88aa-48b3-c1bd-2dad0b17cae8"},"source":["version = \"v9\"\n","\n","if not os.path.isdir(os.path.join(MODEL_DIR, version)):\n","  os.mkdir(os.path.join(MODEL_DIR, version))\n","\n","cfg = load_config(os.path.join(CONF_DIR, 'Base.yaml'))\n","\n","cfg[\"data\"][\"max_input_length\"] = 88 #175 is max and we are skipping frame by 2\n","cfg[\"training\"][\"use_cuda\"] = True\n","cfg[\"data\"][\"max_sent_length\"] = 1\n","cfg[\"data\"][\"skip_frames\"] = 2\n","cfg[\"model\"][\"trg_size\"] = 240 # size of skeleton (xy of face included)\n","cfg[\"training\"][\"logging_freq\"] = 40\n","cfg[\"training\"][\"validation_freq\"] = 300\n","cfg['training'][\"max_output_length\"] = 20\n","cfg[\"training\"][\"batch_size\"] = 32\n","cfg[\"model\"][\"encoder\"][\"num_layers\"] = 1\n","cfg[\"model\"][\"encoder\"][\"num_heads\"] = 4\n","cfg[\"model\"][\"decoder\"][\"num_heads\"] = 4\n","cfg[\"training\"][\"epochs\"] = 1000\n","cfg[\"model\"][\"gaussian_noise\"] = True\n","cfg[\"model\"][\"future_prediction\"] = 0\n","\n","set_seed(seed=cfg[\"training\"].get(\"random_seed\", 42))\n","train_data, dev_data, src_vocab, trg_vocab = load_data(cfg)\n","\n","generator = build_model(cfg, src_vocab=src_vocab, trg_vocab=trg_vocab)\n","discriminator = Discriminator(max_frame=cfg[\"data\"][\"max_input_length\"]) \n","intialize_discriminator(discriminator, cfg[\"model\"])\n","trainer = TrainManager(model=generator, discriminator=discriminator, config=cfg)\n","\n","trainer.logger.info(generator)\n","trainer.logger.info(discriminator)\n","trainer.train_and_validate(train_data=train_data, valid_data=dev_data)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["2020-11-30 19:05:48,815 - __main__ - INFO - Total params: 3072768\n","2020-11-30 19:05:48,819 - __main__ - INFO - Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'src_embed.lut.bias', 'src_embed.lut.weight', 'trg_embed.bias', 'trg_embed.weight']\n","2020-11-30 19:05:55,091 - __main__ - INFO - Can't find checkpoint in directory None\n","2020-11-30 19:05:55,093 - __main__ - INFO - Model(\n","\tencoder=TransformerEncoder(num_layers=1, num_heads=4),\n","\tdecoder=TransformerDecoder(num_layers=2, num_heads=4),\n","\tsrc_embed=Embeddings(embedding_dim=256, vocab_size=1396),\n","\ttrg_embed=Linear(in_features=241, out_features=256, bias=True))\n","2020-11-30 19:05:55,094 - __main__ - INFO - Discriminator(\n","  (discriminate): Sequential(\n","    (0): Conv1d(240, 64, kernel_size=(10,), stride=(1,))\n","    (1): LeakyReLU(negative_slope=0.01)\n","    (2): Conv1d(64, 64, kernel_size=(10,), stride=(1,))\n","    (3): LeakyReLU(negative_slope=0.01)\n","    (4): Conv1d(64, 1, kernel_size=(10,), stride=(1,))\n","    (5): LeakyReLU(negative_slope=0.01)\n","    (6): Linear(in_features=62, out_features=1, bias=True)\n","    (7): Sigmoid()\n","  )\n",")\n","2020-11-30 19:06:07,823 - __main__ - INFO - Epoch   1 Step:       40 Batch Loss:     0.002550 [Torso :     0.001570, Hand :     0.003664, Face :     0.000903]Tokens per Sec:  1450003, Lr: 0.001000\n","2020-11-30 19:06:21,198 - __main__ - INFO - Epoch   1 Step:       80 Batch Loss:     0.001711 [Torso :     0.002011, Hand :     0.001675, Face :     0.000696]Tokens per Sec:  1434200, Lr: 0.001000\n","2020-11-30 19:06:33,809 - __main__ - INFO - Epoch   1 Step:      120 Batch Loss:     0.001526 [Torso :     0.001212, Hand :     0.001991, Face :     0.000457]Tokens per Sec:  1463535, Lr: 0.001000\n","2020-11-30 19:06:47,164 - __main__ - INFO - Epoch   1 Step:      160 Batch Loss:     0.000859 [Torso :     0.000856, Hand :     0.000979, Face :     0.000272]Tokens per Sec:  1439807, Lr: 0.001000\n","2020-11-30 19:07:00,279 - __main__ - INFO - Epoch   1 Step:      200 Batch Loss:     0.001249 [Torso :     0.001243, Hand :     0.001445, Face :     0.000293]Tokens per Sec:  1454347, Lr: 0.001000\n","2020-11-30 19:07:13,414 - __main__ - INFO - Epoch   1 Step:      240 Batch Loss:     0.001048 [Torso :     0.001243, Hand :     0.001061, Face :     0.000208]Tokens per Sec:  1450455, Lr: 0.001000\n","2020-11-30 19:07:26,887 - __main__ - INFO - Epoch   1 Step:      280 Batch Loss:     0.000897 [Torso :     0.000902, Hand :     0.001015, Face :     0.000289]Tokens per Sec:  1427139, Lr: 0.001000\n","2020-11-30 19:07:33,520 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:08:37,187 - __main__ - INFO - Hooray! New best validation result [dtw]!\n","2020-11-30 19:08:37,189 - __main__ - INFO - Saving new checkpoint.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","2020-11-30 19:08:49,642 - __main__ - INFO - Validation result at epoch   1, step      300: Val DTW Score: 161.82, loss:   2.0637,  duration: 76.1204s\n","2020-11-30 19:08:56,007 - __main__ - INFO - Epoch   1: total training loss 0.58628 [torso: 0.58057, hand: 0.65253, face: 0.27790\n","2020-11-30 19:08:56,008 - __main__ - INFO - Epoch   1: disc loss [real: 105.72585, fake: 66.89772], generator [total: 58.78709, adv: 0.15906]\n","2020-11-30 19:08:57,104 - __main__ - INFO - Epoch   2 Step:      320 Batch Loss:     0.001898 [Torso :     0.001548, Hand :     0.002457, Face :     0.000495]Tokens per Sec:  1212656, Lr: 0.001000\n","2020-11-30 19:09:10,106 - __main__ - INFO - Epoch   2 Step:      360 Batch Loss:     0.001692 [Torso :     0.001545, Hand :     0.002081, Face :     0.000340]Tokens per Sec:  1448024, Lr: 0.001000\n","2020-11-30 19:09:22,496 - __main__ - INFO - Epoch   2 Step:      400 Batch Loss:     0.001489 [Torso :     0.001176, Hand :     0.001958, Face :     0.000396]Tokens per Sec:  1506350, Lr: 0.001000\n","2020-11-30 19:09:34,702 - __main__ - INFO - Epoch   2 Step:      440 Batch Loss:     0.001438 [Torso :     0.001185, Hand :     0.001862, Face :     0.000332]Tokens per Sec:  1539916, Lr: 0.001000\n","2020-11-30 19:09:47,794 - __main__ - INFO - Epoch   2 Step:      480 Batch Loss:     0.001182 [Torso :     0.000906, Hand :     0.001590, Face :     0.000249]Tokens per Sec:  1482231, Lr: 0.001000\n","2020-11-30 19:10:00,977 - __main__ - INFO - Epoch   2 Step:      520 Batch Loss:     0.001263 [Torso :     0.000871, Hand :     0.001789, Face :     0.000200]Tokens per Sec:  1465589, Lr: 0.001000\n","2020-11-30 19:10:13,629 - __main__ - INFO - Epoch   2 Step:      560 Batch Loss:     0.001321 [Torso :     0.001145, Hand :     0.001678, Face :     0.000239]Tokens per Sec:  1494189, Lr: 0.001000\n","2020-11-30 19:10:26,057 - __main__ - INFO - Epoch   2 Step:      600 Batch Loss:     0.001492 [Torso :     0.001098, Hand :     0.002045, Face :     0.000307]Tokens per Sec:  1500685, Lr: 0.001000\n","2020-11-30 19:10:26,058 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:11:35,898 - __main__ - INFO - Validation result at epoch   2, step      600: Val DTW Score: 199.01, loss:   4.0857,  duration: 69.8386s\n","2020-11-30 19:11:47,854 - __main__ - INFO - Epoch   2: total training loss 0.46724 [torso: 0.37831, hand: 0.61256, face: 0.09640\n","2020-11-30 19:11:47,856 - __main__ - INFO - Epoch   2: disc loss [real: 70.87313, fake: 47.98614], generator [total: 46.90287, adv: 0.17841]\n","2020-11-30 19:11:50,183 - __main__ - INFO - Epoch   3 Step:      640 Batch Loss:     0.001183 [Torso :     0.000927, Hand :     0.001574, Face :     0.000255]Tokens per Sec:  1316403, Lr: 0.001000\n","2020-11-30 19:12:03,010 - __main__ - INFO - Epoch   3 Step:      680 Batch Loss:     0.001192 [Torso :     0.001047, Hand :     0.001506, Face :     0.000200]Tokens per Sec:  1456911, Lr: 0.001000\n","2020-11-30 19:12:16,112 - __main__ - INFO - Epoch   3 Step:      720 Batch Loss:     0.001198 [Torso :     0.000847, Hand :     0.001683, Face :     0.000172]Tokens per Sec:  1456991, Lr: 0.001000\n","2020-11-30 19:12:28,653 - __main__ - INFO - Epoch   3 Step:      760 Batch Loss:     0.001299 [Torso :     0.000949, Hand :     0.001794, Face :     0.000227]Tokens per Sec:  1476017, Lr: 0.001000\n","2020-11-30 19:12:41,954 - __main__ - INFO - Epoch   3 Step:      800 Batch Loss:     0.001545 [Torso :     0.001186, Hand :     0.002100, Face :     0.000208]Tokens per Sec:  1450300, Lr: 0.001000\n","2020-11-30 19:12:54,982 - __main__ - INFO - Epoch   3 Step:      840 Batch Loss:     0.001307 [Torso :     0.001029, Hand :     0.001745, Face :     0.000232]Tokens per Sec:  1462332, Lr: 0.001000\n","2020-11-30 19:13:08,408 - __main__ - INFO - Epoch   3 Step:      880 Batch Loss:     0.000988 [Torso :     0.000763, Hand :     0.001317, Face :     0.000246]Tokens per Sec:  1437302, Lr: 0.001000\n","2020-11-30 19:13:14,982 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:14:25,987 - __main__ - INFO - Validation result at epoch   3, step      900: Val DTW Score: 189.29, loss:   3.1448,  duration: 71.0036s\n","2020-11-30 19:14:32,388 - __main__ - INFO - Epoch   3 Step:      920 Batch Loss:     0.001168 [Torso :     0.000908, Hand :     0.001570, Face :     0.000199]Tokens per Sec:  1472895, Lr: 0.001000\n","2020-11-30 19:14:43,214 - __main__ - INFO - Epoch   3: total training loss 0.39165 [torso: 0.29913, hand: 0.53044, face: 0.06777\n","2020-11-30 19:14:43,215 - __main__ - INFO - Epoch   3: disc loss [real: 78.07337, fake: 54.15881], generator [total: 39.33524, adv: 0.17051]\n","2020-11-30 19:14:46,159 - __main__ - INFO - Epoch   4 Step:      960 Batch Loss:     0.001262 [Torso :     0.001014, Hand :     0.001673, Face :     0.000196]Tokens per Sec:  1462643, Lr: 0.001000\n","2020-11-30 19:14:59,420 - __main__ - INFO - Epoch   4 Step:     1000 Batch Loss:     0.001036 [Torso :     0.000919, Hand :     0.001293, Face :     0.000218]Tokens per Sec:  1469760, Lr: 0.001000\n","2020-11-30 19:15:12,406 - __main__ - INFO - Epoch   4 Step:     1040 Batch Loss:     0.001330 [Torso :     0.000973, Hand :     0.001842, Face :     0.000199]Tokens per Sec:  1480609, Lr: 0.001000\n","2020-11-30 19:15:25,630 - __main__ - INFO - Epoch   4 Step:     1080 Batch Loss:     0.001017 [Torso :     0.000768, Hand :     0.001383, Face :     0.000177]Tokens per Sec:  1476826, Lr: 0.001000\n","2020-11-30 19:15:38,502 - __main__ - INFO - Epoch   4 Step:     1120 Batch Loss:     0.001250 [Torso :     0.001065, Hand :     0.001607, Face :     0.000206]Tokens per Sec:  1484137, Lr: 0.001000\n","2020-11-30 19:15:50,991 - __main__ - INFO - Epoch   4 Step:     1160 Batch Loss:     0.001147 [Torso :     0.000944, Hand :     0.001503, Face :     0.000174]Tokens per Sec:  1496975, Lr: 0.001000\n","2020-11-30 19:16:03,482 - __main__ - INFO - Epoch   4 Step:     1200 Batch Loss:     0.001172 [Torso :     0.000802, Hand :     0.001673, Face :     0.000143]Tokens per Sec:  1485826, Lr: 0.001000\n","2020-11-30 19:16:03,483 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:17:14,144 - __main__ - INFO - Validation result at epoch   4, step     1200: Val DTW Score: 203.23, loss:   3.0909,  duration: 70.6600s\n","2020-11-30 19:17:28,505 - __main__ - INFO - Epoch   4 Step:     1240 Batch Loss:     0.001111 [Torso :     0.000835, Hand :     0.001501, Face :     0.000265]Tokens per Sec:  1368803, Lr: 0.001000\n","2020-11-30 19:17:37,197 - __main__ - INFO - Epoch   4: total training loss 0.36771 [torso: 0.27663, hand: 0.50226, face: 0.05921\n","2020-11-30 19:17:37,198 - __main__ - INFO - Epoch   4: disc loss [real: 68.70301, fake: 51.32134], generator [total: 36.96123, adv: 0.19066]\n","2020-11-30 19:17:40,715 - __main__ - INFO - Epoch   5 Step:     1280 Batch Loss:     0.001293 [Torso :     0.001168, Hand :     0.001611, Face :     0.000199]Tokens per Sec:  1520628, Lr: 0.001000\n","2020-11-30 19:17:54,124 - __main__ - INFO - Epoch   5 Step:     1320 Batch Loss:     0.001073 [Torso :     0.000784, Hand :     0.001484, Face :     0.000171]Tokens per Sec:  1474246, Lr: 0.001000\n","2020-11-30 19:18:06,932 - __main__ - INFO - Epoch   5 Step:     1360 Batch Loss:     0.001099 [Torso :     0.000806, Hand :     0.001517, Face :     0.000181]Tokens per Sec:  1461486, Lr: 0.001000\n","2020-11-30 19:18:20,332 - __main__ - INFO - Epoch   5 Step:     1400 Batch Loss:     0.001013 [Torso :     0.000734, Hand :     0.001410, Face :     0.000141]Tokens per Sec:  1452789, Lr: 0.001000\n","2020-11-30 19:18:32,784 - __main__ - INFO - Epoch   5 Step:     1440 Batch Loss:     0.001064 [Torso :     0.000709, Hand :     0.001529, Face :     0.000157]Tokens per Sec:  1492725, Lr: 0.001000\n","2020-11-30 19:18:45,596 - __main__ - INFO - Epoch   5 Step:     1480 Batch Loss:     0.001080 [Torso :     0.000730, Hand :     0.001547, Face :     0.000138]Tokens per Sec:  1480933, Lr: 0.001000\n","2020-11-30 19:18:52,735 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:20:02,845 - __main__ - INFO - Validation result at epoch   5, step     1500: Val DTW Score: 176.09, loss:   6.5414,  duration: 70.1093s\n","2020-11-30 19:20:09,772 - __main__ - INFO - Epoch   5 Step:     1520 Batch Loss:     0.001011 [Torso :     0.000956, Hand :     0.001217, Face :     0.000201]Tokens per Sec:  1406961, Lr: 0.001000\n","2020-11-30 19:20:23,374 - __main__ - INFO - Epoch   5 Step:     1560 Batch Loss:     0.000946 [Torso :     0.000661, Hand :     0.001338, Face :     0.000133]Tokens per Sec:  1401297, Lr: 0.001000\n","2020-11-30 19:20:31,527 - __main__ - INFO - Epoch   5: total training loss 0.34394 [torso: 0.25989, hand: 0.46908, face: 0.05442\n","2020-11-30 19:20:31,529 - __main__ - INFO - Epoch   5: disc loss [real: 68.29730, fake: 48.92850], generator [total: 34.57111, adv: 0.17746]\n","2020-11-30 19:20:36,096 - __main__ - INFO - Epoch   6 Step:     1600 Batch Loss:     0.001142 [Torso :     0.000906, Hand :     0.001518, Face :     0.000204]Tokens per Sec:  1484517, Lr: 0.001000\n","2020-11-30 19:20:49,502 - __main__ - INFO - Epoch   6 Step:     1640 Batch Loss:     0.001206 [Torso :     0.000847, Hand :     0.001702, Face :     0.000164]Tokens per Sec:  1450479, Lr: 0.001000\n","2020-11-30 19:21:02,643 - __main__ - INFO - Epoch   6 Step:     1680 Batch Loss:     0.000761 [Torso :     0.000552, Hand :     0.001055, Face :     0.000127]Tokens per Sec:  1454384, Lr: 0.001000\n","2020-11-30 19:21:15,818 - __main__ - INFO - Epoch   6 Step:     1720 Batch Loss:     0.000891 [Torso :     0.000599, Hand :     0.001268, Face :     0.000171]Tokens per Sec:  1454223, Lr: 0.001000\n","2020-11-30 19:21:28,794 - __main__ - INFO - Epoch   6 Step:     1760 Batch Loss:     0.000860 [Torso :     0.000634, Hand :     0.001191, Face :     0.000110]Tokens per Sec:  1462397, Lr: 0.001000\n","2020-11-30 19:21:42,015 - __main__ - INFO - Epoch   6 Step:     1800 Batch Loss:     0.001123 [Torso :     0.000837, Hand :     0.001551, Face :     0.000127]Tokens per Sec:  1453705, Lr: 0.001000\n","2020-11-30 19:21:42,018 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:22:50,568 - __main__ - INFO - Validation result at epoch   6, step     1800: Val DTW Score: 182.58, loss:   4.6993,  duration: 68.5478s\n","2020-11-30 19:23:03,856 - __main__ - INFO - Epoch   6 Step:     1840 Batch Loss:     0.001047 [Torso :     0.000810, Hand :     0.001424, Face :     0.000109]Tokens per Sec:  1406591, Lr: 0.001000\n","2020-11-30 19:23:16,598 - __main__ - INFO - Epoch   6 Step:     1880 Batch Loss:     0.001007 [Torso :     0.000698, Hand :     0.001418, Face :     0.000191]Tokens per Sec:  1478822, Lr: 0.001000\n","2020-11-30 19:23:23,756 - __main__ - INFO - Epoch   6: total training loss 0.32049 [torso: 0.24073, hand: 0.43882, face: 0.04789\n","2020-11-30 19:23:23,757 - __main__ - INFO - Epoch   6: disc loss [real: 70.27609, fake: 50.73129], generator [total: 32.21248, adv: 0.16302]\n","2020-11-30 19:23:29,294 - __main__ - INFO - Epoch   7 Step:     1920 Batch Loss:     0.000913 [Torso :     0.000752, Hand :     0.001190, Face :     0.000173]Tokens per Sec:  1485194, Lr: 0.001000\n","2020-11-30 19:23:42,119 - __main__ - INFO - Epoch   7 Step:     1960 Batch Loss:     0.001015 [Torso :     0.000736, Hand :     0.001412, Face :     0.000144]Tokens per Sec:  1466751, Lr: 0.001000\n","2020-11-30 19:23:54,966 - __main__ - INFO - Epoch   7 Step:     2000 Batch Loss:     0.000749 [Torso :     0.000536, Hand :     0.001040, Face :     0.000143]Tokens per Sec:  1473915, Lr: 0.001000\n","2020-11-30 19:24:08,086 - __main__ - INFO - Epoch   7 Step:     2040 Batch Loss:     0.001163 [Torso :     0.000884, Hand :     0.001586, Face :     0.000171]Tokens per Sec:  1471380, Lr: 0.001000\n","2020-11-30 19:24:21,705 - __main__ - INFO - Epoch   7 Step:     2080 Batch Loss:     0.001057 [Torso :     0.000793, Hand :     0.001449, Face :     0.000157]Tokens per Sec:  1445923, Lr: 0.001000\n","2020-11-30 19:24:28,285 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:25:37,394 - __main__ - INFO - Validation result at epoch   7, step     2100: Val DTW Score: 184.31, loss:   4.2790,  duration: 69.1079s\n","2020-11-30 19:25:44,363 - __main__ - INFO - Epoch   7 Step:     2120 Batch Loss:     0.001138 [Torso :     0.000881, Hand :     0.001535, Face :     0.000186]Tokens per Sec:  1434903, Lr: 0.001000\n","2020-11-30 19:25:58,618 - __main__ - INFO - Epoch   7 Step:     2160 Batch Loss:     0.000778 [Torso :     0.000672, Hand :     0.000995, Face :     0.000113]Tokens per Sec:  1374377, Lr: 0.001000\n","2020-11-30 19:26:11,735 - __main__ - INFO - Epoch   7 Step:     2200 Batch Loss:     0.000851 [Torso :     0.000592, Hand :     0.001208, Face :     0.000103]Tokens per Sec:  1447642, Lr: 0.001000\n","2020-11-30 19:26:17,536 - __main__ - INFO - Epoch   7: total training loss 0.30459 [torso: 0.22922, hand: 0.41629, face: 0.04758\n","2020-11-30 19:26:17,538 - __main__ - INFO - Epoch   7: disc loss [real: 73.07591, fake: 48.38100], generator [total: 30.61874, adv: 0.15952]\n","2020-11-30 19:26:24,324 - __main__ - INFO - Epoch   8 Step:     2240 Batch Loss:     0.001226 [Torso :     0.000831, Hand :     0.001761, Face :     0.000128]Tokens per Sec:  1462842, Lr: 0.001000\n","2020-11-30 19:26:38,319 - __main__ - INFO - Epoch   8 Step:     2280 Batch Loss:     0.000914 [Torso :     0.000692, Hand :     0.001247, Face :     0.000133]Tokens per Sec:  1421386, Lr: 0.001000\n","2020-11-30 19:26:50,378 - __main__ - INFO - Epoch   8 Step:     2320 Batch Loss:     0.000862 [Torso :     0.000671, Hand :     0.001157, Face :     0.000151]Tokens per Sec:  1502397, Lr: 0.001000\n","2020-11-30 19:27:03,635 - __main__ - INFO - Epoch   8 Step:     2360 Batch Loss:     0.000842 [Torso :     0.000610, Hand :     0.001175, Face :     0.000109]Tokens per Sec:  1446421, Lr: 0.001000\n","2020-11-30 19:27:16,999 - __main__ - INFO - Epoch   8 Step:     2400 Batch Loss:     0.000789 [Torso :     0.000547, Hand :     0.001117, Face :     0.000117]Tokens per Sec:  1453174, Lr: 0.001000\n","2020-11-30 19:27:17,001 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:28:28,076 - __main__ - INFO - Validation result at epoch   8, step     2400: Val DTW Score: 176.65, loss:   5.4460,  duration: 71.0741s\n","2020-11-30 19:28:41,801 - __main__ - INFO - Epoch   8 Step:     2440 Batch Loss:     0.000944 [Torso :     0.000644, Hand :     0.001347, Face :     0.000128]Tokens per Sec:  1423194, Lr: 0.001000\n","2020-11-30 19:28:54,400 - __main__ - INFO - Epoch   8 Step:     2480 Batch Loss:     0.000869 [Torso :     0.000640, Hand :     0.001208, Face :     0.000092]Tokens per Sec:  1479066, Lr: 0.001000\n","2020-11-30 19:29:06,610 - __main__ - INFO - Epoch   8 Step:     2520 Batch Loss:     0.001100 [Torso :     0.000984, Hand :     0.001382, Face :     0.000150]Tokens per Sec:  1505996, Lr: 0.001000\n","2020-11-30 19:29:11,573 - __main__ - INFO - Epoch   8: total training loss 0.29659 [torso: 0.22400, hand: 0.40530, face: 0.04338\n","2020-11-30 19:29:11,575 - __main__ - INFO - Epoch   8: disc loss [real: 68.43134, fake: 45.62066], generator [total: 29.83411, adv: 0.17532]\n","2020-11-30 19:29:19,487 - __main__ - INFO - Epoch   9 Step:     2560 Batch Loss:     0.000914 [Torso :     0.000757, Hand :     0.001183, Face :     0.000198]Tokens per Sec:  1471164, Lr: 0.001000\n","2020-11-30 19:29:32,846 - __main__ - INFO - Epoch   9 Step:     2600 Batch Loss:     0.000732 [Torso :     0.000599, Hand :     0.000963, Face :     0.000114]Tokens per Sec:  1472774, Lr: 0.001000\n","2020-11-30 19:29:46,065 - __main__ - INFO - Epoch   9 Step:     2640 Batch Loss:     0.000776 [Torso :     0.000588, Hand :     0.001058, Face :     0.000124]Tokens per Sec:  1463288, Lr: 0.001000\n","2020-11-30 19:29:58,479 - __main__ - INFO - Epoch   9 Step:     2680 Batch Loss:     0.001089 [Torso :     0.000715, Hand :     0.001570, Face :     0.000176]Tokens per Sec:  1509773, Lr: 0.001000\n","2020-11-30 19:30:04,910 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:31:17,241 - __main__ - INFO - Validation result at epoch   9, step     2700: Val DTW Score: 197.93, loss:   3.4379,  duration: 72.3300s\n","2020-11-30 19:31:24,447 - __main__ - INFO - Epoch   9 Step:     2720 Batch Loss:     0.000985 [Torso :     0.000624, Hand :     0.001451, Face :     0.000098]Tokens per Sec:  1428048, Lr: 0.000700\n","2020-11-30 19:31:37,752 - __main__ - INFO - Epoch   9 Step:     2760 Batch Loss:     0.000949 [Torso :     0.000711, Hand :     0.001306, Face :     0.000120]Tokens per Sec:  1420249, Lr: 0.000700\n","2020-11-30 19:31:50,356 - __main__ - INFO - Epoch   9 Step:     2800 Batch Loss:     0.000529 [Torso :     0.000377, Hand :     0.000742, Face :     0.000066]Tokens per Sec:  1485106, Lr: 0.000700\n","2020-11-30 19:32:02,758 - __main__ - INFO - Epoch   9 Step:     2840 Batch Loss:     0.000875 [Torso :     0.000600, Hand :     0.001251, Face :     0.000096]Tokens per Sec:  1508130, Lr: 0.000700\n","2020-11-30 19:32:06,652 - __main__ - INFO - Epoch   9: total training loss 0.26804 [torso: 0.19726, hand: 0.37082, face: 0.03728\n","2020-11-30 19:32:06,654 - __main__ - INFO - Epoch   9: disc loss [real: 58.85328, fake: 38.40157], generator [total: 26.99580, adv: 0.19158]\n","2020-11-30 19:32:15,686 - __main__ - INFO - Epoch  10 Step:     2880 Batch Loss:     0.000714 [Torso :     0.000522, Hand :     0.000988, Face :     0.000109]Tokens per Sec:  1456133, Lr: 0.000700\n","2020-11-30 19:32:28,172 - __main__ - INFO - Epoch  10 Step:     2920 Batch Loss:     0.000949 [Torso :     0.000662, Hand :     0.001346, Face :     0.000109]Tokens per Sec:  1493712, Lr: 0.000700\n","2020-11-30 19:32:41,340 - __main__ - INFO - Epoch  10 Step:     2960 Batch Loss:     0.000686 [Torso :     0.000520, Hand :     0.000940, Face :     0.000084]Tokens per Sec:  1485369, Lr: 0.000700\n","2020-11-30 19:32:55,221 - __main__ - INFO - Epoch  10 Step:     3000 Batch Loss:     0.000826 [Torso :     0.000630, Hand :     0.001126, Face :     0.000114]Tokens per Sec:  1458556, Lr: 0.000700\n","2020-11-30 19:32:55,222 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:34:11,012 - __main__ - INFO - Validation result at epoch  10, step     3000: Val DTW Score: 187.93, loss:   2.5897,  duration: 75.7891s\n","2020-11-30 19:34:24,303 - __main__ - INFO - Epoch  10 Step:     3040 Batch Loss:     0.000876 [Torso :     0.000652, Hand :     0.001212, Face :     0.000098]Tokens per Sec:  1413977, Lr: 0.000700\n","2020-11-30 19:34:36,507 - __main__ - INFO - Epoch  10 Step:     3080 Batch Loss:     0.000813 [Torso :     0.000547, Hand :     0.001170, Face :     0.000093]Tokens per Sec:  1508004, Lr: 0.000700\n","2020-11-30 19:34:49,012 - __main__ - INFO - Epoch  10 Step:     3120 Batch Loss:     0.000968 [Torso :     0.000732, Hand :     0.001331, Face :     0.000097]Tokens per Sec:  1503625, Lr: 0.000700\n","2020-11-30 19:35:02,203 - __main__ - INFO - Epoch  10 Step:     3160 Batch Loss:     0.000861 [Torso :     0.000579, Hand :     0.001233, Face :     0.000126]Tokens per Sec:  1468831, Lr: 0.000700\n","2020-11-30 19:35:05,169 - __main__ - INFO - Epoch  10: total training loss 0.27109 [torso: 0.19566, hand: 0.37887, face: 0.03386\n","2020-11-30 19:35:05,170 - __main__ - INFO - Epoch  10: disc loss [real: 55.09270, fake: 37.12337], generator [total: 27.30893, adv: 0.20024]\n","2020-11-30 19:35:15,704 - __main__ - INFO - Epoch  11 Step:     3200 Batch Loss:     0.000968 [Torso :     0.000607, Hand :     0.001428, Face :     0.000112]Tokens per Sec:  1443952, Lr: 0.000700\n","2020-11-30 19:35:29,040 - __main__ - INFO - Epoch  11 Step:     3240 Batch Loss:     0.000765 [Torso :     0.000533, Hand :     0.001084, Face :     0.000102]Tokens per Sec:  1464911, Lr: 0.000700\n","2020-11-30 19:35:41,512 - __main__ - INFO - Epoch  11 Step:     3280 Batch Loss:     0.000622 [Torso :     0.000413, Hand :     0.000896, Face :     0.000088]Tokens per Sec:  1502221, Lr: 0.000700\n","2020-11-30 19:35:47,893 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:37:00,772 - __main__ - INFO - Validation result at epoch  11, step     3300: Val DTW Score: 216.39, loss:   3.6178,  duration: 72.8776s\n","2020-11-30 19:37:07,735 - __main__ - INFO - Epoch  11 Step:     3320 Batch Loss:     0.001124 [Torso :     0.001155, Hand :     0.001299, Face :     0.000128]Tokens per Sec:  1453484, Lr: 0.000700\n","2020-11-30 19:37:20,144 - __main__ - INFO - Epoch  11 Step:     3360 Batch Loss:     0.000930 [Torso :     0.000657, Hand :     0.001313, Face :     0.000109]Tokens per Sec:  1470586, Lr: 0.000700\n","2020-11-30 19:37:33,224 - __main__ - INFO - Epoch  11 Step:     3400 Batch Loss:     0.000622 [Torso :     0.000410, Hand :     0.000898, Face :     0.000090]Tokens per Sec:  1465289, Lr: 0.000700\n","2020-11-30 19:37:46,196 - __main__ - INFO - Epoch  11 Step:     3440 Batch Loss:     0.000660 [Torso :     0.000518, Hand :     0.000888, Face :     0.000085]Tokens per Sec:  1472219, Lr: 0.000700\n","2020-11-30 19:37:59,275 - __main__ - INFO - Epoch  11 Step:     3480 Batch Loss:     0.000970 [Torso :     0.000761, Hand :     0.001308, Face :     0.000114]Tokens per Sec:  1470801, Lr: 0.000700\n","2020-11-30 19:38:01,386 - __main__ - INFO - Epoch  11: total training loss 0.27337 [torso: 0.19565, hand: 0.38344, face: 0.03386\n","2020-11-30 19:38:01,387 - __main__ - INFO - Epoch  11: disc loss [real: 53.23706, fake: 32.57166], generator [total: 27.54436, adv: 0.20781]\n","2020-11-30 19:38:11,556 - __main__ - INFO - Epoch  12 Step:     3520 Batch Loss:     0.000986 [Torso :     0.000649, Hand :     0.001427, Face :     0.000130]Tokens per Sec:  1504891, Lr: 0.000700\n","2020-11-30 19:38:24,568 - __main__ - INFO - Epoch  12 Step:     3560 Batch Loss:     0.000651 [Torso :     0.000506, Hand :     0.000878, Face :     0.000091]Tokens per Sec:  1469952, Lr: 0.000700\n","2020-11-30 19:38:37,861 - __main__ - INFO - Epoch  12 Step:     3600 Batch Loss:     0.000746 [Torso :     0.000522, Hand :     0.001054, Face :     0.000101]Tokens per Sec:  1473788, Lr: 0.000700\n","2020-11-30 19:38:37,862 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:39:46,616 - __main__ - INFO - Validation result at epoch  12, step     3600: Val DTW Score: 190.99, loss:   3.7439,  duration: 68.7533s\n","2020-11-30 19:40:00,785 - __main__ - INFO - Epoch  12 Step:     3640 Batch Loss:     0.000630 [Torso :     0.000461, Hand :     0.000876, Face :     0.000079]Tokens per Sec:  1373775, Lr: 0.000700\n","2020-11-30 19:40:13,169 - __main__ - INFO - Epoch  12 Step:     3680 Batch Loss:     0.000800 [Torso :     0.000623, Hand :     0.001076, Face :     0.000131]Tokens per Sec:  1485987, Lr: 0.000700\n","2020-11-30 19:40:25,097 - __main__ - INFO - Epoch  12 Step:     3720 Batch Loss:     0.001014 [Torso :     0.000638, Hand :     0.001495, Face :     0.000118]Tokens per Sec:  1527957, Lr: 0.000700\n","2020-11-30 19:40:38,891 - __main__ - INFO - Epoch  12 Step:     3760 Batch Loss:     0.000827 [Torso :     0.000582, Hand :     0.001166, Face :     0.000113]Tokens per Sec:  1442604, Lr: 0.000700\n","2020-11-30 19:40:51,672 - __main__ - INFO - Epoch  12 Step:     3800 Batch Loss:     0.001262 [Torso :     0.000864, Hand :     0.001806, Face :     0.000134]Tokens per Sec:  1491527, Lr: 0.000700\n","2020-11-30 19:40:52,734 - __main__ - INFO - Epoch  12: total training loss 0.28533 [torso: 0.20167, hand: 0.40212, face: 0.03598\n","2020-11-30 19:40:52,735 - __main__ - INFO - Epoch  12: disc loss [real: 55.46166, fake: 38.41179], generator [total: 28.74270, adv: 0.20983]\n","2020-11-30 19:41:04,321 - __main__ - INFO - Epoch  13 Step:     3840 Batch Loss:     0.001045 [Torso :     0.000743, Hand :     0.001474, Face :     0.000110]Tokens per Sec:  1466709, Lr: 0.000700\n","2020-11-30 19:41:17,485 - __main__ - INFO - Epoch  13 Step:     3880 Batch Loss:     0.000676 [Torso :     0.000466, Hand :     0.000959, Face :     0.000093]Tokens per Sec:  1475901, Lr: 0.000700\n","2020-11-30 19:41:23,885 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:42:40,111 - __main__ - INFO - Validation result at epoch  13, step     3900: Val DTW Score: 237.82, loss:   5.7251,  duration: 76.2242s\n","2020-11-30 19:42:46,353 - __main__ - INFO - Epoch  13 Step:     3920 Batch Loss:     0.000847 [Torso :     0.000599, Hand :     0.001194, Face :     0.000104]Tokens per Sec:  1498764, Lr: 0.000700\n","2020-11-30 19:42:59,742 - __main__ - INFO - Epoch  13 Step:     3960 Batch Loss:     0.001056 [Torso :     0.000668, Hand :     0.001544, Face :     0.000171]Tokens per Sec:  1423413, Lr: 0.000700\n","2020-11-30 19:43:12,123 - __main__ - INFO - Epoch  13 Step:     4000 Batch Loss:     0.000827 [Torso :     0.000583, Hand :     0.001165, Face :     0.000110]Tokens per Sec:  1500055, Lr: 0.000700\n","2020-11-30 19:43:24,592 - __main__ - INFO - Epoch  13 Step:     4040 Batch Loss:     0.000991 [Torso :     0.000634, Hand :     0.001454, Face :     0.000108]Tokens per Sec:  1498783, Lr: 0.000700\n","2020-11-30 19:43:37,131 - __main__ - INFO - Epoch  13 Step:     4080 Batch Loss:     0.001145 [Torso :     0.000752, Hand :     0.001669, Face :     0.000098]Tokens per Sec:  1494030, Lr: 0.000700\n","2020-11-30 19:43:49,234 - __main__ - INFO - Epoch  13 Step:     4120 Batch Loss:     0.001204 [Torso :     0.000782, Hand :     0.001758, Face :     0.000122]Tokens per Sec:  1526099, Lr: 0.000700\n","2020-11-30 19:43:49,687 - __main__ - INFO - Epoch  13: total training loss 0.29320 [torso: 0.20914, hand: 0.41190, face: 0.03599\n","2020-11-30 19:43:49,689 - __main__ - INFO - Epoch  13: disc loss [real: 58.34854, fake: 41.91066], generator [total: 29.52851, adv: 0.20821]\n","2020-11-30 19:44:02,330 - __main__ - INFO - Epoch  14 Step:     4160 Batch Loss:     0.000826 [Torso :     0.000544, Hand :     0.001199, Face :     0.000085]Tokens per Sec:  1487434, Lr: 0.000700\n","2020-11-30 19:44:14,456 - __main__ - INFO - Epoch  14 Step:     4200 Batch Loss:     0.001104 [Torso :     0.000733, Hand :     0.001593, Face :     0.000143]Tokens per Sec:  1515756, Lr: 0.000700\n","2020-11-30 19:44:14,458 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:45:30,378 - __main__ - INFO - Validation result at epoch  14, step     4200: Val DTW Score: 228.83, loss:   4.9805,  duration: 75.9194s\n","2020-11-30 19:45:43,968 - __main__ - INFO - Epoch  14 Step:     4240 Batch Loss:     0.001098 [Torso :     0.000755, Hand :     0.001571, Face :     0.000107]Tokens per Sec:  1423744, Lr: 0.000700\n","2020-11-30 19:45:57,103 - __main__ - INFO - Epoch  14 Step:     4280 Batch Loss:     0.000951 [Torso :     0.000715, Hand :     0.001312, Face :     0.000091]Tokens per Sec:  1462108, Lr: 0.000700\n","2020-11-30 19:46:09,802 - __main__ - INFO - Epoch  14 Step:     4320 Batch Loss:     0.000998 [Torso :     0.000623, Hand :     0.001476, Face :     0.000115]Tokens per Sec:  1487420, Lr: 0.000700\n","2020-11-30 19:46:22,784 - __main__ - INFO - Epoch  14 Step:     4360 Batch Loss:     0.001021 [Torso :     0.000676, Hand :     0.001482, Face :     0.000100]Tokens per Sec:  1476936, Lr: 0.000700\n","2020-11-30 19:46:35,094 - __main__ - INFO - Epoch  14 Step:     4400 Batch Loss:     0.001016 [Torso :     0.000641, Hand :     0.001494, Face :     0.000126]Tokens per Sec:  1513277, Lr: 0.000700\n","2020-11-30 19:46:47,080 - __main__ - INFO - Epoch  14: total training loss 0.28796 [torso: 0.20450, hand: 0.40533, face: 0.03499\n","2020-11-30 19:46:47,081 - __main__ - INFO - Epoch  14: disc loss [real: 55.26925, fake: 36.70741], generator [total: 29.00680, adv: 0.21036]\n","2020-11-30 19:46:47,680 - __main__ - INFO - Epoch  15 Step:     4440 Batch Loss:     0.000925 [Torso :     0.000678, Hand :     0.001284, Face :     0.000120]Tokens per Sec:  1511720, Lr: 0.000700\n","2020-11-30 19:46:59,971 - __main__ - INFO - Epoch  15 Step:     4480 Batch Loss:     0.000729 [Torso :     0.000457, Hand :     0.001075, Face :     0.000084]Tokens per Sec:  1521095, Lr: 0.000700\n","2020-11-30 19:47:06,394 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:48:25,171 - __main__ - INFO - Validation result at epoch  15, step     4500: Val DTW Score: 251.99, loss:   5.0113,  duration: 78.7759s\n","2020-11-30 19:48:31,474 - __main__ - INFO - Epoch  15 Step:     4520 Batch Loss:     0.001189 [Torso :     0.000793, Hand :     0.001715, Face :     0.000140]Tokens per Sec:  1470753, Lr: 0.000700\n","2020-11-30 19:48:45,076 - __main__ - INFO - Epoch  15 Step:     4560 Batch Loss:     0.000949 [Torso :     0.000577, Hand :     0.001416, Face :     0.000103]Tokens per Sec:  1396051, Lr: 0.000700\n","2020-11-30 19:48:58,127 - __main__ - INFO - Epoch  15 Step:     4600 Batch Loss:     0.001010 [Torso :     0.000782, Hand :     0.001372, Face :     0.000106]Tokens per Sec:  1469223, Lr: 0.000700\n","2020-11-30 19:49:09,971 - __main__ - INFO - Epoch  15 Step:     4640 Batch Loss:     0.000947 [Torso :     0.000663, Hand :     0.001337, Face :     0.000136]Tokens per Sec:  1530273, Lr: 0.000700\n","2020-11-30 19:49:23,773 - __main__ - INFO - Epoch  15 Step:     4680 Batch Loss:     0.000702 [Torso :     0.000491, Hand :     0.000992, Face :     0.000099]Tokens per Sec:  1434981, Lr: 0.000700\n","2020-11-30 19:49:36,890 - __main__ - INFO - Epoch  15 Step:     4720 Batch Loss:     0.000886 [Torso :     0.000613, Hand :     0.001259, Face :     0.000113]Tokens per Sec:  1472384, Lr: 0.000700\n","2020-11-30 19:49:47,433 - __main__ - INFO - Epoch  15: total training loss 0.29274 [torso: 0.20516, hand: 0.41440, face: 0.03473\n","2020-11-30 19:49:47,434 - __main__ - INFO - Epoch  15: disc loss [real: 57.71521, fake: 45.40400], generator [total: 29.47862, adv: 0.20500]\n","2020-11-30 19:49:49,019 - __main__ - INFO - Epoch  16 Step:     4760 Batch Loss:     0.000807 [Torso :     0.000552, Hand :     0.001155, Face :     0.000088]Tokens per Sec:  1465562, Lr: 0.000700\n","2020-11-30 19:50:01,866 - __main__ - INFO - Epoch  16 Step:     4800 Batch Loss:     0.000852 [Torso :     0.000605, Hand :     0.001203, Face :     0.000088]Tokens per Sec:  1474483, Lr: 0.000700\n","2020-11-30 19:50:01,868 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:51:18,662 - __main__ - INFO - Validation result at epoch  16, step     4800: Val DTW Score: 275.82, loss:   3.7496,  duration: 76.7933s\n","2020-11-30 19:51:32,161 - __main__ - INFO - Epoch  16 Step:     4840 Batch Loss:     0.000778 [Torso :     0.000561, Hand :     0.001088, Face :     0.000096]Tokens per Sec:  1413326, Lr: 0.000700\n","2020-11-30 19:51:44,588 - __main__ - INFO - Epoch  16 Step:     4880 Batch Loss:     0.000925 [Torso :     0.000594, Hand :     0.001352, Face :     0.000113]Tokens per Sec:  1487695, Lr: 0.000700\n","2020-11-30 19:51:57,318 - __main__ - INFO - Epoch  16 Step:     4920 Batch Loss:     0.000926 [Torso :     0.000629, Hand :     0.001329, Face :     0.000097]Tokens per Sec:  1482055, Lr: 0.000700\n","2020-11-30 19:52:10,562 - __main__ - INFO - Epoch  16 Step:     4960 Batch Loss:     0.000742 [Torso :     0.000535, Hand :     0.001037, Face :     0.000093]Tokens per Sec:  1477360, Lr: 0.000700\n","2020-11-30 19:52:23,334 - __main__ - INFO - Epoch  16 Step:     5000 Batch Loss:     0.000894 [Torso :     0.000634, Hand :     0.001256, Face :     0.000125]Tokens per Sec:  1479576, Lr: 0.000700\n","2020-11-30 19:52:36,624 - __main__ - INFO - Epoch  16 Step:     5040 Batch Loss:     0.000912 [Torso :     0.000659, Hand :     0.001275, Face :     0.000104]Tokens per Sec:  1456694, Lr: 0.000700\n","2020-11-30 19:52:47,236 - __main__ - INFO - Epoch  16: total training loss 0.28017 [torso: 0.19597, hand: 0.39699, face: 0.03288\n","2020-11-30 19:52:47,237 - __main__ - INFO - Epoch  16: disc loss [real: 65.54498, fake: 46.67156], generator [total: 28.22898, adv: 0.21171]\n","2020-11-30 19:52:49,568 - __main__ - INFO - Epoch  17 Step:     5080 Batch Loss:     0.001017 [Torso :     0.000812, Hand :     0.001355, Face :     0.000145]Tokens per Sec:  1536269, Lr: 0.000700\n","2020-11-30 19:52:56,099 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:54:13,456 - __main__ - INFO - Validation result at epoch  17, step     5100: Val DTW Score: 246.47, loss:   4.2069,  duration: 77.3558s\n","2020-11-30 19:54:20,423 - __main__ - INFO - Epoch  17 Step:     5120 Batch Loss:     0.001002 [Torso :     0.000731, Hand :     0.001394, Face :     0.000122]Tokens per Sec:  1442117, Lr: 0.000490\n","2020-11-30 19:54:33,261 - __main__ - INFO - Epoch  17 Step:     5160 Batch Loss:     0.001082 [Torso :     0.000832, Hand :     0.001467, Face :     0.000158]Tokens per Sec:  1423419, Lr: 0.000490\n","2020-11-30 19:54:46,459 - __main__ - INFO - Epoch  17 Step:     5200 Batch Loss:     0.000804 [Torso :     0.000523, Hand :     0.001170, Face :     0.000100]Tokens per Sec:  1465051, Lr: 0.000490\n","2020-11-30 19:54:59,945 - __main__ - INFO - Epoch  17 Step:     5240 Batch Loss:     0.000886 [Torso :     0.000633, Hand :     0.001246, Face :     0.000095]Tokens per Sec:  1463004, Lr: 0.000490\n","2020-11-30 19:55:11,998 - __main__ - INFO - Epoch  17 Step:     5280 Batch Loss:     0.000859 [Torso :     0.000606, Hand :     0.001206, Face :     0.000137]Tokens per Sec:  1528734, Lr: 0.000490\n","2020-11-30 19:55:25,258 - __main__ - INFO - Epoch  17 Step:     5320 Batch Loss:     0.000898 [Torso :     0.000580, Hand :     0.001312, Face :     0.000102]Tokens per Sec:  1473309, Lr: 0.000490\n","2020-11-30 19:55:38,211 - __main__ - INFO - Epoch  17 Step:     5360 Batch Loss:     0.000620 [Torso :     0.000422, Hand :     0.000885, Face :     0.000085]Tokens per Sec:  1462469, Lr: 0.000490\n","2020-11-30 19:55:47,378 - __main__ - INFO - Epoch  17: total training loss 0.26684 [torso: 0.19225, hand: 0.37294, face: 0.03475\n","2020-11-30 19:55:47,380 - __main__ - INFO - Epoch  17: disc loss [real: 55.63278, fake: 38.06040], generator [total: 26.89039, adv: 0.20614]\n","2020-11-30 19:55:51,060 - __main__ - INFO - Epoch  18 Step:     5400 Batch Loss:     0.000791 [Torso :     0.000605, Hand :     0.001078, Face :     0.000100]Tokens per Sec:  1416925, Lr: 0.000490\n","2020-11-30 19:55:51,062 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:57:02,362 - __main__ - INFO - Validation result at epoch  18, step     5400: Val DTW Score: 209.45, loss:   4.6027,  duration: 71.2992s\n","2020-11-30 19:57:15,658 - __main__ - INFO - Epoch  18 Step:     5440 Batch Loss:     0.000777 [Torso :     0.000572, Hand :     0.001075, Face :     0.000106]Tokens per Sec:  1412832, Lr: 0.000490\n","2020-11-30 19:57:28,434 - __main__ - INFO - Epoch  18 Step:     5480 Batch Loss:     0.000862 [Torso :     0.000731, Hand :     0.001118, Face :     0.000101]Tokens per Sec:  1483250, Lr: 0.000490\n","2020-11-30 19:57:40,804 - __main__ - INFO - Epoch  18 Step:     5520 Batch Loss:     0.001000 [Torso :     0.000725, Hand :     0.001397, Face :     0.000121]Tokens per Sec:  1483393, Lr: 0.000490\n","2020-11-30 19:57:53,775 - __main__ - INFO - Epoch  18 Step:     5560 Batch Loss:     0.000802 [Torso :     0.000609, Hand :     0.001102, Face :     0.000080]Tokens per Sec:  1485894, Lr: 0.000490\n","2020-11-30 19:58:06,570 - __main__ - INFO - Epoch  18 Step:     5600 Batch Loss:     0.000766 [Torso :     0.000500, Hand :     0.001112, Face :     0.000098]Tokens per Sec:  1497435, Lr: 0.000490\n","2020-11-30 19:58:19,805 - __main__ - INFO - Epoch  18 Step:     5640 Batch Loss:     0.000785 [Torso :     0.000524, Hand :     0.001132, Face :     0.000091]Tokens per Sec:  1465584, Lr: 0.000490\n","2020-11-30 19:58:32,795 - __main__ - INFO - Epoch  18 Step:     5680 Batch Loss:     0.001131 [Torso :     0.000834, Hand :     0.001568, Face :     0.000133]Tokens per Sec:  1471880, Lr: 0.000490\n","2020-11-30 19:58:39,089 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 19:59:52,014 - __main__ - INFO - Validation result at epoch  18, step     5700: Val DTW Score: 220.44, loss:   3.9656,  duration: 72.9242s\n","2020-11-30 19:59:53,782 - __main__ - INFO - Epoch  18: total training loss 0.26275 [torso: 0.18843, hand: 0.36846, face: 0.03155\n","2020-11-30 19:59:53,783 - __main__ - INFO - Epoch  18: disc loss [real: 64.81967, fake: 43.06143], generator [total: 26.48560, adv: 0.21012]\n","2020-11-30 19:59:58,413 - __main__ - INFO - Epoch  19 Step:     5720 Batch Loss:     0.000771 [Torso :     0.000588, Hand :     0.001055, Face :     0.000083]Tokens per Sec:  1439416, Lr: 0.000490\n","2020-11-30 20:00:12,036 - __main__ - INFO - Epoch  19 Step:     5760 Batch Loss:     0.000876 [Torso :     0.000615, Hand :     0.001238, Face :     0.000115]Tokens per Sec:  1397278, Lr: 0.000490\n","2020-11-30 20:00:25,083 - __main__ - INFO - Epoch  19 Step:     5800 Batch Loss:     0.000692 [Torso :     0.000463, Hand :     0.000998, Face :     0.000080]Tokens per Sec:  1476227, Lr: 0.000490\n","2020-11-30 20:00:37,194 - __main__ - INFO - Epoch  19 Step:     5840 Batch Loss:     0.000849 [Torso :     0.000628, Hand :     0.001176, Face :     0.000098]Tokens per Sec:  1505575, Lr: 0.000490\n","2020-11-30 20:00:49,684 - __main__ - INFO - Epoch  19 Step:     5880 Batch Loss:     0.000719 [Torso :     0.000569, Hand :     0.000958, Face :     0.000128]Tokens per Sec:  1497487, Lr: 0.000490\n","2020-11-30 20:01:02,397 - __main__ - INFO - Epoch  19 Step:     5920 Batch Loss:     0.000793 [Torso :     0.000595, Hand :     0.001091, Face :     0.000093]Tokens per Sec:  1492441, Lr: 0.000490\n","2020-11-30 20:01:15,474 - __main__ - INFO - Epoch  19 Step:     5960 Batch Loss:     0.000707 [Torso :     0.000460, Hand :     0.001031, Face :     0.000076]Tokens per Sec:  1461592, Lr: 0.000490\n","2020-11-30 20:01:28,411 - __main__ - INFO - Epoch  19 Step:     6000 Batch Loss:     0.000820 [Torso :     0.000546, Hand :     0.001186, Face :     0.000081]Tokens per Sec:  1479071, Lr: 0.000490\n","2020-11-30 20:01:28,412 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:02:41,177 - __main__ - INFO - Validation result at epoch  19, step     6000: Val DTW Score: 219.22, loss:   3.3825,  duration: 72.7637s\n","2020-11-30 20:02:49,472 - __main__ - INFO - Epoch  19: total training loss 0.24900 [torso: 0.18061, hand: 0.34752, face: 0.02999\n","2020-11-30 20:02:49,475 - __main__ - INFO - Epoch  19: disc loss [real: 58.59682, fake: 41.39747], generator [total: 25.10985, adv: 0.20949]\n","2020-11-30 20:02:55,187 - __main__ - INFO - Epoch  20 Step:     6040 Batch Loss:     0.000803 [Torso :     0.000559, Hand :     0.001140, Face :     0.000092]Tokens per Sec:  1372205, Lr: 0.000490\n","2020-11-30 20:03:07,680 - __main__ - INFO - Epoch  20 Step:     6080 Batch Loss:     0.001030 [Torso :     0.000729, Hand :     0.001451, Face :     0.000132]Tokens per Sec:  1495364, Lr: 0.000490\n","2020-11-30 20:03:20,571 - __main__ - INFO - Epoch  20 Step:     6120 Batch Loss:     0.000647 [Torso :     0.000445, Hand :     0.000919, Face :     0.000090]Tokens per Sec:  1494566, Lr: 0.000490\n","2020-11-30 20:03:33,329 - __main__ - INFO - Epoch  20 Step:     6160 Batch Loss:     0.000670 [Torso :     0.000480, Hand :     0.000941, Face :     0.000078]Tokens per Sec:  1492030, Lr: 0.000490\n","2020-11-30 20:03:46,461 - __main__ - INFO - Epoch  20 Step:     6200 Batch Loss:     0.000687 [Torso :     0.000542, Hand :     0.000924, Face :     0.000087]Tokens per Sec:  1470083, Lr: 0.000490\n","2020-11-30 20:03:59,048 - __main__ - INFO - Epoch  20 Step:     6240 Batch Loss:     0.000757 [Torso :     0.000585, Hand :     0.001028, Face :     0.000087]Tokens per Sec:  1477492, Lr: 0.000490\n","2020-11-30 20:04:12,164 - __main__ - INFO - Epoch  20 Step:     6280 Batch Loss:     0.000807 [Torso :     0.000668, Hand :     0.001060, Face :     0.000102]Tokens per Sec:  1470084, Lr: 0.000490\n","2020-11-30 20:04:18,581 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:05:27,835 - __main__ - INFO - Validation result at epoch  20, step     6300: Val DTW Score: 211.15, loss:   4.1423,  duration: 69.2520s\n","2020-11-30 20:05:34,405 - __main__ - INFO - Epoch  20 Step:     6320 Batch Loss:     0.000742 [Torso :     0.000543, Hand :     0.001030, Face :     0.000095]Tokens per Sec:  1473781, Lr: 0.000490\n","2020-11-30 20:05:42,076 - __main__ - INFO - Epoch  20: total training loss 0.25171 [torso: 0.18288, hand: 0.35081, face: 0.03159\n","2020-11-30 20:05:42,077 - __main__ - INFO - Epoch  20: disc loss [real: 60.89082, fake: 42.57346], generator [total: 25.38077, adv: 0.20948]\n","2020-11-30 20:05:49,040 - __main__ - INFO - Epoch  21 Step:     6360 Batch Loss:     0.001067 [Torso :     0.000735, Hand :     0.001526, Face :     0.000097]Tokens per Sec:  1448062, Lr: 0.000490\n","2020-11-30 20:06:02,349 - __main__ - INFO - Epoch  21 Step:     6400 Batch Loss:     0.000765 [Torso :     0.000492, Hand :     0.001122, Face :     0.000071]Tokens per Sec:  1461543, Lr: 0.000490\n","2020-11-30 20:06:15,329 - __main__ - INFO - Epoch  21 Step:     6440 Batch Loss:     0.000867 [Torso :     0.000524, Hand :     0.001290, Face :     0.000122]Tokens per Sec:  1467650, Lr: 0.000490\n","2020-11-30 20:06:28,235 - __main__ - INFO - Epoch  21 Step:     6480 Batch Loss:     0.000891 [Torso :     0.000556, Hand :     0.001316, Face :     0.000101]Tokens per Sec:  1475504, Lr: 0.000490\n","2020-11-30 20:06:41,134 - __main__ - INFO - Epoch  21 Step:     6520 Batch Loss:     0.000836 [Torso :     0.000599, Hand :     0.001171, Face :     0.000108]Tokens per Sec:  1475669, Lr: 0.000490\n","2020-11-30 20:06:53,916 - __main__ - INFO - Epoch  21 Step:     6560 Batch Loss:     0.000888 [Torso :     0.000697, Hand :     0.001192, Face :     0.000136]Tokens per Sec:  1485012, Lr: 0.000490\n","2020-11-30 20:07:07,392 - __main__ - INFO - Epoch  21 Step:     6600 Batch Loss:     0.000850 [Torso :     0.000544, Hand :     0.001243, Face :     0.000110]Tokens per Sec:  1456652, Lr: 0.000490\n","2020-11-30 20:07:07,393 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:08:21,251 - __main__ - INFO - Validation result at epoch  21, step     6600: Val DTW Score: 243.80, loss:   4.6088,  duration: 73.8568s\n","2020-11-30 20:08:34,635 - __main__ - INFO - Epoch  21 Step:     6640 Batch Loss:     0.000680 [Torso :     0.000491, Hand :     0.000950, Face :     0.000083]Tokens per Sec:  1402955, Lr: 0.000490\n","2020-11-30 20:08:39,803 - __main__ - INFO - Epoch  21: total training loss 0.26952 [torso: 0.18974, hand: 0.38073, face: 0.03259\n","2020-11-30 20:08:39,804 - __main__ - INFO - Epoch  21: disc loss [real: 58.93475, fake: 39.59024], generator [total: 27.16173, adv: 0.21005]\n","2020-11-30 20:08:47,161 - __main__ - INFO - Epoch  22 Step:     6680 Batch Loss:     0.001031 [Torso :     0.000703, Hand :     0.001479, Face :     0.000098]Tokens per Sec:  1468939, Lr: 0.000490\n","2020-11-30 20:08:59,581 - __main__ - INFO - Epoch  22 Step:     6720 Batch Loss:     0.000809 [Torso :     0.000551, Hand :     0.001159, Face :     0.000096]Tokens per Sec:  1496004, Lr: 0.000490\n","2020-11-30 20:09:13,572 - __main__ - INFO - Epoch  22 Step:     6760 Batch Loss:     0.000795 [Torso :     0.000523, Hand :     0.001153, Face :     0.000098]Tokens per Sec:  1433202, Lr: 0.000490\n","2020-11-30 20:09:26,365 - __main__ - INFO - Epoch  22 Step:     6800 Batch Loss:     0.000926 [Torso :     0.000654, Hand :     0.001308, Face :     0.000105]Tokens per Sec:  1468705, Lr: 0.000490\n","2020-11-30 20:09:39,084 - __main__ - INFO - Epoch  22 Step:     6840 Batch Loss:     0.000765 [Torso :     0.000479, Hand :     0.001129, Face :     0.000089]Tokens per Sec:  1483200, Lr: 0.000490\n","2020-11-30 20:09:52,323 - __main__ - INFO - Epoch  22 Step:     6880 Batch Loss:     0.001019 [Torso :     0.000754, Hand :     0.001413, Face :     0.000110]Tokens per Sec:  1461723, Lr: 0.000490\n","2020-11-30 20:09:59,156 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:11:09,533 - __main__ - INFO - Validation result at epoch  22, step     6900: Val DTW Score: 204.86, loss:   5.1698,  duration: 70.3759s\n","2020-11-30 20:11:16,438 - __main__ - INFO - Epoch  22 Step:     6920 Batch Loss:     0.000829 [Torso :     0.000630, Hand :     0.001130, Face :     0.000122]Tokens per Sec:  1429927, Lr: 0.000490\n","2020-11-30 20:11:29,376 - __main__ - INFO - Epoch  22 Step:     6960 Batch Loss:     0.000992 [Torso :     0.000736, Hand :     0.001374, Face :     0.000107]Tokens per Sec:  1428402, Lr: 0.000490\n","2020-11-30 20:11:34,010 - __main__ - INFO - Epoch  22: total training loss 0.27176 [torso: 0.19050, hand: 0.38462, face: 0.03254\n","2020-11-30 20:11:34,011 - __main__ - INFO - Epoch  22: disc loss [real: 65.56770, fake: 45.42704], generator [total: 27.36317, adv: 0.18682]\n","2020-11-30 20:11:42,407 - __main__ - INFO - Epoch  23 Step:     7000 Batch Loss:     0.001043 [Torso :     0.000687, Hand :     0.001517, Face :     0.000100]Tokens per Sec:  1470779, Lr: 0.000490\n","2020-11-30 20:11:55,314 - __main__ - INFO - Epoch  23 Step:     7040 Batch Loss:     0.000697 [Torso :     0.000495, Hand :     0.000983, Face :     0.000075]Tokens per Sec:  1463559, Lr: 0.000490\n","2020-11-30 20:12:08,322 - __main__ - INFO - Epoch  23 Step:     7080 Batch Loss:     0.001034 [Torso :     0.000733, Hand :     0.001457, Face :     0.000119]Tokens per Sec:  1475725, Lr: 0.000490\n","2020-11-30 20:12:20,895 - __main__ - INFO - Epoch  23 Step:     7120 Batch Loss:     0.000724 [Torso :     0.000473, Hand :     0.001055, Face :     0.000074]Tokens per Sec:  1489439, Lr: 0.000490\n","2020-11-30 20:12:33,786 - __main__ - INFO - Epoch  23 Step:     7160 Batch Loss:     0.000802 [Torso :     0.000568, Hand :     0.001131, Face :     0.000094]Tokens per Sec:  1470688, Lr: 0.000490\n","2020-11-30 20:12:46,470 - __main__ - INFO - Epoch  23 Step:     7200 Batch Loss:     0.000944 [Torso :     0.000674, Hand :     0.001326, Face :     0.000115]Tokens per Sec:  1484366, Lr: 0.000490\n","2020-11-30 20:12:46,471 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:14:02,579 - __main__ - INFO - Validation result at epoch  23, step     7200: Val DTW Score: 219.85, loss:   4.7404,  duration: 76.1069s\n","2020-11-30 20:14:15,908 - __main__ - INFO - Epoch  23 Step:     7240 Batch Loss:     0.000704 [Torso :     0.000422, Hand :     0.001057, Face :     0.000070]Tokens per Sec:  1435342, Lr: 0.000490\n","2020-11-30 20:14:29,438 - __main__ - INFO - Epoch  23 Step:     7280 Batch Loss:     0.000980 [Torso :     0.000704, Hand :     0.001376, Face :     0.000104]Tokens per Sec:  1422826, Lr: 0.000490\n","2020-11-30 20:14:33,297 - __main__ - INFO - Epoch  23: total training loss 0.26367 [torso: 0.18559, hand: 0.37265, face: 0.03103\n","2020-11-30 20:14:33,298 - __main__ - INFO - Epoch  23: disc loss [real: 66.22234, fake: 45.94094], generator [total: 26.56086, adv: 0.19433]\n","2020-11-30 20:14:42,654 - __main__ - INFO - Epoch  24 Step:     7320 Batch Loss:     0.000829 [Torso :     0.000588, Hand :     0.001169, Face :     0.000098]Tokens per Sec:  1466633, Lr: 0.000490\n","2020-11-30 20:14:55,597 - __main__ - INFO - Epoch  24 Step:     7360 Batch Loss:     0.000664 [Torso :     0.000499, Hand :     0.000913, Face :     0.000079]Tokens per Sec:  1467107, Lr: 0.000490\n","2020-11-30 20:15:08,238 - __main__ - INFO - Epoch  24 Step:     7400 Batch Loss:     0.001026 [Torso :     0.000672, Hand :     0.001484, Face :     0.000148]Tokens per Sec:  1470462, Lr: 0.000490\n","2020-11-30 20:15:21,173 - __main__ - INFO - Epoch  24 Step:     7440 Batch Loss:     0.000737 [Torso :     0.000550, Hand :     0.001015, Face :     0.000098]Tokens per Sec:  1469815, Lr: 0.000490\n","2020-11-30 20:15:34,648 - __main__ - INFO - Epoch  24 Step:     7480 Batch Loss:     0.000840 [Torso :     0.000568, Hand :     0.001204, Face :     0.000110]Tokens per Sec:  1452134, Lr: 0.000490\n","2020-11-30 20:15:42,014 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:16:55,518 - __main__ - INFO - Validation result at epoch  24, step     7500: Val DTW Score: 219.23, loss:   4.8454,  duration: 73.5029s\n","2020-11-30 20:17:01,668 - __main__ - INFO - Epoch  24 Step:     7520 Batch Loss:     0.000987 [Torso :     0.000675, Hand :     0.001413, Face :     0.000109]Tokens per Sec:  1450374, Lr: 0.000343\n","2020-11-30 20:17:15,193 - __main__ - INFO - Epoch  24 Step:     7560 Batch Loss:     0.000975 [Torso :     0.000639, Hand :     0.001414, Face :     0.000123]Tokens per Sec:  1411059, Lr: 0.000343\n","2020-11-30 20:17:27,740 - __main__ - INFO - Epoch  24 Step:     7600 Batch Loss:     0.000951 [Torso :     0.000605, Hand :     0.001399, Face :     0.000100]Tokens per Sec:  1473099, Lr: 0.000343\n","2020-11-30 20:17:30,861 - __main__ - INFO - Epoch  24: total training loss 0.26750 [torso: 0.18832, hand: 0.37818, face: 0.03087\n","2020-11-30 20:17:30,862 - __main__ - INFO - Epoch  24: disc loss [real: 69.61580, fake: 45.36461], generator [total: 26.94341, adv: 0.19307]\n","2020-11-30 20:17:41,056 - __main__ - INFO - Epoch  25 Step:     7640 Batch Loss:     0.000678 [Torso :     0.000438, Hand :     0.000989, Face :     0.000084]Tokens per Sec:  1472498, Lr: 0.000343\n","2020-11-30 20:17:53,720 - __main__ - INFO - Epoch  25 Step:     7680 Batch Loss:     0.000694 [Torso :     0.000478, Hand :     0.000987, Face :     0.000098]Tokens per Sec:  1495203, Lr: 0.000343\n","2020-11-30 20:18:07,238 - __main__ - INFO - Epoch  25 Step:     7720 Batch Loss:     0.000762 [Torso :     0.000561, Hand :     0.001046, Face :     0.000143]Tokens per Sec:  1457740, Lr: 0.000343\n","2020-11-30 20:18:20,300 - __main__ - INFO - Epoch  25 Step:     7760 Batch Loss:     0.000793 [Torso :     0.000558, Hand :     0.001121, Face :     0.000092]Tokens per Sec:  1452507, Lr: 0.000343\n","2020-11-30 20:18:33,446 - __main__ - INFO - Epoch  25 Step:     7800 Batch Loss:     0.000780 [Torso :     0.000738, Hand :     0.000957, Face :     0.000069]Tokens per Sec:  1433393, Lr: 0.000343\n","2020-11-30 20:18:33,447 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:19:44,604 - __main__ - INFO - Validation result at epoch  25, step     7800: Val DTW Score: 208.46, loss:   4.3481,  duration: 71.1552s\n","2020-11-30 20:19:58,384 - __main__ - INFO - Epoch  25 Step:     7840 Batch Loss:     0.000767 [Torso :     0.000494, Hand :     0.001123, Face :     0.000085]Tokens per Sec:  1388308, Lr: 0.000343\n","2020-11-30 20:20:11,505 - __main__ - INFO - Epoch  25 Step:     7880 Batch Loss:     0.000766 [Torso :     0.000507, Hand :     0.001112, Face :     0.000076]Tokens per Sec:  1467762, Lr: 0.000343\n","2020-11-30 20:20:23,680 - __main__ - INFO - Epoch  25 Step:     7920 Batch Loss:     0.000757 [Torso :     0.000514, Hand :     0.001084, Face :     0.000098]Tokens per Sec:  1509190, Lr: 0.000343\n","2020-11-30 20:20:25,492 - __main__ - INFO - Epoch  25: total training loss 0.25449 [torso: 0.17780, hand: 0.36103, face: 0.02850\n","2020-11-30 20:20:25,493 - __main__ - INFO - Epoch  25: disc loss [real: 67.19058, fake: 51.98893], generator [total: 25.63638, adv: 0.18756]\n","2020-11-30 20:20:37,206 - __main__ - INFO - Epoch  26 Step:     7960 Batch Loss:     0.000634 [Torso :     0.000454, Hand :     0.000887, Face :     0.000082]Tokens per Sec:  1466538, Lr: 0.000343\n","2020-11-30 20:20:49,866 - __main__ - INFO - Epoch  26 Step:     8000 Batch Loss:     0.000820 [Torso :     0.000584, Hand :     0.001156, Face :     0.000080]Tokens per Sec:  1484724, Lr: 0.000343\n","2020-11-30 20:21:02,160 - __main__ - INFO - Epoch  26 Step:     8040 Batch Loss:     0.000917 [Torso :     0.000580, Hand :     0.001352, Face :     0.000094]Tokens per Sec:  1470468, Lr: 0.000343\n","2020-11-30 20:21:15,157 - __main__ - INFO - Epoch  26 Step:     8080 Batch Loss:     0.000952 [Torso :     0.000664, Hand :     0.001352, Face :     0.000111]Tokens per Sec:  1459271, Lr: 0.000343\n","2020-11-30 20:21:21,840 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:22:33,675 - __main__ - INFO - Validation result at epoch  26, step     8100: Val DTW Score: 216.66, loss:   4.2799,  duration: 71.8336s\n","2020-11-30 20:22:40,417 - __main__ - INFO - Epoch  26 Step:     8120 Batch Loss:     0.000874 [Torso :     0.000595, Hand :     0.001254, Face :     0.000091]Tokens per Sec:  1449362, Lr: 0.000343\n","2020-11-30 20:22:53,966 - __main__ - INFO - Epoch  26 Step:     8160 Batch Loss:     0.000816 [Torso :     0.000521, Hand :     0.001198, Face :     0.000086]Tokens per Sec:  1393113, Lr: 0.000343\n","2020-11-30 20:23:06,950 - __main__ - INFO - Epoch  26 Step:     8200 Batch Loss:     0.000966 [Torso :     0.000730, Hand :     0.001328, Face :     0.000096]Tokens per Sec:  1481510, Lr: 0.000343\n","2020-11-30 20:23:20,510 - __main__ - INFO - Epoch  26 Step:     8240 Batch Loss:     0.000879 [Torso :     0.000626, Hand :     0.001232, Face :     0.000134]Tokens per Sec:  1448867, Lr: 0.000343\n","2020-11-30 20:23:21,127 - __main__ - INFO - Epoch  26: total training loss 0.25862 [torso: 0.17732, hand: 0.36968, face: 0.02851\n","2020-11-30 20:23:21,128 - __main__ - INFO - Epoch  26: disc loss [real: 62.99348, fake: 50.17610], generator [total: 26.04687, adv: 0.18518]\n","2020-11-30 20:23:34,373 - __main__ - INFO - Epoch  27 Step:     8280 Batch Loss:     0.000727 [Torso :     0.000550, Hand :     0.000997, Face :     0.000080]Tokens per Sec:  1420251, Lr: 0.000343\n","2020-11-30 20:23:47,321 - __main__ - INFO - Epoch  27 Step:     8320 Batch Loss:     0.000812 [Torso :     0.000538, Hand :     0.001174, Face :     0.000096]Tokens per Sec:  1483213, Lr: 0.000343\n","2020-11-30 20:23:59,894 - __main__ - INFO - Epoch  27 Step:     8360 Batch Loss:     0.000633 [Torso :     0.000437, Hand :     0.000902, Face :     0.000071]Tokens per Sec:  1476536, Lr: 0.000343\n","2020-11-30 20:24:12,601 - __main__ - INFO - Epoch  27 Step:     8400 Batch Loss:     0.000478 [Torso :     0.000362, Hand :     0.000656, Face :     0.000052]Tokens per Sec:  1473311, Lr: 0.000343\n","2020-11-30 20:24:12,602 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:25:24,426 - __main__ - INFO - Validation result at epoch  27, step     8400: Val DTW Score: 202.43, loss:   3.8440,  duration: 71.8232s\n","2020-11-30 20:25:37,679 - __main__ - INFO - Epoch  27 Step:     8440 Batch Loss:     0.000693 [Torso :     0.000510, Hand :     0.000959, Face :     0.000093]Tokens per Sec:  1428527, Lr: 0.000343\n","2020-11-30 20:25:51,126 - __main__ - INFO - Epoch  27 Step:     8480 Batch Loss:     0.000616 [Torso :     0.000453, Hand :     0.000853, Face :     0.000078]Tokens per Sec:  1422991, Lr: 0.000343\n","2020-11-30 20:26:03,405 - __main__ - INFO - Epoch  27 Step:     8520 Batch Loss:     0.000918 [Torso :     0.000593, Hand :     0.001347, Face :     0.000073]Tokens per Sec:  1483035, Lr: 0.000343\n","2020-11-30 20:26:16,562 - __main__ - INFO - Epoch  27: total training loss 0.24270 [torso: 0.16991, hand: 0.34389, face: 0.02794\n","2020-11-30 20:26:16,563 - __main__ - INFO - Epoch  27: disc loss [real: 57.69914, fake: 49.29745], generator [total: 24.46099, adv: 0.19063]\n","2020-11-30 20:26:17,013 - __main__ - INFO - Epoch  28 Step:     8560 Batch Loss:     0.000668 [Torso :     0.000449, Hand :     0.000962, Face :     0.000072]Tokens per Sec:  1237996, Lr: 0.000343\n","2020-11-30 20:26:30,715 - __main__ - INFO - Epoch  28 Step:     8600 Batch Loss:     0.000641 [Torso :     0.000453, Hand :     0.000907, Face :     0.000062]Tokens per Sec:  1447772, Lr: 0.000343\n","2020-11-30 20:26:44,182 - __main__ - INFO - Epoch  28 Step:     8640 Batch Loss:     0.000723 [Torso :     0.000489, Hand :     0.001038, Face :     0.000088]Tokens per Sec:  1427752, Lr: 0.000343\n","2020-11-30 20:26:56,405 - __main__ - INFO - Epoch  28 Step:     8680 Batch Loss:     0.000871 [Torso :     0.000592, Hand :     0.001245, Face :     0.000112]Tokens per Sec:  1477847, Lr: 0.000343\n","2020-11-30 20:27:02,870 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:28:17,054 - __main__ - INFO - Validation result at epoch  28, step     8700: Val DTW Score: 201.39, loss:   3.2331,  duration: 74.1834s\n","2020-11-30 20:28:24,316 - __main__ - INFO - Epoch  28 Step:     8720 Batch Loss:     0.000878 [Torso :     0.000617, Hand :     0.001244, Face :     0.000090]Tokens per Sec:  1415364, Lr: 0.000343\n","2020-11-30 20:28:39,016 - __main__ - INFO - Epoch  28 Step:     8760 Batch Loss:     0.000601 [Torso :     0.000389, Hand :     0.000875, Face :     0.000075]Tokens per Sec:  1332695, Lr: 0.000343\n","2020-11-30 20:28:53,125 - __main__ - INFO - Epoch  28 Step:     8800 Batch Loss:     0.000843 [Torso :     0.000610, Hand :     0.001182, Face :     0.000083]Tokens per Sec:  1396695, Lr: 0.000343\n","2020-11-30 20:29:05,566 - __main__ - INFO - Epoch  28 Step:     8840 Batch Loss:     0.000728 [Torso :     0.000530, Hand :     0.001015, Face :     0.000085]Tokens per Sec:  1481076, Lr: 0.000343\n","2020-11-30 20:29:16,946 - __main__ - INFO - Epoch  28: total training loss 0.24223 [torso: 0.17127, hand: 0.34188, face: 0.02780\n","2020-11-30 20:29:16,948 - __main__ - INFO - Epoch  28: disc loss [real: 64.49099, fake: 41.31034], generator [total: 24.41896, adv: 0.19598]\n","2020-11-30 20:29:18,428 - __main__ - INFO - Epoch  29 Step:     8880 Batch Loss:     0.000689 [Torso :     0.000571, Hand :     0.000905, Face :     0.000075]Tokens per Sec:  1345563, Lr: 0.000343\n","2020-11-30 20:29:31,150 - __main__ - INFO - Epoch  29 Step:     8920 Batch Loss:     0.000865 [Torso :     0.000635, Hand :     0.001201, Face :     0.000104]Tokens per Sec:  1464752, Lr: 0.000343\n","2020-11-30 20:29:44,380 - __main__ - INFO - Epoch  29 Step:     8960 Batch Loss:     0.000753 [Torso :     0.000486, Hand :     0.001101, Face :     0.000080]Tokens per Sec:  1455071, Lr: 0.000343\n","2020-11-30 20:29:57,443 - __main__ - INFO - Epoch  29 Step:     9000 Batch Loss:     0.000969 [Torso :     0.000688, Hand :     0.001365, Face :     0.000115]Tokens per Sec:  1452447, Lr: 0.000343\n","2020-11-30 20:29:57,444 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:31:12,362 - __main__ - INFO - Validation result at epoch  29, step     9000: Val DTW Score: 212.06, loss:   4.0534,  duration: 74.9161s\n","2020-11-30 20:31:26,768 - __main__ - INFO - Epoch  29 Step:     9040 Batch Loss:     0.000821 [Torso :     0.000541, Hand :     0.001195, Face :     0.000075]Tokens per Sec:  1304520, Lr: 0.000343\n","2020-11-30 20:31:40,601 - __main__ - INFO - Epoch  29 Step:     9080 Batch Loss:     0.000806 [Torso :     0.000565, Hand :     0.001140, Face :     0.000102]Tokens per Sec:  1371009, Lr: 0.000343\n","2020-11-30 20:31:54,749 - __main__ - INFO - Epoch  29 Step:     9120 Batch Loss:     0.000827 [Torso :     0.000576, Hand :     0.001174, Face :     0.000094]Tokens per Sec:  1366188, Lr: 0.000343\n","2020-11-30 20:32:07,756 - __main__ - INFO - Epoch  29 Step:     9160 Batch Loss:     0.000882 [Torso :     0.000728, Hand :     0.001155, Face :     0.000135]Tokens per Sec:  1418922, Lr: 0.000343\n","2020-11-30 20:32:18,878 - __main__ - INFO - Epoch  29: total training loss 0.25309 [torso: 0.18182, hand: 0.35474, face: 0.02989\n","2020-11-30 20:32:18,879 - __main__ - INFO - Epoch  29: disc loss [real: 66.05871, fake: 43.73430], generator [total: 25.50758, adv: 0.19900]\n","2020-11-30 20:32:21,263 - __main__ - INFO - Epoch  30 Step:     9200 Batch Loss:     0.000707 [Torso :     0.000488, Hand :     0.001005, Face :     0.000091]Tokens per Sec:  1366313, Lr: 0.000343\n","2020-11-30 20:32:34,856 - __main__ - INFO - Epoch  30 Step:     9240 Batch Loss:     0.000731 [Torso :     0.000517, Hand :     0.001033, Face :     0.000074]Tokens per Sec:  1426473, Lr: 0.000343\n","2020-11-30 20:32:48,657 - __main__ - INFO - Epoch  30 Step:     9280 Batch Loss:     0.000849 [Torso :     0.000577, Hand :     0.001218, Face :     0.000099]Tokens per Sec:  1417804, Lr: 0.000343\n","2020-11-30 20:32:55,349 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:34:09,332 - __main__ - INFO - Validation result at epoch  30, step     9300: Val DTW Score: 223.08, loss:   3.7488,  duration: 73.9825s\n","2020-11-30 20:34:16,136 - __main__ - INFO - Epoch  30 Step:     9320 Batch Loss:     0.000718 [Torso :     0.000503, Hand :     0.001014, Face :     0.000096]Tokens per Sec:  1406993, Lr: 0.000343\n","2020-11-30 20:34:30,230 - __main__ - INFO - Epoch  30 Step:     9360 Batch Loss:     0.000628 [Torso :     0.000456, Hand :     0.000876, Face :     0.000076]Tokens per Sec:  1351648, Lr: 0.000343\n","2020-11-30 20:34:43,880 - __main__ - INFO - Epoch  30 Step:     9400 Batch Loss:     0.000591 [Torso :     0.000432, Hand :     0.000821, Face :     0.000079]Tokens per Sec:  1405264, Lr: 0.000343\n","2020-11-30 20:34:56,843 - __main__ - INFO - Epoch  30 Step:     9440 Batch Loss:     0.000662 [Torso :     0.000484, Hand :     0.000922, Face :     0.000077]Tokens per Sec:  1450544, Lr: 0.000343\n","2020-11-30 20:35:09,456 - __main__ - INFO - Epoch  30 Step:     9480 Batch Loss:     0.000877 [Torso :     0.000587, Hand :     0.001268, Face :     0.000087]Tokens per Sec:  1473095, Lr: 0.000343\n","2020-11-30 20:35:19,174 - __main__ - INFO - Epoch  30: total training loss 0.24916 [torso: 0.17676, hand: 0.35098, face: 0.02969\n","2020-11-30 20:35:19,176 - __main__ - INFO - Epoch  30: disc loss [real: 61.15074, fake: 37.85401], generator [total: 25.10605, adv: 0.18966]\n","2020-11-30 20:35:22,416 - __main__ - INFO - Epoch  31 Step:     9520 Batch Loss:     0.000758 [Torso :     0.000607, Hand :     0.001013, Face :     0.000083]Tokens per Sec:  1449938, Lr: 0.000343\n","2020-11-30 20:35:35,662 - __main__ - INFO - Epoch  31 Step:     9560 Batch Loss:     0.000839 [Torso :     0.000591, Hand :     0.001187, Face :     0.000089]Tokens per Sec:  1438750, Lr: 0.000343\n","2020-11-30 20:35:50,383 - __main__ - INFO - Epoch  31 Step:     9600 Batch Loss:     0.000641 [Torso :     0.000464, Hand :     0.000897, Face :     0.000065]Tokens per Sec:  1399952, Lr: 0.000343\n","2020-11-30 20:35:50,385 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:37:01,432 - __main__ - INFO - Validation result at epoch  31, step     9600: Val DTW Score: 171.47, loss:   3.3422,  duration: 71.0458s\n","2020-11-30 20:37:15,377 - __main__ - INFO - Epoch  31 Step:     9640 Batch Loss:     0.000666 [Torso :     0.000488, Hand :     0.000926, Face :     0.000077]Tokens per Sec:  1346561, Lr: 0.000343\n","2020-11-30 20:37:29,118 - __main__ - INFO - Epoch  31 Step:     9680 Batch Loss:     0.000601 [Torso :     0.000480, Hand :     0.000805, Face :     0.000067]Tokens per Sec:  1398182, Lr: 0.000343\n","2020-11-30 20:37:42,272 - __main__ - INFO - Epoch  31 Step:     9720 Batch Loss:     0.000819 [Torso :     0.000579, Hand :     0.001157, Face :     0.000084]Tokens per Sec:  1425496, Lr: 0.000343\n","2020-11-30 20:37:55,955 - __main__ - INFO - Epoch  31 Step:     9760 Batch Loss:     0.000574 [Torso :     0.000380, Hand :     0.000829, Face :     0.000073]Tokens per Sec:  1411930, Lr: 0.000343\n","2020-11-30 20:38:08,553 - __main__ - INFO - Epoch  31 Step:     9800 Batch Loss:     0.000752 [Torso :     0.000569, Hand :     0.001031, Face :     0.000088]Tokens per Sec:  1444899, Lr: 0.000343\n","2020-11-30 20:38:17,198 - __main__ - INFO - Epoch  31: total training loss 0.25834 [torso: 0.18192, hand: 0.36527, face: 0.02934\n","2020-11-30 20:38:17,199 - __main__ - INFO - Epoch  31: disc loss [real: 57.34750, fake: 37.84859], generator [total: 26.03723, adv: 0.20352]\n","2020-11-30 20:38:21,165 - __main__ - INFO - Epoch  32 Step:     9840 Batch Loss:     0.000857 [Torso :     0.000604, Hand :     0.001210, Face :     0.000103]Tokens per Sec:  1487999, Lr: 0.000343\n","2020-11-30 20:38:34,607 - __main__ - INFO - Epoch  32 Step:     9880 Batch Loss:     0.000920 [Torso :     0.000685, Hand :     0.001268, Face :     0.000119]Tokens per Sec:  1420791, Lr: 0.000343\n","2020-11-30 20:38:40,819 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:39:54,848 - __main__ - INFO - Validation result at epoch  32, step     9900: Val DTW Score: 195.45, loss:   4.0299,  duration: 74.0273s\n","2020-11-30 20:40:01,791 - __main__ - INFO - Epoch  32 Step:     9920 Batch Loss:     0.000916 [Torso :     0.000553, Hand :     0.001372, Face :     0.000090]Tokens per Sec:  1423953, Lr: 0.000240\n","2020-11-30 20:40:16,243 - __main__ - INFO - Epoch  32 Step:     9960 Batch Loss:     0.000685 [Torso :     0.000485, Hand :     0.000967, Face :     0.000073]Tokens per Sec:  1334726, Lr: 0.000240\n","2020-11-30 20:40:29,461 - __main__ - INFO - Epoch  32 Step:    10000 Batch Loss:     0.000821 [Torso :     0.000533, Hand :     0.001199, Face :     0.000078]Tokens per Sec:  1426639, Lr: 0.000240\n","2020-11-30 20:40:42,375 - __main__ - INFO - Epoch  32 Step:    10040 Batch Loss:     0.000625 [Torso :     0.000492, Hand :     0.000842, Face :     0.000076]Tokens per Sec:  1436372, Lr: 0.000240\n","2020-11-30 20:40:56,590 - __main__ - INFO - Epoch  32 Step:    10080 Batch Loss:     0.000662 [Torso :     0.000497, Hand :     0.000911, Face :     0.000074]Tokens per Sec:  1392206, Lr: 0.000240\n","2020-11-30 20:41:09,983 - __main__ - INFO - Epoch  32 Step:    10120 Batch Loss:     0.000612 [Torso :     0.000462, Hand :     0.000839, Face :     0.000080]Tokens per Sec:  1420749, Lr: 0.000240\n","2020-11-30 20:41:18,168 - __main__ - INFO - Epoch  32: total training loss 0.25335 [torso: 0.17940, hand: 0.35739, face: 0.02899\n","2020-11-30 20:41:18,169 - __main__ - INFO - Epoch  32: disc loss [real: 56.40369, fake: 32.09592], generator [total: 25.54271, adv: 0.20727]\n","2020-11-30 20:41:23,115 - __main__ - INFO - Epoch  33 Step:    10160 Batch Loss:     0.001060 [Torso :     0.000688, Hand :     0.001545, Face :     0.000119]Tokens per Sec:  1444301, Lr: 0.000240\n","2020-11-30 20:41:36,548 - __main__ - INFO - Epoch  33 Step:    10200 Batch Loss:     0.000910 [Torso :     0.000639, Hand :     0.001294, Face :     0.000073]Tokens per Sec:  1430754, Lr: 0.000240\n","2020-11-30 20:41:36,550 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:42:50,203 - __main__ - INFO - Validation result at epoch  33, step    10200: Val DTW Score: 204.95, loss:   3.9399,  duration: 73.6520s\n","2020-11-30 20:43:04,333 - __main__ - INFO - Epoch  33 Step:    10240 Batch Loss:     0.000796 [Torso :     0.000571, Hand :     0.001118, Face :     0.000083]Tokens per Sec:  1329975, Lr: 0.000240\n","2020-11-30 20:43:17,858 - __main__ - INFO - Epoch  33 Step:    10280 Batch Loss:     0.000852 [Torso :     0.000574, Hand :     0.001223, Face :     0.000106]Tokens per Sec:  1403962, Lr: 0.000240\n","2020-11-30 20:43:30,895 - __main__ - INFO - Epoch  33 Step:    10320 Batch Loss:     0.000885 [Torso :     0.000695, Hand :     0.001187, Face :     0.000132]Tokens per Sec:  1425148, Lr: 0.000240\n","2020-11-30 20:43:44,575 - __main__ - INFO - Epoch  33 Step:    10360 Batch Loss:     0.000768 [Torso :     0.000522, Hand :     0.001101, Face :     0.000088]Tokens per Sec:  1429302, Lr: 0.000240\n","2020-11-30 20:43:57,925 - __main__ - INFO - Epoch  33 Step:    10400 Batch Loss:     0.000712 [Torso :     0.000462, Hand :     0.001037, Face :     0.000092]Tokens per Sec:  1421826, Lr: 0.000240\n","2020-11-30 20:44:12,208 - __main__ - INFO - Epoch  33 Step:    10440 Batch Loss:     0.000990 [Torso :     0.000631, Hand :     0.001456, Face :     0.000097]Tokens per Sec:  1371027, Lr: 0.000240\n","2020-11-30 20:44:19,150 - __main__ - INFO - Epoch  33: total training loss 0.25079 [torso: 0.17619, hand: 0.35483, face: 0.02898\n","2020-11-30 20:44:19,152 - __main__ - INFO - Epoch  33: disc loss [real: 56.28671, fake: 36.21815], generator [total: 25.29333, adv: 0.21449]\n","2020-11-30 20:44:25,010 - __main__ - INFO - Epoch  34 Step:    10480 Batch Loss:     0.000894 [Torso :     0.000653, Hand :     0.001249, Face :     0.000087]Tokens per Sec:  1470828, Lr: 0.000240\n","2020-11-30 20:44:32,196 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:45:44,545 - __main__ - INFO - Validation result at epoch  34, step    10500: Val DTW Score: 182.24, loss:   3.1227,  duration: 72.3486s\n","2020-11-30 20:45:52,904 - __main__ - INFO - Epoch  34 Step:    10520 Batch Loss:     0.000634 [Torso :     0.000464, Hand :     0.000878, Face :     0.000099]Tokens per Sec:  1331081, Lr: 0.000240\n","2020-11-30 20:46:06,204 - __main__ - INFO - Epoch  34 Step:    10560 Batch Loss:     0.000975 [Torso :     0.000653, Hand :     0.001407, Face :     0.000100]Tokens per Sec:  1409804, Lr: 0.000240\n","2020-11-30 20:46:19,386 - __main__ - INFO - Epoch  34 Step:    10600 Batch Loss:     0.000784 [Torso :     0.000597, Hand :     0.001073, Face :     0.000094]Tokens per Sec:  1439400, Lr: 0.000240\n","2020-11-30 20:46:32,580 - __main__ - INFO - Epoch  34 Step:    10640 Batch Loss:     0.000625 [Torso :     0.000463, Hand :     0.000866, Face :     0.000071]Tokens per Sec:  1417567, Lr: 0.000240\n","2020-11-30 20:46:46,824 - __main__ - INFO - Epoch  34 Step:    10680 Batch Loss:     0.000601 [Torso :     0.000402, Hand :     0.000867, Face :     0.000073]Tokens per Sec:  1379634, Lr: 0.000240\n","2020-11-30 20:46:58,939 - __main__ - INFO - Epoch  34 Step:    10720 Batch Loss:     0.000955 [Torso :     0.000683, Hand :     0.001344, Face :     0.000094]Tokens per Sec:  1467419, Lr: 0.000240\n","2020-11-30 20:47:12,146 - __main__ - INFO - Epoch  34 Step:    10760 Batch Loss:     0.000851 [Torso :     0.000596, Hand :     0.001203, Face :     0.000114]Tokens per Sec:  1426193, Lr: 0.000240\n","2020-11-30 20:47:17,736 - __main__ - INFO - Epoch  34: total training loss 0.25352 [torso: 0.17726, hand: 0.35950, face: 0.02860\n","2020-11-30 20:47:17,737 - __main__ - INFO - Epoch  34: disc loss [real: 61.52726, fake: 39.28705], generator [total: 25.55904, adv: 0.20751]\n","2020-11-30 20:47:24,809 - __main__ - INFO - Epoch  35 Step:    10800 Batch Loss:     0.000670 [Torso :     0.000440, Hand :     0.000974, Face :     0.000069]Tokens per Sec:  1449614, Lr: 0.000240\n","2020-11-30 20:47:24,810 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:48:36,843 - __main__ - INFO - Validation result at epoch  35, step    10800: Val DTW Score: 191.78, loss:   4.3097,  duration: 72.0316s\n","2020-11-30 20:48:50,257 - __main__ - INFO - Epoch  35 Step:    10840 Batch Loss:     0.000992 [Torso :     0.000649, Hand :     0.001449, Face :     0.000084]Tokens per Sec:  1377380, Lr: 0.000240\n","2020-11-30 20:49:04,334 - __main__ - INFO - Epoch  35 Step:    10880 Batch Loss:     0.000658 [Torso :     0.000501, Hand :     0.000896, Face :     0.000093]Tokens per Sec:  1382934, Lr: 0.000240\n","2020-11-30 20:49:17,376 - __main__ - INFO - Epoch  35 Step:    10920 Batch Loss:     0.000860 [Torso :     0.000551, Hand :     0.001264, Face :     0.000082]Tokens per Sec:  1421633, Lr: 0.000240\n","2020-11-30 20:49:31,798 - __main__ - INFO - Epoch  35 Step:    10960 Batch Loss:     0.000695 [Torso :     0.000485, Hand :     0.000986, Face :     0.000081]Tokens per Sec:  1359522, Lr: 0.000240\n","2020-11-30 20:49:45,608 - __main__ - INFO - Epoch  35 Step:    11000 Batch Loss:     0.000586 [Torso :     0.000416, Hand :     0.000822, Face :     0.000084]Tokens per Sec:  1387803, Lr: 0.000240\n","2020-11-30 20:49:59,439 - __main__ - INFO - Epoch  35 Step:    11040 Batch Loss:     0.000768 [Torso :     0.000468, Hand :     0.001146, Face :     0.000077]Tokens per Sec:  1410328, Lr: 0.000240\n","2020-11-30 20:50:13,430 - __main__ - INFO - Epoch  35 Step:    11080 Batch Loss:     0.000799 [Torso :     0.000579, Hand :     0.001117, Face :     0.000095]Tokens per Sec:  1400777, Lr: 0.000240\n","2020-11-30 20:50:18,049 - __main__ - INFO - Epoch  35: total training loss 0.26002 [torso: 0.18090, hand: 0.36966, face: 0.02829\n","2020-11-30 20:50:18,050 - __main__ - INFO - Epoch  35: disc loss [real: 55.44582, fake: 35.96721], generator [total: 26.22189, adv: 0.22004]\n","2020-11-30 20:50:19,703 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:51:32,228 - __main__ - INFO - Validation result at epoch  36, step    11100: Val DTW Score: 174.69, loss:   3.7475,  duration: 72.5232s\n","2020-11-30 20:51:39,182 - __main__ - INFO - Epoch  36 Step:    11120 Batch Loss:     0.000986 [Torso :     0.000683, Hand :     0.001403, Face :     0.000113]Tokens per Sec:  1377139, Lr: 0.000240\n","2020-11-30 20:51:54,379 - __main__ - INFO - Epoch  36 Step:    11160 Batch Loss:     0.000857 [Torso :     0.000652, Hand :     0.001177, Face :     0.000078]Tokens per Sec:  1298759, Lr: 0.000240\n","2020-11-30 20:52:07,989 - __main__ - INFO - Epoch  36 Step:    11200 Batch Loss:     0.000831 [Torso :     0.000589, Hand :     0.001171, Face :     0.000098]Tokens per Sec:  1367427, Lr: 0.000240\n","2020-11-30 20:52:21,645 - __main__ - INFO - Epoch  36 Step:    11240 Batch Loss:     0.000804 [Torso :     0.000495, Hand :     0.001198, Face :     0.000077]Tokens per Sec:  1396133, Lr: 0.000240\n","2020-11-30 20:52:34,412 - __main__ - INFO - Epoch  36 Step:    11280 Batch Loss:     0.000835 [Torso :     0.000596, Hand :     0.001176, Face :     0.000085]Tokens per Sec:  1442037, Lr: 0.000240\n","2020-11-30 20:52:47,736 - __main__ - INFO - Epoch  36 Step:    11320 Batch Loss:     0.000834 [Torso :     0.000637, Hand :     0.001140, Face :     0.000096]Tokens per Sec:  1392803, Lr: 0.000240\n","2020-11-30 20:53:01,468 - __main__ - INFO - Epoch  36 Step:    11360 Batch Loss:     0.000845 [Torso :     0.000561, Hand :     0.001223, Face :     0.000096]Tokens per Sec:  1384581, Lr: 0.000240\n","2020-11-30 20:53:16,600 - __main__ - INFO - Epoch  36 Step:    11400 Batch Loss:     0.000777 [Torso :     0.000529, Hand :     0.001114, Face :     0.000085]Tokens per Sec:  1316542, Lr: 0.000240\n","2020-11-30 20:53:16,601 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:54:32,081 - __main__ - INFO - Validation result at epoch  36, step    11400: Val DTW Score: 213.75, loss:   3.6265,  duration: 75.4790s\n","2020-11-30 20:54:36,253 - __main__ - INFO - Epoch  36: total training loss 0.26026 [torso: 0.17953, hand: 0.37115, face: 0.02879\n","2020-11-30 20:54:36,254 - __main__ - INFO - Epoch  36: disc loss [real: 55.62493, fake: 34.63132], generator [total: 26.23649, adv: 0.21015]\n","2020-11-30 20:54:46,363 - __main__ - INFO - Epoch  37 Step:    11440 Batch Loss:     0.000824 [Torso :     0.000575, Hand :     0.001176, Face :     0.000065]Tokens per Sec:  1320720, Lr: 0.000240\n","2020-11-30 20:55:00,173 - __main__ - INFO - Epoch  37 Step:    11480 Batch Loss:     0.000641 [Torso :     0.000490, Hand :     0.000873, Face :     0.000084]Tokens per Sec:  1366616, Lr: 0.000240\n","2020-11-30 20:55:14,327 - __main__ - INFO - Epoch  37 Step:    11520 Batch Loss:     0.000704 [Torso :     0.000464, Hand :     0.001019, Face :     0.000088]Tokens per Sec:  1386922, Lr: 0.000240\n","2020-11-30 20:55:27,881 - __main__ - INFO - Epoch  37 Step:    11560 Batch Loss:     0.000797 [Torso :     0.000563, Hand :     0.001127, Face :     0.000087]Tokens per Sec:  1407826, Lr: 0.000240\n","2020-11-30 20:55:41,649 - __main__ - INFO - Epoch  37 Step:    11600 Batch Loss:     0.000762 [Torso :     0.000506, Hand :     0.001103, Face :     0.000081]Tokens per Sec:  1394897, Lr: 0.000240\n","2020-11-30 20:55:54,260 - __main__ - INFO - Epoch  37 Step:    11640 Batch Loss:     0.000613 [Torso :     0.000432, Hand :     0.000865, Face :     0.000079]Tokens per Sec:  1454326, Lr: 0.000240\n","2020-11-30 20:56:07,685 - __main__ - INFO - Epoch  37 Step:    11680 Batch Loss:     0.000875 [Torso :     0.000556, Hand :     0.001286, Face :     0.000100]Tokens per Sec:  1419612, Lr: 0.000240\n","2020-11-30 20:56:14,559 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 20:57:29,884 - __main__ - INFO - Validation result at epoch  37, step    11700: Val DTW Score: 204.52, loss:   3.4006,  duration: 75.3245s\n","2020-11-30 20:57:36,978 - __main__ - INFO - Epoch  37 Step:    11720 Batch Loss:     0.000975 [Torso :     0.000571, Hand :     0.001474, Face :     0.000102]Tokens per Sec:  1367395, Lr: 0.000240\n","2020-11-30 20:57:40,404 - __main__ - INFO - Epoch  37: total training loss 0.25886 [torso: 0.17537, hand: 0.37176, face: 0.02835\n","2020-11-30 20:57:40,405 - __main__ - INFO - Epoch  37: disc loss [real: 53.78949, fake: 31.96599], generator [total: 26.10724, adv: 0.22089]\n","2020-11-30 20:57:51,578 - __main__ - INFO - Epoch  38 Step:    11760 Batch Loss:     0.000932 [Torso :     0.000595, Hand :     0.001367, Face :     0.000104]Tokens per Sec:  1328233, Lr: 0.000240\n","2020-11-30 20:58:04,858 - __main__ - INFO - Epoch  38 Step:    11800 Batch Loss:     0.000792 [Torso :     0.000560, Hand :     0.001118, Face :     0.000084]Tokens per Sec:  1435848, Lr: 0.000240\n","2020-11-30 20:58:18,754 - __main__ - INFO - Epoch  38 Step:    11840 Batch Loss:     0.000798 [Torso :     0.000581, Hand :     0.001114, Face :     0.000087]Tokens per Sec:  1421432, Lr: 0.000240\n","2020-11-30 20:58:31,821 - __main__ - INFO - Epoch  38 Step:    11880 Batch Loss:     0.000694 [Torso :     0.000465, Hand :     0.001000, Face :     0.000084]Tokens per Sec:  1444367, Lr: 0.000240\n","2020-11-30 20:58:45,814 - __main__ - INFO - Epoch  38 Step:    11920 Batch Loss:     0.000757 [Torso :     0.000532, Hand :     0.001065, Face :     0.000118]Tokens per Sec:  1406655, Lr: 0.000240\n","2020-11-30 20:58:58,489 - __main__ - INFO - Epoch  38 Step:    11960 Batch Loss:     0.000875 [Torso :     0.000632, Hand :     0.001225, Face :     0.000101]Tokens per Sec:  1437333, Lr: 0.000240\n","2020-11-30 20:59:11,583 - __main__ - INFO - Epoch  38 Step:    12000 Batch Loss:     0.000784 [Torso :     0.000515, Hand :     0.001142, Face :     0.000070]Tokens per Sec:  1446094, Lr: 0.000240\n","2020-11-30 20:59:11,584 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 21:00:22,832 - __main__ - INFO - Validation result at epoch  38, step    12000: Val DTW Score: 187.47, loss:   3.5968,  duration: 71.2456s\n","2020-11-30 21:00:37,281 - __main__ - INFO - Epoch  38 Step:    12040 Batch Loss:     0.000636 [Torso :     0.000381, Hand :     0.000953, Face :     0.000067]Tokens per Sec:  1330354, Lr: 0.000240\n","2020-11-30 21:00:39,108 - __main__ - INFO - Epoch  38: total training loss 0.25973 [torso: 0.17567, hand: 0.37334, face: 0.02799\n","2020-11-30 21:00:39,109 - __main__ - INFO - Epoch  38: disc loss [real: 55.68345, fake: 40.85130], generator [total: 26.18490, adv: 0.21143]\n","2020-11-30 21:00:50,637 - __main__ - INFO - Epoch  39 Step:    12080 Batch Loss:     0.000715 [Torso :     0.000459, Hand :     0.001047, Face :     0.000078]Tokens per Sec:  1430483, Lr: 0.000240\n","2020-11-30 21:01:03,242 - __main__ - INFO - Epoch  39 Step:    12120 Batch Loss:     0.001023 [Torso :     0.000793, Hand :     0.001388, Face :     0.000114]Tokens per Sec:  1457572, Lr: 0.000240\n","2020-11-30 21:01:16,760 - __main__ - INFO - Epoch  39 Step:    12160 Batch Loss:     0.000931 [Torso :     0.000676, Hand :     0.001301, Face :     0.000100]Tokens per Sec:  1424611, Lr: 0.000240\n","2020-11-30 21:01:30,287 - __main__ - INFO - Epoch  39 Step:    12200 Batch Loss:     0.000894 [Torso :     0.000564, Hand :     0.001320, Face :     0.000084]Tokens per Sec:  1425513, Lr: 0.000240\n","2020-11-30 21:01:43,617 - __main__ - INFO - Epoch  39 Step:    12240 Batch Loss:     0.000780 [Torso :     0.000528, Hand :     0.001123, Face :     0.000078]Tokens per Sec:  1423353, Lr: 0.000240\n","2020-11-30 21:01:56,754 - __main__ - INFO - Epoch  39 Step:    12280 Batch Loss:     0.000693 [Torso :     0.000501, Hand :     0.000967, Face :     0.000089]Tokens per Sec:  1440130, Lr: 0.000240\n","2020-11-30 21:02:03,365 - __main__ - INFO - Starting validation calculation.\n","2020-11-30 21:03:14,838 - __main__ - INFO - Validation result at epoch  39, step    12300: Val DTW Score: 188.43, loss:   4.0809,  duration: 71.4717s\n","2020-11-30 21:03:14,839 - __main__ - INFO - Training ended since minimum lr 0.000200 was reached.\n","2020-11-30 21:03:14,844 - __main__ - INFO - Best validation result at step      300: 161.82 dtw.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"I_U0SaRNJoq_"},"source":[""],"execution_count":null,"outputs":[]}]}